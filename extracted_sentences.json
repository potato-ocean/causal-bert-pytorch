{
    "deep": [
        "we demonstrate the application of minimum probability flow learning to parameter estimation in ising models , deep belief networks , multivariate gaussian distributions and a continuous model with a highly general energy function defined as a power series .",
        "recursive neural networks are non - linear adaptive models that are able to learn deep structured information .",
        "we demonstrate the application of minimum probability flow learning to parameter estimation in ising models , deep belief networks , multivariate gaussian distributions and a continuous model with a highly general energy function defined as a power series .",
        "recursive neural networks are non - linear adaptive models that are able to learn deep structured information .",
        "in this paper , we developed an adaptive beamforming based on least mean squared error algorithm and null deepening to combat co - channel interference ( cci ) for the space - time coded ofdm ( stc - ofdm ) system .",
        "the problem of deciding whether csp instances admit solutions has been deeply studied in the literature , and several structural tractability results have been derived so far .",
        "recently we were able to significantly improve this result , using graphics cards to greatly speed up training of simple but deep mlps , which achieved 0 .",
        "in this talk i will present my project of extending traditional nlp techniques to radicals and strokes , aiming to obtain a deeper understanding of the way ideographic languages model the world .",
        "the deep boltzmann machine ( dbm ) has been an important development in the quest for powerful \" deep \" probabilistic models .",
        "we demonstrate that this regularization can be easily combined with standard stochastic maximum likelihood to yield an effective training strategy for the simultaneous training of all layers of the deep boltzmann machine .",
        "this approach has many advantages and has led to a deep and beautiful theory .",
        "this task essentially requires deep understanding of clauses structures .",
        "an efficient way to learn deep density models that have many layers of latent variables is to learn one layer at a time using a model that has only one layer of latent variables .",
        "in this paper , we present a greedy layer - wise learning algorithm for deep mixtures of factor analysers ( dmfas ) .",
        "combining deep belief nets with the lambertian reflectance assumption , our model can learn good priors over the albedo from 2d images .",
        "the properties of this graph separation as well as of local independence are investigated in detail within a framework of asymmetric ( semi ) graphoids allowing a deeper insight into what information can be read off these graphs .",
        "it has previously been hypothesized , and supported with some experimental evidence , that deeper representations , when well trained , tend to do a better job at disentangling the underlying factors of variation .",
        "these advances have been motivated by and related to the optimization issues surrounding deep learning .",
        "recent studies have shown that deep neural networks ( dnns ) perform significantly better than shallow networks and gaussian mixture models ( gmms ) on large vocabulary speech recognition tasks .",
        "a key characteristic of work on deep learning and neural networks in general is that it relies on representations of the input that support generalization , robust inference , domain adaptation and other desirable functionalities .",
        "in its time - unfolded form , the network can be seen as a very deep multi - layer network in which the weights are shared between the hidden layers .",
        "the depth allows the system to exhibit all the power of deep network while substantially reducing the number of trainable parameters .",
        "the main advantage of a deep semantic analyse is too represent meaning by logical formulae that can be easily used e .",
        "a modification of the algorithm takes advantage of an iterative deepening scheme to trade off inference time and the quality of the computed strategy .",
        "our project aims for a deeper understanding of hardness of sat problems that arise in practice .",
        "deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations , with higher levels representing more abstract concepts .",
        "although the study of deep learning has already led to impressive theoretical results , learning algorithms and breakthrough experiments , several challenges lie ahead .",
        "this paper proposes to examine some of these challenges , centering on the questions of scaling deep learning algorithms to much larger models and datasets , reducing optimization difficulties due to ill - conditioning or local minima , designing more efficient and powerful inference and sampling procedures , and learning to disentangle the factors of variation underlying the observed data .",
        "stochastic neurons can be useful for a number of reasons in deep learning models , but in many cases they pose a challenging problem : how to estimate the gradient of a loss function with respect to the input of such stochastic neurons , i .",
        "we demonstrate that there is significant redundancy in the parameterization of several deep learning models .",
        "as a consequence , one can define deep architectures similar to deep boltzmann machines in that units are stochastic , that the model can learn to generate a distribution similar to its training distribution , that it can easily handle missing inputs , but without the troubling problem of intractable partition function and intractable inference as stumbling blocks for both training and using these models .",
        "the sp theory promises deeper insights and better solutions in several areas of application , including natural language processing , autonomous robots , computer vision , intelligent databases , structuring of documents , software engineering , information compression , the economical transmission of data , big data , the semantic web , medical diagnosis , the detection of computer viruses , data fusion , and new kinds of computer .",
        "experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these \" deep and wide multiscale recursive \" ( dawmr ) networks lead to new levels of image labeling performance .",
        "moreover , unlike the original nade , our training procedure scales to deep models .",
        "empirically , ensembles of deep nade models obtain state of the art density estimation performance .",
        "we give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by hinton and others .",
        "we introduce a multilayer deep generative model capable of learning hierarchies of sparse distributed representations from data .",
        "besides describing effective model and features , we will discuss about the lessons we learned while using deep learning in this competition .",
        "however , like many deep models , there is little guidance on how the architecture of the model should be selected .",
        "we find that for a given parameter budget , deeper models are preferred over shallow ones , and models with more parameters are preferred to those with fewer .",
        "this suggests that , computational efficiency considerations aside , parameter sharing within deep networks may not be so beneficial as previously supposed .",
        "for any deep computational processing of language we need evidences , and one such set of evidences is corpus .",
        "in this this work , we extend the mixture of experts to a stacked model , the deep mixture of experts , with multiple sets of gating and experts .",
        "on a randomly translated version of the mnist dataset , we find that the deep mixture of experts automatically learns to develop location - dependent ( \" where \" ) experts at the first layer , and class - specific ( \" what \" ) experts at the second layer .",
        "the deep nin is thus implemented as stacking of multiple sliding micro neural networks .",
        "in this paper , we propose an extremely simple deep model for the unsupervised nonlinear dimensionality reduction - - deep distributed random samplings , which performs like a stack of unsupervised bootstrap aggregating .",
        "experimental results on nonlinear dimensionality reduction show that the proposed method can learn abstract representations on both large - scale and small - scale problems , and meanwhile is much faster than deep neural networks on large - scale problems .",
        "scalability properties of deep neural networks raise key research questions , particularly as the problems considered become larger and more challenging .",
        ", where the nodes of a deep network are augmented by a set of gating units that determine when a node should be calculated .",
        "experimental results using the mnist and svhn data sets with a fully - connected deep neural network demonstrate the performance robustness of the proposed scheme with respect to the error introduced by the conditional computation process .",
        "deep learning embeddings have been successfully used for many natural language processing ( nlp ) problems .",
        "when deep learning is applied to visual object recognition , data augmentation is often used to generate additional training data without extra labeling cost .",
        "although deep learning is not really necessary for generating good word embeddings , we show that it can provide an easy way to adapt embeddings to specific tasks .",
        "there are two main approaches to the distributed representation of words : low - dimensional deep learning embeddings and high - dimensional distributional models , in which each dimension corresponds to a context word .",
        "in this paper , we combine these two approaches by learning embeddings based on distributional - model vectors - as opposed to one - hot vectors as is standardly done in deep learning .",
        "we present the first deep learning model to successfully learn control policies directly from high - dimensional sensory input using reinforcement learning .",
        "in this paper , we propose a new unsupervised feature learning framework , namely deep sparse coding ( deepsc ) , that extends sparse coding to a multi - layer architecture for visual object recognition tasks .",
        "combining the feature representations from multiple layers , deepsc achieves the state - of - the - art performance on multiple object recognition tasks .",
        "this paper explores the complexity of deep feed forward networks with linear presynaptic couplings and rectified linear activations .",
        "this is a contribution to the growing body of work contrasting the representational power of deep and shallow network architectures .",
        "in particular , we offer a framework for comparing deep and shallow models that belong to the family of piece - wise linear functions based on computational geometry .",
        "we look at a deep ( two hidden layers ) rectifier multilayer perceptron ( mlp ) with linear outputs units and compare it with a single layer version of the model .",
        "there are a number of methods used for this task such as deep belief networks ( dbns ) and discrete fourier transforms ( dfts ) .",
        "we applied these two methods to a deep belief network trained for a face recognition task .",
        "deep belief networks which are hierarchical generative models are effective tools for feature representation and extraction .",
        "the system uses a deep learning architecture ( dla ) composed of two input / output channels formed from stacked restricted boltzmann machines ( rbm ) and an associative memory network that combines the two channels .",
        "currently , deep neural networks are the state of the art on problems such as speech recognition and computer vision .",
        "in this extended abstract , we show that shallow feed - forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models .",
        "moreover , the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model .",
        "we evaluate our method on timit phoneme recognition task and are able to train shallow fully - connected nets that perform similarly to complex , well - engineered , deep convolutional architectures .",
        "our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed - forward nets than those currently available .",
        "deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks .",
        "we show through experiments that for low - dimensional graphs it is possible to learn convolutional layers with $ o ( 1 ) $ parameters , resulting in efficient deep architectures .",
        "though deep convolutional networks have proven to be a competitive approach for image classification , a question remains : have these models have solved the dataset bias problem ?",
        "in general , training or fine - tuning a state - of - the - art deep model on a new domain requires a significant amount of data , which for many applications is simply not available .",
        "in this paper , we pose the following question : is a single image dataset , much larger than previously explored for adaptation , comprehensive enough to learn general deep models that may be effectively applied to new image domains ?",
        "in other words , are deep cnns trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be ?",
        "we show that a generic supervised deep cnn model trained on a large dataset reduces , but does not remove , dataset bias .",
        "furthermore , we propose several methods for adaptation with deep models that are able to operate with little ( one example per category ) or no labeled domain specific data .",
        "our experiments show that adaptation of deep models on benchmark visual domain adaptation data",
        "we investigate the use of deep neural networks for the novel task of class generic object detection .",
        "the main contribution of this paper is showing , for the first time , that a specific variation of deep learning is able to outperform all existing traditional architectures on this task .",
        "we propose two novel zero - shot learning methods for semantic utterance classification ( suc ) using deep learning .",
        "both approaches rely on learning deep semantic embeddings from a large amount of query click log data obtained from a search engine .",
        "a rooted tree exhibits an ultrametric property ; that is , for any three leaves of the tree it must be that one pair has a deeper most recent common ancestor than the other pairs , or that all three have the same most recent common ancestor .",
        "we marry ideas from deep neural networks and approximate bayesian inference to derive a generalised class of deep , directed generative models , endowed with a new algorithm for scalable inference and learning .",
        ", the automatic derivation of meaning representation such as an instantiated predicate - argument structure for a sentence , plays a critical role in deep processing of natural language .",
        "meanwhile , in recent years , deep neural networks ( dnns ) have shown state - of - the - art performance on various asr tasks .",
        "pdnn is a lightweight deep learning toolkit developed under the theano environment .",
        "applying our approach to training sigmoid belief networks and deep autoregressive networks , we show that it outperforms the wake - sleep algorithm on mnist and achieves state - of - the - art results on the reuters rcv1 document dataset .",
        "we then extend the algorithm to deep models and demonstrate the relevance of ordered representations to a number of applications .",
        "we study the complexity of functions computable by deep feedforward neural networks with piece - wise linear activations in terms of the number of regions of linearity that they have .",
        "deep networks are able to sequentially map portions of each layer ' s input space to the same output .",
        "in this way , deep models compute functions with a compositional structure that is able to re - use pieces of computation exponentially often in terms of their depth .",
        "in this paper , we propose a simple but effective coupled neural network , called deeply coupled autoencoder networks ( dcan ) , which seeks to build two deep neural networks , coupled with each other in every corresponding layers .",
        "in dcan , each deep structure is developed via stacking multiple discriminative coupled auto - encoders , a denoising auto - encoder trained with maximum margin criterion consisting of intra - class compactness and inter - class penalty .",
        "to achieve acceptable performance for ai tasks , one can either use sophisticated feature extraction methods as the first layer in a two - layered supervised learning model , or learn the features directly using a deep ( multi - layered ) model .",
        "we propose exact and inexact learning strategies for wide learning and show that wide learning with single layer outperforms single layer as well as deep architectures of finite width for some benchmark datasets .",
        "here we present a new supervised generative stochastic network ( gsn ) based method to predict local secondary structure with deep hierarchical representations .",
        "gsn is a recently proposed deep learning technique ( bengio & amp ; thibodeau - laufer , 2013 ) to globally train deep generative model .",
        "such personal data is used to enhance the quality of service via personalization of content and to maximize revenues via better targeting of advertisements and deeper engagement of users on sites .",
        "we present a method for training a deep neural network containing sinusoidal activation functions to fit to time - series data .",
        "we show how deeper layers can be utilized to model the observed sequence using a sparser set of sinusoid units , and how non - uniform regularization can improve generalization by promoting the shifting of weight toward simpler units .",
        "here we argue , based on results from statistical physics , random matrix theory , and neural network theory , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep neural network training , and provide preliminary numerical evidence for its superior performance .",
        "focusing on a large set of web portals owned and managed by a private communications company , we propose methods by which these sites ' clickstream data can be used to provide a deep understanding of their visitors , as well as their interests and preferences .",
        "our results underscore the value of the proposed measures to offer a deeper insight into models ' behavior and their impact on real applications , which benefit both data mining researchers and practitioners .",
        "we also show that types of noise other than dropout improve performance in a deep network through sparsifying , decorrelating , and spreading information across representations .",
        "we propose several simple approaches to training deep neural networks on data with noisy labels .",
        "the parameters of this noise layer can be estimated as part of the training process and involve simple modifications to current training infrastructures for deep networks .",
        "we introduce a deep scattering network , which computes invariants with iterated contractions adapted to training data .",
        "it defines a deep convolution network model , whose contraction properties can be analyzed mathematically .",
        "here we argue , based on results from statistical physics , random matrix theory , neural network theory , and empirical evidence , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep or recurrent neural network training , and provide numerical evidence for its superior optimization performance .",
        "these random views are then used to train a deep convolutional neural network ( cnn ) classifier .",
        "deep convolutional neural networks have recently proven extremely competitive in challenging image recognition tasks .",
        "this paper proposes the epitomic convolution as a new building block for deep neural networks .",
        "an epitomic convolution layer replaces a pair of consecutive convolution and max - pooling layers found in standard deep convolutional neural networks .",
        "training deep directed graphical models with many hidden variables and performing inference remains a major challenge .",
        "helmholtz machines and deep belief networks are such models , and the wake - sleep algorithm has been proposed to train them .",
        "we propose an heterogeneous multi - task learning framework for human pose estimation from monocular image with deep convolutional neural network .",
        "in particular , we simultaneously learn a pose - joint regressor and a sliding - window body - part detector in a deep network architecture .",
        "we show that deep generative models and approximate bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements , making generative approaches highly competitive for semi - supervised learning .",
        "it uses a deep layered architecture , parts of which are borrowed from recent work on neural network learning , and parts of which incorporate computations that are specific to image deconvolution .",
        "moreover , we show that advanced neural networks and deep learning methods can be compressed as privileged information .",
        "in recent years the performance of deep learning algorithms has been demonstrated in a variety of application domains .",
        "the goal of this paper is to enrich deep learning to be able to predict a set of random variables while taking into account their dependencies .",
        "so does our deep attention selective network ( dasnet ) architecture .",
        "dropout training , originally designed for deep neural networks , has been successful on high - dimensional single - layer natural language tasks .",
        "caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state - of - the - art deep learning algorithms and a collection of reference models .",
        "the framework is a bsd - licensed c + + library with python and matlab bindings for training and deploying general - purpose convolutional neural networks and other deep models efficiently on commodity architectures .",
        "we explore combining the benefits of convolutional architectures and autoencoders for learning deep representations in an unsupervised manner .",
        "learning is computationally efficient and we show that our method can be used to train shallow and deep convolutional autoencoders whose representations can be used to achieve classification rates on the mnist , cifar - 10 and norb datasets that are competitive with the state of the art .",
        "this approach enables us to send the detected ambiguous records to another discrimination method for a deeper investigation , thus increasing the accuracy by lowering the error rate .",
        "deep neural networks ( dnns ) are powerful models that have achieved excellent performance on difficult learning tasks .",
        "our method uses a multilayered long short - term memory ( lstm ) to map the input sequence to a vector of a fixed dimensionality , and then another deep lstm to decode the target sequence from the vector .",
        "deep learning has made significant breakthroughs in various fields of artificial intelligence .",
        "advantages of deep learning include the ability to capture highly complicated features , weak involvement of human engineering , etc .",
        "however , it is still virtually impossible to use deep learning to analyze programs since deep architectures cannot be trained effectively with pure back propagation .",
        "in this pioneering paper , we propose the \" coding criterion \" to build program vector representations , which are the premise of deep learning for program analysis .",
        "our representation learning approach directly makes deep learning a reality in this new field .",
        "to evaluate whether deep learning is beneficial for program analysis , we feed the representations to deep neural networks , and achieve higher accuracy in the program classification task than \" shallow \" methods , such as logistic regression and the support vector machine .",
        "this result confirms the feasibility of deep learning to analyze programs .",
        "we believe deep learning will become an outstanding technique for program analysis in the near future .",
        "another popular approach to model the multimodal data is through deep neural networks , such as the deep boltzmann machine ( dbm ) .",
        "second , we propose a deep extension of our model and provide an efficient way of training the deep model .",
        "unconstrained video recognition and deep convolution network ( dcn ) are two active topics in computer vision recently .",
        "the same lack - of - training - sample problem limits the usage of deep models on a wide range of computer vision problems where obtaining training data are difficult .",
        "deep neural networks have made significant breakthroughs in many fields of artificial intelligence .",
        "to our best knowledge , this paper is the first to analyze programs with deep neural networks ; we extend the scope of deep learning to the field of programming language processing .",
        "top - performing deep architectures are trained on massive amounts of labeled data .",
        "here , we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain ( no labeled target - domain data is necessary ) .",
        "in this paper , we use deep learning algorithms to investigate a data - driven parameterization technique that is designed for the specific requirements of synthesis .",
        "existing deep convolutional neural network ( cnn ) architectures are trained as n - way classifiers to distinguish between n output classes .",
        "towards this end , we introduce hierarchical branching cnns , named as hierarchical deep cnn ( hd - cnn ) , wherein classes that can be easily distinguished are classified in the higher layer coarse category cnn , while the most difficult classifications are done on lower layer fine category cnn .",
        "we present a library that provides optimized implementations for deep learning primitives .",
        "deep learning workloads are computationally intensive , and optimizing the kernels of deep learning workloads is difficult and time - consuming .",
        "however , there is no analogous library for deep learning .",
        "without such a library , researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels , and this work must be repeated as new parallel processors emerge .",
        "to address this problem , we have created a library similar in intent to blas , with optimized routines for deep learning workloads .",
        "we present a deep layered architecture that generalizes classical convolutional neural networks ( convnets ) .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "recently proposed neural network activation functions such as rectified linear , maxout , and local winner - take - all have allowed for faster and more effective training of deep neural architectures on large and complex datasets .",
        "neural machine translation ( nmt ) has recently attracted a lot of attention due to the very high performance achieved by deep neural networks in other domains .",
        "we propose a deep learning framework for modeling complex high - dimensional densities via non - linear independent component estimation ( nice ) .",
        "we parametrize this transformation so that computing the determinant of the jacobian and inverse jacobian is trivial , yet we maintain the ability to learn complex non - linear transformations , via a composition of simple building blocks , each based on a deep neural network .",
        "we carried out experiments using the switchboard corpus , with both mel frequency cepstral coefficient features and bottleneck feature derived from a deep neural network .",
        "reductions in word error rate were obtained by using tied plda , compared with the plda mixture model , subspace gaussian mixture models , and deep neural networks .",
        "many deep neural networks trained on natural images exhibit a curious phenomenon in common : on the first layer they learn features similar to gabor filters and color blobs .",
        "in this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results .",
        "nowadays this is very popular to use deep architectures in machine learning .",
        "deep belief networks ( dbns ) are deep architectures that use stack of restricted boltzmann machines ( rbm ) to create a powerful generative model using training data .",
        "we disambiguate the input word vectors before they are fed into a compositional deep net .",
        "a series of evaluations shows the positive effect of prior disambiguation for such deep models .",
        "the method transforms it into a graph representing the deep semantic structure of a natural language phrase .",
        "compared to image representation based on low - level local descriptors , deep neural activations of convolutional neural networks ( cnns ) are richer in mid - level representation , but poorer in geometric invariance properties .",
        "to overcome these challenges in large scale in synonym extraction , we proposed ( 1 ) a new cost function to accommodate the unbalanced learning problem , and ( 2 ) a feature learning based deep neural network to model the complicated relationships in synonym pairs .",
        "we propose a multimodal deep learning framework that can transfer the knowledge obtained from a single - modal neural network to a network with a different modality .",
        "the field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images .",
        "in this paper , we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure .",
        "al , 2012 ) in a deep neural network trains a pseudo - ensemble of child subnetworks generated by randomly masking nodes in the parent network .",
        "recent work has shown deep neural networks ( dnns ) to be highly susceptible to well - designed , small perturbations at the input layer , or so - called adversarial examples .",
        "as a solution , we propose deep contractive network , a model with a new end - to - end training procedure that includes a smoothness penalty inspired by the contractive autoencoder ( cae ) .",
        "we present a state - of - the - art speech recognition system developed using end - to - end deep learning .",
        "our system , called deepspeech , outperforms previously published results on the widely studied switchboard hub5 ' 00 , achieving 16 .",
        "deepspeech also handles challenging noisy environments better than widely used , state - of - the - art commercial speech systems .",
        "since the advent of deep learning , it has been used to solve various problems using many different architectures .",
        "we thus propose a new generic architecture called the deep belief network - bidirectional long short - term memory ( dbn - blstm ) network that models sequences by keeping track of the temporal information while enabling deep representations in the data .",
        "deep convolutional neural networks ( cnn ) has become the most promising method for object recognition , repeatedly demonstrating record breaking results for image classification and object detection in recent years .",
        "however , a very deep cnn generally involves many layers with millions of parameters , making the storage of the network model to be extremely large .",
        "this prohibits the usage of deep cnns on resource limited hardware , especially cell phones or other embedded devices .",
        "in this paper , we introduce a novel deep learning framework , termed purine .",
        "in purine , a deep network is expressed as a bipartite graph ( bi - graph ) , which is composed of interconnected operators and data tensors .",
        "stacked denoising auto encoders ( daes ) are well known to learn useful deep representations , which can be used to improve supervised training by initializing a deep network .",
        "we investigate a training scheme of a deep dae , where dae layers are gradually added and keep adapting as additional layers are added .",
        "recently researchers have also started to show interest in the generative aspects of cnns in order to gain a deeper understanding of what they have learned and how to further improve them .",
        "methods of deep machine learning enable to to reuse low - level representations efficiently for generating more abstract high - level representations .",
        "originally , deep learning has been applied passively ( e .",
        "although \" flat \" connectionist methods have already been used for model - based rl , up to now , only model - free variants of rl have been equipped with methods from deep learning .",
        "we propose a variant of deep model - based rl that enables an agent to learn arbitrarily abstract hierarchical representations of its environment .",
        "while depth tends to improve network performances , it also makes gradient - based training more difficult since deeper networks tend to be more non - linear .",
        "in this paper , we extend this idea to allow the training of a student that is deeper and thinner than the teacher , using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student .",
        "this allows one to train deeper students that can generalize better or run faster , a trade - off that is controlled by the chosen student capacity .",
        "for example , on cifar - 10 , a deep student network with almost 10 .",
        "in this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge .",
        "by augmenting deep autoencoders with a supervised cost and an additional unsupervised cost , we create a semi - supervised model that can discover and explicitly represent factors of variation beyond those relevant for categorization .",
        "current state - of - the - art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting .",
        "we consider a prediction consistent if the same prediction is made given similar percepts , where the notion of similarity is between deep network features computed from the input data .",
        "on a set of deep learning benchmarks , we also demonstrate their effectiveness for single and multi - label classification .",
        "among these , the restricted boltzmann machine ( rbm ) has been the prototype for some recent advancements in the unsupervised training of deep neural networks .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "we study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints .",
        "we empirically demonstrate that in the deep learning setting , due to the existence of many local optima , allowing more exploration can lead to the improved performance .",
        "yet , it is highly correlated to the classification network and offers some in - deep review of cnn structures .",
        "we develop a deep learning method that takes multiple channels of heterogeneous data , to detect the misalignment of the lidar - video inputs .",
        "to the best of our knowledge the use of multi - modal deep convolutional neural networks for dynamic real - time lidar - video registration has not been presented .",
        "we trained a deep convolutional neural network ( cnn ) to identify occlusion edges in images and videos with both rgb - d and rgb inputs .",
        "we present results comparing our model to state - of - the - art in fine - grained categorization as well as state - of - the - art deep visual models .",
        "deep convolutional neural networks ( dcnns ) have recently shown state of the art performance in high level vision tasks , such as image classification and object detection .",
        "we overcome this poor localization property of deep networks by combining the responses at the final dcnn layer with a fully connected conditional random field ( crf ) .",
        "qualitatively , our \" deeplab \" system is able to localize segment boundaries at a level of accuracy which is beyond previous methods .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "additionally , we hope that ordering parameters may provide additional insights into optimization of deep convolutional neural networks and how the network architecture impacts performance .",
        "this paper proposes a novel framework for unsupervised audio source separation using a deep autoencoder .",
        "deep neural networks have been extremely successful at various image , speech , video recognition tasks because of their ability to model deep structures within the data .",
        "in this study , we propose a deep temporal convolutional neural network architecture for brain decoding task in order to reduce dimensionality of feature space along with improved classification performance .",
        "back - propagation has been the workhorse of recent successes of deep learning but it relies on infinitesimal effects ( partial derivatives ) in order to perform credit assignment .",
        "this could become a serious issue as one considers deeper and more non - linear functions , e .",
        "in this spirit , we explore a novel approach to credit assignment in deep networks that we call target propagation .",
        "recently , deep machine learning has shown unique abilities to address hard problems that resisted machine algorithms for long .",
        "this motivated us to explore the use of deep learning in the context of photo editing .",
        "our experiments demonstrate that our deep learning formulation applied using these descriptors successfully capture sophisticated photographic styles .",
        "the proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image .",
        "a process centric view of robust pca ( rpca ) allows its fast approximate implementation based on a special form o a deep neural network with weights shared across all layers .",
        "deep networks have inspired a renaissance in neural network use , and are becoming the default option for difficult tasks on large datasets .",
        "in this report we show that published deep network results on the mnist handwritten digit dataset can straightforwardly be replicated ( error rates below 1 % , without use of any distortions ) with shallow ' extreme learning machine ' ( elm ) networks , with a very rapid training time ( ~ 10 minutes ) .",
        "to achieve this performance , we introduce several methods for enhancing elm implementation , which individually and in combination can significantly improve performance , to the point where it is nearly indistinguishable from deep network performance .",
        "we present a method for gesture detection and localisation based on multi - scale and multi - modal deep learning .",
        "introduced the skip - gram model into the study of social network for the first time , and designed an algorithm named deepwalk for learning node embedding on a graph .",
        "we prove that the deepwalk algorithm is actually factoring a matrix m where each entry m _ { ij } is logarithm of the average probability that node i randomly walks to node j in fix steps .",
        "the sparse snnm modules are further stacked to build a sparse deep stacking network ( s - dsn ) .",
        "fortunately , recent advances in deep learning can learn unsupervised features effectively , and have yielded state of the art performance in many classification problems , such as character recognition , object recognition and document categorization .",
        "however , little attention has been paid to the potential of deep learning for unsupervised clustering problems .",
        "in this paper , we propose a deep belief network with nonparametric clustering .",
        "as an unsupervised method , our model first leverages the advantages of deep learning for feature representation and dimension reduction .",
        "lastly model parameters are refined in the deep belief network .",
        "in this paper , we present methods in deep multimodal learning for fusing speech and visual modalities for audio - visual automatic speech recognition ( av - asr ) .",
        "first , we study an approach where uni - modal deep networks are trained separately and their final hidden layers fused to obtain a joint feature space in which another deep network is built .",
        "second , we present a new deep network architecture that uses a bilinear softmax layer to account for class specific correlations between modalities .",
        "fortunately , deep learning has led to great success on feature learning recently .",
        "inspired by the advances of deep learning , we propose a deep transductive semi - supervised maximum margin clustering approach .",
        "we pretrain the deep network structure with restricted boltzmann machines ( rbms ) layer by layer greedily , and optimize our objective function with gradient descent .",
        "by checking the most violated constraints , our approach updates the model parameters through error backpropagation , in which deep features are learned automatically .",
        "this paper describes maxdnn , a computationally efficient convolution kernel for deep learning with the nvidia maxwell gpu .",
        "3 \\ % computational efficiency on typical deep learning network architectures using a single kernel .",
        "in this work , we investigate smbo to identify architecture hyper - parameters of deep convolution networks ( dcns ) object recognition .",
        "this article demontrates that we can apply deep learning to text understanding from character - level inputs all the way up to abstract text concepts , using temporal convolutional networks ( convnets ) .",
        "our empirical evaluation of different rnn units , revealed that in both tasks , the gf - rnn outperforms the conventional approaches to build deep stacked rnns .",
        "training of large - scale deep neural networks is often constrained by the available computational resources .",
        "our results show that deep networks can be trained using only 16 - bit wide fixed - point number representation when using stochastic rounding , and incur little to no degradation in the classification accuracy .",
        "we consider the problem of learning deep generative models from data .",
        "recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation .",
        "however , as deep features eventually transition from general to specific along the network , the feature transferability drops significantly in higher layers with increasing domain discrepancy .",
        "in this paper , we propose a new deep adaptation network ( dan ) architecture , which generalizes deep convolutional neural network to the domain adaptation scenario .",
        "training deep neural networks is complicated by the fact that the distribution of each layer ' s inputs changes during training , as the parameters of the previous layers change .",
        "experimental results show that our method , which uses deep learning , mobile cloud computing , distance estimation and size calibration inside a mobile device , leads to an accuracy improvement to 95 % on average compared to previous work",
        "we present a work - in - progress snapshot of learning with a 15 billion parameter deep learning network on hpc architectures applied to the largest publicly available natural image and video dataset released to - date .",
        "recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers .",
        "we train our three - layer deep neural network on the yahoo !",
        "our simple framework can be applied to multiple architectures , including deep ones .",
        "deep neural networks ( dnn ) are the state of the art on many engineering problems such as computer vision and audition .",
        "in this study we applied the word2vec deep learning toolkit to medical corpora to test its potential for identifying relationships from unstructured text .",
        "we introduce deep neural programs ( dnp ) , a novel programming paradigm for writing adaptive controllers for cy - ber - physical systems ( cps ) .",
        "inspired by the brain , deep neural networks ( dnn ) are thought to learn abstract representations through their hierarchical architecture .",
        "in this paper , we explore joint optimization of masking functions and deep recurrent neural networks for monaural source separation tasks , including the monaural speech separation task , monaural singing voice separation task , and speech denoising task .",
        "the joint optimization of the deep recurrent neural networks with an extra masking layer enforces a reconstruction constraint .",
        "neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology .",
        "we explore more biologically plausible versions of deep representation learning , focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised , unsupervised and reinforcement learning .",
        "parameter - specific adaptive learning rate methods are computationally efficient ways to reduce the ill - conditioning problems encountered when training large deep networks .",
        "the fgrn paradigm provides great flexibility and modularity and appears as a promising candidate for building deep networks : the system can be easily extended by introducing new and different ( in cardinality and in type ) variables .",
        "here , we train a deep neural network to re - synthesize its inputs at its output layer for a given class of data .",
        "we then exploit the fact that this abstract transformation , which we call a deep transform ( dt ) , inherently rejects information ( errors ) existing outside of the abstract feature space .",
        "this paper introduces the deep recurrent attentive writer ( draw ) neural network architecture for image generation .",
        "available publications show that the problem of rule generation from ontologies based on inductive learning is not investigated deeply enough .",
        "in recent years multilayer perceptrons ( mlps ) with many hid - den layers deep neural network ( dnn ) has performed sur - prisingly well in many speech tasks , i .",
        "in this paper , deep belief network ( dbn ) , a class of dnn family has been employed and applied to model the f0 contour of synthesized speech which was generated by hmm - based speech synthesis system .",
        "this scheme provides a direct method for transferring ideas between the fields of deep learning and computational neuroscience .",
        "for this task we use a deep learning approach with restricted boltzmann machines .",
        "we present a deep network that , in an empirical evaluation , outperforms a number of competitive methods from the literature",
        "for pretraining of deep networks on mnist , rectangle data , convex shapes , norb , and cifar , rfns were superior to restricted boltzmann machines ( rbms ) and denoising autoencoders .",
        "on cifar - 10 and cifar - 100 , rfn pretraining always improved the results of deep networks for different architectures like alexnet , deep supervised net ( dsn ) , and a simple \" network in network \" architecture .",
        "this paper presents a new state - of - the - art for document image classification and retrieval , using features learned by deep convolutional neural networks ( cnns ) .",
        "in object and scene analysis , deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations .",
        "however , literature defines a general error - correcting capability for ecocs without analyzing how it distributes among classes , hindering a deeper analysis of pair - wise error - correction .",
        "in this paper , we propose a new approach which uses deep neural network to learn features automatically from data .",
        "we then refine this alignment using a state - of - the - art visual food detector , based on a deep convolutional neural network .",
        "in this paper we present our approach to learning several specialist models using deep learning techniques , each focusing on one modality .",
        "among these are a convolutional neural network , focusing on capturing visual information in detected faces , a deep belief net focusing on the representation of the audio stream , a k - means based \" bag - of - mouths \" model , which extracts visual features around the mouth region and a relational autoencoder , which addresses spatio - temporal aspects of videos .",
        "deep neural networks have recently achieved state of the art performance thanks to new training algorithms for rapid parameter estimation and new regularization methods to reduce overfitting .",
        "this representation , together with target language words , are fed to a deep neural network ( dnn ) to form a stronger nnjm .",
        "we present a bayesian approach to adapting parameters of a well - trained context - dependent deep - neural - network hid - den markov models ( cd - dnn - hmms ) to improve automatic speech recognition performance .",
        "deep neural networks ( dnns ) are analyzed via the theoretical framework of the information bottleneck ( ib ) principle .",
        "we believe that this new insight can lead to new optimality bounds and deep learning algorithms .",
        "this paper presents the deep convolution inverse graphics network ( dc - ign ) that aims to learn an interpretable representation of images that is disentangled with respect to various transformations such as object out - of - plane rotations , lighting variations , and texture .",
        "this approach allows us to rapidly learn , sample from , and evaluate probabilities in deep generative models with thousands of layers or time steps .",
        "2 % ) image classification databases , with very fast training times compared to standard deep network approaches .",
        "we highlight and discuss our findings in light of a cross - lingual approach : while we discover differences in evoked emotions and corresponding viral effects , we provide preliminary evidence of a generalized explanatory model rooted in the deep structure of emotions : the valence - arousal - dominance ( vad ) circumplex .",
        "successful experiments are conducted , validating these theoretical results , on two image datasets and with a particular architecture that mimics the deep boltzmann machine gibbs sampler but allows training to proceed with backprop , without the need for layer",
        "here , we train a convolutional deep neural network to re - synthesize input time - domain speech signals at its output layer .",
        "we then use this abstract transformation , which we call a deep transform ( dt ) , to perform probabilistic re - synthesis on further speech ( of the same speaker ) which has been degraded .",
        "here , we trained two separate convolutive autoencoder deep neural networks ( dnn ) to separate monaural and binaural mixtures of two concurrent speech streams .",
        "we then used these dnns as convolutive deep transform ( cdt ) devices to perform probabilistic re - synthesis .",
        "our ratiolog project addresses the problem of rational reasoning in deep question answering by methods from automated deduction and cognitive computing .",
        "here , we train a convolutional deep neural network , on a two - speaker cocktail party problem , to make probabilistic predictions about binary masks .",
        "our results approach ideal binary mask performance , illustrating that relatively simple deep neural networks are capable of robust binary mask prediction .",
        "in particular , we propose ( 1 ) a multi - output deep regression model to project an image into a semantic word space , which explicitly exploits the correlations in the intermediate semantic layer of word vectors ; ( 2 ) a novel zero - shot learning algorithm for multi - label data that exploits the unique compositionality property of semantic word vector representations ; and ( 3 ) a transductive learning strategy to enable the regression model learned from seen classes to generalise well to unseen classes .",
        "our models are also competitive to most state - of - the - art results , including rnns based on long short term memory and deep cnns / rnns .",
        "stacked denoising auto encoders ( daes ) are well known to learn useful deep representations , which can be used to improve supervised training by initializing a deep network .",
        "we investigate a training scheme of a deep dae , where dae layers are gradually added and keep adapting as additional layers are added .",
        "as deep nets are increasingly used in applications suited for mobile devices , a fundamental dilemma becomes apparent : the trend in deep learning is to grow models to absorb ever - increasing data set sizes ; however mobile devices are designed with very little memory and cannot store such large models .",
        "deep generative models ( dgms ) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability .",
        "in this paper , we present max - margin deep generative models ( mmdgms ) , which explore the strongly discriminative principle of max - margin learning to improve the discriminative power of dgms , while retaining the generative capability .",
        "deep learning has shown state - of - art classification performance on datasets such as imagenet , which contain a single object in each image .",
        "we present a unified framework which leverages the strengths of multiple machine learning methods , viz deep learning , probabilistic models and kernel methods to obtain state - of - art performance on microsoft coco , consisting of non - iconic images .",
        "this paper proposes an architecture for deep neural networks with hidden layer branches that learn targets of lower hierarchy than final layer targets .",
        "however , network training becomes more difficult with increasing depth and training of very deep networks remains an open problem .",
        "in this extended abstract , we introduce a new architecture designed to ease gradient - based training of very deep networks .",
        "highway networks with hundreds of layers can be trained directly using stochastic gradient descent and with a variety of activation functions , opening up the possibility of studying extremely deep and efficient architectures .",
        "for example , deep neural networks have been more successful than shallow networks because they can perform a greater number of sequential computational steps ( each highly parallel ) .",
        "we present an interleaved text / image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital ' s picture archiving and communication system .",
        "set functions , and specifically submodular set functions , characterize a wide variety of naturally occurring optimization problems , and the property of submodularity of set functions has deep theoretical consequences with wide ranging applications .",
        "we propose an object detection system that relies on a multi - region deep convolutional neural network ( cnn ) that also encodes semantic segmentation - aware features .",
        "we exploit the above properties of our recognition module by integrating it on an iterative localization mechanism that alternates between scoring a box proposal and refining its location with a deep cnn regression model .",
        "this report provides an overview of the current state of the art deep learning architectures and optimisation techniques , and uses the adni hippocampus mri dataset as an example to compare the effectiveness and efficiency of different convolutional architectures on the task of patch - based 3 - dimensional hippocampal segmentation , which is important in the diagnosis of alzheimer ' s disease .",
        "deep neural networks have recently achieved state - of - the - art results in many machine learning problems , e .",
        "in this paper , we present a fully automatic brain tumor segmentation method based on deep neural networks ( dnns ) .",
        "in this paper , we propose a novel unsupervised deep learning model , called pca - based convolutional network ( pcn ) .",
        "the results show that pcn performs competitive with or even better than state - of - the - art deep learning models .",
        "more importantly , since there is no back propagation for supervised finetuning , pcn is much more efficient than existing deep networks .",
        "nowadays , represented by deep learning techniques , the field of machine learning is experiencing unprecedented prosperity and its influence is demonstrated in academia , industry and civil society . \"",
        "our approach is based on the charwnn deep neural network , which uses word - level and character - level representations ( embeddings ) to perform sequential classification .",
        "although deep neural networks ( dnn ) are able to scale with direct advances in computational power ( e .",
        "recent research shows that deep neural networks ( dnns ) can be used to extract deep speaker vectors ( d - vectors ) that preserve speaker characteristics and can be used in speaker verification .",
        "this paper aims to accelerate the test - time computation of convolutional neural networks ( cnns ) , especially very deep cnns that have substantially impacted the computer vision community .",
        "for the widely used very deep vgg - 16 model , our method achieves a whole - model speedup of 4x with merely a 0 .",
        "this paper proposes boosting - like deep learning ( bdl ) framework for pedestrian detection .",
        "due to overtraining on the limited training samples , overfitting is a major problem of deep learning .",
        "we incorporate a boosting - like technique into deep learning to weigh the training samples , and thus prevent overtraining in the iterative process .",
        "81 % reduction in the average miss rate compared with acf and jointdeep on the largest caltech benchmark dataset , respectively .",
        "in this work , we explore whether such tests can be solved automatically by artificial intelligence technologies , especially the deep learning technologies that are recently developed and successfully applied in a number of fields .",
        "inspired by deep learning , the authors propose a supervised framework for learning vector representation of words to provide additional supervised fine tuning after unsupervised learning .",
        "recently , deep learning has achieved great success in many fields , such as image , sounds and text processing .",
        "in this paper , deep learning method has been used for feature extraction and feature selection .",
        "experiments using joint - embedding and deep learning methods show promising results on these tasks .",
        "this paper proposes an ros learning approach based on deep neural networks ( dnn ) , which involves an ros feature as the input of the dnn model and so the spectrum distortion caused by ros can be learned and compensated for .",
        "this article presents a deep analysis of the influence of context information on dialogue act recognition .",
        "our general - purpose methods may have wide applications for understanding compositionality and other semantic properties of deep networks , and also shed light on why lstms outperform simple recurrent nets ,",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning algorithm , learning to find the best structured object ( such as a label sequence ) given a structured input ( such as a vector sequence ) by globally considering the mapping relationships between the structure rather than item by item .",
        "it is known that the learning rate is the most important hyper - parameter to tune for training deep convolutional neural networks ( i .",
        "deep learning refers to a shining branch of machine learning that is based on learning levels of representations .",
        "convolutional neural networks ( cnn ) is one kind of deep neural network .",
        "deep structured output learning shows great promise in tasks like semantic image segmentation .",
        "we proffer a new , efficient deep structured model learning scheme , in which we show how deep convolutional neural networks ( cnns ) can be used to estimate the messages in message passing inference for structured prediction with conditional random fields ( crfs ) .",
        "deep neural networks trained on large - scale dataset can learn transferable features that promote learning multiple tasks for inductive transfer and labeling mitigation .",
        "as deep features eventually transition from general to specific along the network , a fundamental problem is how to exploit the relationship structure across different tasks while accounting for the feature transferability in the task - specific layers .",
        "in this work , we propose a novel deep relationship network ( drn ) architecture for multi - task learning by discovering correlated tasks based on multiple task - specific layers of a deep convolutional neural network .",
        "deep learning tools have recently gained much attention in applied machine learning .",
        "we call this iterative system the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) which generates high quality features for track 1 of the challenge and acoustic tokens for track 2 of the challenge .",
        "deep learning with a convolutional neural network ( cnn ) has been proved to be very effective in feature extraction and representation of images .",
        "for image classification problems , this work aim at finding which classifier is more competitive based on high - level deep features of images .",
        "in this report , we have discussed the nearest neighbor , support vector machines and extreme learning machines for image classification under deep convolutional activation feature representation .",
        "the deep features of the object dataset are obtained by a well - trained cnn with five convolutional layers and three fully - connected layers on the challenging imagenet .",
        "recently , strong results have been demonstrated by deep recurrent neural networks on natural language transduction problems .",
        "we show that these architectures exhibit superior generalisation performance to deep rnns and are often able to learn the underlying generating algorithms in our transduction experiments .",
        "in this context , we deeply study the effects of restart , branching heuristics and clauses learning .",
        "we revisit the choice of sgd for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights .",
        "while our theoretical guarantees assume convexity , we discuss the applicability of our method to deep neural networks , and experimentally demonstrate its merits .",
        "this paper proposes a set of new error criteria and learning approaches , adaptive normalized risk - averting training ( anrat ) , to attack the non - convex optimization problem in training deep neural networks ( dnns ) .",
        "in practice , we show how this method improves training of deep neural networks to solve visual recognition tasks on the mnist and cifar - 10 datasets .",
        "performance on deep / shallow multilayer perceptrons and denoised auto - encoders is also explored .",
        "finally we show that nasmc is able to train a neural network - based deep recurrent generative model achieving results that compete with the state - of - the -",
        "this allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure .",
        "meanwhile , feed - forward neural network is a traditional classifier , which is very hot at present with a deeper architecture .",
        "discrete fourier transforms provide a significant speedup in the computation of convolutions in deep learning .",
        "unsupervised training of deep generative models containing latent variables and performing inference remains a challenging problem for complex , high dimen - sional distributions .",
        "inspired by the recent successes of deep learning methods , we propose an end - to - end learning approach for the place classification problem .",
        "with the deep architectures , this methodology automatically discovers features and contributes in general to higher classification accuracies .",
        "secondly , each layer of data is fed into a deep neural network model for classification , where a graph regularization is imposed to the deep architecture for keeping local consistency between adjacent samples .",
        "we consider the problem of bayesian parameter estimation for deep neural networks , which is important in problem settings where we may have little data , and / or where we need accurate posterior predictive densities , e .",
        "we present a novel network architecture , frequency - sensitive hashed nets ( freshnets ) , which exploits inherent redundancy in both convolutional layers and fully - connected layers of a deep learning model , leading to dramatic savings in memory and storage consumption .",
        "the online learning of deep neural networks is an interesting problem of machine learning because , for example , major it companies want to manage the information of the massive data uploaded on the web daily , and this technology can contribute to the next generation of lifelong learning .",
        "we aim to train deep models from new data that consists of new classes , distributions , and tasks at minimal computational cost , which we call online deep learning .",
        "unfortunately , deep neural network learning through classical online and incremental methods does not work well in both theory and practice .",
        "in this paper , we introduce dual memory architectures for online incremental deep learning .",
        "the proposed architecture consists of deep representation learners and fast learnable shallow kernel networks , both of which synergize to track the information of new data .",
        "performing inference and learning of deep generative networks in a bayesian setting is desirable , where a sparsity - inducing prior can be adopted on model parameters or a nonparametric bayesian process can be used to infer the network structure .",
        "however , posterior inference for such deep models is an extremely challenging task , which has largely not been well - addressed .",
        "in this paper , we present doubly stochastic gradient - based mcmc , a simple and effective method that can be widely applied for bayesian inference of deep generative models in continuous parameter spaces .",
        "we demonstrate the effectiveness on learning deep sigmoid belief networks ( dsbns ) .",
        "deep directed generative models have attracted much attention recently due to their expressive representation power and the ability of ancestral sampling .",
        "qualitative and quantitative evaluations of our model against state of the art deep models on benchmark datasets demonstrate the effectiveness of the proposed algorithm in data representation and reconstruction .",
        "deep learning ' s recent successes have mostly relied on convolutional networks , which exploit fundamental statistical properties of images , sounds and video data : the local stationarity and multi - scale compositional structure , that allows expressing long range interactions in terms of shorter , localized interactions .",
        "deep neural networks ( dnn ) have achieved huge practical success in recent years .",
        "this paper proposes a deep denoising auto - encoder technique to extract better acoustic features for speech synthesis .",
        "ntram is broad enough to subsume the state - of - the - art neural translation model in [ 2 ] as its special case , while significantly improves upon the model with its deeper architecture .",
        "recent years have produced great advances in training large , deep neural networks ( dnns ) , including notable successes in training convolutional neural networks ( convnets ) to recognize natural images .",
        "in this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market .",
        "e2c consists of a deep generative model , belonging to the family of variational autoencoders , that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear .",
        "a deep learning approach has been proposed recently to derive speaker identifies ( d - vector ) by a deep neural network ( dnn ) .",
        "this paper presents two improvements for the deep learning approach : a phonedependent dnn structure to normalize phone variation , and a new scoring approach based on dynamic time warping ( dtw ) .",
        "we employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback .",
        "the network differs from existing deep lstm architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data .",
        "it therefore provides a unified way of using lstm for both deep and sequential computation .",
        "to exploit both deep learning and linguistic structures , we propose a tree - based convolutional neural network model which exploit various long - distance relationships between words .",
        "we introduce a new framework for unsupervised learning of deep representations based on a novel hierarchical decomposition of information .",
        "we combine supervised learning with unsupervised learning in deep neural networks .",
        "however , training becomes more difficult as depth increases , and training of very deep networks remains an open problem .",
        "this enables the study of extremely deep and efficient architectures .",
        "while not composed of natural scenes , frames in atari games are high - dimensional in size , can involve tens of objects with one or more objects being controlled by the actions directly and many other objects being influenced indirectly , can involve entry and departure of objects , and can involve deep partial observability .",
        "we propose and evaluate two deep neural network architectures that consist of encoding , action - conditional transformation , and decoding layers based on convolutional neural networks and recurrent neural networks .",
        "the central challenge arises from two compounding factors : the broader domain results in an open - ended set of relations , and the deeper compositionality results in a combinatorial explosion in the space of logical forms .",
        "deep compositional models of meaning acting on distributional representations of words in order to produce vectors of larger text constituents are evolving to a popular area of nlp research .",
        "distinctive features and advantages of the sp system compared with alternatives in : minimum length encoding and related concepts ; deep learning in neural networks ; universal search ; bayesian networks and other models for ai ; analysis and production of natural language ; learning natural language ; exact and inexact reasoning ; representation and processing of diverse forms of knowledge ; ibm ' s watson ; problems associated with big data , and in the development of intelligence in autonomous robots .",
        "the success of deep learning often derives from well - chosen operational building blocks .",
        "regularisation of deep neural networks ( dnn ) during training is critical to performance .",
        "we propose a method combining relational - logic representations with deep neural network learning .",
        "the relational rule - set serves as a template for unfolding possibly deep neural networks whose structures also reflect the structure of given training or testing examples .",
        "contemporary deep neural networks exhibit impressive results on practical problems .",
        "we analyze this behavior in the context of deep , infinite neural networks .",
        "we show that deep infinite layers are naturally aligned with gaussian processes and kernel methods , and devise stochastic kernels that encode the information of these networks .",
        "deep neural networks is a branch in machine learning that has seen a meteoric rise in popularity due to its powerful abilities to represent and model high - level abstractions in highly complex data .",
        "one area in deep neural networks that is ripe for exploration is neural connectivity formation .",
        "motivated by this intriguing finding , we introduce the concept of stochasticnet , where deep neural networks are formed via stochastic connectivity between neurons .",
        "such stochastic synaptic formations in a deep neural network architecture can potentially allow for efficient utilization of neurons for performing specific tasks .",
        "to evaluate the feasibility of such a deep neural network architecture , we train a stochasticnet using three image datasets .",
        "experimental results show that a stochasticnet can be formed that provides comparable accuracy and reduced overfitting when compared to conventional deep neural networks with more than two times the number of neural connections .",
        "neural reasoner has 1 ) a specific interaction - pooling mechanism , allowing it to examine multiple facts , and 2 ) a deep architecture , allowing it to model the complicated logical relations in reasoning tasks .",
        "this thesis describes the design and implementation of a smile detector based on deep convolutional neural networks .",
        "despite the promise of brain - inspired machine learning , deep neural networks ( dnn ) have frustratingly failed to bridge the deceptively large gap between learning and memory .",
        "deep learning has demonstrated the power of detailed modeling of complex high - order ( multivariate ) interactions in data .",
        "for some learning tasks there is power in learning models that are not only deep but also broad .",
        "in this paper , we propose an algorithm for deep broad learning called dbl .",
        "comparisons are offered against traditional models such as bag of words , n - grams and their tfidf variants , and deep learning models such as word - based convnets and recurrent neural networks .",
        "evolution of visual object recognition architectures based on convolutional neural networks & amp ; convolutional deep belief networks paradigms has revolutionized artificial vision science .",
        "we propose a two level hierarchical deep learning architecture inspired by divide & amp ; conquer principle that decomposes the large scale recognition architecture into root & amp ; leaf level model architectures .",
        "each of the root & amp ; leaf level models is trained exclusively to provide superior results than possible by any 1 - level deep learning architecture prevalent today .",
        "this paper proposes so - called deep attribute framework to alleviate this issue from three aspects .",
        "as soft - max layer directly corresponds to semantic concepts , this representation is named \" deep attributes \" .",
        "in this paper , we present a system that employs a wearable acoustic sensor and a deep convolutional neural network for detecting coughs .",
        "in this work , we investigate a deep - learning approach to learning the representation of states in partially observable tasks , with minimal prior knowledge of the domain .",
        "in particular , we study reinforcement learning with deep neural networks , including rnn and lstm , which are equipped with the desired property of being able to capture long - term dependency on history , and thus providing an effective way of learning the representation of hidden states .",
        "in a recent article we described a new type of deep neural network - a perpetual learning machine ( plm ) - which is capable of learning ' on the fly ' like a brain by existing in a state of perpetual stochastic gradient descent ( psgd ) .",
        "the performance of mdrnn is improved by further increasing its depth , and the difficulty of learning the deeper network is overcome by hessian - free ( hf ) optimization .",
        "automatic speech recognition ( asr ) is achieved by two multi - pass deep neural network systems with adaptation and rescoring techniques .",
        "in this paper , we investigate whether distributional semantics in the form of word embeddings can enable a deeper , i .",
        "with the impressive capability to capture visual content , deep convolutional neural networks ( cnn ) have demon - strated promising performance in various vision - based ap - plications , such as classification , recognition , and objec - t detection .",
        "in this paper , to address this problem , we proposed a new kernelized deep convolutional neural network .",
        "rectified linear units ( relu ) seem to have displaced traditional ' smooth ' nonlinearities as activation - function - du - jour in many - but not all - deep neural network ( dnn ) applications .",
        "stochastic gradient descent ( sgd ) is arguably the most popular of the machine learning methods applied to training deep neural networks ( dnn ) today .",
        "to make use of such noisy machine labeled data , we employ a progressive strategy to fine - tune the deep network .",
        "in the back - end , several techniques are taken advantage to improve the noisy automatic speech recognition ( asr ) performance including deep neural network ( dnn ) , convolutional neural network ( cnn ) and long short - term memory ( lstm ) using medium vocabulary , lattice rescoring with a big vocabulary language model finite state transducer , and rover scheme .",
        "in this work we more deeply investigate the direct utility of using clustering to improve prediction accuracy and provide explanations for why this may be so .",
        "in particular , we first show that the recent dqn algorithm , which combines q - learning with a deep neural network , suffers from substantial overestimations in some games in the atari 2600 domain .",
        "deep neural networks currently demonstrate state - of - the - art performance in several domains .",
        "in particular , for the very deep vgg networks we report the compression factor of the dense weight matrix of a fully - connected layer up to 200000 times leading to the compression factor of the whole network up to 7 times .",
        "borrowing techniques from the literature on training deep generative models , we present the wake - sleep recurrent attention model , a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients .",
        "deep dynamic generative models are developed to learn sequential dependencies in time - series data .",
        "in this paper , we evaluate convolutional neural network ( cnn ) features using the alexnet architecture and very deep convolutional network ( vggnet ) architecture .",
        "deep neural network architectures have recently produced excellent results in a variety of areas in artificial intelligence and visual recognition , well surpassing traditional shallow architectures trained using hand - designed features .",
        "the power of deep networks stems both from their ability to perform local computations followed by pointwise non - linearities over increasingly larger receptive fields , and from the simplicity and scalability of the gradient - descent training procedure based on backpropagation .",
        "log - tangent space metrics defined over the manifold of symmetric positive definite matrices ) while preserving the validity and efficiency of an end - to - end deep training framework .",
        "in this paper we propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures .",
        "we perform segmentation experiments using the bsds and mscoco benchmarks and demonstrate that deep networks relying on second - order pooling and normalized cuts layers , trained end - to -",
        "the recent great improvements on benchmark data sets achieved by increasingly complex unsupervised learning methods and deep learning models with lots of parameters usually requires many tedious tricks and much expertise to tune .",
        "in addition , some beneficial methods such as local contrast normalization and whitening are added to the proposed deep trans - layer networks to further boost performance .",
        "compared to traditional deep learning methods , the implemented feature learning method has much less parameters and is validated in several typical experiments , such as digit recognition",
        "this note provides a family of classification problems , indexed by a positive integer $ k $ , where all shallow networks with fewer than exponentially ( in $ k $ ) many nodes exhibit error at least $ 1 / 3 $ , whereas a deep network with 2 nodes in each of $ 2k $ layers achieves zero error , as does a recurrent network with 3 distinct nodes iterated $ k $ times .",
        "this paper provides a new approach for scalable optimisation of the mutual information by merging techniques from variational inference and deep learning .",
        "because of their performance , deep neural networks are increasingly used for object recognition .",
        "we also conducted a deep analysis of provided polish data as preparatory work for the automatic data correction and cleaning phase .",
        "recently , represented by deep learning techniques , the field of machine learning is experiencing unprecedented prosperity and some applications with near human - level performance bring researchers confidence to imply that their approaches are the promising candidate for understanding the mechanism of human brain .",
        "however , cnns in lvcsr have not kept pace with recent advances in other domains where deeper neural networks provide superior performance .",
        "first , we introduce a very deep convolutional network architecture with up to 14 weight layers .",
        "we then evaluate the very deep cnns on the hub5 ' 00 benchmark ( using the 262 hours of swb - 1 training data )",
        "an orthogonal haar scattering transform is a deep network , computed with a hierarchy of additions , subtractions and absolute values , over pairs of coefficients .",
        "it provides a simple mathematical model for unsupervised deep network learning .",
        "furthermore , the proposed modeling and synthesis platform outperforms a leading - edge , vocoded , deep bidirectional long short - term memory recurrent neural network ( dblstm - rnn ) - based baseline system in various objective evaluation metrics conducted .",
        "we consider the task of building compact deep learning pipelines suitable for deployment on storage and power constrained mobile devices .",
        "we make use of visual features extracted from product images using ( pre - trained ) deep networks , on top of which we learn an additional layer that uncovers the visual dimensions that best explain the variation in people ' s feedback .",
        "deep cca is a recently proposed deep neural network extension to the traditional canonical correlation analysis ( cca ) , and has been successful for multi - view representation learning in several domains .",
        "however , stochastic optimization of the deep cca objective is not straightforward , because it does not decouple over training examples .",
        "previous optimizers for deep cca are either batch - based algorithms or stochastic optimization using large minibatches , which can have high memory consumption .",
        "in this paper , we tackle the problem of stochastic optimization for deep cca with small minibatches , based on an iterative solution to the cca objective , and show that we can achieve as good performance as previous optimizers and thus alleviate the memory requirement .",
        "when training deep neural networks , it is typically assumed that the training examples are uniformly difficult to learn .",
        "in this article , using a deep neural network to encode a video , we show that oddball sgd can be used to enforce uniform error across the training set .",
        "special attention is paid to the deep learning techniques and architectures implemented from scratch using python and numpy for this competition .",
        "this project is mainly focused on the solution to the issues above , combining deep learning algorithm with cloud computing platform to deal with large - scale data .",
        "careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data , how mapreduce is implemented on deep learning neural network , and why this combination accelerates computation .",
        "this observation could be an element of a theory for explaining how brains perform credit assignment in deep hierarchies as efficiently as back - propagation does .",
        "we propose adaapt : a deep architecture for adaptive policy transfer , which addresses these challenges .",
        "for most deep learning algorithms training is notoriously time consuming .",
        "we also executed a deep analysis of polish data as preparatory work before automatized data processing such as true casing or punctuation normalization phase .",
        "the increasing complexity of deep learning architectures is resulting in training time requiring weeks or even months .",
        "this slow training is due in part to vanishing gradients , in which the gradients used by back - propagation are extremely large for weights connecting deep layers ( layers near the output layer ) , and extremely small for shallow layers ( near the input layer ) ; this results in slow learning in the shallow layers .",
        "additionally , it has also been shown that in highly non - convex problems , such as deep neural networks , there is a proliferation of high - error low curvature saddle points , which slows down learning dramatically .",
        "in this paper , we attempt to overcome the two above problems by proposing an optimization method for training deep neural networks which uses learning rates which are both specific to each layer in the network and adaptive to the curvature of the function , increasing the learning rate at low curvature points .",
        "the purpose of this paper is to research the application of deep learning techniques to this problem to identify at the beginning of a drive cycle the driver specific vehicle speed profile for an individual driver repeated drive cycle , which can be used in an optimization algorithm to minimize the amount of fossil fuel energy used during the trip .",
        "in this paper , a framework for testing deep neural network ( dnn ) design in python is presented .",
        "in this paper we explore deep learning models with memory component or attention mechanism for question answering task .",
        "we train spiking deep networks using leaky integrate - and - fire ( lif ) neurons , and achieve state - of - the - art results for spiking networks on the cifar - 10 and mnist datasets .",
        "this demonstrates that biologically - plausible spiking lif neurons can be integrated into deep networks can perform as well as other spiking models ( e .",
        "it also provides new methods for training deep networks to run on neuromorphic hardware , with the aim of fast , power - efficient image classification for robotics applications .",
        "in this paper , we extend the deep long short - term memory ( dlstm ) recurrent neural networks by introducing gated direct connections between memory cells in adjacent layers .",
        "these direct links , called highway connections , enable unimpeded information flow across different layers and thus alleviate the gradient vanishing problem when building deeper lstms .",
        "experiments on the ami distant speech recognition ( dsr ) task indicate that we can train deeper lstms and achieve better improvement from sequence training with highway lstms ( hlstms ) .",
        "we introduce a novel schema for sequence to sequence learning with a deep q - network ( dqn ) , which decodes the output sequence iteratively .",
        "deep neural networks ( dnn ) have achieved state - of - the - art results in a wide range of tasks , with the best results obtained with large training sets and large models .",
        "as a result , there is much interest in research and development of dedicated hardware for deep learning ( dl ) .",
        "we present a novel and practical deep fully convolutional neural network architecture for semantic pixel - wise segmentation termed segnet .",
        "recent works have highlighted scale invariance or symmetry present in the weight space of a typical deep network and the adverse effect it has on the euclidean gradient based stochastic gradient descent optimization .",
        "in this work , we show that a commonly used deep network , which uses convolution , batch normalization , relu , max - pooling , and sub - sampling pipeline , possess more complex forms of symmetry arising from scaling - based reparameterization of the network weights .",
        "we com - pare the outcomes of regularization methods that are popularly used to train deep neural networks and study how different context functions can affect the classification performance .",
        "this paper is an empirical study of the distributed deep learning for a question answering subtask : answer selection .",
        "recent works have highlighted scale invariance or symmetry that is present in the weight space of a typical deep network and the adverse effect that it has on the euclidean gradient based stochastic gradient descent optimization .",
        "in this work , we show that these and other commonly used deep networks , such as those which use a max - pooling and sub - sampling layer , possess more complex forms of symmetry arising from scaling based reparameterization of the network weights .",
        "we study hierarchical variational models on a variety of deep discrete latent variable models .",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning framework .",
        "in this paper , we have proposed a system based on matrix factorization ( mf ) and deep recurrent neural networks ( drnns ) for genotype imputation and phenotype sequences prediction .",
        "this paper reports a novel deep architecture referred to as maxout network in network ( min ) , which can enhance model discriminability and facilitate the process of information abstraction within the receptive field .",
        "this paper proposes a new framework of spectral - spatial feature extraction for hsi classification , in which for the first time the concept of deep learning is introduced .",
        "this paper presents a new method for pre - training neural networks that can decrease the total training time for a neural network while maintaining the final performance , which motivates its use on deep neural networks .",
        "following the recent successes of deep convolutional neural networks ( dcnn ) for large scale image classification , descriptors extracted from dcnns are increasingly used in place of the traditional hand crafted descriptors such as fisher vectors ( fv ) with better retrieval performances .",
        "uth consists of two successive deep learning steps .",
        "first , stacked restricted boltzmann machines ( srbm ) , a type of unsupervised deep",
        "then we demonstrate a straightforward and effective deep supervision strategy in which we replicate targets at each sequence step .",
        "in spite of its simplicity , universum prescription obtained competitive results in training deep convolutional networks for cifar - 10 , cifar - 100 and stl - 10 datasets .",
        "we build upon the success of recent deep reinforcement learning and develop a system for learning target reaching with a three - joint robot manipulator using external visual observation .",
        "a deep q network ( dqn ) was demonstrated to perform target reaching after training in simulation .",
        "we present a large - scale study , exploring the capability of temporal deep neural networks in interpreting natural human kinematics and introduce the first method for active biometric authentication with mobile inertial sensors .",
        "the run - time of computing the gradient of the proposed surrogate objective with respect to each training exemplar is quadratic in the the tree depth , and thus training deep trees is feasible .",
        "in this paper , we apply a general deep learning ( dl ) framework for the answer selection task , which does not depend on manually defined features or linguistic tools .",
        "we use multi - layered recurrent neural networks ( rnns ) with long short - term memory ( lstm ) units which are deep both spatially and temporally .",
        "recent work has shown that deep neural networks are capable of approximating both value functions and policies in reinforcement learning domains featuring continuous state and action spaces .",
        "however , to the best of our knowledge no previous work has succeeded at using deep neural networks in structured ( parameterized ) continuous action spaces .",
        "as such , this paper represents a successful extension of deep reinforcement learning to the class of parameterized action space mdps .",
        "we introduce and compare several strategies for learning discriminative features from electroencephalography ( eeg ) recordings using deep learning techniques .",
        "hydra - nets allow for separate processing pathways adapting to subsets of a dataset and thus combine the advantages of individual feature learning ( better adaptation of early , low - level processing ) with group model training ( better generalization of higher - level processing in deeper layers ) .",
        "first a siamese network is trained with deep supervision on the labeled text of training dataset which project texts in a similarity manifold .",
        "the deeply supervised siamese network learn the visual similarity of texts .",
        "the creation of practical deep learning data - products often requires the parallelization across processors and computers to make deep learning feasible on large data sets , but bottlenecks in communication bandwidth make it difficult to attain good speedups through parallelism .",
        "in this paper , we propose the deep reinforcement relevance network ( drrn ) , a novel deep architecture , for handling an unbounded action space with applications to language understanding for text - based games .",
        "therefore , it is very difficult to pre - define the action set as in the deep q - network ( dqn ) .",
        "we consider the problem of human activity recognition using triaxial accelerometers and deep learning paradigms .",
        "this paper shows that deep activity recognition models ( a ) provide better recognition accuracy of human activities , ( b ) avoid the expensive design of handcrafted features in existing systems , and ( c ) utilize the massive unlabeled acceleration samples for unsupervised feature extraction .",
        "moreover , a hybrid approach of deep learning and hidden markov models ( dl - hmm ) is presented for sequential activity recognition .",
        "this hybrid approach integrates the hierarchical representations of deep activity recognition models with the stochastic modeling of temporal sequences in the hidden markov models .",
        "we introduce deep linear discriminant analysis ( deeplda ) which learns linearly separable latent representations in an end - to - end fashion .",
        "the central idea of this paper is to put lda on top of a deep neural network .",
        "deeplda produces competitive results on all three datasets and sets a new state of the art on stl - 10 with a test set accuracy of 81 .",
        "several nonlinear extensions of the classical linear cca method have been proposed , including kernel and deep neural network methods .",
        "have shown that the use of a deep learning approach that jointly learns and computes the features , is very promising for the steganalysis .",
        "we investigated how the application of deep learning , specifically the use of convolutional networks trained with gpus , can help to build better predictive models in telecommunication business environments , and fill this gap .",
        "this paper presents a new method for the discovery of latent domains in diverse speech data , for the use of adaptation of deep neural networks ( dnns ) for automatic speech recognition .",
        "we show that the internal representations of an image in a deep neural network ( dnn ) can be manipulated to mimic those of other natural images with only minor , imperceptible perturbations to the original image .",
        "with the rise of deep architectures , the prime focus has been on object category recognition .",
        "deep learning methods have achieved wide success in this task .",
        "in this paper we show how deep architectures , specifically convolutional neural networks ( cnn ) , can be adapted to the task of simultaneous categorization and pose estimation of objects .",
        "deep neural networks are powerful parametric models that can be trained efficiently using the backpropagation algorithm .",
        "our findings also build a better understanding of certain deep architectures , which contain randomly weighted and untrain",
        "deep neural networks with millions of parameters are at the heart of many state of the art machine learning models today .",
        "in this paper , we apply deep learning techniques to detect the broad absorption bump .",
        "the success of deep learning based method inspires us to generalize a common methodology for the broader science discovery problems .",
        "we present our on - going work to build the deepdis system for such kind of applications .",
        "a lbn decomposes into a deep linear network where each linear unit can be turned on or off by non - deterministic binary latent units .",
        "in this paper , we introduce a new deep convolutional neural network ( convnet ) module that promotes competition among a set of multi - scale convolutional filters .",
        "we show that the use of our proposed module in typical deep convnets produces classification results that are either better than or comparable to the state of the art on the following benchmark datasets : mnist , cifar - 10 , cifar - 100 and svhn .",
        "our net2net technique accelerates the experimentation process by instantaneously transferring the knowledge from a previous network to each new deeper or wider network .",
        "as a result , the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution .",
        "generative model approaches to deep learning are of interest in the quest for both better understanding as well as training methods requiring fewer labeled samples .",
        "the linear layer is one of the most pervasive modules in deep learning representations .",
        "here , we introduce a deep , differentiable , fully - connected neural network module composed of diagonal matrices of parameters , $ \\ mathbf { a } $ and $ \\ mathbf { d } $ , and the discrete cosine transform $ \\ mathbf { c } $ .",
        "we present theoretical results showing how deep cascades of acdc layers approximate linear layers .",
        "we use prioritized experience replay in the deep q - network ( dqn ) algorithm , which achieved human - level performance in atari games .",
        "recent advances in neural variational inference have spawned a renaissance in deep latent variable models .",
        "recent advance in deep learning shows that transfer learning becomes much easier and more effective with high - level abstract features learned by deep models , and the ` transfer ' can be conducted not only between data distributions and data types , but also between model structures ( e .",
        ", shallow nets and deep nets ) or even model types ( e .",
        "we present a new supervised architecture termed mediated mixture - of - experts ( mmoe ) that allows us to improve classification accuracy of deep convolutional networks ( dcn ) .",
        "the recent promising achievements of deep learning rely on the large amount of labeled data .",
        "in this work , we revisit graph - based semi - supervised learning algorithms and propose an online graph construction technique which suits deep convolutional neural network better .",
        "we consider an em - like algorithm for semi - supervised learning on deep neural networks : in forward pass , the graph is constructed based on the network output , and the graph is then used for loss calculation to help update the network by back propagation in the backward pass .",
        "the task of labeling data for training deep neural networks is daunting and tedious , requiring millions of labels to achieve the current state - of - the - art results .",
        "in this work , we propose to train a deep convolutional network based on an enhanced version of the k - means clustering algorithm , which reduces the number of correlated parameters in the form of similar filters , and thus increases test categorization accuracy .",
        "we further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data .",
        "a deep belief network ( dbn ) requires large , multiple hidden layers with high number of hidden units to learn good features from the raw pixels of large images .",
        "policies for complex visual tasks have been successfully learned with deep reinforcement learning , using an approach called deep q - networks ( dqn ) , but relatively large ( task - specific ) networks and extensive training are needed to achieve good performance .",
        "deep learning has become the state - of - art tool in many applications , but the evaluation and training of deep models can be time - consuming and computationally expensive .",
        "our model is parameterized by only a mean and variance per pixel which simplifies computations and makes our method scalable to a deep architecture .",
        "unregularized deep neural networks ( dnns ) can be easily overfit with a limited sample size .",
        "in this paper , we propose deep embedded clustering ( dec ) , a method that simultaneously learns feature representations and cluster assignments using deep neural networks .",
        "this method , termed \" actor - mimic \" , exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers .",
        "we then show that the representations learnt by the deep policy network are capable of generalizing to new tasks , speeding up learning in novel environments .",
        "combined with the inherent nature of medical images that make them ideal for deep - learning , further application of such systems to medical image classification holds much promise .",
        "a deep architecture is used to define an energy function of candidate labels , and then predictions are produced by using back - propagation to iteratively optimize the energy with respect to the labels .",
        "this deep architecture captures dependencies between labels that would lead to intractable graphical models , and performs structure learning by automatically learning discriminative features of the structured output .",
        "overall , deep learning provides remarkable tools for learning features of the inputs to a prediction problem , and this work extends these techniques to learning features of the outputs .",
        "learning meaningful representations using deep neural networks involves designing efficient training schemes and well - structured networks .",
        "in recent years increasingly complex architectures for deep convolution networks ( dcns ) have been proposed to boost the performance on image recognition tasks .",
        "deep networks are increasingly being applied to problems involving image synthesis , e .",
        "we compare the consequences of using ssim versus se loss on representations formed in deep autoencoder and recurrent neural network architectures .",
        "a pure pattern - matching approach , based on a deep convolutional neural network ( dcnn ) that predicts the next move , can perform as well as monte carlo tree search ( mcts ) - based open source go engines such as pachi [ baudis & amp ; gailly ( 2012 ) ] if its search budget is limited .",
        "supervised training of deep neural nets typically relies on minimizing cross - entropy .",
        "in this paper we proposed a direct loss minimization approach to train deep neural networks , taking into account the application - specific loss functions .",
        "layer - sequential unit - variance ( lsuv ) initialization - a simple strategy for weight initialization for deep net learning - is proposed .",
        "we show that with the strategy , learning of very deep nets via standard stochastic gradient descent is at least as fast as the complex schemes proposed specifically for very deep nets such as fitnets ( romero et al .",
        "our method relies on percepts that are extracted from all level of a deep convolutional network trained on the large imagenet dataset .",
        "we show that a deep convolutional network with an architecture inspired by the models used in image recognition can yield accuracy similar to a long - short term memory ( lstm ) network , which achieves the state - of - the - art performance on the standard switchboard automatic speech recognition task .",
        "we introduce a class of cnns called deep convolutional generative adversarial networks ( dcgans ) , that have certain architectural constraints , and demonstrate that they are a strong candidate for unsupervised learning .",
        "training on various image datasets , we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator .",
        "deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation .",
        "this paper presents a comparative study of four deep learning frameworks , namely caffe , neon , theano , and torch , on three aspects : extensibility , hardware utilization , and speed .",
        "the study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both ( multi - threaded ) cpu and gpu ( nvidia titan x ) settings .",
        "the speed performance metrics used here include the gradient computation time , which is important during the training phase of deep networks , and the forward time , which is important from the deployment perspective of trained networks .",
        "we observe that torch is best suited for any deep architecture on cpu , followed by theano .",
        "next , we train a deep recurrent - convolutional network inspired by state - of - the - art video classification to learn robust representations from the sequence of images .",
        "although deep convolutional neural networks ( cnns ) have achieved remarkable results on object detection and segmentation , pre - and post - processing steps such as region proposals and non - maximum suppression ( nms ) , have been required .",
        "in this work , we propose a novel end - to - end trainable deep neural network architecture that generates the correct number of object instances and their bounding boxes ( or segmentation masks ) given an image , using only a single network evaluation without any pre - or post - processing steps .",
        "we study a theoretical model that connects deep learning to finding the ground state of the hamiltonian of a spherical spin glass .",
        "existing results motivated from statistical physics show that deep networks have a highly non - convex energy landscape with exponentially many local minima and energy barriers beyond which gradient descent algorithms cannot make progress .",
        "we show that a number of regularization schemes in deep learning can benefit from this phenomenon .",
        "the complexity of deep neural network algorithms for hardware implementation can be much lowered by optimizing the word - length of weights and signals .",
        "in this work , the effects of retraining are analyzed for a feedforward deep neural network ( ffdnn ) and a convolutional neural network ( cnn ) .",
        "we propose a method for integration of features extracted using deep representations of convolutional neural networks ( cnns ) each of which is learned using a different image dataset of objects and materials for material recognition .",
        "experimental results show that the proposed method achieves state - of - the - art performance by integrating deep features .",
        "although the latest high - end smartphone has powerful cpu and gpu , running deeper convolutional neural networks ( cnns ) for complex tasks such as imagenet classification on mobile devices is challenging .",
        "to deploy deep cnns on mobile devices , we present a simple and effective scheme to compress the entire cnn , which we call one - shot whole network compression .",
        "in recent years there have been many successes of using deep representations in reinforcement learning .",
        "dracula learns a dictionary of $ n $ - grams that efficiently compresses a given corpus and recursively compresses its own dictionary ; in effect , dracula is a ` deep ' extension of compressive feature learning .",
        "we here apply , for the first time , deep learning methods to mobile phone metadata using a convolutional network .",
        "these results show great potential for deep learning approaches for prediction tasks using standard mobile phone metadata .",
        "we propose a method for hand pose estimation based on a deep regressor trained on two different kinds of input .",
        "traditionally in deep learning , one makes a static trade - off between the needs of early and late optimization .",
        "for example , we can gradually transition from linear to non - linear networks , deterministic to stochastic computation , shallow to deep architectures , or even simple downsampling to fully differentiable attention mechanisms .",
        "two novel deep hybrid architectures , the deep hybrid boltzmann machine and the deep hybrid denoising auto - encoder , are proposed for handling semi - supervised learning problems .",
        "we propose a structured prediction architecture for images centered around deep recurrent neural networks .",
        "on theone hand , can deep directed models be success - fully trained without intractable posterior infer - ence and difficult optimization of very deep neu - ral networks in inference and generative mod - els ?",
        "we introduce the \" exponential linear unit \" ( elu ) which speeds up learning in deep neural networks and leads to higher classification accuracies .",
        "in this work we show that deep convolutional neural networks can outperform humans on the task of boundary detection , as measured on the standard berkeley segmentation dataset .",
        "recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers .",
        "this paper describes a successful application of deep reinforcement learning ( drl ) for training intelligent agents with strategic conversational skills , in a situated dialogue setting .",
        "existing deep models rely on a single sentence representation or multiple granularity representations for matching .",
        "to tackle this problem , we present a new deep architecture to match two sentences with multiple positional sentence representations .",
        "recently , dropout has seen increasing use in deep learning .",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "we use deep q - learning based on feature representations of both the state and action to learn the value of whole slates .",
        "mxnet is a multi - language machine learning ( ml ) library to ease the development of ml algorithms , especially for deep neural networks .",
        "in this article , considering arbitrary and monotone missing data patterns , we hypothesize that the use of deep neural networks built using autoencoders and denoising autoencoders in conjunction with genetic algorithms , swarm intelligence and maximum likelihood estimator methods as novel data imputation techniques will lead to better imputed values than existing techniques .",
        "we also intend to use fuzzy logic in tandem with deep neural networks to perform the missing data imputation tasks , as well as different building blocks for the deep neural networks like stacked restricted",
        "recently , dropout has seen increasing use in deep learning .",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "the recently introduced deep q - networks ( dqn ) algorithm has gained attention as one of the first successful combinations of deep neural networks and reinforcement learning .",
        "we advance the state of the art in biomolecular interaction extraction with three contributions : ( i ) we show that deep , abstract meaning representations ( amr ) significantly improve the accuracy of a biomolecular interaction extraction system when compared to a baseline that relies solely on surface - and syntax - based features ; ( ii ) in contrast with previous approaches that infer relations on a sentence - by - sentence basis , we expand our framework to enable consistent predictions over sets of sentences ( documents ) ; ( iii ) we further modify and expand a graph kernel learning framework to enable concurrent exploitation of automatically induced amr ( semantic ) and dependency structure ( syntactic ) representations .",
        "the development of a deep ( stacked ) convolutional auto - encoder in the caffe deep learning framework is presented in this paper .",
        "a deep learning approach to reinforcement learning led to a general learner able to train on visual input to play a variety of arcade games at the human and superhuman levels .",
        "its creators at the google deepmind ' s team called the approach : deep q - network ( dqn ) .",
        "tests of the proposed deep attention recurrent q - network ( darqn ) algorithm on multiple atari 2600 games show level of performance superior to that of dqn .",
        "this paper presents a restricted visual turing test ( vtt ) for story - line based deep understanding in long - term and multi - camera captured videos .",
        "we also study different graph construction mechanisms for natural language applications and propose a robust graph augmentation strategy trained using state - of - the - art unsupervised deep learning architectures that yields further significant quality gains .",
        "while emerging deep - learning systems have outclassed knowledge - based approaches in many tasks , their application to detection tasks for autonomous technologies remains an open field for scientific exploration .",
        "boltzmann machine , as a fundamental construction block of deep belief network and deep boltzmann machines , is widely used in deep learning community and great success has been achieved .",
        "using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real - world complexity .",
        "using these results as a benchmark , we discuss the role that the discount factor may play in the quality of the learning process of a deep q - network ( dqn ) .",
        "the promising performance of deep learning ( dl ) in speech recognition has motivated the use of dl in other speech technology applications such as speaker recognition .",
        "given i - vectors as inputs , the authors proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on deep belief networks ( dbn ) and deep neural networks ( dnn ) to discriminatively model each target speaker .",
        "we show that an end - to - end deep learning approach can be used to recognize either english or mandarin chinese speech - - two vastly different languages .",
        "for speech recognition , deep neural network ( dnn ) have significantly improved the recognition accuracy in most of benchmark datasets and application domains .",
        "in this paper , we study the application of the recently proposed highway network to train small - footprint dnns , which are thinner and deeper and have significantly smaller number of model parameters compared to conventional dnns .",
        "it is expected these methods will now be widely used for the training of neural networks for deep learning not only because of their non - iterative and deterministic nature but also because of their efficiency and speed and will supercede other classification methods which are iterative in nature and rely on error minimization .",
        "we first show that this unexpected equivalence can actually be generalized to other example / rado losses , with necessary and sufficient conditions for the equivalence , exemplified on four losses that bear popular names in various fields : exponential ( boosting ) , mean - variance ( finance ) , linear hinge ( on - line learning ) , relu ( deep learning ) , and unhinged ( statistics ) .",
        "in this paper , we propose a deep convolutional neural network for active object recognition that simultaneously predicts the object label , and selects the next action to perform on the object with the aim of improving recognition performance .",
        "a network pretrained in a different domain with abundant data is used as a feature extractor , while a subsequent classifier is trained on a small target dataset ; and a deep architecture trained with heavy augmentation and equipped with sophisticated regularization methods .",
        "deep learning ( dl ) has achieved notable successes in many machine learning tasks .",
        "a number of frameworks have been developed to expedite the process of designing and training deep neural networks ( dnns ) , such as caffe , torch and theano .",
        "in this paper , we present a novel deep learning method dealing with the surface material classification problem based on a fully convolutional network ( fcn ) , which takes as input the aforementioned acceleration signal and a corresponding image of the surface texture .",
        "compared to previous surface material classification solutions , which rely on a careful design of hand - crafted domain - specific features , our method automatically extracts discriminative features utilizing the advanced deep learning methodologies .",
        "deep neural networks have proved very successful in domains where large training sets are available , but when the number of training samples is small , their performance suffers from overfitting .",
        "this is the document of multimodal deep learning library , mdl , which is written in c + + .",
        "it explains principles and implementations with details of restricted boltzmann machine , deep neural network , deep belief network , denoising autoencoder , deep boltzmann machine , deep canonical correlation analysis , and modal prediction model .",
        "so mdl could be used as a frame for testings in deep learning .",
        "in the last few years , deep learning has lead to very good performance on a variety of problems , such as object recognition , speech recognition and natural language processing .",
        "among different types of deep neural networks , convolutional neural networks have been most extensively studied .",
        "the recently released stanford natural language inference ( snli ) corpus has made it possible to develop and evaluate learning - centered methods such as deep neural networks for the nli task .",
        "experimental results show that the proposed keyword spotter significantly outperforms the deep neural network ( dnn ) and hidden markov model ( hmm ) based keyword - filler model even with less computations .",
        "to tackle the issue , we propose two novel models using deep neural networks ( dnns ) to automatically learn effective patterns from categorical feature interactions and make predictions of users ' ad clicks .",
        "although recent studies have demonstrated that lstms can achieve significantly better performance on spss than deep feed - forward neural networks , little is known about why .",
        "we propose a novel deep neural network architecture for speech recognition that explicitly employs knowledge of the background environmental noise within a deep neural network acoustic model .",
        "a deep neural network is used to predict the acoustic environment in which the system in being used .",
        "the discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model .",
        "we formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point - cloud , natural language , and manipulation trajectory data into a shared embedding space using a deep neural network .",
        "in term of learning method , we also experience a method to learn the parameter of smoothing from unannotated data with a deep analysis and comparision between different learning methods .",
        "in this paper , we propose deep recurrent neural networks ( drnns ) to tackle this challenge .",
        "first , we show how some seemingly disconnected mechanisms used in deep learning such as smart initialization , annealed learning rate , layerwise pretraining , and noise injection ( as done in dropout and sgd ) arise naturally and automatically from this framework , without manually crafting them into the algorithms .",
        "in this paper , we design a deep dual - domain ( $ \\ mathbf { d ^ 3 } $ ) based fast restoration model to remove artifacts of jpeg compressed images .",
        "it leverages the large learning capacity of deep networks , as well as the problem - specific expertise that was hardly incorporated in the past design of deep architectures .",
        "specifically , our best model is capable of outperforming the latest deep model for around 1 db in psnr , and is 30 times faster .",
        "being extensively inspired by the scientific advances in the human visual perception and neuroaesthetics , we design the brain - inspired deep networks ( bdn ) for this task .",
        "this paper presents ' simpleds ' , a simple and publicly available dialogue system trained with deep reinforcement learning .",
        "i provide a fairly thorough treatment of the method of normalized graph cuts , a deeply original method due to shi and malik , including complete proofs .",
        "in the context of speech processing , a deep neural network ( dnn ) is an effective computational method to infer the probability of individual phonological classes from a short segment of speech signal .",
        "however , of late , deep learning techniques have offered a compelling alternative - - that of automatically learning problem - specific features .",
        "with this new paradigm , every problem in computer vision is now being re - examined from a deep learning perspective .",
        "therefore , it has become important to understand what kind of deep networks are suitable for a given problem .",
        "deep - networks ) exist , a survey specific to computer vision is missing .",
        "we specifically consider one form of deep networks widely used in computer vision - convolutional neural networks ( cnns ) .",
        "we hope that our recipe - style survey will serve as a guide , particularly for novice practitioners intending to use deep - learning techniques for computer vision .",
        "we present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions .",
        "architectural novelties include fast two - dimensional recurrent layers and an effective use of residual connections in deep recurrent networks .",
        "we present datagrad , a general back - propagation style training procedure for deep neural architectures that uses regularization of a deep jacobian - based penalty .",
        "it can be viewed as a deep extension of the layerwise contractive auto - encoder penalty .",
        "more importantly , it unifies previous proposals for adversarial training of deep neural nets - - this list includes directly modifying the gradient , training on a mix of original and adversarial examples , using contractive penalties , and approximately optimizing constrained adversarial objective functions .",
        "in an experiment using a deep sparse rectifier network , we find that the deep jacobian regularization of datagrad ( which also has l1 and l2 flavors of regularization ) outperforms traditional l1 and l2 regularization both on the original dataset as well as on adversarial examples .",
        "in the last two years , there have been numerous papers that have looked into using deep neural networks to replace the acoustic model in traditional statistical parametric speech synthesis .",
        "inspired by recent successes of deep learning in computer vision , we propose a novel application of deep convolutional neural networks to facial expression recognition , in particular smile recognition .",
        "in this paper , we propose a novel hashing approach based on unsupervised deep learning to hierarchically transform features into hash codes .",
        "within the heterogeneous deep hashing framework , the autoencoder layers with specific constraints are considered to model the nonlinear mapping between features and binary codes .",
        "the multiple sets of token labels are then used as the targets of a multi - target deep neural network ( mdnn ) trained on low - level acoustic features .",
        "we call this iterative deep learning framework the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) , which generates both high quality speech features for the track 1 of the challenge and acoustic tokens for the track 2 of the challenge .",
        "the increasing popularity of http adaptive video streaming services has dramatically increased bandwidth requirements on operator networks , which attempt to shape their traffic through deep packet inspection ( dpi ) .",
        "we achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks .",
        "previous work on this problem has proposed several techniques based on deep neural networks , typically involving either autoencoder - like networks with a reconstruction objective or paired feedforward networks with a batch - style correlation - based objective .",
        "we find an advantage for correlation - based representation learning , while the best results on most tasks are obtained with our new variant , deep canonically correlated autoencoders ( dccae ) .",
        "the average loss is more popular , particularly in deep learning , due to three main reasons .",
        "we propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers .",
        "in this paper , we present a new model that added memory cells to gate the feeding of image features to the deep neural network .",
        "given the i - vectors , several classifiers are adopted for the language detection task including support vector machines ( svm ) , multi - class logistic regression ( mclr ) , probabilistic linear discriminant analysis ( plda ) and deep neural networks ( dnn ) .",
        "dropout has been witnessed with great success in training deep neural networks by independently zeroing out the outputs of neurons at random .",
        "to tackle the issue of evolving distribution of neurons in deep learning , we propose an efficient adaptive dropout ( named \\ textbf { evolutional dropout } ) that computes the sampling probabilities on - the - fly from a mini - batch of examples .",
        "we propose three advances in training algorithms of variational autoencoders , for the first time allowing to train deep models of up to five stochastic layers , ( 1 ) using a structure similar to the ladder network as the inference model , ( 2 ) warm - up period to support stochastic units staying active in early training , and ( 3 ) use of batch normalization .",
        "we show how deep learning methods can be applied in the context of crowdsourcing and unsupervised ensemble learning .",
        "next , to address the more general case , where classifiers may strongly violate the conditional independence assumption , we propose to apply rbm - based deep neural net ( dnn ) .",
        "in this work we introduce a binarized deep neural network ( bdnn ) model .",
        "we propose a class of loss functions , which we call deep perceptual similarity metrics ( deepsim ) , that mitigate this problem .",
        "instead of computing distances in the image space , we compute distances between image features extracted by deep neural networks .",
        "we show three applications : autoencoder training , a modification of a variational autoencoder , and inversion of deep convolutional networks .",
        "in recent years there is a growing interest in using deep representations for reinforcement learning .",
        "in this paper , we present a methodology and tools to analyze deep q - networks ( dqns ) in a non - blind matter .",
        "moreover we are able to understand and describe the policies learned by dqns for three different atari2600 games and suggest ways to interpret , debug and optimize of deep neural networks in reinforcement learning .",
        "we propose deep distributed recurrent q - networks ( ddrqn ) , which enable teams of agents to learn to solve communication - based coordination tasks .",
        "to our knowledge , this is the first time deep reinforcement learning has succeeded in learning communication protocols .",
        "deep learning is increasingly used in several machine learning tasks as deep neural networks ( dnns ) frequently outperform other techniques .",
        "at run - time , binarynet drastically reduces memory usage and replaces most multiplications by 1 - bit exclusive - not - or ( xnor ) operations , which might have a big impact on both general - purpose and dedicated deep learning hardware .",
        "deep artificial neural networks have made remarkable progress in different tasks in the field of computer vision .",
        "in this work , we show that deep learning models cannot generalize to atypical images that are substantially different from training images .",
        "deeper , more complex models are preferable for representations to be used in supervised systems , but shallow log - linear models work best for building representation spaces that can be decoded with simple spatial distance metrics .",
        "we show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task .",
        "deep gaussian processes ( dgps ) are multi - layer hierarchical generalisations of gaussian processes ( gps ) and are formally equivalent to neural networks with multiple , infinitely wide hidden layers .",
        "dgps are nonparametric probabilistic models and as such are arguably more flexible , have a greater capacity to generalise , and provide better calibrated uncertainty estimates than alternative deep models .",
        "we start with the best - performing approaches from prior work , based on tandem models and segmental conditional random fields ( scrfs ) , with features based on deep neural network ( dnn ) classifiers of letters and phonological features .",
        "experiments show that habcnn outperforms prior deep learning approaches by a big margin .",
        "the recent success of deep neural networks relies on massive amounts of labeled data .",
        "in this paper , we propose a new approach to domain adaptation in deep networks that can simultaneously learn adaptive classifiers and transferable features from labeled data in the source domain and unlabeled data in the target domain .",
        "we enable classifier adaptation by plugging several layers into the deep network to explicitly learn the residual function with reference to the target classifier .",
        "unlike dithering strategies such as epsilon - greedy exploration , bootstrapped dqn carries out temporally - extended ( or deep ) exploration ; this can lead to exponentially faster learning .",
        "the results presented here make it more biologically plausible that a mechanism similar to back - propagation may take place in brains in order to achieve credit assignment in deep networks .",
        "deep generative models parameterized by neural networks have recently achieved state - of - the - art performance in unsupervised and semi - supervised learning .",
        "we extend deep generative models with auxiliary variables which improves the variational approximation .",
        "our findings suggest that more expressive and properly specified deep generative models converge faster with better results .",
        "the identification accuracy is up to 93 \\ % among nine different devices , and shows the method of getting feature vector from the noise of each device and identifying with deeplearning techniques is viable , and well - preformed .",
        "we develop a general duality between neural networks and compositional kernels , striving towards a better understanding of deep learning .",
        "it has been generally believed that training deep neural networks is hard with saturated activation functions , including sigmoid and tanh .",
        "recent works shows that deep tanh networks are able to converge with careful model initialization while deep sigmoid networks still fail .",
        "our preliminary results on deep convolution networks shown that , even without stabilization technologies such as batch normalization and sophisticated initialization , the \" re - scaled sigmoid \" converges to local optimality robustly .",
        "multilayer networks have seen a resurgence under the umbrella of deep learning .",
        "current deep learning algorithms train the layers of the network sequentially , improving algorithmic performance as well as providing some regularization .",
        "we present a new training algorithm for deep networks which trains \\ emph { each node in the network } sequentially .",
        "we explore the use of deep learning hierarchical models for problems in financial prediction and classification .",
        "applying deep learning methods to these problems can produce more useful results than standard methods in finance .",
        "in particular , deep learning can detect and exploit interactions in the data that are , at least currently , invisible to any existing financial economic theory .",
        "thereafter we attempt to democratize deep - learning by training on an ethernet based aws cluster and show ~ 14x scaling on 16 nodes .",
        "recent progress in deep latent variable models has largely been driven by the development of flexible and scalable variational inference methods .",
        "we propose two novel techniques - - - stacking bottleneck features and minimum trajectory error training criterion - - - to improve the performance of deep neural network ( dnn ) - based speech synthesis .",
        "this article presents an overview and brief tutorial of deep learning in mbd analytics and discusses a scalable learning framework over apache spark .",
        "specifically , a distributed deep learning is executed as an iterative mapreduce computing on many spark workers .",
        "each spark worker learns a partial deep model on a partition of the overall mbd , and a master deep model is then built by averaging the parameters of all partial models .",
        "this spark - based framework speeds up the learning of deep models consisting of many hidden layers and millions of parameters .",
        "deep learning researchers commonly suggest that converged models are stuck in local minima .",
        "recent research on deep neural networks has focused primarily on improving accuracy .",
        "recently , the deep neural network ( derived from the artificial neural network ) has attracted many researchers ' attention by its outstanding performance .",
        "in order to improve the deep neural network , many trials have been made by refining the network structure or training strategy .",
        "unlike those trials , in this paper , we focused on the basic propagation function of the artificial neural network and proposed the binarized deep neural network .",
        "in this paper , we propose an automatic detection pipeline based on deep learning for identifying and counting pests in images taken inside field traps .",
        "memory units have been widely used to enrich the capabilities of deep networks on capturing long - term dependencies in reasoning and prediction tasks , but little investigation exists on deep generative models ( dgms ) which are good at inferring high - level invariant representations from unlabeled data .",
        "this paper presents a deep generative model with a possibly large external memory and an attention mechanism to capture the local detail information that is often lost in the bottom - up abstraction process in representation learning .",
        "it can be combined with any learning algorithm and any non - linear function approximation , including the important special case of deep learning .",
        "previous work on applying deep learning to this domain relied on clipping the rewards to make learning in different games more homogeneous , but this uses the domain - specific knowledge that in these games counting rewards is often almost as informative as summing these .",
        "this means that our method can also be applied successfully to recurrent models such as lstms and to noise - sensitive applications such as deep reinforcement learning or generative models , for which batch normalization is less well suited .",
        "we demonstrate the usefulness of our method on applications in supervised image recognition , generative modelling , and deep reinforcement learning .",
        "we illustrate the parallel clones method and hierarchical conflict propagation with a character - level deep rnn tasked with memorizing a paragraph of moby dick ( by herman melville ) .",
        "this typically requires deep knowledge on which skills are typically needed for the position , what are their alternatives , which companies are likely to have such candidates , etc .",
        "the increasing complexity of deep neural networks ( dnns ) has made it challenging to exploit existing large - scale data process pipelines for handling massive data and parameters involved in dnn training .",
        "in this paper , we propose deepspark , a distributed and parallel deep learning framework that simultaneously exploits apache spark for large - scale distributed data management and caffe for gpu - based acceleration .",
        "deepspark directly accepts caffe input specifications , providing seamless compatibility with existing designs and network structures .",
        "to support parallel operations , deepspark automatically distributes workloads and parameters to caffe - running nodes using spark and iteratively aggregates training results by a novel lock - free asynchronous variant of the popular elastic averaging stochastic gradient descent ( sgd ) update scheme , effectively complementing the synchronized processing capabilities of spark .",
        "deepspark is an on - going project , and the current release is available at",
        "to enhance the performance of affective models and reduce the cost of acquiring physiological signals for real - world applications , we adopt multimodal deep learning approach to construct affective models from multiple physiological signals .",
        "11 % on seed dataset is achieved with shared representations generated by deep autoencoder ( dae ) model .",
        "for multimodal facilitation tasks , we demonstrate that the bimodal deep autoencoder ( bdae ) achieves the mean accuracies of 91 .",
        "despite its simplicity , analyzing its running time and quality of approximation is surprisingly difficult and can lead to deep insights that can be used to improve the algorithm .",
        "with the deployment of deep packet inspection ( dpi ) in telecom networks , it is possible for the telco operators to obtain user online preference .",
        "convolutional neural networks with rectified linear activation and max or average pooling , are the cornerstone of modern deep learning .",
        "specifically , it is known that convolutional arithmetic circuits posses the property of \" complete depth efficiency \" , meaning that besides a negligible set , all functions that can be implemented by a deep network of polynomial size , require exponential size in order to be implemented ( or even approximated ) by a shallow network .",
        "in this paper , we explore algorithms and representations to reduce the sample complexity of deep reinforcement learning for continuous control tasks .",
        "while shallow methods like information extraction techniques are robust to data scarcity , they are less expressive than deep understanding methods , thereby failing at answering questions involving multiple constraints .",
        "while the universal approximation property holds both for hierarchical and shallow networks , we prove that deep ( hierarchical ) networks can approximate the class of compositional functions with the same accuracy as shallow networks but with exponentially lower vc - dimension as well as the number of training parameters .",
        "this leads to the question of approximation by sparse polynomials ( in the number of independent parameters ) and , as a consequence , by deep networks .",
        "for example , it is now well - known that the arithmetic operations of deep networks can be encoded down to 8 - bit fixed - point without significant deterioration in performance .",
        "our method combines fictitious self - play with deep reinforcement learning .",
        "in this paper , we explore the ability of deep feed - forward models to learn such intuitive physics .",
        "while the authors of batch normalization ( bn ) identify and address an important problem involved in training deep networks - - \\ textit { internal covariate shift } - - the current solution has multiple drawbacks .",
        "we exploit the observation that the pre - activation before rectified linear units follow a gaussian distribution in deep networks , and that once the first and second order statistics of any given dataset are normalized , we can forward propagate this normalization without the need for recalculating the approximate",
        "thanks to the size of these datasets , the associated text comprehension task is well suited for deep - learning techniques that currently seem to outperform all alternative approaches .",
        "in the specific case of musical harmony , defining the salient features of chord transitions and evaluating invented harmonic spaces requires deep musicological background knowledge .",
        "our work is based on both deep generative model for semi - supervised learning \\ cite { kingma2014semi } and variational auto - encoder for sequence modeling \\ cite { bowman2015generating } .",
        "we introduce the drow detector , a deep learning based detector for 2d range data .",
        "deep neural networks are capable of modelling highly non - linear functions by capturing different levels of abstraction of data hierarchically .",
        "while training deep networks , first the system is initialized near a good optimum by greedy layer - wise unsupervised pre - training .",
        "in this paper a synchronized parallel algorithm for pre - training deep networks on multi - core machines has been proposed .",
        "deep learning consists in training neural networks to perform computations that sequentially unfold in many steps over a time dimension or an intrinsic depth dimension .",
        "effective learning in this setting is usually accomplished by specialized network architectures that are designed to mitigate the vanishing gradient problem of naive deep networks .",
        "many of these architectures , such as lstms , grus , highway networks and deep residual network , are based on a single structural principle : the state passthrough .",
        "we propose the method of deep shifting , which remembers previously calculated results of convolution operations in order to minimize the number of calculations .",
        "it is able to retrieve a deep semantic meaning representation for the discourse from the memory .",
        "previous studies exploit discriminative models that are built on either powerful manual features or deep discourse representations .",
        "we use deep neural networks to address both tasks , quantitatively and qualitatively measure the results in a variety of novel manners , and present a thorough investigation of the weaknesses and strengths of the approach .",
        "the system is flexible and can be used to express a wide variety of algorithms , including training and inference algorithms for deep neural network models , and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields , including speech recognition , computer vision , robotics , information retrieval , natural language processing , geographic information extraction , and computational drug discovery .",
        "coreference resolution is one of the first stages in deep language understanding and its importance has been well recognized in the natural language processing community .",
        "deep neural networks ( dnn ) have shown unprecedented success in various computer vision applications such as image classification and object detection .",
        "in this work we present a deep learning framework for video compressive sensing .",
        "we then extend the linear formulation to deep fully - connected networks and explore the performance gains using deeper architectures .",
        "we develop machine learning systems with this important capacity by developing new deep generative models , models that combine the representational power of deep learning with the inferential power of bayesian reasoning .",
        "many deep convolutional neural networks ( cnn ) make incorrect predictions on adversarial samples obtained by imperceptible perturbations of clean samples .",
        "our proposed task offers a new challenge to the community which we hope can spur further interest in exploring deeper connections between vision & amp ; language .",
        "in this paper we propose a technique for domain adaptation in stacked autoencoder ( sae ) based deep neural networks ( dnn ) performed in two stages : ( i ) unsupervised weight adaptation using systematic dropouts in mini - batch training , ( ii ) supervised fine - tuning with limited number of labeled samples in target domain .",
        "the resulting deep shading simulates all screen - space effects as well as arbitrary combinations thereof at competitive quality and speed while not being programmed by human experts but learned from example images .",
        "we present a deep learning approach for speeding up constrained procedural modeling .",
        "we present a deep hierarchical recurrent neural network for sequence tagging .",
        "given a sequence of words , our model employs deep gated recurrent units on both character and word levels to encode morphology and context information , and applies a conditional random field layer to predict the tags .",
        "combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce unpredictability of the neural models .",
        "in this paper we present architectures based on deep neural nets for gesture recognition in videos , which are invariant to local scaling .",
        "we present a new action recognition deep neural network which adaptively learns the best action velocities in addition to the classification .",
        "while deep neural networks have reached maturity for image understanding tasks , we are still exploring network topologies and features to handle the richer environment of video clips .",
        "in this paper , we revisit the algorithm introduced in [ 1 ] and present a deep interpretation of this framework that achieves state - of - the - art under such challenging scenarios .",
        "in our deep network architecture the global and local constraints that define a face can be efficiently modeled and learned end - to - end using training data .",
        "we optimize the deep network using a new loss function for super - resolution that combines reconstruction error with a learned face quality measure in adversarial setting , producing improved visual results .",
        "here , we present a tutorial of deep neural networks ( dnns ) , and some insights about the origin of the term \" deep \" ; references to deep learning are also given .",
        "deep belief networks ( dbns ) , which are used to build networks with more than two layers , are also described .",
        "this system has the capability to process key machine learning algorithms such as deep neural network , autoencoder , and k - means clustering .",
        "in this paper , we present deep extreme feature extraction ( defe ) , a new ensemble mva method for searching $ \\ tau ^ { + } \\ tau ^ { - } $ channel of higgs bosons in high energy physics .",
        "defe can be viewed as a deep ensemble learning scheme that trains a strongly diverse set of neural feature learners without explicitly encouraging diversity and penalizing correlations .",
        "this is achieved by adopting an implicit neural controller ( not involved in feedforward compuation ) that directly controls and distributes gradient flows from higher level deep prediction network .",
        "defe makes the ensembles ' deep ' in the sense that it allows deep post - process of these features that tries to learn to select and abstract the ensemble of neural feature learners .",
        "in comparison of the classic deep neural network , defe shows a state - of - the - art performance : the error rate has decreased by about 37 \\ % , the accuracy has broken through 90",
        "in this paper , we propose a new deep learning approach , called neural association model ( nam ) , for probabilistic reasoning in artificial intelligence .",
        "in this work , as two case studies , we have investigated two nam structures , namely deep neural networks ( dnns ) and relation modulated neural nets ( rmnns ) , on several probabilistic reasoning tasks in ai , including recognizing textual entailment , triple classification in multirelational knowledge bases and common - sense reasoning .",
        "considering that recurrent neural networks ( rnns ) with long short - term memory ( lstm ) can learn feature representations and model long - term temporal dependencies automatically , we propose an end - to - end fully connected deep lstm network for skeleton based action recognition .",
        "to train the deep lstm network effectively , we propose a new dropout algorithm which simultaneously operates on the gates , cells , and output responses of the lstm neurons .",
        "as a consequence , the deep learning tool - chain can perform as an early detection framework for combustion instabilities that will have a transformative impact on the safety and performance of modern engines .",
        "recently , deep learning techniques have enjoyed success in various multimedia applications , such as image classification and multi - modal data analysis .",
        "large deep learning models are developed for learning rich representations of complex data .",
        "there are two challenges to overcome before deep learning can be widely adopted in multimedia and other applications .",
        "the other is scalability , that is the deep learning system must be able to provision for a huge demand of computing resources for training large models with massive datasets .",
        "to address these two challenges , in this paper , we design a distributed deep learning platform called singa which has an intuitive programming model based on the common layer abstraction of deep learning models .",
        "singa runs on gpus as well as on cpus , and we show that it outperforms many other state - of - the - art deep learning systems .",
        "our experience with developing and training deep learning models for real - life multimedia applications in singa shows that the platform is both usable and scalable .",
        "we employ a deep q - network , trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort .",
        "meanwhile , the abundant online review resources concerning academic books can be used to mine deeper information and content utilizing altmetric perspectives .",
        "the problem of rare and unknown words is an important issue that can potentially effect the performance of many nlp systems , including both traditional count based models and deep learning models .",
        "this paper introduces the visually informed embedding of word ( view ) , a continuous vector representation for a word extracted from a deep neural model trained using the microsoft coco data set to forecast the spatial arrangements between visual objects , given a textual description .",
        "the model is composed of a deep multilayer perceptron ( mlp ) stacked on the top of a long short term memory ( lstm ) network , the latter being preceded by an embedding layer .",
        "deep neural networks ( dnns ) are powerful types of artificial neural networks ( anns ) that use several hidden layers .",
        "we report an implementation of a clinical information extraction tool that leverages deep neural network to annotate event spans and their attributes from raw clinical notes and pathology reports .",
        "to address this challenge , we propose a new deep neural network architecture that jointly leverage pre - trained word embedding and auxiliary character embedding to learn sentence meanings .",
        "deep learning has dramatically improved the performance of speech recognition systems through learning hierarchies of features optimized for the task at hand .",
        "we present a deep neural network ( dnn ) acoustic model including parametrised and differentiable pooling operators .",
        "this work , concerning paraphrase identification task , on one hand contributes to expanding deep learning embeddings to include continuous and discontinuous linguistic phrases .",
        "this work presents an end - to - end trainable deep bidirectional lstm ( long - short term memory ) model for image captioning .",
        "our model builds on a deep convolutional neural network ( cnn ) and two separate lstm networks .",
        "two novel deep bidirectional variant models , in which we increase the depth of nonlinearity transition in different way , are proposed to learn hierarchical visual - language embeddings .",
        "data augmentation techniques such as multi - crop , multi - scale and vertical mirror are proposed to prevent overfitting in training deep models .",
        "the recent success of deep learning approaches for domains like speech recognition ( hinton et al .",
        "while a single gpu often provides algorithmic simplicity and speed up to a given scale of data and model , there exist an operating point where a distributed implementation of training algorithms for deep architectures becomes necessary .",
        "residual learning has recently surfaced as an effective means of constructing very deep neural networks for object recognition .",
        "we propose a novel extension of residual learning for deep networks that enables intuitive learning across multiple related tasks using cross - connections called cross - residuals .",
        "we investigate the $ \\ ell _ \\ infty $ - constrained representation which demonstrates robustness to quantization errors , utilizing the tool of deep learning .",
        "based on the alternating direction method of multipliers ( admm ) , we formulate the original convex minimization problem as a feed - forward neural network , named \\ textit { deep $ \\ ell _ \\ infty $ encoder } , by introducing the novel bounded linear unit ( blu ) neuron and modeling the lagrange multipliers as network biases .",
        "we then investigate the effective use of the proposed model in the application of hashing , by coupling the proposed encoders under a supervised pairwise loss , to develop a \\ textit { deep siamese $ \\ ell _ \\ infty $ network } , which can be optimized from end to end .",
        "representation and learning of commonsense knowledge is one of the foundational problems in the quest to enable deep language understanding .",
        "we discuss these implications for script and story learning , and offer suggestions for deeper language understanding .",
        "very deep cnns with small 3x3 kernels have recently been shown to achieve very strong performance as acoustic models in hybrid nn - hmm speech recognition systems .",
        "in this paper , we demonstrate that the accuracy gains of these deep cnns are retained both on larger scale data , and after sequence training .",
        "our very deep cnn model sequence trained on the 2000h switchboard dataset obtains 9 .",
        "as recurrent neural networks become larger and deeper , training times for single networks are rising into weeks or even months .",
        "this tension has recently surfaced in the realm of educational data mining , where a deep learning approach to predicting students ' performance as they work through a series of exercises - - - termed deep knowledge tracing or dkt - - - has demonstrated a stunning performance advantage over the mainstay of the field , bayesian knowledge tracing or bkt .",
        "the success of deep neural networks is mostly due their ability to learn meaningful features from the data .",
        "features learned in the hidden layers of deep neural networks trained in computer vision tasks have been shown to be similar to mid - level vision features .",
        "in this paper , we describe a novel deep convolutional neural networks ( cnn ) based approach called contextual deep cnn that can jointly exploit spatial and spectral features for hyperspectral image classification .",
        "the contextual deep cnn first concurrently applies multiple 3 - dimensional local convolutional filters with different sizes jointly exploiting spatial and spectral features of a hyperspectral image .",
        "we begin with the observation that a shallow rnn is exactly equivalent to a very deep resnet with weight sharing among the layers .",
        "we propose 1 ) a generalization of both rnn and resnet architectures and 2 ) the conjecture that a class of moderately deep rnns is a biologically - plausible model of the ventral stream in visual cortex .",
        "in contrast , most deep learning architectures are computationally wasteful in that they consider every part of the input when performing an image processing task .",
        "the deep slow local representations are learned offline on unlabeled data and transferred to the observational model of our proposed tracker .",
        "specifically , deep recurrent neural networks were used for improving joint positions and velocities of kinect skeleton , and three methods were proposed to integrate the refined positions and velocities for further enhancement .",
        "here we propose a simple initial seed selection algorithm for k - means clustering along one attribute that draws initial cluster boundaries along the ' deepest valleys ' or greatest gaps in dataset .",
        "an architecture which implements reflexivity may be based on the interaction of one or several modules of deep learning , which may be specialized or not , and interconnected in a relevant way .",
        "we present hierarchical - dqn ( h - dqn ) , a framework to integrate hierarchical value functions , operating at different temporal scales , with intrinsically motivated deep reinforcement learning .",
        "secondly , we build a deep learning - based dp generator for input sentences in decoding when no corresponding references exist .",
        "recently , researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning .",
        "the agent learns reusable skills using deep q networks ( mnih et .",
        "these reusable skills , which we refer to as deep skill networks ( dsns ) , are then incorporated into our novel hierarchical deep reinforcement learning network ( h - drln ) architecture .",
        "the h - drln is a hierarchical version of deep qnetworks and learns to efficiently solve tasks by reusing knowledge from previously learned dsns .",
        "the h - drln exhibits superior performance and lower learning sample complexity ( by taking advantage of temporal extension ) compared to the regular deep q network ( mnih et .",
        "this paper applies a deep convolutional / highway mlp framework to classify genomic sequences on the transcription factor binding site task .",
        "we show that our system , deep motif ( demo ) , extracts motifs that are similar to , and in some cases outperform the current well known motifs .",
        "in addition , we find that a deeper model consisting of multiple convolutional and highway layers can outperform a single convolutional and fully connected layer in the previous state - of - the - art .",
        "deep learning is a very powerful machine learning model .",
        "deep learning trains a large number of parameters for multiple layers and is very slow when data is in large scale and the architecture size is large .",
        "inspired from the shrinking technique used in accelerating computation of support vector machines ( svm ) algorithm and screening technique used in lasso , we propose a shrinking deep learning with recall ( sdlr ) approach to speed up deep learning computation .",
        "we experiment shrinking deep learning with recall ( sdlr ) using deep neural network ( dnn ) , deep belief network ( dbn ) and convolution neural network ( cnn ) on 4 data sets .",
        "results show that the speedup using shrinking deep learning with recall ( sdlr ) can reach more than 2 .",
        "consequently , a lengthy sequence of algorithm iterations can be viewed as a deep network with shared , hand - crafted layer weights .",
        "in contrast , we demonstrate both theoretically and empirically the potential for a trained deep network to recover minimal $ \\ ell _ 0 $ - norm representations in regimes where existing methods fail .",
        "here we present deeplift ( learning important features ) , an efficient and effective method for computing importance scores in a neural network .",
        "deeplift compares the activation of each neuron to its ' reference activation ' and assigns contribution scores according to the difference .",
        "we apply deeplift to models trained on natural images and genomic data , and show significant advantages over gradient - based methods .",
        "the recent advances in deep neural networks have led to effective vision - based reinforcement learning methods that have been employed to obtain human - level controllers in atari 2600 games from pixel data .",
        "using convolutional deep neural networks with q - learning and experience replay , for both scenarios , we were able to train competent bots , which exhibit human - like behaviors .",
        "we study the problem of how to distribute the training of large - scale deep learning models in the parallel computing environment .",
        "an asynchronous and momentum variant of the easgd method is applied to train deep convolutional neural networks for image classification on the cifar and imagenet datasets .",
        "we also present how deep nade models can be trained to be agnostic to the ordering of input dimensions used by the autoregressive product rule decomposition .",
        "finally , we also show how to exploit the topological structure of pixels in images using a deep convolutional architecture for nade .",
        "lightnet is a lightweight , versatile and purely matlab - based deep learning framework .",
        "the aim of the design is to provide an easy - to - understand , easy - to - use and efficient computational platform for deep learning research .",
        "the implemented framework supports major deep learning architectures such as multilayer perceptron networks ( mlp ) , convolutional neural networks ( cnn ) and recurrent neural networks ( rnn ) .",
        "recently , a few deep learning models have surpassed the traditional window based multilayer perceptron .",
        "taking inspiration from the image classification domain we propose a deep convolutional neural network architecture , must - cnn , to predict protein properties .",
        "\\ cite { hermann2015teaching } therefore release a large scale news article dataset and propose a deep lstm reader system for machine comprehension .",
        "in recent years , deep architectures have been used for transfer learning with state - of - the - art performance in many datasets .",
        "in this work , we present an extensive analysis of the resiliency of feature vectors extracted from deep models , with special focus on the trade - off between performance and compression rate .",
        "by introducing perturbations to image descriptions extracted from a deep convolutional neural network , we change their precision and number of dimensions , measuring how it affects the final score .",
        "we show that deep features are more robust to these disturbances when compared to classical approaches , achieving a compression rate of 98 .",
        "our deep learning algorithm significantly outperforms the previous state - of - the - art .",
        "she will get \" smarter \" and more empathetic through its deep learning algorithms , and by gathering more data and learning from it .",
        "in this paper , we present our work so far in the areas of deep learning of emotion and sentiment recognition , as well as humor recognition .",
        "predictions of prominent ai researchers vary broadly from very pessimistic predictions of andrew ng to much more moderate predictions of geoffrey hinton and optimistic predictions of shane legg , deepmind cofounder .",
        "in this paper we present deeplearningkit - an open source framework that supports using pretrained deep learning models ( convolutional neural networks ) for ios , os x and tvos .",
        "deeplearningkit is developed in metal in order to utilize the gpu efficiently and swift for integration with applications , e .",
        "the goal is to support using deep learning models trained with popular frameworks such as caffe , torch , tensorflow , theano , pylearn , deeplearning4j and mocha .",
        "given the massive gpu resources and time required to train deep learning models we suggest an app store like model to distribute and download pretrained and reusable deep learning models .",
        "linkedin search is deeply personalized - for the same queries , different searchers expect completely different results .",
        "deep learning algorithm display powerful ability in computer vision area , in recent year , the cnn has been applied to solve problems in the subarea of image - generating , which has been widely applied in areas such as photo editing , image design , computer animation , real - time rendering for large scale of scenes and for visual effects in movies .",
        "the state - of - art cnn can not capture the spatial location of texture in image , lead to significant distortion after texture synthesize , we propose a new way to generating - image by adding the semantic segment step with deep learning algorithm as pre - processing and analyze the outcome .",
        "deep neural networks are typically represented by a much larger number of parameters than shallow models , making them prohibitive for small footprint devices .",
        "recent research shows that there is considerable redundancy in the parameter space of deep neural networks .",
        "in this paper , we propose a method to compress deep neural networks by using the fisher information metric , which we estimate through a stochastic optimization method that keeps track of second - order information in the network .",
        "in this paper , a deep neural network is proposed to incorporate background knowledge for conversation modeling .",
        "finally , we present our attempts to extend the automated skills acquisition framework to complex tasks such as learning to play video games where we use deep learning techniques for representation learning to aid our spatio -",
        "deep reinforcement learning methods have achieved state of the art performance in learning control policies for the games in the atari 2600 domain .",
        "the current state of the art architectures like deep q - network ( dqn ) and dueling network architectures ( dudqn ) consist of a framework with a static frame skip rate , where the action output from the network is repeated for a fixed number of frames regardless of the current state .",
        "in this paper , we propose a new architecture , dynamic frame skip deep q - network ( dfdqn ) which makes the frame skip rate a dynamic learnable parameter .",
        "deep learning ( dl ) became the method of choice in recent years for solving problems ranging from object recognition and speech recognition to robotic perception and human disease prediction .",
        "the learning of stage - wise transformations provides deep insights into the physical flow deformation .",
        "recently , there is rising interest in modelling the interactions of two sentences with deep neural networks .",
        "in this paper , we propose a deep architecture to model the strong interaction of sentence pair with two coupled - lstms .",
        "despite recent breakthroughs in the applications of deep neural networks , one setting that presents a persistent challenge is that of \" one - shot learning . \"",
        "we show that our method achieves reasonably competitive performance on some standard \" deep learning \" image classification datasets such as cifar - 10 and svhn , and also state - of - the - art results for image super - resolution , demonstrating",
        "here , we first propose a new intuitive principle of unsupervised deep learning from time series which uses the nonstationary structure of the data .",
        "this setting is considered shallow in the era of deep learning .",
        "in this paper , we present a new deep multi - task representation learning framework that learns cross - task sharing structure at every layer in a deep network .",
        "our approach is based on generalising the matrix factorisation techniques explicitly or implicitly used by many conventional mtl algorithms to tensor factorisation , to realise automatic learning of end - to - end knowledge sharing in deep networks .",
        "this is in contrast to existing deep learning approaches that need a user - defined multi - task sharing strategy .",
        "experiments demonstrate the efficacy of our deep multi - task representation learning in terms of both higher accuracy and fewer design choices .",
        "deep neural networks can capture complex non - linear features ; however this ability comes at the cost of high computational and memory requirements .",
        "to enable embedded devices such as smartphones , google glasses and monitoring cameras with the astonishing power of deep learning , dedicated hardware accelerators can be used to decrease both execution time and power consumption .",
        "many hardware accelerators for deep neural networks have been proposed recently .",
        "a first important step of accelerator design is hardware - oriented approximation of deep networks , which enables energy - efficient inference .",
        ", only 10 - 34 layers deep .",
        "our sparse connection structure facilitates a significant reduction in computational cost and number of parameters of state - of - the - art deep cnns without compromising accuracy .",
        "for the deeper resnet 200 our model has 25 % fewer floating point operations and 44 % fewer parameters , while maintaining state - of - the - art accuracy .",
        "large knowledge bases ( kbs ) are useful in many tasks , but it is unclear how to integrate this sort of knowledge into \" deep \" gradient - based learning systems .",
        "as the complexity of deep neural networks ( dnns ) trend to grow to absorb the increasing sizes of data , memory and energy consumption has been receiving more and more attentions for industrial applications , especially on mobile devices .",
        "for each entry in a deep net , funhashnn uses multiple low - cost hash functions to fetch values in the compression space , and then employs a small reconstruction network to recover that entry .",
        "deep networks rely on massive amounts of labeled data to learn powerful models .",
        "this paper addresses deep transfer learning under a more general scenario that the joint distributions of features and labels may change substantially across domains .",
        "transfer learning is enabled in deep convolutional networks , where the dataset shifts may linger in multiple task - specific feature layers and the classifier layer .",
        "by embracing deep neural networks , we are able to demonstrate end - to - end learning of protocols in complex environments inspired by communication riddles and multi - agent computer vision problems with partial observability .",
        "the former uses deep q - learning , while the latter exploits the fact that , during learning , agents can propagate error derivatives through ( noisy ) communication channels .",
        "deep conditional generative models are developed to simultaneously learn the temporal dependencies of multiple sequences .",
        "we show that a polynomially sized deep network supports exponentially high separation ranks for certain input partitions , while being limited to polynomial separation ranks for others .",
        "in addition to analyzing deep networks , we show that shallow ones support only linear separation ranks , and by this gain insight into the benefit of functions brought forth by depth - they are able to efficiently model strong correlation under favored partition",
        "as the emerging field of machine learning , deep learning shows excellent ability in solving complex learning problems .",
        "however , the size of the networks becomes increasingly large scale due to the demands of the practical applications , which poses significant challenge to construct a high performance implementations of deep learning neural networks .",
        "in order to improve the performance as well to maintain the low power cost , in this paper we design dlau , which is a scalable accelerator architecture for large - scale deep learning networks using fpga as the hardware prototype .",
        "the dlau accelerator employs three pipelined processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications .",
        "recent advances in deep learning have enabled the extraction of high - level features from raw sensor data which has opened up new possibilities in many different fields , including computer generated choreography .",
        "at the core of chor - rnn is a deep recurrent neural network trained on raw motion capture data and that can generate new dance sequences for a solo dancer .",
        "recent progress on many imaging and vision tasks has been driven by the use of deep feed - forward neural networks , which are trained by propagating gradients of a loss defined on the final output , back through the network up to the first layer that operates directly on the image .",
        "for an expected loss function of a deep nonlinear neural network , we prove the following statements under the independence assumption adopted from recent work : 1 ) the function is non - convex and non - concave , 2 ) every local minimum is a global minimum , 3 ) every critical point that is not a global minimum is a saddle point , and 4 ) the property of saddle points differs for shallow networks ( with three layers ) and deeper networks ( with more than three layers ) .",
        "moreover , we prove that the same four statements hold for deep linear neural networks with any depth , any widths and no unrealistic assumptions .",
        "as a result , we present an instance , for which we can answer to the following question : how difficult to directly train a deep model in theory ?",
        "we note that even though we have advanced the theoretical foundations of deep learning , there is still a",
        "deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance .",
        "however , each fraction of a percent of improved accuracy costs nearly doubling the number of layers , and so training very deep residual networks has a problem of diminishing feature reuse , which makes these networks very slow to train .",
        "we call the resulting network structures wide residual networks ( wrns ) and show that these are far superior over their commonly used thin and very deep counterparts .",
        "for example , we demonstrate that even a simple 16 - layer - deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks , including thousand - layer - deep networks , achieving new state - of - the - art results on cifar - 10 , cifar - 100 and svhn .",
        "we show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the mnist and cifar - 10 datasets .",
        "in this paper , we attack the anomaly detection problem by directly modeling the data distribution with deep architectures .",
        "we propose deep structured energy based models ( dsebms ) , where the energy function is the output of a deterministic deep neural network with structure .",
        "large labeled training sets are the critical building blocks of supervised learning methods and are key enablers of deep learning techniques .",
        "we present a new framework of applying deep neural networks ( dnn ) to devise a universal discrete denoiser .",
        "to the best of our knowledge , this is the first work to apply deep learning to open ie .",
        "further , we are proposing \" deepsurvey \" as a mechanism embodying the entire process from the reading through all the papers , the generation of ideas , and to the writing of paper .",
        "first steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made - - - for the continuous - time case - - - in mallat , 2012 , and wiatowski and b \\ \" olcskei , 2015 .",
        "we develop a scalable and extendable training framework that can utilize gpus across nodes in a cluster and accelerate the training of deep learning models based on data parallelism .",
        "finally , we release the framework as open - source for further research on distributed deep learning",
        "apart from traditional approach , including named entity recognition ( ner ) solutions , a novel technique , called deep entity recognition ( deeper ) , is introduced and implemented .",
        "deeper also provides automatic evaluation , which makes possible numerous experiments , including over a thousand questions from a quiz tv show answered on the grounds of polish wikipedia .",
        "the final results of a manual evaluation on a separate question set show that the strength of deeper approach lies in its ability to answer questions that demand answers beyond the traditional categories of named entities .",
        "we introduce a deep memory network for aspect level sentiment classification .",
        "the deep memory network with 9 layers is 15 times faster than lstm with a cpu implementation .",
        "we then use these tasks to systematically compare and contrast existing deep reinforcement learning ( drl ) architectures with our new memory - based drl architectures .",
        "in the original mvso release , adjective - noun pair ( anp ) detectors were trained for the six languages using an alexnet - styled architecture by fine - tuning from deepsentibank .",
        "this paper presents research in progress investigating the viability and adaptation of reinforcement learning using deep neural network based function approximation for the task of radio control and signal detection in the wireless domain .",
        "deep neural networks ( dnns ) have demonstrated state - of - the - art results on many pattern recognition tasks , especially vision classification problems .",
        "here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful , learned prior : a deep generator network ( dgn ) .",
        "the activation function of deep neural networks ( dnns ) has undergone many changes during the last decades .",
        "auto - encoders are often used as building blocks of deep network classifier to learn feature extractors , but task - irrelevant information in the input data may lead to bad extractors and result in poor generalization performance of the network .",
        "finally , cf - nade can be extended to a deep model , with only moderately increased computational complexity .",
        "this paper proposes an approach that predicts the road course from camera sensors leveraging deep learning techniques .",
        "attention mechanisms have recently been introduced in deep learning for various tasks in natural language processing and computer vision .",
        "while there are methods with optimality guarantees in the setting of discrete state and action spaces , these methods cannot be applied in high - dimensional deep rl scenarios .",
        "non - linear extensions based on kernels and ( deep ) neural networks are derived , achieving better performance than the linear ones .",
        "the maturity of deep learning techniques has led in recent years to a breakthrough in object recognition in visual media .",
        "furthermore , we evaluated the performances of the architectures with varying the number of layers on a larger dataset ( million song dataset ) , and found that deeper models outperformed the 4 - layer architecture .",
        "our system does not rely on handwritten rules or engineered features ; instead , we train deep neural networks on a large conversational dataset .",
        "general game playing artificial intelligence has recently seen important advances due to the various techniques known as ' deep learning ' .",
        "on the other hand , deep learning systems which do beat human champions , such as in go , do not generalise well .",
        "the power of deep learning simultaneously exposes its weakness .",
        "given that deep learning is mostly clever reconfigurations of well - established methods , moving beyond the state of art calls for forward - thinking visionary solutions , not just more of the same .",
        "pretraining is widely used in deep neutral network and one of the most famous pretraining models is deep belief network ( dbn ) .",
        "in this paper , we pretrained deep neutral network by different pretraining models and hence investigated the difference between dbn and stacked denoising autoencoder ( sda ) when used as pretraining model .",
        "in recent year , parallel implementations have been used to speed up the training of deep neural networks ( dnn ) .",
        "this paper presents an universal framework for exploiting these multi - typed treebanks to improve parsing with deep multi - task learning .",
        "we propose a simple duality between this dense associative memory and neural networks commonly used in deep learning .",
        "on the deep learning side of the duality , this family corresponds to feedforward neural networks with one hidden layer and various activation functions , which transmit the activities of the visible neurons to the hidden layer .",
        "in this paper , we show that by feeding the weights of a deep neural network ( dnn ) during training into a deep q - network ( dqn ) as its states , this dqn can learn policies to accelerate the training of that dnn .",
        "in this paper , we show how to integrate these goals , applying deep reinforcement learning to model future reward in chatbot dialogue .",
        "in recent years deep neural networks have achieved great success in sentiment classification for english , thanks in part to the availability of copious annotated resources .",
        "to combat this problem , we propose the adversarial deep averaging network ( adan ) to transfer sentiment knowledge learned from labeled english data to low - resource languages where only unlabeled data exists .",
        "in order to capture some of these advantages in machine perception , we ask two questions : whether deep neural networks can learn universal image representations , useful not only for a single task but for all of them , and how the solutions to the different tasks can be integrated in this framework .",
        "we answer by proposing a new architecture , which we call \\ emph { multinet } , in which not only deep image features are shared between tasks , but where tasks can interact in a recurrent manner by encoding the results of their analysis in a common shared representation of the data .",
        "however , these architectures are rather shallow in comparison to the deep convolutional networks which are very successful in computer vision .",
        "to the best of our knowledge , this is the first time that very deep convolutional nets have been applied to nlp .",
        "the purposes of the ssa ontology are to explore the potential for ontology development and engineering to ( i ) represent ssa data , general knowledge , and domain objects , ( ii ) clearly annotate and express the meaning of that orbital , near - earth and deep - space da - ta , and ( iii ) foster ssa data sharing among ssa actors and space object catalogs .",
        "by improving global ssa via actionable data - and knowledge - exchange , we can achieve the broader goals ( and motivations ) of ( iv ) advancing our capacity for planetary defense from near - or deep - space ob - ects , and ( v ) improving spaceflight safety for future generations .",
        "recent results show that deep neural networks achieve excellent performance even when , during training , weights are quantized and projected to a binary representation .",
        "powered by deep recurrent neural networks and neural embeddings , our proposed cfo achieves an accuracy of 75 .",
        "the google deepmind challenge match in march 2016 was a historic achievement for computer go development .",
        "recently there has been an increasing trend to use deep learning frameworks for both 2d consumer images and for 3d medical images .",
        "however , there has been little effort to use deep frameworks for volumetric vascular segmentation .",
        "we demonstrated the use of deep learning framework consisting both 2d and 3d convolutional filters ( convnet ) .",
        "inspired by this connection , we develop deep convolutional networks using a family of structured convolutional matrices and achieve state - of - the - art trade - off between energy efficiency and classification accuracy for well - known image recognition tasks .",
        "we empirically show that ( i ) by modeling uncertainty on the output value , disco nets outperform equivalent non - probabilistic predictive networks and ( ii ) disco nets accurately model the uncertainty of the output , outperforming existing probabilistic models based on deep neural networks .",
        "this paper presents an end - to - end framework for task - oriented dialog systems using a variant of deep recurrent q - networks ( drqn ) .",
        "seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local , next - word distributions .",
        "building systems that possess the sensitivity and intelligence to identify and describe high - level attributes in music audio signals continues to be an elusive goal , but one that surely has broad and deep implications for a wide variety of applications .",
        "we carry this intuition forward in our second approach , and probe deeper into the nature of graph - based systems by designing several summarizers based on centrality measures .",
        "in this paper , we propose to use deep policy networks which are trained with an advantage actor - critic method for statistically optimised dialogue systems .",
        "first , we show that , on summary state and action spaces , deep reinforcement learning ( rl ) outperforms gaussian processes methods .",
        "in order to remove the need to define such summary spaces , we show that deep rl can also be trained efficiently on the original state and action spaces .",
        "we show that a deep rl method based on an actor - critic architecture can exploit a small amount of data very efficiently .",
        "indeed , with only a few hundred dialogues collected with a handcrafted policy , the actor - critic deep learner is considerably bootstrapped from a combination of supervised and batch rl .",
        "in addition , convergence to an optimal policy is significantly sped up compared to other deep rl methods initialized on the data with batch rl .",
        "we also propose the addition of an intermap pooling ( imp ) layer to deep cnns .",
        "potential areas of investigation , including possible architectures for incorporating machine learning into robotic nodes , training approaches , and the possibility of using deep learning approaches for automatic feature extraction , are discussed .",
        "novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub - actions .",
        "in contrast to many deep multi - task learning work , we do not predefine a parameter sharing strategy by tying some ( usually bottom ) layers ' parameters , instead , our framework allows the sharing for all shareable layers thus the sharing strategy is learned from a pure data - driven way .",
        "despite recent advances in important domains such as vision and language , the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data .",
        "in this work , we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories .",
        "deep neural networks have dramatically advanced the state of the art for many areas of machine learning .",
        "in this work , we introduce a new type of linear connections , named fast - forward connections , based on deep long short - term memory ( lstm ) network , together with the interleaved bi - directional way for stacking them .",
        "fast - forward connections play an essential role to propagate the gradients in building the deep topology of depth 16 .",
        "maximum mean discrepancy ( mmd ) has been successfully applied to learn deep generative models for characterizing a joint distribution of variables via kernel mean embedding .",
        "large - scale supervised classification algorithms , especially those based on deep convolutional neural networks ( dcnns ) , require vast amounts of training data to achieve state - of - the - art performance .",
        "the concept is illustrated by a specific knowledge model provided by a deep generative autoencoder .",
        "we show how real logic can be implemented in deep tensor neural networks with the use of google ' s tensorflow primitives .",
        "deep neural networks have recently been shown to lack robustness against adversarially crafted inputs .",
        "to our knowledge , this is the first time deep learning has been applied to theorem proving .",
        "we perform a study of the factors affecting training time in multi - device deep learning systems .",
        "deep neural networks ( dnn ) have shown promise in a wide range of machine learning tasks , but for behavioral signal processing ( bsp ) tasks their application has been constrained due to limited quantity of data .",
        "then , the hidden layers of these classifiers become parts of a deeper network that integrates all feature streams .",
        "deep reinforcement learning has been shown to be a powerful framework for learning policies from complex high - dimensional sensory inputs to actions in complex tasks , such as the atari domain .",
        "in this paper , we explore output representation modeling in the form of temporal abstraction to improve convergence and reliability of deep reinforcement learning approaches .",
        "we offer analysis and explanation for both convergence and final results , revealing a problem deep rl approaches have with sparse reward signals .",
        "in this work , we propose a novel video captioning framework , termed as \\ emph { bidirectional long - short term memory } ( bilstm ) , which deeply captures bidirectional global temporal structure in video .",
        "unsupervised learning is the most challenging problem in machine learning and especially in deep learning .",
        "we present a novel deep recurrent neural network architecture that learns to build implicit plans in an end - to - end manner by purely interacting with an environment in reinforcement learning setting .",
        "deep neural networks ( dnn ) have been successful in en - hancing noisy speech signals .",
        "in this paper we propose a novel deep learning model inspired by insights from human audio visual perception .",
        "to what extent is the success of deep visualization due to the training ?",
        "could we do deep visualization using untrained , random weight networks ?",
        "to address this issue , we explore new and powerful generative models for three popular deep visualization tasks using untrained , random weight convolutional neural networks .",
        "to our knowledge this is the first demonstration of image representations using untrained deep neural networks .",
        "our work provides a new and fascinating tool to study the representation of deep network architecture and sheds light on new understandings on deep visualization .",
        "our goal is to be able to build a generative model from a deep neural network architecture to try to create music that has both harmony and melody and is passable as music composed by humans .",
        "our approach , however , is to perform end - to - end learning and generation with deep neural nets alone .",
        "experimental results show that the proposed method which is based on semi - supervised training of a deep neural network largely outperforms phoneme based continuous speech recognition on the timit dataset .",
        "while this does not seem like a challenging task , many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35 % - 65 % on benchmark sets .",
        "deep reinforcement learning ( drl ) is a trending field of research , showing great promise in challenging problems such as playing atari , solving go and controlling robots .",
        "discriminative methods based on deep learning , which are very effective in other learning scenarios , are ill - suited for one - shot learning as they need large amounts of training data .",
        "in this paper , we propose a method to learn the parameters of a deep model in one shot .",
        "we construct the learner as a second deep network , called a learnet , which predicts the parameters of a pupil network from a single exemplar .",
        "we study the expressivity of deep neural networks with random weights .",
        "we combine riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic , deep neural networks with random weights .",
        "we prove this generic class of deep random functions cannot be efficiently computed by any shallow network , going beyond prior work restricted to the analysis of single functions .",
        "moreover , we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space .",
        "our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities , and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions .",
        "we present a natural language generator based on the sequence - to - sequence approach that can be trained to produce natural language strings as well as deep syntax dependency trees from input dialogue acts , and we use it to directly compare two - step generation with separate sentence planning and surface realization stages to a joint , one - step approach .",
        "guided by the ranking , recruiters can get deeper insights from candidate profiles and validate why and how the application ranked them .",
        "natural language understanding often requires deep semantic knowledge .",
        "we utilized recent advances in short text categorization using deep learning to create word - level and character - level models .",
        "in conventional deep neural network based speech synthesis , the input text features are repeated for the entire duration of phoneme for mapping text and speech parameters .",
        "we then use this acoustic representation at unit - level to synthesize speech using deep neural network based statistical parametric speech synthesis technique .",
        "in the era of big data and deep learning , there is a common view that machine learning approaches are the only way to cope with the robust and scalable information extraction and summarization .",
        "fisher information and natural gradient provided deep insights and powerful tools to artificial neural networks .",
        "however , the diversity and large - scale data size have posed a significant challenge to construct a flexible and high - performance implementation of deep learning neural networks .",
        "to improve the performance and maintain the scalability , we present cnnlab , a novel deep learning framework using gpu and fpga - based accelerators .",
        "unsupervised learning and supervised learning are key research topics in deep learning .",
        "we present a comprehensive study of deep bidirectional long short - term memory ( lstm ) recurrent neural network ( rnn ) based acoustic models for automatic speech recognition ( asr ) .",
        "in this paper , we introduce a model that employs information retrieval by utilizing convolutional deep structured semantic neural network - based features in the ranker to present human - like responses in ongoing conversation with a user .",
        "in conversations , accounting for context is critical to the retrieval model ; we show that our context - sensitive approach using a convolutional deep structured semantic model ( cdssm ) with character trigrams significantly outperforms several conventional baselines in terms of the relevance of responses retrieved .",
        "current aqp systems either learn models using - a ) various hand - crafted features ( hcf ) or b ) use deep learning ( dl ) techniques which automatically learn the required feature representations .",
        "this latter issue is tackled by recent works dealing with deep representation learn ing of texts .",
        "with this in mind , we argue that embedding kbs within deep neural architectures supporting documentquery matching would give rise to fine - grained latent representations of both words and their semantic relations .",
        "we then propose some avenues to incorporate kbs in deep neural approaches for document ranking .",
        "to address the challenge of detecting dynamic classes of events , we propose a novel deep learning model to classify a given query into a predetermined set of multiple event types .",
        "unlike previous works that optimized mrfs using iterative algorithm , we solve mrf by proposing a convolutional neural network ( cnn ) , namely deep parsing network ( dpn ) , which enables deterministic end - to - end computation in a single forward pass .",
        "recently , a number of deep - learning based models have been proposed for the task of visual question answering ( vqa ) .",
        "we propose a novel approach based on deep neural networks for modeling the dynamics of robot ' s interactions directly from images , by jointly estimating forward and inverse models of dynamics .",
        "we propose a deep learning - based framework to automatically : ( 1 ) tag the images available in a review dataset , ( 2 ) generate a caption for each image that does not have one , and ( 3 ) enhance each review by recommending relevant images that might not be uploaded by the corresponding reviewer .",
        "recent work in information retrieval ( ir ) using deep learning models has yielded state of the art results on a variety of ir tasks .",
        "deep neural networks ( dnn ) are capable of learning ideal representations of data during the training process , removing the need for independently extracting features .",
        "in this paper we propose to use a fully deep neural network ( dnn ) framework to handle the multi - label classification task in a regression way .",
        "a deep pyramid structure was also designed to extract more robust high - level features related to the target tags .",
        "deep feedforward neural networks with many hidden layers also suffer from this effect .",
        "we propose novel object captioner ( noc ) , a deep visual semantic captioning model that can describe a large number of object categories not present in existing image - caption datasets .",
        "here we propose a power - efficient approach for real - time inference , in which deep neural networks ( dnns ) are implemented through low - power analog circuits .",
        "we propose a framework that exploits the power of deep learning to compensate for this mismatch by incorporating the measured variations of the devices as constraints in the dnn training process .",
        "in this work , we pose the task of producing multiple outputs as a learning problem over an ensemble of deep networks - - introducing a novel stochastic gradient descent based approach to minimize the loss with respect to an oracle .",
        "our approach achieves lower oracle error compared to existing methods on a wide range of tasks and deep architectures .",
        "in addition , we dive into open information extraction and deep learning , two emerging and influential techniques and envision next generation of bioie .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "in this paper , we present subgraph2vec , a novel approach for learning latent representations of rooted subgraphs from large graphs inspired by recent advancements in deep learning and graph kernels .",
        "also , we show that the subgraph vectors could be used for building a deep learning variant of weisfeiler - lehman graph kernel .",
        "one is a recent deep reinforcement learning method based on an actor - critic algorithm , deep deterministic policy gradient ( ddpg ) , that has been shown to perform well on various control benchmarks .",
        "neural machine translation ( nmt ) , like many other deep learning domains , typically suffers from over - parameterization , resulting in large storage sizes .",
        "numerical experiments on mnist and 20news demonstrate the ability of this novel deep learning system to learn local , stationary , and compositional features on graphs , as long as the graph is well - constructed .",
        "a catastrophic forgetting problem makes deep neural networks forget the previously learned information , when learning data collected in new environments , such as by different sensors or in different light conditions .",
        "finally , we show our less - forgetting learning method is also helpful to improve the performance of deep neural networks in terms of recognition rates .",
        "we propose a novel deep learning model , which supports permutation invariant training ( pit ) , for speaker independent multi - talker speech separation , commonly known as the cocktail - party problem .",
        "different from most of the prior arts that treat speech separation as a multi - class regression problem and the deep clustering technique that considers it a segmentation ( or clustering ) problem , our model optimizes for the separation regression error , ignoring the order of mixing sources .",
        "this strategy cleverly solves the long - lasting label permutation problem that has prevented progress on deep learning based techniques for speech separation .",
        "however , from gaussian mixture models hmms ( gmm - hmm ) to deep neural network hmms ( dnn - hmm ) , the underlying markovian chain of state - of - the - art models did not changed much .",
        "however , recurrent neural networks with such ' deep ' transition functions remain difficult to train , even when using long short - term memory networks .",
        "guided policy search algorithms can be used to optimize complex nonlinear policies , such as deep neural networks , without directly computing policy gradients in the high - dimensional parameter space .",
        "we propose a technique that tackles these problems by de - conflating the representations of words based on the deep knowledge it derives from a semantic network .",
        "the task contains a rich variety of challenging classification and extraction sub - tasks , making it well - suited for end - to - end models such as deep neural networks ( dnns ) .",
        "high demand for computation resources severely hinders deployment of large - scale deep neural networks ( dnn ) in resource constrained devices .",
        "the results show that for cifar - 10 , regularization on layer depth can reduce 20 layers of a deep residual network ( resnet ) to 18 layers while improve the accuracy from 91 .",
        "the sentence vectors are used as features for subsequent machine learning tasks or for pre - training in the context of deep learning .",
        "the ability of deep convolutional neural networks ( cnn ) to learn discriminative spectro - temporal patterns makes them well suited to environmental sound classification .",
        "this study has two primary contributions : first , we propose a deep convolutional neural network architecture for environmental sound classification .",
        "we show that the improved performance stems from the combination of a deep , high - capacity model and an augmented training set : this combination outperforms both the proposed cnn without augmentation and a \" shallow \" dictionary learning model with augmentation .",
        "unsupervised neural networks , such as restricted boltzmann machines ( rbms ) and deep belief networks ( dbns ) , are powerful tools for feature selection and pattern recognition tasks .",
        "we demonstrate that overfitting occurs in such models just as in deep feedforward neural networks , and discuss possible regularization methods to reduce overfitting .",
        "deep learning has become a ubiquitous technology to improve machine intelligence .",
        "however , most of the existing deep models are structurally very complex , making them difficult to be deployed on the mobile platforms with limited computational power .",
        "the different types of features are integrated in a neural network that uses a novel architecture to learn latent modes of discussion structure that perform as well as deep neural networks but are more interpretable .",
        "the optimization of deep neural networks can be more challenging than traditional convex optimization problems due to the highly non - convex nature of the loss function , e .",
        "in order to cope with a wide range of reverberations in real - world situations , we present novel approaches for acoustic modeling including an ensemble of deep neural networks ( dnns ) and an ensemble of jointly trained dnns .",
        "stacked auto - encoder ( sae ) is a kind of deep learning algorithm for unsupervised learning .",
        "these methods first convert the ascii text to a phonetic script , and then learn a deep neural network to synthesize speech from that .",
        "their inherent deep feedforward structure allows learning complex sequential patterns .",
        "this paper emphasizes the significance to jointly exploit the problem structure and the parameter structure , in the context of deep modeling .",
        "as a specific and interesting example , we describe the deep double sparsity encoder ( ddse ) , which is inspired by the double sparsity model for dictionary learning .",
        "deep learning has been popularized by its recent successes on challenging artificial intelligence problems .",
        "we believe the first step is to examine the characteristics of cutting edge models from across the deep learning community .",
        "our approach is based on deep contextual sequence learning and utilizes stacked bidirectional lstm networks .",
        "recent work has shown that convolutional networks can be substantially deeper , more accurate and efficient to train if they contain shorter connections between layers close to the input and those close to the output .",
        "deep learning has been shown as a successful machine learning method for a variety of tasks , and its popularity results in numerous open - source deep learning software tools coming to public .",
        "training a deep network is usually a very time - consuming process .",
        "to address the huge computational challenge in deep learning , many tools exploit hardware features such as multi - core cpus and many - core gpus to shorten the training time .",
        "however , different tools exhibit different features and running performance when training different types of deep networks on different hardware platforms , which makes it difficult for end users to select an appropriate pair of software and hardware .",
        "in this paper , we aim to make a comparative study of the state - of - the - art gpu - accelerated deep learning software tools , including caffe , cntk , tensorflow , and torch .",
        "first , for deep learning end users , our benchmarking results can serve as a guide to selecting appropriate software tool and hardware platform .",
        "second , for deep learning software developers , our in - depth analysis points out possible future directions to further optimize the",
        "we compare two learning approaches on the ms - coco dataset : a state - of - the - art recurrent network based on an lstm ( show , attend and tell ) , and a simple structured prediction model on top of a deep network .",
        "deep learning techniques have been paramount in the last years , mainly due to their outstanding results in a number of applications , that range from speech recognition to face - based user identification .",
        "despite other techniques employed for such purposes , deep boltzmann machines are among the most used ones , which are composed of layers of restricted boltzmann machines ( rbms ) stacked on top of each other .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "we perform experiments and show that the derived bounds provide very accurate estimates when applied to various state - of - the - art deep neural networks and datasets .",
        "deep neural networks have shown striking progress and obtained state - of - the - art results in many ai research fields in the recent years .",
        "the computation and storage requirements for deep neural networks ( dnns ) are usually high .",
        "in this paper , we propose ternary neural networks ( tnns ) in order to make deep learning more resource - efficient .",
        "when we use our predictive model to analyze millions of other reddit posts , we find evidence that suggests dogmatism is a deeper personality trait , present for dogmatic users across many different domains , and that users who engage on dogmatic comments tend to show increases in dogmatic posts themselves .",
        "compared with deep models pre - trained on word embedding ( we ) strategy , our character - sequential representation ( csr ) based method shows a much simpler procedure and more stable performance across different benchmarks .",
        "the method was evaluated on several deep learning tasks , demonstrating promising results .",
        "for learning deeper networks , we train ccnns in a layer - wise manner .",
        "our approach effectively captures the multimodal semantics of queries and videos using state - of - the - art deep neural networks and creates a summary that is both semantically coherent and visually attractive .",
        "this formulation combines the expressive power of deep neural networks and the cyclic dependency structure of mrf in a unified model , bringing the modeling capability to a new level .",
        "though deep learning has pushed the boundaries of classification forward , in recent years hints of the limits of standard classification have begun to emerge .",
        "our approach is based on a deep neural network architecture that ingests curated article information such as tags and images , and is trained to predict sales for a large set of frequent customers .",
        "this paper describes our deep learning - based approach to sentiment analysis in twitter as part of semeval - 2016 task 4 .",
        "this paper describes our deep learning - based approach to multilingual aspect - based sentiment analysis as part of semeval 2016 task 5 .",
        "our constrained system ( unconstrained for english ) achieves competitive results across all languages and domains , placing first or second in 5 and 7 out of 11 language - domain pairs for aspect category detection ( slot 1 ) and sentiment polarity ( slot 3 ) respectively , thereby demonstrating the viability of a deep learning - based approach for multilingual aspect - based sentiment analysis .",
        "we describe a novel approach to stride length estimation that uses deep convolutional neural networks to map stride - specific inertial sensor data to the resulting stride length .",
        "to overcome this , we present a method to translate the abstract information provided by wearable sensors to context - related expert features based on deep convolutional neural networks .",
        "by reference to a node threshold three features are described 1 ) a mechanism for primary reinforcement , capable of solving linearly inseparable problems 2 ) the learning scheme is extended to include a mechanism for conditioned reinforcement , capable of forming long term strategy 3 ) the learning scheme is modified to use a threshold - based deep learning algorithm , providing a robust and biologically inspired alternative to backpropagation .",
        "we present a dependency parser implemented as a single deep neural network that reads orthographic representations of words and directly generates dependencies and their labels .",
        "this paper introduces wavenet , a deep neural network for generating raw audio waveforms .",
        "since deep neural networks are powerful models that have achieved excellent performance over many difficult tasks , in this paper , we propose to use the long short - term memory ( lstm ) encoder - decoder model for sentence level ts , which makes minimal assumptions about word sequence .",
        "recent trends to solve this problem have seen a shift to end - to - end solutions using deep reinforcement learning to learn policies from visual input , rather than relying on a handcrafted , modular pipeline .",
        "building upon the recent success of deep q - networks , we present an approach which uses three - dimensional simulations to train a 7 - dof robotic arm in a robot arm control task without any prior knowledge .",
        "our results demonstrate that deep q - networks can be used to learn policies for a task that involves locating a cube , grasping , and then finally lifting .",
        "we also highlight the superiority of classification approaches over regression approaches , quantify the benefits of deeper architectures and extended training data , and demonstrate that synthetic data is beneficial even when using imagenet training data .",
        "while it holds a great promise to produce a better accuracy than non - collective classifiers , collective classification is computational challenging and has not leveraged on the recent breakthroughs of deep learning .",
        "we present column network ( cln ) , a novel deep learning model for collective classification in multi - relational domains .",
        "cln has many desirable theoretical properties : ( i ) it encodes multi - relations between any two instances ; ( ii ) it is deep and compact , allowing complex functions to be approximated at the network level with a small set of free parameters ; ( iii ) local and relational features are learned simultaneously ; ( iv ) long - range , higher - order dependencies between instances are supported naturally ; and ( v ) crucially , learning and inference are efficient , linear in the size of the network and the number of relations .",
        "many success stories involving deep neural networks are instances of supervised learning , where available labels power gradient - based learning methods .",
        "building on recent advances in image caption generation and optical character recognition ( ocr ) , we present a general - purpose , deep learning - based system to decompile an image into presentational markup .",
        "in this paper , we propose to use deep - q - learning techniques instead to determine the machine actions for interactive spoken content retrieval .",
        "deep - q - learning bypasses the need for estimation of the hand - crafted states , and directly determine the best action base on the present retrieval status even without any human knowledge .",
        "we are interested in exploring the possibility and benefits of structure learning for deep models .",
        "deep reinforcement learning ( drl ) brings the power of deep neural networks to bear on the generic task of trial - and - error learning , and its effectiveness has been convincingly demonstrated on tasks such as atari video games and the game of go .",
        "however , contemporary drl systems inherit a number of shortcomings from the current generation of deep learning techniques .",
        "advances in deep reinforcement learning have allowed autonomous agents to perform well on atari games , often outperforming humans , using only raw pixels to make their decisions .",
        "typically , deep reinforcement learning methods only utilize visual input for training .",
        "inspired by the recent success of deep reinforcement learning , we present neural - based models that jointly learn a policy and the behavior of opponents .",
        "instead of explicitly predicting the opponent ' s action , we encode observation of the opponents into a deep q - network ( dqn ) ; however , we retain explicit modeling ( if desired ) using multitasking .",
        "we instead propose to build graphs over the scene objects and over the question words , and we describe a deep neural network that exploits the structure in these representations .",
        "to this end , we study the application of deep conditional generative models in generating realistic galaxy images .",
        "deep neural networks have achieved remarkable results across many language processing tasks , however these methods are highly sensitive to noise and adversarial attacks .",
        "this paper presents an overview of political event data , including methods and ontologies , and a set of experiments to determine the applicability of deep neural networks to the extraction of political events from news text .",
        "deep neural networks are learning models with a very high capacity and therefore prone to over - fitting .",
        "we propose a novel semantic tagging task , semtagging , tailored for the purpose of multilingual semantic parsing , and present the first tagger using deep residual networks ( resnets ) .",
        "these are scalar - valued ( potentially deep ) neural networks with constraints on the network parameters such that the output of the network is a convex function of ( some of ) the inputs .",
        "in this paper , we propose two deep architectures which can be trained jointly on multiple related tasks .",
        "in this work we explore deep generative models of text in which the latent representation of a document is itself drawn from a discrete language model distribution .",
        "implementing an accurate and fast activation function with low cost is a crucial aspect to the implementation of deep neural networks ( dnns ) on fpgas .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "our model consists of a deep lstm network with 8 encoder and 8 decoder layers using attention and residual connections .",
        "this paper proposes new nonnegative ( shallow and multi - layer ) autoencoders by combining the model of spiking random neural network ( rnn ) , the network architecture in the deep - learning area and the training technique in the nonnegative matrix factorization ( nmf ) area .",
        "with the fast development of deep learning , people have started to train very big neural networks using massive data .",
        "these difficulties are tackled in this work , presenting a deep autoencoder that maps the audio spectrogram of bird vocalizations to its corresponding binary mask that encircles the spectral blobs of vocalizations while suppressing other audio sources .",
        "based on the database and another two free data resources ( thchs30 and the cmu dictionary ) , a speech recognition ( asr ) baseline was constructed with the deep neural network - hidden markov model ( dnn - hmm ) hybrid system .",
        "experimental results show that the proposed method delivers substantial performance improvement over the baseline system , especially when a deep neural network ( dnn ) is used as the decision maker , and the dnn input involves some statistical features derived from the cohort scores .",
        "the system uses only byte representations in a deep residual network ( resnet ) .",
        "the focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks , where hypernetworks can be viewed as relaxed form of weight - sharing across layers .",
        "specifically , we focused on papers and works developed by the teamcore of university of southern california , which deepened different directions in this field .",
        "inspired by the recently presented deeptracking approach [ ondruska , 2016 ] , we employ a recurrent neural network ( rnn ) to capture the temporal evolution of the state of the environment , and propose to use spatial transformer modules to exploit estimates of the egomotion of the vehicle .",
        "training a deep neural network for segmentation typically requires a large amount of training data .",
        "the system drastically improves learning in a range of deep neural networks on various data - sets in comparison to non - cpn neural networks .",
        "we introduce a unified algorithm to efficiently learn a broad class of linear and non - linear state space models , including variants where the emission and transition distributions are modeled by deep neural networks .",
        "in this paper , we propose a deep - learning - based approach , called st - resnet , to collectively forecast the in - flow and out - flow of crowds in each and every region through a city .",
        "it provides new and fruitful perspectives on a number of machine learning areas , including cluster analysis , topic detection , and deep probabilistic modeling .",
        "in this work , we propose very deep convolutional neural networks ( cnns ) that directly use time - domain waveforms as inputs .",
        "we demonstrate the performance gains with the deeper models .",
        "by applying deep recurrent neural networks we learn to discriminate between several application layer traffic types on top of a constant envelope modulation without using an expert demodulation algorithm .",
        "in this paper , we develop a chinese event extraction system that uses word embedding vectors to represent language , and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering .",
        "in this paper , we propose to use deep neural network ( dnn ) to address two types of information needs of response organizations : 1 ) identifying informative tweets and 2 ) classifying them into topical classes .",
        "we hope that after reading this tutorial , the reader will be able to use deep learning frameworks , such as keras and introduced kraino , to build various architectures that will lead to a further performance improvement on this challenging task .",
        "we establish rigorous error bounds showing that deep relu networks are significantly more expressive than shallow ones as long as approximations of smooth functions are concerned .",
        "deep learning is a branch of artificial intelligence employing deep neural network architectures that has significantly advanced the state - of - the - art in computer vision , speech recognition , natural language processing and other domains .",
        "in november 2015 , google released $ \\ textit { tensorflow } $ , an open source deep learning software library for defining , training and deploying machine learning models .",
        "in this paper , we review tensorflow and put it in context of modern deep learning concepts and software .",
        "and then we investigate the advancement of multi - view representation learning that ranges from shallow methods including multi - modal topic learning , multi - view sparse coding , and multi - view latent space markov networks , to deep methods including multi - modal restricted boltzmann machines , multi - modal autoencoders , and multi - modal recurrent neural networks .",
        "sample complexity and safety are major challenges when learning policies with reinforcement learning for real - world tasks - - especially when the policies are represented using rich function approximators like deep neural networks .",
        "as another improvement , it uses deep neural networks for joint - speaker identification and gain estimation which makes these two steps easier than before producing competitive results for these steps .",
        "a state - of - the - art technology , deep learning , even fails to perform well in these scenarios .",
        "visual question answering ( vqa ) is a recent problem in computer vision and natural language processing that has garnered a large amount of interest from the deep learning , computer vision , and natural language processing communities .",
        "based on new deep learning technologies we developed , the virtual agent is capable of learning how to interact with users , how to answer user questions , what is the next question to ask , and what to recommend when chatting with a human user .",
        "we propose a deep reinforcement learning method for the exploration of mobile robots in an indoor environment with the depth information from an rgb - d sensor only .",
        "based on the deep q - network framework , the raw depth image is taken as the only input to estimate the q values corresponding to all moving commands .",
        "besides , through analysis of receptive fields of feature representations , deep reinforcement learning motivates the convolutional networks to estimate the traversability of the scenes .",
        "the test results are compared with the exploration strategies separately based on deep learning or reinforcement learning .",
        "the main idea is to combine the generative capability of deep belief network ( dbn ) with a discriminative ability and sequence pattern recognizing capability of long short - term memory ( lstm ) .",
        "the word denoising embeddings are obtained by strengthening salient information and weakening noise in the original word embeddings , based on a deep feed - forward neural network filter .",
        "the second technique involves two deep network classifiers , i .",
        ", dbn ( deep belief networks ) , and sae ( stacked denoising",
        "however , implementation strategy of metaheuristic for accuracy improvement on convolution neural networks ( cnn ) , a famous deep learning method , is still rarely investigated .",
        "deep learning relates to a type of machine learning technique , where its aim is to move closer to the goal of artificial intelligence of creating a machine that could successfully perform any intellectual tasks that can be carried out by a human .",
        "deep neural networks have proven to be quite effective in a wide variety of machine learning tasks , ranging from improved speech recognition systems to advancing the development of autonomous vehicles .",
        "addressing this weakness is of utmost importance if deep neural architectures are to be applied to critical applications , such as those in the domain of cybersecurity .",
        "more importantly , we present a unifying framework for protecting deep neural models using a non - invertible data transformation - - developing two adversary - resilient architectures utilizing both linear and nonlinear dimensionality reduction .",
        "the compared feature extractors are deep belief networks ( dbn ) and fuzzy c - means ( fcm ) clustering .",
        "parallel implementations of stochastic gradient descent ( sgd ) have received significant research attention , thanks to excellent scalability properties of this algorithm , and to its efficiency in the context of training deep neural networks .",
        "in this paper , we present a simple and efficient method for training deep neural networks in a semi - supervised setting where only a small portion of training data is labeled .",
        "the first is the success of deep learning , which often requires frequent transfers of big data for training .",
        "this thesis report studies methods to solve visual question - answering ( vqa ) tasks with a deep learning framework .",
        "we propose deep optimistic linear support learning ( dol ) to solve high - dimensional multi - objective decision problems where the relative importances of the objectives are not known a priori .",
        "to our knowledge , this is the first time that deep reinforcement learning has succeeded in learning multi - objective policies .",
        "in addition , we provide a testbed with two experiments to be used as a benchmark for deep multi - objective reinforcement learning .",
        "in our work , we successively train very deep convolutional networks to add more expressive power and better generalization for end - to - end asr models .",
        "we apply network - in - network principles , batch normalization , residual connections and convolutional lstms to build very deep recurrent and convolutional structures .",
        "5 \\ % word error rate without any dictionary or language using a 15 layer deep network .",
        "to the best of our knowledge , this work is the first to explore deep learning models for paraphrase generation .",
        "this allows for efficient training of deep lstms .",
        "we evaluate our model and other state - of - the - art deep learning models on three different datasets : ppdb , wikianswers and mscoco .",
        "on the other hand , the convolutional neural networks ( cnns ) have brought significant improvements to deep feed - forward neural networks ( ffnns ) , as they are able to better reduce spectral variation in the input signal .",
        "based on this novel skip connections , we successfully train deep stacked bidirectional lstm models and obtain state - of - the - art results on ccg supertagging and comparable results on pos tagging .",
        "recently , attempts have been made to remove gaussian mixture models ( gmm ) from the training process of deep neural network - based hidden markov models ( hmm / dnn ) .",
        "we present deep variational canonical correlation analysis ( vcca ) , a deep multi - view learning model that extends the latent variable model interpretation of linear cca ~ \\ citep { bachjordan05a } to nonlinear observation models parameterized by deep neural networks ( dnns ) .",
        "during execution , at each time step our approach computes what the simulation - based control policy would do , but then , rather than executing these controls on the real robot , our approach computes what the simulation expects the resulting next state ( s ) will be , and then relies on a learned deep inverse dynamics model to decide which real - world action is most suitable to achieve those next states .",
        "deep models are only as good as their training data , and we also propose an approach for data collection to ( incrementally )",
        "question generation has been a research topic for a long time , where a big challenge is how to generate deep and natural questions .",
        "this paper presents a deep learning architecture for the semantic decoder component of a statistical spoken dialogue system .",
        "recently there has been much interest in understanding why deep neural networks are preferred to shallow networks .",
        "in this paper , we show that , for a large class of piecewise smooth functions , the number of neurons needed by a shallow network to approximate a function is exponentially larger than the corresponding number of neurons needed by a deep network for a given degree of function approximation .",
        ", networks whose depth does not depend on $ \\ varepsilon $ ) require $ \\ omega ( \\ text { poly } ( 1 / \\ varepsilon ) ) $ neurons while deep networks ( i .",
        "deep reinforcement learning algorithms are too slow to achieve performance on a real robot , but their potential has been demonstrated in simulated environments .",
        "moreover , rather than relying on model - based trajectory optimisation , the task learning is accomplished using only deep reinforcement learning and sparse rewards .",
        "to recover the ` clustering - friendly ' latent representations and to better cluster the data , we propose a joint dr and k - means clustering approach in which dr is accomplished via learning a deep neural network ( dnn ) .",
        "the motivation is to keep the advantages of jointly optimizing the two tasks , while exploiting the deep neural network ' s ability to approximate any nonlinear function .",
        "the proposed methods are evaluated on the application of training a deep neural network to perform image classification .",
        "recently , er has contributed to improving the performance of deep reinforcement learning .",
        "for several plays of disputed co - authorship , a deeper analysis is performed by attributing every act and scene separately , in which we both corroborate existing breakdowns and provide evidence of new assignments .",
        "conventional deep neural networks ( dnn ) for speech acoustic modeling rely on gaussian mixture models ( gmm ) and hidden markov model ( hmm ) to obtain binary class labels as the targets for dnn training .",
        "however , compared to the conventional gaussian mixture models , deep neural network ( dnn ) based acoustic models usually have much larger number of model parameters , making it challenging for their applications in resource constrained platforms such as mobile devices .",
        "in this paper , we study the application of the recently proposed highway deep neural network ( hdnn ) for training small - footprint acoustic models .",
        "we solve these two problems with the recent advances in deep learning : 1 ) rnn - based autoencoders ( rnn - aes ) can automatically learn low - dimensional representation of a malware from its raw api call sequence .",
        "i ) structured matrices under consideration can either be fully - randomized or learned , ii ) our structured family contains as special cases all previously considered structured schemes , iii ) the setting extends to the non - linear case where the projections are followed by non - linear functions , and iv ) the method finds numerous applications including kernel approximations via random feature maps , dimensionality reduction algorithms , new fast cross - polytope lsh techniques , deep learning , convex optimization algorithms via newton sketches , quantization with random projection trees , and more .",
        "to this end , our method sequentially constructs an ensemble of deep belief nets ( dbns ) with varying depths .",
        "we validate our models with experiments on deep learning training and belief propagation .",
        "there exist many approaches to vqa , the majority of which do not exhibit deeper semantic understanding of the candidate answers they produce .",
        "experiments on synthetic data and deep neural networks validate our theory , demonstrating the effectiveness and scalability of sg - mcmc with stale gradients .",
        "in this paper we describe a deep network architecture that maps visual input to control actions for a robotic planar reaching task with 100 % reliability in real - world trials .",
        "we quantify a source of ineffectual computations when processing the multiplications of the convolutional layers in deep neural networks ( dnns ) and propose pragmatic ( pra ) , an architecture that exploits it improving performance and energy efficiency .",
        "these models have broad applications in image registration , and they are a fundamental aspect of novel machine vision or deep learning algorithms , such as convolutional neural networks ( cnn ) , which perform shift and scale invariant functions followed by classification .",
        "deconvolutional networks fully exploit the advantage the powerful expressiveness of deep neural networks in the manner of unsupervised learning .",
        "in this work we investigate the construction of a single , scalable deep network that can parsimoniously capture the artistic style of a diversity of paintings .",
        "in this paper , we focus on discussing the indispensable role of knowledge for deeper understanding of complex text and multimodal data in situations where ( i ) large amounts of training data ( labeled / unlabeled ) are not available or labor intensive to create , ( ii ) the objects ( particularly text ) to be recognized are complex ( i .",
        "we investigate how well generic deep - learning approaches adapt to these tasks , and how they perform in comparison with established and more specialized methods , including our own adaptation of pruned crfs .",
        "we explore the suitability of a deep neural network architecture for this task , particularly a deep bi - lstm network applied on a character level .",
        "several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years .",
        "sarcasm , however , can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp .",
        "existing deep embedding methods in vision tasks are capable of learning a compact euclidean space from images , where euclidean distances correspond to a similarity metric .",
        "in this paper , we introduce a position - dependent deep metric ( pddm ) unit , which is capable of learning a similarity metric adaptive to local feature structure .",
        "the metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner .",
        "while the method can in principle be applied to deep networks , we restrict ourselves for simplicity in this paper to one and two hidden layer networks .",
        "this paper presents a generalized haar filter based deep network which is suitable for the object detection tasks in traffic scene .",
        "then , we handle the local regression tasks by using several tiny deep networks which simultaneously output the bounding boxes , categories and confidence scores of detected objects .",
        "to reduce the consumption of storage and computing resources , the weights of the deep networks are constrained to the form of generalized haar filter in training phase .",
        "we propose feature map and kernel level pruning for reducing the computational complexity of a deep convolutional neural network .",
        "the remarkable successes of deep learning models across various applications have resulted in the design of deeper networks that can solve complex problems .",
        "however , the increasing depth of such models also results in a higher storage and runtime complexity , which restricts the deployability of such very deep models on mobile and portable devices , which have limited storage and battery capacity .",
        "while many methods have been proposed for deep model compression in recent years , almost all of them have focused on reducing storage complexity .",
        "in this work , we extend the teacher - student framework for deep model compression , since it has the potential to address runtime and train time complexity too .",
        "building large models with parameter sharing accounts for most of the success of deep convolutional neural networks ( cnns ) .",
        "practically , a dcnn can be easily implemented by a two - step convolution procedure , which is supported by most modern deep learning libraries .",
        "this paper investigates the use of deep reinforcement learning for runtime parameters of cloud databases under latency constraints .",
        "in this work , we use continuous deep reinforcement learning to learn optimal cache expirations for http caching in content delivery networks .",
        "we model the output vocabulary of about 100 , 000 words directly using deep bi - directional lstm rnns with ctc loss .",
        "in this way , even a simple linear readout from the ts representation can implement a highly expressive deep - network - like function .",
        "we develop several methods to train the ts network , including equivalent kernels for infinitely wide and deep ts networks , a one - pass linear learning algorithm , and two backpropagation - inspired representation learning algorithms .",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "we apply the proposedmethod for object recognition with temporal context in videos and obtain better results than comparable methods in the literature , including the deep predictive coding networks previously proposed by chalasani and principe .",
        "our contributions can be summarized as a scalable reinterpretation of the deep predictive coding networks trained end - to - end with backpropagation through time , an extension of the previously proposed winner - take - all autoencoders to sequences in time , and a new technique for initializing and regularizing convolutional - recurrent neural networks .",
        "in practice , the current deep embedding methods use the euclidean distance for the training and test .",
        "deep models like deep neural networks , on the other hand , cannot be directly applied for the high - dimensional input because of the huge feature space .",
        "despite outstanding success in vision amongst other domains , many of the recent deep learning approaches have evident drawbacks for robots .",
        "this manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain , either as means of estimation or as a tool to resolve motor commands directly from raw percepts .",
        "we suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence .",
        "deep kernel learning combines the non - parametric flexibility of kernel methods with the inductive biases of deep learning architectures .",
        "we propose a novel deep kernel learning model and stochastic variational inference procedure which generalizes deep kernel learning approaches to enable classification , multi - task learning , additive covariance structures , and stochastic gradient training .",
        "specifically , we apply additive base kernels to subsets of output features from deep neural architectures , and jointly learn the parameters of the base kernels and deep network through a gaussian process marginal likelihood objective .",
        "we show improved performance over stand alone deep networks , svms , and state of the art scalable gaussian processes on several classification benchmarks , including an airline delay dataset containing 6 million training points , cifar , and imagenet .",
        "we introduce a multiple input deep regression model to predict the cf latent embedding vectors of items based on their textual description and metadata .",
        "the model generalizes recent advances in recurrent deep learning from i .",
        "we present torchcraft , an open - source library that enables deep learning research on real - time strategy ( rts ) games such as starcraft : brood war , by making it easier to control these games from a machine learning framework , here torch .",
        "despite their advantages in terms of computational resources , latency , and power consumption , event - based implementations of neural networks have not been able to achieve the same performance figures as their equivalent state - of - the - art deep network models .",
        "we show how inference carried out in deep counter networks converges to the same accuracy levels as are achieved with state - of - the - art conventional networks .",
        "the paper reviews an emerging body of theoretical results on deep learning including the conditions under which it can be exponentially better than shallow learning .",
        "deep convolutional networks represent an important special case of these conditions , though weight sharing is not the main reason for their exponential advantage .",
        "recent research in the deep learning field has produced a plethora of new architectures .",
        "at the same time , a growing number of groups are applying deep learning to new applications and problems .",
        "many of these groups might be composed of inexperienced deep learning practitioners who are baffled by the dizzying array of architecture choices and therefore use an older architecture , such as alexnet .",
        "here , we are attempting to bridge this gap by mining the collective knowledge contained in recent deep learning research to discover underlying principles for designing neural network architectures .",
        "many models such as svm , random forest , and deep neural nets have been proposed and achieved great success .",
        "the use of deep reinforcement learning allows for high - dimensional state descriptors , but little is known about how the choice of action representation impacts the learning difficulty and the resulting performance .",
        "we apply modern deep reinforcement learning methods to build a truly adaptive traffic signal control agent in the traffic microsimulator sumo .",
        "the discrete traffic state encoding is used as input to a deep convolutional neural network , trained using q - learning with experience replay .",
        "this paper presents an actor - critic deep reinforcement learning agent with experience replay that is stable , sample efficient , and performs remarkably well on challenging environments , including the discrete 57 - game atari domain and several continuous control problems .",
        "latent representation learned from multi - layered neural networks via hierarchical feature abstraction enables recent success of deep learning .",
        "under the deep learning framework , generalization performance highly depends on the learned latent representation which is obtained from an appropriate training scenario with a task - specific objective on a designed network model .",
        "recently deep neural networks have received considerable attention due to their ability to extract and represent high - level abstractions in data sets .",
        "deep neural networks such as fully - connected and convolutional neural networks have shown excellent performance on a wide range of recognition and classification tasks .",
        "in fact , they contain most of the deep neural network parameters .",
        "deep networks are successfully used as classification models yielding state - of - the - art results when trained on a large number of labeled samples .",
        "this criterion is based on a deep metric embedding over distance relations within the set of labeled samples , together with constraints over the embeddings of the unlabeled set .",
        "in recent years , model - free methods that use deep learning have achieved great success in many different reinforcement learning environments .",
        "in this paper , we present a model based approach to deep reinforcement learning which we use to solve different tasks simultaneously .",
        "we specifically apply this idea to modify adam , a popular algorithm for training deep neural networks .",
        "we conduct experiments to compare the resulting algorithm , which we call eve , with state of the art methods used for training deep learning models .",
        "more recent deep lipreading approaches are end - to - end trainable ( wand et al .",
        "to the best of our knowledge , lipnet is the first lipreading model to operate at sentence - level , using a single end - to - end speaker - independent deep model to simultaneously learn spatiotemporal visual features and a sequence model .",
        "deep neural network models , though very powerful and highly successful , are computationally expensive in terms of space and time .",
        "experiments on both feedforward and recurrent networks show that the proposed loss - aware binarization algorithm outperforms existing binarization schemes , and is also more robust for wide and deep networks .",
        "several deep learning models have been proposed for question answering .",
        "we explain why this is an alternative approach to deep q - learning , for using deep learning in robotics .",
        "lastly , we argue that this is a big step for deep learning in robotics , as it opens up new possibilities to optimize robots , both in hardware and software .",
        "while deep learning parsing approaches have proven very successful at finding the structure of sentences , most neural dependency parsers use neural networks only for feature extraction , and then use those features in traditional parsing algorithms .",
        "in this paper we present a domain adaptation technique for formant estimation using a deep network .",
        "we first train a deep learning network on a small read speech dataset .",
        "we describe a framework for multitask deep reinforcement learning guided by policy sketches .",
        "in this paper , we study deep generative models for effective unsupervised learning .",
        "recently deeplearning models have been shown to be capable of making remarkable performance in sentences and documents classification tasks .",
        "regularization is key for deep learning since it allows training more complex models while keeping lower levels of overfitting .",
        "in recent years , deep neural networks ( dnns ) based methods have achieved remarkable performance in a wide range of tasks and have been among the most powerful and widely used techniques in computer vision , speech recognition and natural language processing .",
        "we develop a first line of attack for solving programming competition - style problems from input - output examples using deep learning .",
        "model - free deep reinforcement learning ( rl ) methods have been successful in a wide variety of simulated domains .",
        "however , a major obstacle facing deep rl in the real world is the high sample complexity of such methods .",
        "we also achieve almost the same accuracy as a very deep lstm setup on wmt ' 14 english - french translation .",
        "nevertheless , methods from convex optimization such as gradient descent and adam are widely used as building blocks for deep learning algorithms .",
        "nowadays deep learning is dominating the field of machine learning with state - of - the - art performance in various application areas .",
        "recently , spiking neural networks ( snns ) have been attracting a great deal of attention , notably owning to their power efficiency , which can potentially allow us to implement a low - power deep learning engine suitable for real - time / mobile applications .",
        "however , implementing snn - based deep learning remains challenging , especially gradient - based training of snns by error backpropagation .",
        "consequently , most of the previous studies employ a workaround technique , which first trains a conventional weighted - sum deep neural network and then maps the learning weights to the snn under training , instead of training snn parameters directly .",
        "in order to eliminate this workaround , recently proposed is a new class of snn named deep spiking networks ( dsns ) , which can be trained directly ( without a mapping from conventional deep networks ) by error backpropagation with stochastic gradient descent .",
        "embedding and visualizing large - scale high - dimensional data in a two - dimensional space is an important problem since such visualization can reveal deep insights out of complex data .",
        "unfortunately , in nonlinear deep networks , not only individual neurons but also the whole network can saturate , and as a result an important input feature can have a tiny gradient .",
        "we used the latest deep neural network algorithms which provide a leap in performance over the traditional gmm approach , and apply data augmentation methods to improve robustness to noise and speaker variation .",
        "an intriguing property of deep neural networks is the existence of adversarial examples , which can transfer among different architectures .",
        "these transferable adversarial examples may severely hinder deep neural network - based applications .",
        "we propose efficient ways to solve this by augmenting deep q - learning with a cross - entropy reward and deriving novel off - policy methods for rnns from stochastic optimal control ( soc ) .",
        "recent work has demonstrated the effectiveness of employing explicit external memory structures in conjunction with deep neural models for algorithmic learning ( graves et al .",
        "in this work , we propose a training algorithm for an audio - visual automatic speech recognition ( av - asr ) system using deep recurrent neural network ( rnn ) .",
        "first , we train a deep rnn acoustic model with a connectionist temporal classification ( ctc ) objective function .",
        "the frame labels obtained from the acoustic model are then used to perform a non - linear dimensionality reduction of the visual features using a deep bottleneck network .",
        "deep learning research over the past years has shown that by increasing the scope or difficulty of the learning problem over time , increasingly complex learning problems can be addressed .",
        "deep neural networks ( dnns ) have come to outperform humans in visual classifications tasks .",
        "as an alternative we propose to use situated interactions between agents as a driving force for communication , and the framework of deep recurrent q - networks ( drqn ) for learning a common language grounded in the provided environment .",
        "despite their massive size , successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance .",
        "sum - product networks are a class of deep models where , surprisingly , inference remains tractable even when an arbitrary number of hidden layers are present .",
        "842 accuracy on english online debate forum data , which also significantly outperforms results from previous work as well as other deep learning models , showing that utcnn performs well regardless of language or platform .",
        "we present a method for performing hierarchical object detection in images guided by a deep reinforcement learning agent .",
        "our hypothesis is that the performance of using polyphonic sound sequence as features and both lstm and gru as the gating mechanisms for the neural network outperform the traditional mfcc features using a unidirectional deep neural network .",
        "we propose ( cad ) $ ^ 2 $ rl , a flight controller for collision avoidance via deep reinforcement learning that can be used to perform collision - free flight in the real world although it is trained entirely in a 3d cad model simulator .",
        "to obtain accurate predictions , we develop a deep reinforcement learning algorithm for learning indoor navigation , which uses the actual performance of the current policy to construct accurate supervision .",
        "the collision prediction model is represented by a deep convolutional neural network that directly processes raw image inputs .",
        "our collision avoidance system is entirely trained in simulation and thus addresses the high sample complexity of deep reinforcement learning and avoids the dangers of trial - and - error learning in the real world .",
        "we illustrate the distributed nature of the learned representations via output entropy computations for synthetic data , and demonstrate superior performance , compared to standard alternatives such as autoencoders , in training a deep convolutional net on standard image datasets .",
        "to take advantage of traditional methods in ner such as crf , we combine transition probability with deep learning in our model .",
        "a shared component of many powerful generative models is a decoder network , a parametric deep neural net that defines a generative distribution .",
        "we use deep bidirectional lstm embedding models and multi - view contrastive losses .",
        "we present earliness - aware deep convolutional networks ( ea - convnets ) , an end - to - end deep learning framework , for early classification of time series data .",
        "unlike most existing methods for early classification of time series data , that are designed to solve this problem under the assumption of the availability of a good set of pre - defined ( often hand - crafted ) features , our framework can jointly perform feature learning ( by learning a deep hierarchy of \\ emph { shapelets } capturing the salient characteristics in each time series ) , along with a dynamic truncation model to help our deep feature learning architecture focus on the early parts of each time series .",
        "to the best of our knowledge , the proposed framework is the first to perform data - driven ( deep ) feature learning in the context of early classification of time series data .",
        "training time on large datasets for deep neural networks is the principal workflow bottleneck in a number of important applications of deep learning , such as object classification and detection in automatic driver assistance systems ( adas ) .",
        "to minimize training time , the training of a deep neural network must be scaled beyond a single machine to as many machines as possible by distributing the optimization method used for training .",
        "recent deep rl exploration strategies are able to deal with high - dimensional continuous state spaces through complex heuristics , often relying on optimism in the face of uncertainty or intrinsic motivation .",
        "in this work , we describe a surprising finding : a simple generalization of the classic count - based approach can reach near state - of - the - art performance on various high - dimensional and / or continuous deep rl benchmarks .",
        "we further extend the model to deep structures and show that deep models can be used for unsupervised pre - training of rectifier neural networks .",
        "we then consider two interpolation methods for generalizing to a wider range of initial conditions : deep learning , and nearest neighbors .",
        "lstms have become a basic building block for many deep nlp models .",
        "in recent years , many improvements and variations have been proposed for deep sequence models in general , and lstms in particular .",
        "we observe compounding improvements on traditional lstms using monte carlo test - time model averaging , deep vector averaging ( dva ) , and residual connections , along with four other suggested modifications .",
        "various deep neural architectures underperform human baselines on these tasks , suggesting that comics contains fundamental challenges for both vision and language .",
        "we describe a method to train spiking deep networks that can be run using leaky integrate - and - fire ( lif ) neurons , achieving state - of - the - art results for spiking lif networks on five datasets , including the large imagenet ilsvrc - 2012 benchmark .",
        "our method for transforming deep artificial neural networks into spiking networks is scalable and works with a wide range of neural nonlinearities .",
        "in the context of deep neural networks , this idea is often realized by hand - designed network architectures with layers that are shared across tasks and branches that encode task - specific features .",
        "however , the space of possible multi - task deep architectures is combinatorially large and often the final architecture is arrived at by manual exploration of this space subject to designer ' s bias , which can be both error - prone and tedious .",
        "in this work , we propose a principled approach for designing compact multi - task deep learning architectures .",
        "deep reinforcement learning agents have achieved state - of - the - art results by directly maximising cumulative reward .",
        "in this paper we introduce a novel approach which employs deep learning to tackle this problem in any cf based recommendation engine .",
        "we then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow .",
        "the current trend in object detection and localization is to learn predictions with high capacity deep neural networks trained on a very large amount of annotated data and using a high amount of processing power .",
        "we also demonstrate the performance of the relative test of similarity over a broad selection of model comparisons problems in deep generative models .",
        "our analysis provides a deeper understanding of potential trade - offs of using different learning algorithms and between the effort required for featuring ( creating new features ) and labeling ( providing labels for objects ) .",
        "recently , the rapid development of deep learning and representation learning has brought new inspiration to various domains .",
        "researchers have recently started investigating deep neural networks for dialogue applications .",
        "nowadays , the number of layers and of neurons in each layer of a deep network are typically set manually .",
        "while very deep and wide networks have proven effective in general , they come at a high memory and computation cost , thus making them impractical for constrained platforms .",
        "in this paper , we introduce an approach to automatically determining the number of neurons in each layer of a deep network during learning .",
        "the complexity of deep neural network algorithms for hardware implementation can be lowered either by scaling the number of units or reducing the word - length of weights .",
        "for this study , the performances of fully - connected deep neural networks ( fcdnns ) and convolutional neural networks ( cnns ) are evaluated while changing the network complexity and the word - length of weights .",
        "deep neural network architectures with external memory components allow the model to perform inference and capture long term dependencies , by storing information explicitly .",
        "adaptive stochastic gradient methods such as adagrad have gained popularity in particular for training deep neural networks .",
        "deep neural networks with lots of parameters are typically used for large - scale computer vision tasks such as image classification .",
        "we propose a novel deep network architecture for grayscale and color image denoising that is based on a non - local image model .",
        "we build on this concept and introduce deep networks that perform non - local processing and at the same time they significantly benefit from discriminative learning .",
        "it is also worth noting that this increase in performance comes at no extra cost on the capacity of the network compared to existing alternative deep network architectures .",
        "this connection is of significant importance since it allows our models to take full advantage of the latest advances on gpu computing in deep learning and makes them amenable to efficient implementations through their inherent parallelism .",
        "deep neural networks often require good regularizers to generalize well .",
        "dropout is one such regularizer that is widely used among deep learning practitioners .",
        "these information objects and their applications are known as quantified - self , mobile health or personal informatics , and they can be used to provide a deeper insight into our behavior .",
        "performance of end - to - end automatic speech recognition ( asr ) systems can significantly be improved by the increasing large speech corpus and deeper neural network .",
        "given the arising problem of training speed and recent success of deep convolutional neural network in asr , we build a novel deep recurrent convolutional network for acoustic modeling and apply deep residual learning framework to it , our experiments show that it has not only faster convergence speed but better recognition accuracy over traditional deep convolutional recurrent network .",
        "we mainly compare convergence speed of two acoustic models , which are novel deep recurrent convolutional networks and traditional deep convolutional recurrent networks .",
        "with faster convergence speed , our novel deep recurrent convolutional networks can reach the comparable performance .",
        "we further show that applying deep residual learning can boost both convergence speed and recognition accuracy of our novel recurret convolutional networks .",
        "our evaluation results show that our model applied with deep residual learning can reach the best per of 17 .",
        "deep convolutional neural networks have become a widespread tool to address high - level computer vision tasks very successfully .",
        "a new model for video captioning is developed , using a deep three - dimensional convolutional neural network ( c3d ) as an encoder for videos and a recurrent neural network ( rnn ) as a decoder for captions .",
        "many extensions have been invented based on rbm in order to produce deeper architectures with greater power .",
        "the most famous ones among them are deep belief network , which stacks multiple layer - wise pretrained rbms to form a hybrid model , and deep boltzmann machine , which allows connections between hidden units to form a multi - layer structure .",
        "we call the resulted structure deep restricted boltzmann network .",
        "we prototyped deep learning models to establish initial baselines of the introduced tasks .",
        "in this paper we present deep constrained local model ( dclm ) algorithm and the novel dense - projection network ( dpn ) as a local detector .",
        "dpn is a deep neural network that consists of two important layers : template projection layer and dense aggregate layer .",
        "our multimodal deep reinforcement learning agent perceives multimodal features and exhibits verbal and non - verbal actions while playing .",
        "standard deep reinforcement learning methods such as deep q - networks ( dqn ) for multiple tasks ( domains ) face scalability problems .",
        "despite the overwhelming success of deep learning in various speech processing tasks , the problem of separating simultaneous speakers in a mixture remains challenging .",
        "we propose a novel deep learning framework for single channel speech separation by creating attractor points in high dimensional embedding space of the acoustic signals which pull together the time - frequency bins corresponding to each source .",
        "this paper addresses the task of set prediction using deep learning .",
        "we define a likelihood for a set distribution and learn its parameters using a deep neural network .",
        "we show that by using time - dilated convolutions with a very deep vgg - style cnn with batch normalization , we achieve best published single model accuracy result on the switchboard - 2000 benchmark dataset .",
        "currently , heuristically designed features based on the domain knowledge requires tremendous effort in hand - crafting , while features extracted through deep network are difficult for human to interpret .",
        "we train input specific state - of - the - art deep neural networks for each input source , show the potential of forging them together into a multi - modal architecture and train a novel policy network that learns to choose between them .",
        "we study methods for automated parsing of informal mathematical expressions into formal ones , a main prerequisite for deep computer understanding of informal mathematical texts .",
        "we propose a context - based parsing approach that combines efficient statistical learning of deep parse trees with their semantic pruning by type checking and large - theory automated theorem proving .",
        "generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks .",
        "this paper presents a concept of a novel method for adjusting hyper - parameters in deep learning ( dl ) algorithms .",
        "an external agent - observer monitors a performance of a selected deep learning algorithm .",
        "we demonstrate an improved method for building conditional models , the co - embedding deep variational auto encoder .",
        "our model takes graphs as input , performs object - and relation - centric reasoning in a way that is analogous to a simulation , and is implemented using deep neural networks .",
        "recent literature has pointed out that machine learning classifiers , including deep neural networks ( dnn ) , are vulnerable to adversarial samples that are maliciously created inputs that force a machine learning classifier to produce wrong output labels .",
        "deep reinforcement learning ( rl ) can acquire complex behaviors from low - level inputs , such as images .",
        "deep networks are known to achieve remarkable generalization when provided with massive amounts of labeled data , but can we provide this breadth of experience to an rl agent , such as a robot ?",
        "recently it has been shown that policy - gradient methods for reinforcement learning can be utilized to train deep end - to - end systems directly on non - differentiable metrics for the task at hand .",
        "a deep convolutional autoencoder is trained on healthy retinal images .",
        "we present probabilistic neural programs , a framework for program induction that permits flexible specification of both a computational model and inference algorithm while simultaneously enabling the use of deep neural networks .",
        "the success is mostly due to advances in deep learning .",
        "however , deep learning can make mistakes and its generalization abilities to new tasks are questionable .",
        "we ask when and how one can combine network outputs , when ( i ) details of the observations are evaluated by learned deep components and ( ii ) facts and confirmation rules are available in knowledge based systems .",
        "we argue that the combination of sparse outlier detection with deep components that can support each other diminish the fragility of deep methods , an important requirement for engineering applications .",
        "recently , there have been several promising methods to generate realistic imagery from deep convolutional networks .",
        "in this paper , we propose a deep adversarial image synthesis architecture that is conditioned on coarse sketches and sparse color strokes to generate realistic cars , bedrooms , or faces .",
        "to address the issues , we propose an end - to - end deep recurrent neural network with limited contextual dialogue memory by jointly training nlu and sap on dstc4 multi - domain human - human dialogues .",
        "this paper introduces deepbach , a statistical model aimed at modeling polyphonic music and specifically four parts , hymn - like pieces .",
        "a key strength of deepbach is that it is agnostic and flexible .",
        "deepbach ' s generation is fast , making it usable for interactive",
        "deep neural networks are widely used in machine learning applications .",
        "as a proof of concept for the proposed scheme , we designed a system consisting of deep convolutional neural networks , and applied it to successfully learn a computerized agent capable of autonomous highway steering over the",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "network quantization is one of network compression techniques employed to reduce the redundancy of deep neural networks .",
        "we develop a probabilistic framework for deep learning based on the deep rendering mixture model ( drmm ) , a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables .",
        "we demonstrate that max - sum inference in the drmm yields an algorithm that exactly reproduces the operations in deep convolutional neural networks ( dcns ) , providing a first principles derivation .",
        "extensive experiments on four benchmark datasets demonstrate that the deeply - learned features with l - softmax loss become more discriminative , hence significantly boosting the performance on a variety of visual classification and verification tasks .",
        "we present an architecture which lets us train deep , directed generative models with many layers of latent variables .",
        "while depth of representation has been posited as a primary reason for their success , there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer .",
        "the predictron yielded significantly more accurate predictions than conventional deep neural network architectures .",
        "the above limitations can be overcome by using deep cases and neural network .",
        "hence we propose a modified qas in which we create a deep artificial neural network with associative memory from text documents .",
        "in this paper we introduce deepstack , a new algorithm for imperfect information settings such as poker .",
        "it combines recursive reasoning to handle information asymmetry , decomposition to focus computation on the relevant decision , and a form of intuition about arbitrary poker situations that is automatically learned from self - play games using deep learning .",
        "in a study involving dozens of participants and 44 , 000 hands of poker , deepstack becomes the first computer program to beat professional poker players in heads - up no - limit texas hold ' em .",
        "with the advent of deep learning new models of unsupervised learning of features for time - series analysis and forecast have been developed .",
        "such new developments are the topic of this paper : a review of the main deep learning techniques is presented , and some applications on time - series analysis are summaried .",
        "the results make it clear that deep learning has a lot to contribute to the field .",
        "moreover , a taxonomy and survey of shallow and deep networks intrusion detection systems is presented based on previous and current works .",
        "in recent years , deep learning ( dl ) has found great success in domains such as multimedia understanding .",
        "deep reinforcement learning has enabled the learning of policies for complex tasks in partially observable environments , without explicitly learning the underlying model of the tasks .",
        "we propose a deep - learning - based approach , called st - resnet , to collectively forecast two types of crowd flows ( i .",
        "we define this requirement as the \" image - to - image translation \" problem , and propose a general approach to achieve it , based on deep convolutional and conditional generative adversarial networks ( gans ) , which has gained a phenomenal success to learn mapping images from noise input since 2014 .",
        "in this paper , a novel architecture for a deep recurrent neural network , residual lstm is introduced .",
        "the proposed residual lstm architecture provides an additional spatial shortcut path from lower layers for efficient training of deep networks with multiple lstm layers .",
        "on the other hand deep learning is considered to be the new frontier to extract meaningful information out of large amount of raw data in an automated manner .",
        "therefore , we would like to omit it and use deep neural networks that learn from simple features .",
        "most of the current deep neural network ( dnn ) based methods consider these tasks as a sequence labeling problem , in which a word , rather than a chunk , is treated as the basic unit for labeling .",
        "we study characteristics of receptive fields of units in deep convolutional networks .",
        "deep learning classifiers are known to be inherently vulnerable to manipulation by intentionally perturbed inputs , named adversarial examples .",
        "in this work , we establish that reinforcement learning techniques based on deep q - networks ( dqns ) are also vulnerable to adversarial input perturbations , and verify the transferability of adversarial examples across different dqn models .",
        "end - to - end ( e2e ) systems have achieved competitive results compared to conventional hybrid hidden markov model ( hmm ) - deep neural network based automatic speech recognition ( asr ) systems .",
        "our base perception module is based on recent development in object detection and recognition using deep learning .",
        "in this paper , we present a deep model to learn item properties and user behaviors jointly from review text .",
        "the proposed model , named deep cooperative neural networks ( deepconn ) , consists of two parallel neural networks coupled in the last layers .",
        "experimental results demonstrate that deepconn significantly outperforms all baseline recommender systems on a variety of datasets .",
        "this paper presents the development of several models of a deep convolutional auto - encoder in the caffe deep learning framework and their experimental evaluation on the example of mnist dataset .",
        "the paper also discusses practical details of the creation of a deep convolutional auto - encoder in the very popular caffe deep learning framework .",
        "we report up to 128 fold compression of popular architectures without a large loss of accuracy providing additional evidence to the fact that modern deep architectures are very redundant .",
        "introduction to deep neural networks and their history .",
        "this work aims to investigate the use of deep neural network to detect commercial hobby drones in real - life environments by analyzing their sound data .",
        "recently , several deep learning approaches have been presented which automatically extract features from the mouth images and aim to replace the feature extraction stage .",
        "many aspects of people ' s lives are proven to be deeply connected to their jobs .",
        "deep learning techniques lie at the heart of several significant ai advances in recent years including object recognition and detection , image captioning , machine translation , speech recognition and synthesis , and playing the game of go .",
        "here we suggest deep learning based guidance in the proof search of the theorem prover e .",
        "we train and compare several deep neural network models on the traces of existing atp proofs of mizar statements and use them to select processed clauses during proof search .",
        "we give experimental evidence that with a hybrid , two - phase approach , deep learning based guidance can significantly reduce the average number of proof search steps while increasing the number of theorems proved .",
        "using a few proof guidance strategies that leverage deep neural networks , we have found first - order proofs of 7 .",
        "we give an overview of recent exciting achievements of deep reinforcement learning ( rl ) .",
        "we start with background of deep learning and reinforcement learning , as well as introduction of testbeds .",
        "next we discuss deep q - network ( dqn ) and its extensions , asynchronous methods , policy optimization , reward , and planning .",
        "the application of deep neural networks for ranking in search engines may obviate the need for the extensive feature engineering common to current learning - to - rank methods .",
        "however , we show that combining simple relevance matching features like bm25 with existing deep neural net models often substantially improves the accuracy of these models , indicating that they do not capture essential local relevance matching signals .",
        "we describe a novel deep recurrent neural net - based model that we call match - tensor .",
        "standard error backpropagation is used in almost all modern deep network training .",
        "extensive numerical simulations on a toy deep learning model verify its excellent performance .",
        "the reinforced backpropagation can significantly improve test performance of the deep network training , especially when the data are scarce .",
        "proposed approach uses deep recurrent neural network trained on a sequence of acoustic features calculated over small speech intervals .",
        "experiments using deep neural network models trained on social media data show that the combination of visual and textual context can enhance the quality of generated conversational turns .",
        "the recent success of deep convolutional neural networks on image classification and recognition tasks has led to new applications in very diversifying contexts .",
        "several novel and recent approaches have also embedded control policy with efficient perceptual representation using deep learning .",
        "this has led to the emergence of a new branch of dynamic robot control system called deep r inforcement learning ( drl ) .",
        "in this paper , we take a step towards generating sensory data that can pass a deep learning based discriminator model test , and make two specific contributions : first , we present a deep learning based architecture for synthesizing sensory data .",
        "we then define a new class of submodular functions we call { \\ em deep submodular functions } or dsfs .",
        "we show that dsfs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks ( dnns ) .",
        "skip connections made the training of very deep neural networks possible and have become an indispendable component in a variety of neural architectures .",
        "here , we present an explanation for the benefits of skip connections in training very deep neural networks .",
        "we argue that skip connections help break symmetries inherent in the loss landscapes of deep networks , leading to drastically simplified landscapes .",
        "this hypothesis is supported by evidence from a toy model with binary weights and from experiments with fully - connected networks suggesting ( i ) that skip connections do not necessarily improve training unless they help break symmetries and ( ii ) that alternative ways of breaking the symmetries also lead to significant performance improvements in training deep networks , hence there is nothing special about skip connections in this respect .",
        "it is well known that it is challenging to train deep neural networks and recurrent neural networks for tasks that exhibit long term dependencies .",
        "here , we take the first steps in this direction and present a deep learning pipeline that takes as input images of the undeciphered indus script , as found in archaeological artifacts , and returns as output a string of graphemes , suitable for inclusion in a standard corpus .",
        "multiple pcgml methods are covered , including neural networks , long short - term memory ( lstm ) networks , autoencoders , and deep convolutional networks ; markov models , $ n $ - grams , and multi - dimensional markov chains ; clustering",
        "deep learning to hash , which improves retrieval quality by end - to - end representation learning and hash encoding , has received increasing attention recently .",
        "subject to the vanishing gradient difficulty in the optimization with binary activations , existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step , which suffer from substantial loss of retrieval quality .",
        "this paper presents hashnet , a novel deep architecture for deep learning to hash by continuation method , which learns exactly binary hash codes from imbalanced similarity data where the number of similar pairs is much smaller than the number of dissimilar pairs .",
        "the key idea is to attack the vanishing gradient problem in optimizing deep networks with non - smooth binary activations by continuation method , in which we begin from learning an easier network with smoothed activation function and let it evolve during the training , until it eventually goes back to being the original , difficult to optimize , deep network with the sign activation function .",
        "a clearer understanding of the strict link between distributed / distributional representations and symbols will certainly lead to radically new deep learning networks .",
        "we employ a pixelcnn architecture to define a strong prior over natural images and jointly optimize this prior with a deep conditioning convolutional network .",
        "attention networks have proven to be an effective approach for embedding categorical inference within a deep neural network .",
        "in this work , we experiment with incorporating richer structural distributions , encoded using graphical models , within deep networks .",
        "the problem of quantizing the activations of a deep neural network is considered .",
        "the problem of approximating the relu non - linearity , widely used in the recent deep learning literature , is then considered .",
        "deep learning ( dl ) methods show very good performance when trained on large , balanced data sets .",
        "we use a single neural network to model users and products , capturing their correlation and generating customised product representations using a deep memory network , from which customised ratings and reviews are constructed jointly .",
        "in this paper we propose to exploit the automatic quality estimation ( qe ) of asr hypotheses to perform the unsupervised adaptation of a deep neural network modeling acoustic probabilities .",
        "the backbone of our system is a deep convolutional neural network that is not only computationally inexpensive , but also provides state - of - the - art results on several competitive benchmarks .",
        "additionally , our deep network is trained on a large dataset of several million images which are labeled through a semi - automated process .",
        "in addition , our style - based classifier establishes a new state - of - the - art result on the story cloze challenge , substantially higher than previous results based on deep learning models .",
        "deep neural networks ( dnn ) have revolutionized the field of natural language processing ( nlp ) .",
        "previous deep learning - based approaches to domain adaptation need to be trained jointly on source and target domain data and are therefore unappealing in scenarios where models need to be adapted to a large number of domains or where a domain is evolving , e .",
        "in this paper , we propose a new autonomous braking system based on deep reinforcement learning .",
        "the policy used for brake control is learned through computer simulations using the deep reinforcement learning method called deep q - network ( dqn ) .",
        "we combine the advantages of these two methods by training a deep network that learns to synthesize video frames by flowing pixel values from existing ones , which we call deep voxel flow .",
        "to this end , we develop a character - level deep conflation model that encodes the input text strings from character level into finite dimension feature vectors , which are then used to compute the cosine similarity between the text strings .",
        "specifically , we propose two variants of the deep conflation model , based on long - short - term memory ( lstm ) recurrent neural network ( rnn ) and convolutional neural network ( cnn ) , respectively .",
        "we analyze the dynamics of policies learned by multiple self - interested independent learning agents , each using its own deep q - network , on two markov games we introduce here : 1 .",
        "two decades after teasauro ' s td - gammon achieved near top - level human performance in backgammon , the deep reinforcement learning algorithm dqn ( combining q - learning with a deep neural network , experience replay , and a separate target network ) achieved human - level performance in many atari 2600 games .",
        "fully connected network has been widely used in deep learning , and its computation efficiency is highly benefited from the matrix multiplication algorithm with cublas on gpu .",
        "to reduce the impact of nt operation by cublas , we exploit the out - of - place transpose of matrix $ \\ textbf { b } $ to avoid using nt operation , and then we apply our method to caffe , which is a popular deep learning tool .",
        "several machine learning algorithms ( naive bayes , support vector machine and logistic regression ) alongside deep and convolutional neural networks were utilized in our experiments of sentiment analysis on our health dataset .",
        "batch normalization is quite effective at accelerating and improving the training of deep models .",
        "in this work , we propose to train a deep neural network by distributed optimization over a graph .",
        "recently , machine learning methods have provided a broad spectrum of original and efficient algorithms based on deep neural networks ( dnn ) to automatically predict an outcome with respect to a sequence of inputs .",
        "using deep learning for different machine learning tasks such as image classification and word embedding has recently gained many attentions .",
        "in this paper , we use deep learning to embed wikipedia concepts and entities .",
        "in this paper we explore whether or not deep neural architectures can learn to classify boolean satisfiability ( sat ) .",
        "in this paper , we propose a system that uses deep learning techniques for morphological disambiguation .",
        "many of the state - of - the - art results in computer vision , speech recognition and natural language processing have been obtained through deep learning models .",
        "however , applying deep learning techniques to morphologically rich languages is not well studied .",
        "in this paper , we developed a deep neural network ( dnn ) that learns to solve simultaneously the three tasks of the cqa challenge proposed by the semeval - 2016 task 3 , i .",
        "in order to improve the reliability of speaker verification systems , we develop a new filter bank based cepstral feature , deep neural network filter bank cepstral coefficients ( dnn - fbcc ) , to distinguish between natural and spoofed speech .",
        "the deep neural network filter bank is automatically generated by training a filter bank neural network ( fbnn ) using natural and synthetic speech .",
        "the backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive , but also provide state - of - the - art results on several competitive benchmarks .",
        "to power our novel deep networks , we collected large labeled datasets through a semi - supervised pipeline to reduce the annotation effort / time .",
        "previous studies support the idea of merging auditory - based gabor features with deep learning architectures to achieve robust automatic speech recognition , however , the cause behind the gain of such combination is still unknown .",
        "we believe these representations provide the deep learning decoder with more discriminable cues .",
        "this article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input .",
        "the state - of - the - art results provided by deep learning come at the price of an intensive use of computing resources .",
        "in this paper , we ask the following question : is distributed deep learning computation on wan connected devices feasible , in spite of the traffic caused by learning tasks ?",
        "deep neural networks ( dnns ) have set state of the art results in many machine learning and nlp tasks .",
        "uoro is a modification of nobacktrack that bypasses the need for model sparsity and makes implementation easy in current deep learning frameworks , even for complex models .",
        "furthermore , we show that rns can act as a bottleneck that induces the factorization of objects from entangled scene description inputs , and from distributed deep representations of scene images provided by a variational autoencoder .",
        "we propose a deep learning model for identifying structure within experiment narratives in scientific literature .",
        "the paper [ 1 ] shows that simple linear classifier can compete with complex deep learning algorithms in text classification applications .",
        "combining bag of words ( bow ) and linear classification techniques , fasttext [ 1 ] attains same or only slightly lower accuracy than deep learning algorithms [ 2 - 9 ] that are orders of magnitude slower .",
        "this paper focuses on the development of randomized approaches for building deep neural networks .",
        "such a class of randomized leaner models with deep architecture is termed as deep stochastic configuration networks ( deepscns ) , of which the universal approximation property is verified with rigorous proof .",
        "given abundant samples from a continuous distribution , deepscns can speedily produce a learning representation , that is , a collection of random basis functions with the cascaded inputs together with the read - out weights .",
        "deep neural networks are currently among the most commonly used classifiers .",
        "while one can find impressively wide spread of various configurations of almost every aspect of the deep nets , one element is , in authors ' opinion , underrepresented - while solving classification problems , vast majority of papers and applications simply use log loss .",
        "in this paper we try to investigate how particular choices of loss functions affect deep models and their learning dynamics , as well as resulting classifiers robustness to various effects .",
        "in particular we show that l1 and l2 losses are , quite surprisingly , justified classification objectives for deep nets , by providing probabilistic interpretation in terms of expected misclassification .",
        "we also introduce two losses which are not typically used as deep nets objectives and show that they are viable alternatives to the existing ones .",
        "motivated by human collaborative learning , in this paper we propose a collaborative deep reinforcement learning ( cdrl ) framework that performs adaptive knowledge transfer among heterogeneous learning agents .",
        "specifically , the proposed cdrl conducts a novel deep knowledge distillation method to address the heterogeneity among different learning tasks with a deep alignment network .",
        "furthermore , we present an efficient collaborative asynchronous advantage actor - critic ( ca3c ) algorithm to incorporate deep knowledge distillation into the online training of agents , and demonstrate the effectiveness of the cdrl framework using extensive empirical evaluation on openai gym .",
        "distributed training of deep learning models on large - scale training data is typically conducted with asynchronous stochastic optimization to maximize the rate of updates , at the cost of additional noise introduced from asynchrony .",
        "figar can be used for improving any deep reinforcement learning algorithm which maintains an explicit policy estimate by enabling temporal abstractions in the action space .",
        "we empirically demonstrate the efficacy of our framework by showing performance improvements on top of three policy search algorithms in different domains : asynchronous advantage actor critic in the atari 2600 domain , trust region policy optimization in mujoco domain and deep deterministic policy gradients in the torcs car racing domain .",
        ", to learn deep features in an end - to - end manner .",
        "neural networks have been successfully applied to this problem , and in this paper , we propose an attention - based deep neural network which better incorporates different embeddings of the queries and search results with an attention - based mechanism .",
        "many classes of rl tasks , from atari games to motor control to board games , are now solvable by fairly generic algorithms , based on deep learning , that learn to play from experience with minimal knowledge of the specific domain of interest .",
        "specifically , we propose an optimized accelerator architecture tailored for bitwise convolution and normalization that features massive spatial parallelism with deep pipelines stages .",
        "finally , we also research new dropout prediction architectures based on deep , fully - connected , feed - forward neural networks and find that ( 4 ) networks with as many as 5 hidden layers can",
        "in this paper , we explore deep learning techniques for answering multi - step reasoning questions that operate on semi - structured tables .",
        "in this paper , we motivate guided deep list , the first tool for building automated line lists ( in near real - time ) from open source reports of emerging disease outbreaks .",
        "guided deep list uses distributed vector representations ( ala word2vec ) to discover a set of indicators for each line list feature .",
        "we evaluate the performance of guided deep list against a human annotated line list provided by healthmap corresponding to mers outbreaks in saudi arabia .",
        "many enlightening vqa works explore deep into the image and question encodings and fusing methods , of which attention is the most effective and infusive mechanism .",
        "recent studies have shown that deep neural networks ( dnn ) are vulnerable to adversarial samples : maliciously - perturbed samples crafted to yield incorrect model outputs .",
        "to overcome this problem , we introduce a defensive mechanism called deepmask .",
        "by identifying and removing unnecessary features in a dnn model , deepmask limits the capacity an attacker can use generating adversarial samples and therefore increase the robustness against such inputs .",
        "comparing with other defensive approaches , deepmask is easy to implement and computationally efficient .",
        "experimental results show that deepmask can increase the performance of state - of - the - art dnn models against adversarial samples .",
        "limited annotated data is available for the research of estimating facial expression intensities , which makes the training of deep networks for automated expression assessment very challenging .",
        "the proposed transferred deep regressor is applied in estimating the intensity of facial action units ( 2017 emotionnet challenge ) and in particular pain intensity estimation ( unbs - mcmaster shoulder - pain dataset ) .",
        "deep neural nets have caused a revolution in many classification tasks .",
        "the back - propagation ( bp ) algorithm has been considered the de facto method for training deep neural networks .",
        "first , the model generalizes previous methods by incorporating content , network , and deep features learned from social context .",
        "motivated by recent progress in deep learning , we focus on the specific case where agents update their actions according to gradient descent .",
        "the adaptation of the meta - parameters is an open question in reinforcement learning , which arguably has become more of an issue recently with the success of deep reinforcement learning in high - dimensional state spaces .",
        "recently , there was a paradigm shift towards using word embeddings and deep neural networks , where the use of surface features is very limited .",
        "in this paper , we theoretically address three fundamental problems involving deep convolutional networks regarding invariance , depth and hierarchy .",
        "deeper networks are able to model much richer classes of transformations .",
        "our results provide useful insight into these three fundamental problems in deep learning using convnets .",
        "deep neural network ( dnn ) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene .",
        "deep learning approaches have been widely used in automatic speech recognition ( asr ) and they have achieved a significant accuracy improvement .",
        "however , most cnns used in existing work have less than 10 layers which may not be deep enough to capture all human speech signal information .",
        "in this paper , we propose a novel deep and wide cnn architecture denoted as rcnn - ctc , which has residual connections and connectionist temporal classification ( ctc ) loss function .",
        "we present deep voice , a production - quality text - to - speech system constructed entirely from deep neural networks .",
        "deep voice lays the groundwork for truly end - to - end neural speech synthesis .",
        "for the segmentation model , we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification ( ctc ) loss .",
        "deep learning is an important component of big - data analytic tools and intelligent applications , such as , self - driving cars , computer vision , speech recognition , or precision medicine .",
        "modern parallel computing systems provide the capability to reduce the required training time of deep neural networks .",
        "deep learning models are often successfully trained using gradient descent , despite the worst case hardness of the underlying non - convex optimization problem .",
        "motivated by the idea that criticality and universality of phase transitions might play a crucial role in achieving and sustaining learning and intelligent behaviour in biological and artificial networks , we analyse a theoretical and a pragmatic experimental set up for critical phenomena in deep learning .",
        "on the theoretical side , we use results from statistical physics to carry out critical point calculations in feed - forward / fully connected networks , while on the experimental side we set out to find traces of criticality in deep neural networks .",
        "this is our first step in a series of upcoming investigations to map out the relationship between criticality and learning in deep networks .",
        "we employ a model free deep reinforcement learning framework to learn the motoric skills of striking the puck accurately in order to score .",
        "we propose certain improvements to the standard learning scheme which make the deep q - learning algorithm feasible when it might otherwise fail .",
        "fixed - point optimization of deep neural networks plays an important role in hardware based design and low - power implementations .",
        "many deep neural networks show fairly good performance even with 2 - or 3 - bit precision when quantized weights are fine - tuned by retraining .",
        "the experiments are conducted for feed - forward deep neural networks ( ffdnns ) , convolutional neural networks ( cnns ) , and recurrent neural networks ( rnns ) .",
        "we introduce deepnat , a 3d deep convolutional neural network for the automatic segmentation of neuroanatomy in t1 - weighted magnetic resonance images .",
        "deepnat is an end - to - end learning - based approach to brain segmentation that jointly learns an abstract feature representation and a multi - class classification .",
        "multi - task learning ( mtl ) in deep neural networks for nlp has recently received increasing interest due to some compelling benefits , including its potential to efficiently regularize models and to reduce the need for labeled data .",
        "despite this importance , deep reinforcement learning ( drl ) agents have so far used relatively simple memory architectures , with the main methods to overcome partial observability being either a temporal convolution over the past k frames or an lstm layer .",
        "deep - layered models trained on a large number of labeled samples boost the accuracy of many tasks .",
        "deep networks thrive when trained on large scale data collections .",
        "this has given imagenet a central role in the development of deep architectures for visual object classification .",
        "we contribute to this research thread with two findings : ( 1 ) a study correlating a given level of noisily labels to the expected drop in accuracy , for two deep architectures , on two different types of noise , that clearly identifies googlenet as a suitable architecture for learning from web data ; ( 2 ) a recipe for the creation of web datasets with minimal noise and maximum visual variability , based on a visual and natural language processing concept expansion strategy .",
        "however , it is difficult to create a large dataset to train the ability of deep neural network models ( dnns ) .",
        "deep learning , a subfield of machine learning , promises to change this by operating on raw input signals and automating the process of feature design and extraction .",
        "in this paper we propose the expose neural network , which uses a deep learning approach we have developed to take generic , raw short character strings as input ( a common case for security inputs , which include artifacts like potentially malicious urls , file paths , named pipes , named mutexes , and registry keys ) , and learns to simultaneously extract features and classify using character - level embeddings and convolutional neural network .",
        "a long - standing obstacle to progress in deep learning is the problem of vanishing and exploding gradients .",
        "preliminary experiments show the new initialization allows to train very deep networks without the addition of skip - connections .",
        "we used a novel deep regression structure for overall completeness estimation .",
        "these findings represent a paradigm shift especially when it comes to harnessing the power of deep networks for primary and secondary clustering applications in large datasets .",
        "deep neural networks require a large amount of labeled training data during supervised learning .",
        "in this paper , we introduce a source - target selective joint fine - tuning scheme for improving the performance of deep learning tasks with insufficient training data .",
        "deep residual networks have reached the state of the art in many image processing tasks such image classification .",
        "for example , a 152 - layer - deep residual network can be reduced to 106 convolutional layers , i .",
        "therefore , a key challenge is to translate the success of deep learning on single - agent rl to the multi - agent setting .",
        "a key stumbling block is that independent q - learning , the most popular multi - agent rl method , introduces nonstationarity that makes it incompatible with the experience replay memory on which deep rl relies .",
        "we formally study ldr matrices in deep learning .",
        "deep convolutional networks have demonstrated remarkable results for image and video classification tasks .",
        "in particular , images are represented as signals on graphs , which permits to replace classical convolution and pooling layers in deep networks with graph spectral convolution and dynamic graph pooling layers that together contribute to invariance to isometric transformations .",
        "deep reinforcement learning has been successful in various virtual tasks , but it is still rarely used in real world applications especially for continuous control of mobile robots navigation .",
        "we show that , through an asynchronous deep reinforcement learning method , a mapless motion planner can be trained end - to - end without any manually designed features and prior demonstrations .",
        "this paper presents optnet , a network architecture that integrates optimization problems ( here , specifically in the form of quadratic programs ) as individual layers in larger end - to - end trainable deep networks .",
        "we show that the incorporation of sgs does not affect the representational strength of the learning system for a neural network , and prove the convergence of the learning system for linear and deep linear models .",
        "the success of deep learning depends on finding an architecture to fit the task .",
        "as deep learning has scaled up to more challenging tasks , the architectures have become difficult to design by hand .",
        "this paper proposes an automated method , codeepneat , for optimizing deep learning architectures through evolution .",
        "given the anticipated increases in available computing power , evolution of deep networks is promising approach to constructing deep learning applications in the future .",
        "in this work we propose the first wii approach based upon deep convolutional neural networks ( cnns ) .",
        "in deep learning the ubiquitous architecture used for this task is the siamese neural network which maps each entity to a representation through a learnable function and expresses similarity through the distances among the entities in the representation space .",
        "in the task of similarity learning , our simplistic model that does not use any convolutions performs on par with deep convolutional siamese networks and significantly better when convolutional layers are also used .",
        "stochastic gradient algorithms are the main focus of large - scale optimization problems and led to important successes in the recent advancement of the deep learning algorithms .",
        "in our experiments with deep neural networks , we obtained better performance compared to the popular stochastic gradient algorithms .",
        "despite their great success , there is still no com - prehensive theoretical understanding of learning with deep neural networks ( dnns ) or their in - ner organization .",
        "deep neural networks have been successfully applied in applications with a large amount of labeled data .",
        "our results can be directly applied to many machine learning applications , including deep learning .",
        "generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain .",
        "the efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks .",
        "the focus of past machine learning research for reading comprehension tasks has been primarily on the design of novel deep learning architectures .",
        "this paper presents an end - to - end learning framework for task - completion neural dialogue systems , which leverages supervised and reinforcement learning with various deep - learning models .",
        "fully - connected feed - forward neural networks ( dnns ) and deep unidirectional long short - term memory ( lstm ) recurrent neural networks ( rnns ) are successfully trained with proposed method for large vocabulary continuous speech recognition on shenma voice search data in mandarin .",
        ", robotics control , sequential prediction ) with deep neural network models .",
        "we present a new deep learning model : we extend the state - of - the - art convolutional object detection network for the detection of human hands in training videos based on image information , and newly introduce the concept of using a fully convolutional network to regress ( i .",
        "we demonstrate the performance of our proposed system on a range of tasks from the atari suite and also from a 3d deepmind lab environment .",
        "deep reinforcement learning methods have demonstrated the ability to learn with highly general policy classes for complex tasks with high - dimensional inputs , such as raw images .",
        "on the other hand , it is comparatively easy to build discriminative models on top of complex states such as images using standard deep neural networks .",
        "we study the problem of attributing the prediction of a deep network to its input features , a problem previously studied by several other works .",
        "we apply this method to a couple of image models , a couple of text models and a chemistry model , demonstrating its ability to debug networks , to extract rules from a deep network , and to enable users to engage with models better .",
        "we present a new distributed representation in deep neural nets wherein the information is represented in native form as a matrix .",
        "deep convolutional neural networks ( cnn ) have shown their good performances in many computer vision tasks .",
        "this paper presents chain - nn , a novel energy - efficient 1d chain architecture for accelerating deep cnns .",
        "we frame the problem in the context of unsupervised domain adaptation and apply an adversarial framework to train a deep neural network with the additional objective to align features across domains .",
        "recent successes in deep reinforcement learning have been achieved mostly using simple heuristic exploration strategies such as $ \\ epsilon $ - greedy action selection or gaussian control noise , but there are many tasks where these methods are insufficient to make any learning progress .",
        "first , a novel deep learning model codae , in which two mid - layers from separate stack denoising autoencoders are fused into one shared layer .",
        "we show that the nonlinearity of a deep network does not need to be continuous , non expansive or point - wise , to achieve good performance .",
        "we show that increasing the width of our network permits being competitive with very deep networks .",
        "indeed , a 1 - nearest neighbor classifier applied on deep features progressively improves with depth , which indicates that the representation is progressively more regular .",
        "recently , the end - to - end approach that learns hierarchical representations from raw data using deep convolutional neural networks has been successfully explored in the image , text and speech domains .",
        "to this end , we propose sample - level deep convolutional neural networks which learn representations from very small grains of waveforms ( e .",
        "we show how deep architectures with sample - level filters improve the accuracy in music auto - tagging and they provide results that are com - parable to previous state - of - the - art performances for the magnatagatune dataset and million song dataset .",
        "deep neural network is difficult to train and this predicament becomes worse as the depth increases .",
        "equipped with these two ingredients , we propose several novel optimization solutions that can be utilized for training a specific - structured ( repetitively triple modules of conv - bnrelu ) extremely deep convolutional neural network ( cnn ) without any shortcuts / identity mappings from scratch .",
        "deep reinforcement learning methods attain super - human performance in a wide range of environments .",
        "we propose neural episodic control : a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them .",
        "we show across a wide range of environments that our agent learns significantly faster than other state - of - the - art , general purpose deep reinforcement learning agents .",
        "advances in deep learning over the last few years have produced major speech recognition improvements on the representative switchboard conversational corpus .",
        "although there are some experts in vietnam as well as international having deeply researched this problem , there are still no reasonable results meeting the demand , in particular , no treated thoroughly the ambiguous phenomenon , in the process of khmer language processing so far .",
        "recently , triggered by the impressive results in tv - games or game of go by google deepmind , end - to - end reinforcement learning ( rl ) is collecting attentions .",
        "deep neural networks coupled with fast simulation and improved computation have led to recent successes in the field of reinforcement learning ( rl ) .",
        "even though active learning forms an important pillar of machine learning , deep learning tools are not prevalent within it .",
        "deep learning poses several difficulties when used in an active learning setting .",
        "recent advances in deep learning , on the other hand , are notorious for their dependence on large amounts of data .",
        "second , many al acquisition functions rely on model uncertainty , yet deep learning methods rarely represent such model uncertainty .",
        "in this paper we combine recent advances in bayesian deep learning into the active learning framework in a practical way .",
        "to obtain uncertainty estimates with real - world bayesian deep learning models , practical inference approximations are needed .",
        "we prove new upper and lower bounds on the vc - dimension of deep neural networks with the relu activation function .",
        "to capture such global interdependency , we propose a deep variation - structured reinforcement learning ( vrl ) framework to sequentially discover object relationships and attributes in the whole image .",
        "we then make sequential predictions using a deep rl framework , incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector .",
        "deep convolutional neural network ( cnn ) inference requires significant amount of memory and computation , which limits its deployment on embedded devices .",
        "among the main results we show that suppes ' constraints deeply simplify the learning task , by reducing the solution search space and providing a temporal ordering on the variables .",
        "despite recent advances , memory - augmented deep neural networks are still limited when it comes to life - long and one - shot learning , especially in remembering rare events .",
        "we present a large - scale life - long memory module for use in deep learning .",
        "training deep neural networks is a highly nontrivial task , involving carefully selecting appropriate training algorithms , scheduling step sizes and tuning other hyperparameters .",
        "recently , researchers have tried to use deep learning algorithms to exploit the landscape of the loss function of the training problem of interest , and learn how to optimize over it in an automatic way .",
        "our optimizer outperforms generic , hand - crafted optimization algorithms and state - of - the - art learning - to - learn optimizers by deepmind in many tasks .",
        "we demonstrate the effectiveness of our algorithms on a number of tasks , including deep mlps , cnns , and simple lstms .",
        "we introduce a method for learning the dynamics of complex nonlinear systems based on deep generative models over temporal segments of states and actions .",
        "deep learning has led to remarkable advances when applied to problems where the data distribution does not change over the course of learning .",
        "we approach structured output prediction by learning a deep value network ( dvn ) that evaluates different output structures for a given input .",
        "in addition , on image segmentation , the proposed deep value network learns complex shape priors and effectively combines image information with the prior to obtain competitive segmentation results .",
        "terminology is one of the sectors in which the arabic language requires a deep modernization of its classical productivity models .",
        "despite their overwhelming capacity to overfit , deep learning architectures tend to generalize relatively well to unseen data , allowing them to be deployed in practice .",
        "this paper argues that most notions of flatness are problematic for deep models and can not be directly applied to explain generalization .",
        "specifically , when focusing on deep networks with rectifier units , we can exploit the particular geometry of parameter space induced by the inherent symmetries that these architectures exhibit to build equivalent models corresponding to arbitrarily sharper minima .",
        "in this paper , we propose a deep neural networks ( dnn ) based pbe model called neural programming by example ( npbe ) , which can learn from input - output strings and induce programs that solve the string manipulation problems .",
        "deep learning with convolutional neural networks ( deep convnets ) has revolutionized computer vision through end - to - end learning , i .",
        "now , there is increasing interest in using deep convnets for end - to - end eeg analysis .",
        "current deep learning approaches have been very successful using convolutional neural networks ( cnn ) trained on large graphical processing units ( gpu ) - based computers .",
        "in this paper , we evaluate deep learning models using three different computing architectures to address these problems : quantum computing to train complex topologies , high performance computing ( hpc ) to automatically determine network topology , and neuromorphic computing for a low - power hardware implementation .",
        "our results show the feasibility of using the three architectures in tandem to address the above deep learning limitations .",
        "an energy function over candidate structured outputs is given by a deep network , and predictions are formed by gradient - based optimization .",
        "in this paper , we demonstrate that such data can be automatically extracted by deep neural networks ( aka deep learning ) , which is a cutting - edge type of artificial intelligence .",
        "in particular , we use the existing human - labeled images from the snapshot serengeti dataset to train deep convolutional neural networks for identifying 48 species in 3 .",
        "deep learning models ( dlms ) are state - of - the - art techniques in speech recognition .",
        "in this paper we aim at filling this gap by comparing four popular parallel training algorithms in speech recognition , namely asynchronous stochastic gradient descent ( asgd ) , blockwise model - update filtering ( bmuf ) , bulk synchronous parallel ( bsp ) and elastic averaging stochastic gradient descent ( easgd ) , on 1000 - hour librispeech corpora using feed - forward deep neural networks ( dnns ) and convolutional , long short - term memory , dnns ( cldnns ) .",
        "taking advantage of the recent success of unsupervised learning in deep neural networks , we propose an end - to - end learning framework that is able to extract more robust multi - modal representations across domains .",
        "we propose anogan , a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability , accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space .",
        "this strategy effectively solves the label permutation problem observed in deep learning based techniques for speech separation .",
        "we examine the effects of transfer learning for deep hierarchical recurrent networks across domains , applications , and languages , and show that significant improvement can often be obtained .",
        "recently , semantic segmentation of rgb imagery has advanced significantly due to deep learning .",
        "this makes it difficult to directly train a deep neural network for semantic segmentation , because it will be prone to overfitting .",
        "to cope with this , deep learning models typically use convolutional neural networks pre - trained on large - scale image classification datasets , which are then fine - tuned for semantic segmentation .",
        "in this paper , we developed two deep neural networks for semantic segmentation of multispectral remote sensing imagery .",
        "cltune is evaluated on two gpu case - studies inspired by the recent successes in deep learning : 2d convolution and matrix - multiplication ( gemm ) .",
        "additionally , deeper ensemble architectures such as classifier stacking have not been closely evaluated .",
        "we use deep reinforcement learning ( rl ) to learn the policies of these agents end - to - end - - from pixels to multi - agent multi - round dialog to game reward .",
        "expressive efficiency is a concept that allows formally reasoning about the representational capacity of deep network architectures .",
        "a well - known example is the exponential expressive efficiency of depth , namely , that in many cases shallow networks must grow exponentially large in order to represent functions realized by deep networks .",
        "we focus on dilated convolutional networks , a family of deep models gaining increased attention , underlying state of the art architectures like google ' s wavenet and bytenet .",
        "this work thus presents a comparison of several state - of - the - art deep learning models on the ieee challenge on detection and classification of acoustic scenes and events ( dcase ) 2016 challenge task and data , classifying sounds into one of fifteen common indoor and outdoor acoustic scenes , such as bus , cafe , car , city center , forest path , library , train , etc .",
        "on these features , we apply five models : gaussian mixture model ( gmm ) , deep neural network ( dnn ) , recurrent neural network ( rnn ) , convolutional deep neural net - work ( cnn ) and i - vector .",
        "to our knowledge , this is the first successful transfer of a deep neural network trained only on simulated rgb images ( without pre - training on real images ) to the real world for the purpose of robotic control .",
        "we have assumed that using advanced deep machine learning methods may considerably increase the accuracy of predictions .",
        "we started with simple machine learning methods to estimate basic prediction performance and moved further by applying advanced methods based on shallow and deep neural networks .",
        "we believe that applying deep machine learning for psychological profiling may have an enormous impact on the society ( for good or worse ) and providing full source code of our research we hope to",
        "we achieve this using a deep generative model to create novel instances along a 1d line .",
        "in this paper , we proposed a novel deep learning framework , namely long - and short - term time - series network ( lstnet ) , to address this open challenge .",
        "deeper lstm models perform well on large vocabulary continuous speech recognition , because of their impressive learning ability .",
        "however , it is more difficult to train a deeper network .",
        "we introduce a training framework with layer - wise training and exponential moving average methods for deeper lstm models .",
        "it is a competitive framework that lstm models of more than 7 layers are successfully trained on shenma voice search data in mandarin and they outperform the deep lstm models trained by conventional approach .",
        "moreover , in order for online streaming speech recognition applications , the shallow model with low real time factor is distilled from the very deep model .",
        "deep learning has shown promising results in many machine learning applications .",
        "the hierarchical feature representation built by deep networks enable compact and precise encoding of the data .",
        "a kernel analysis of the trained deep networks demonstrated that with deeper layers , more simple and more accurate data representations are obtained .",
        "in this paper , we propose an approach for layer - wise training of a deep network for the supervised classification task .",
        "this paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2d and 3d face alignment datasets .",
        "large - scale deep convolutional neural networks ( cnns ) are widely used in machine learning applications .",
        "we demonstrate a novel method , based on learning deep networks , to model the global landscapes of optimization problems .",
        "to represent the search space concisely and accurately , the deep networks must encode information about the underlying parameter interactions and their contributions to the quality of the solution .",
        "moreover , with the increasing need of deep semantic processing , text - based dialogue understanding is attracting more attention in the community .",
        "in recent years , deep learning has become the go - to solution for a broad range of applications , often outperforming state - of - the - art .",
        "however , it is important , for both theoreticians and practitioners , to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms .",
        "to address both concerns , we propose a novel architecture based on a network of deep neural networks , where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them .",
        "firstly , features of text images are extracted by the cnn network to obtain the deep visual representations .",
        "deep convolutional neural networks are generally regarded as robust function approximators .",
        "while recent work has proposed several techniques for automated option discovery , they do not scale to multi - level hierarchies and to expressive representations such as deep networks .",
        "we present discovery of deep options ( ddo ) , a policy - gradient algorithm that discovers parametrized options from a set of demonstration trajectories , and can be used recursively to discover additional levels of the hierarchy .",
        "we demonstrate that using the discovered options to augment the action space of deep q - network agents can accelerate learning by guiding exploration in tasks where random actions are unlikely to reach valuable states .",
        "to address this concern , a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network .",
        "large - scale deep neural networks ( dnn ) have been successfully used in a number of tasks from image recognition to natural language processing .",
        "specifically , using deep reinforcement learning , this work develops a time - efficient navigation policy that respects common social norms .",
        "we use the scattering network as a generic and fixed initialization of the first layers of a supervised hybrid deep network .",
        "we show that early layers do not necessarily need to be learned , providing the best results to - date with pre - defined representations while being competitive with deep cnns .",
        "in this paper , we present a joint compression and classification approach of eeg and emg signals using a deep learning approach .",
        "specifically , we build our system based on the deep autoencoder architecture which is designed not only to extract discriminant features in the multimodal data representation but also to reconstruct the data from the latent representation using encoder - decoder layers .",
        "we survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition .",
        "in a driving simulator domain where an agent learns an image - to - action deep network policy , our algorithm dart achieves a better performance than dagger with 75 % fewer demonstrations .",
        "recently , deep learning ( dl ) methods have been introduced very successfully into human activity recognition ( har ) scenarios in ubiquitous and wearable computing .",
        "especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real - life har application .",
        "in this paper we tackle such challenges through ensembles of deep long short term memory ( lstm ) networks .",
        "we demonstrate , both formally and empirically , that ensembles of deep lstm learners outperform the individual lstm networks .",
        "multiple different approaches of generating adversarial examples have been proposed to attack deep neural networks .",
        "to circumvent these issues , deep networks are being increasingly used , thanks to their ability to learn complex functions from large example sets .",
        "universal logic reasoning in turn , as envisioned already by leibniz , may support the rigorous formalisation and deep logical analysis of rational arguments within machines .",
        "in this paper , we propose a joint deep network model that combines adversarial training and perceptual feature regression for texture generation , while only random noise and user - defined perceptual attributes are required as input .",
        "our deep framework for the agent is trained end to end : it learns simultaneously the visual representations of the environment , the syntax and semantics of the language , and the action module that outputs actions .",
        "previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima .",
        "however , the practical observation is that , at least for the most successful deep convolutional neural networks ( dcnns ) for visual processing , practitioners can always increase the network size to fit the training data ( an extreme example would be [ 1 ] ) .",
        "to address this issue , we present two structure learning algorithms for deep cnn models .",
        "within hadid , a top - down hierarchical classification is applied , in which we use deep neural networks ( dnns ) method to build a local classifier for every parent node into the hierarchy dialect structure .",
        "an hybrid of a hidden markov model ( hmm ) and a deep neural network ( dnn ) is considered .",
        "in particular , the limitations of hand - designed structures and algorithms currently used in most deep neural networks could be overcome by more flexible and innovative solutions .",
        "deep neural perception and control networks are likely to be a key component of self - driving vehicles .",
        "we proposed a deep learning method for interpretable diabetic retinopathy ( dr ) detection .",
        "we believe this advantage of the proposed deep learning model is highly desired for dr detection because in practice , users are not only interested with high prediction performance , but also keen to understand the insights of dr detection and why the adopted learning model works .",
        "in this paper , we present midinet , a deep convolutional neural network ( cnn ) based generative adversarial network ( gan ) that is intended to provide a general , highly adaptive network structure for symbolic - domain music generation .",
        "we address the simplification problem with an encoder - decoder model coupled with a deep reinforcement learning framework .",
        "we demonstrate that standard deep features , in our case taken from a model trained for object classification , can be used together with a bilinear predictive model to learn an effective visual servo that is robust to visual variation , changes in viewing angle and appearance , and occlusions .",
        "one of the defining properties of deep learning is that models are chosen to have many more parameters than available training data .",
        "one roadblock to explaining these phenomena in terms of implicit regularization , structural properties of the solution , and / or easiness of the data is that many learning bounds are quantitatively vacuous in this \" deep learning \" regime .",
        "by optimizing the pac - bayes bound directly , we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples .",
        "we describe a method to produce a network where current methods such as deepfool have great difficulty producing adversarial samples .",
        "our construction suggests some insights into how deep networks work .",
        "however , training multiple deep networks for model averaging is computationally expensive .",
        "owing to the success of deep learning techniques for tasks such as q / a and text - based dialog , there is an increasing demand for ai agents in several domains such as retail , travel , entertainment , etc .",
        "however , deep learning research is this area has been limited primarily due to the lack of availability of large - scale , open conversation datasets .",
        "we also propose two novel multi - modal deep learning models in the encode - attend - decode paradigm and demonstrate their performance on two of the sub - tasks , namely text response generation and best image response selection .",
        "to overcome this , we explore several auxiliary tasks , including semantic super - sense tagging and identification of multi - word expressions , and cast the task as a multi - task learning problem with deep recurrent neural networks .",
        "in this work we present a new approach to learn compressible representations in deep architectures with an end - to - end training strategy .",
        "deep neural networks ( dnns ) have advanced the state - of - the - art in a variety of machine learning tasks and are deployed in increasing numbers of products and services .",
        "in this work , we propose dynamic variable effort deep neural networks ( dyvedeep ) to reduce the computational requirements of dnns during inference .",
        "complementary to these approaches , dyvedeep is a dynamic approach that exploits the heterogeneity in the inputs to dnns to improve their compute efficiency with comparable classification accuracy .",
        "dyvedeep equips dnns with dynamic effort mechanisms that , in the course of processing an input , identify how critical a group of computations are to classify the input .",
        "dyvedeep dynamically focuses its compute effort only on the critical computa - tions , while skipping or approximating the rest .",
        "although deep neural networks ( dnns ) have achieved great success in many computer vision tasks , recent studies have shown they are vulnerable to adversarial examples .",
        "we propose a novel deep layer cascade ( lc ) method to improve the accuracy and speed of semantic segmentation .",
        "unlike the conventional model cascade ( mc ) that is composed of multiple independent models , lc treats a single deep model as a cascade of several sub - models .",
        "first , lc classifies most of the easy regions in the shallow stage and makes deeper stage focuses on a few hard regions .",
        "second , lc accelerates both training and testing of deep network thanks to early decisions in the shallow stage .",
        "regarding integration , we note that the most impactful recent contributions have been made possible through the integration of recent machine learning methods ( based in particular on deep learning and recurrent neural networks ) with more traditional ones ( e .",
        "this report is targeted to groups who are subject matter experts in their application but deep learning novices .",
        "it contains practical advice for those interested in testing the use of deep neural networks on applications that are novel for deep learning .",
        "end - to - end training of deep learning - based models allows for implicit learning of intermediate representations based on the final task loss .",
        "we hypothesize that using intermediate representations as auxiliary supervision at lower levels of deep networks may be a good way of combining the advantages of end - to - end training and more traditional pipeline approaches .",
        "we explored three different deep learning approaches : a character - level convolutional neural network ( cnn ) , a stacked learner with an mlp meta - classifier , and an attention based bi - lstm .",
        "recently , deep learning methods have been shown to improve the performance of recommender systems over traditional methods , especially when review text is available .",
        "for example , a recent model , deepconn , uses neural nets to learn one latent representation for the text of all reviews written by a target user , and a second latent representation for the text of all reviews for a target item , and then combines these latent representations to obtain state - of - the - art performance on recommendation tasks .",
        "our model , called transnets , extends the deepconn model by introducing an additional latent layer representing the target user - target item pair .",
        "the method exploits the temporal structure of a speech signal and more specifically , it trains deep neural networks ( dnns ) to discriminate temporal events obtained by uniformly segmenting the signal without using any label information , in contrast to conventional dnn based bn feature extraction methods that train dnns using labeled data to discriminate speakers or passphrases or phones or a combination of them .",
        "here we present deeplift ( deep learning important features ) , a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input .",
        "deeplift compares the activation of each neuron to its ' reference activation ' and assigns contribution scores according to the difference .",
        "by optionally giving separate consideration to positive and negative contributions , deeplift can also reveal dependencies which are missed by other approaches .",
        "we apply deeplift to models trained on mnist and simulated genomic data , and show significant advantages over gradient - based methods .",
        "together with the proper choice of graph coarsening , we explore constructing deep neural networks for graph classification .",
        "in particular , we demonstrate the generality of our formulation in point cloud classification , where we set the new state of the art , and on a graph classification dataset , where we outperform other deep learning approaches .",
        "deep reinforcement learning has achieved many impressive results in recent years .",
        "deep learning and reinforcement learning methods have recently been used to solve a variety of problems in continuous control domains .",
        "we introduce two extensions to the deep deterministic policy gradient algorithm ( ddpg ) , a model - free q - learning based method , which make it significantly more data - efficient and scalable .",
        "for computer vision applications , prior works have shown the efficacy of reducing the numeric precision of model parameters ( network weights ) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters .",
        "given such a scenario , a standard deep reinforcement learning based dialogue agent may suffer to find a good policy due to the issues such as : increased state and action spaces , high sample complexity demands , sparse reward and long horizon , etc .",
        "in this paper , we propose to use hierarchical deep reinforcement learning approach which can operate at different temporal scales and is intrinsically motivated to attack these problems .",
        "experiments on both simulations and human evaluation show that our model significantly outperforms flat deep reinforcement learning agents in terms of success rate , rewards and user rating .",
        "it has been believed that stochastic feedforward neural networks ( sfnns ) have several advantages beyond deterministic deep neural networks ( dnns ) : they have more expressive power allowing multi - modal mappings and regularize better due to their stochastic nature .",
        "as the first step to model emotional state of a person , we build sentiment analysis models with existing deep neural network algorithms and compare the models with psychological measurements to enlighten the relationship .",
        "the result shows that although cnn performed the best among other deep neural network algorithms ( lstm , gru ) , its results are not related to the psychological state .",
        "in the meanwhile , deep learning has been widely studied and used in various classification problems includ - ing multi - label classification , however it has not been sufficiently studied in this extreme but practi - cal case , where the label space can be as large as in millions .",
        "in this paper , we propose a practical deep embedding method for extreme multi - label classifi - cation .",
        "deep reinforcement learning ( rl ) has achieved several high profile successes in difficult control problems .",
        "this may be acceptable for a simulator , but it severely limits the applicability of deep rl to many real - world tasks , where the agent must learn in the real environment .",
        "we present an algorithm , deep q - learning from demonstrations ( dqfd ) , that leverages this data to massively accelerate the learning process even from relatively small amounts of demonstration data .",
        "we show that dqfd has better initial performance than deep q - networks ( dqn ) on 40 of 42 atari games and it receives more average rewards than dqn on 27 of 42 atari games .",
        "when you need to enable deep learning on low - cost embedded socs , is it better to port an existing deep learning framework or should you build one from scratch ?",
        "our conclusion is that , on embedded devices , we most likely will use very simple deep learning models for inference , and with well - developed building blocks such as acl , it may be better in both performance and development time to build the engine from scratch .",
        "this paper presents a new 3d point cloud classification benchmark data set with over four billion manually labelled points , meant as input for data - hungry ( deep ) learning methods .",
        "we also discuss first submissions to the benchmark that use deep convolutional neural networks ( cnns ) as a work horse , which already show remarkable performance improvements over state - of - the - art .",
        "with the massive data set presented in this paper , we aim at closing this data gap to help unleash the full potential of deep learning methods for 3d labelling tasks .",
        "recent advances in deep neural networks have substantially improved the performance of this task .",
        "in order to adopt deep learning for ad - hoc information retrieval , it is essential to establish suitable representations of query - document pairs and to design neural architectures that are able to digest such representations .",
        "in this work , we address this gap by encoding the relevance matching in terms of similarity matrices and using a deep model to digest such matrices .",
        "recently , deep learning methods proved suitable to deal with remote sensing data mainly for scene classification ( i .",
        "convolutional neural networks - cnns - on single images ) while only very few studies exist involving temporal deep learning approaches ( i .",
        "in this work , we propose class - enhanced attentive response ( clear ) : an approach to visualize and understand the decisions made by deep neural networks ( dnns ) given a specific input .",
        "in this paper , we present an entity - drivenrecursive deep modelfor the chinese discourse coherence evaluation based on current english discourse coherenceneural network model .",
        "we introduce a novel framework for evaluating multimodal deep learning models with respect to their language understanding and generalization abilities .",
        "we develop direct and highly efficient reconstruction algorithms based on deep - learning .",
        "in this approach image reconstruction is performed with a deep convolutional neural network ( cnn ) , whose weights are adjusted prior to the actual image reconstruction based on a set of training data .",
        "our results demonstrate that the proposed deep learning approach reconstructs images with a quality komparable to state of the art iterative approaches from sparse data .",
        "the agent uses a deep recurrent neural network for function approximation .",
        "we propose a novel deep learning model for joint document - level entity disambiguation , which leverages learned neural representations .",
        "our approach thereby combines benefits of deep learning with more traditional approaches such as graphical models and probabilistic mention - entity maps .",
        "adversarial attack has cast a shadow on the massive success of deep neural networks .",
        "despite being almost visually identical to the clean data , the adversarial images can fool deep neural networks into wrong predictions with very high confidence .",
        "the framework represents the encoder as a deep nonlinear function through which samples from a simple distribution are fed .",
        "unlike recently released datasets , such as deepmind cnn / dailymail and squad , the proposed searchqa was constructed to reflect a full pipeline of general question - answering .",
        "we conduct human evaluation as well as test two baseline methods , one simple word selection and the other deep learning based , on the searchqa .",
        "to learn from the resulting rhetoric structure , we propose a tensor - based , tree - structured deep neural network ( named rst - lstm ) in order to process the complete discourse tree .",
        "this paper introduces a generic framework to train deep networks , end - to - end , with no supervision .",
        "we propose to fix a set of target representations , called noise as targets ( nat ) , and to constrain the deep features to align to them .",
        "we study the performance of faulty implementations of certain deep neural networks based on pessimistic and optimistic models of the effect of hardware faults .",
        "we introduce the first deep reinforcement learning agent that learns to beat atari games with the aid of natural language instructions .",
        "our agent significantly outperforms deep q - networks ( dqns ) , asynchronous advantage actor - critic ( a3c ) agents , and the best agents posted to openai gym on what is often considered the hardest atari 2600 environment : montezuma ' s revenge .",
        "despite being so vital to success of support vector machines , the principle of separating margin maximisation is not used in deep learning .",
        "we show that minimisation of margin variance and not maximisation of the margin is more suitable for improving generalisation in deep architectures .",
        "we propose the halfway loss function that minimises the normalised margin variance ( nmv ) at the output of a deep learning models and evaluate its performance against the softmax cross - entropy loss on the mnist , smallnorb and cifar - 10 datasets .",
        "in this paper , we propose a novel mer method by using deep convolutional neural network ( cnn ) on the music spectrograms that contains both the original time and frequency domain information .",
        "this paper presents an end - to - end deep learning framework using passive wifi sensing to classify and estimate human respiration activity .",
        "based on the results , we conclude that deep learning techniques coupled with passive radars offer great potential for end - to - end human activity recognition .",
        "we further analyze the effect of training iterations , compare networks trained with different initializations , examine the impact of network depth and width , and measure the effect of dropout and batch normalization on the interpretability of deep visual representations .",
        "recent studies have shown that embedding textual relations using deep neural networks greatly helps relation extraction .",
        "this paper presents a deep attention model on the basis of recurrent neural networks ( rnn ) to learn \\ textit { selectively } temporal hidden representations of sequential posts for identifying rumors .",
        "extensive experiments on real datasets collected from social media websites demonstrate that ( 1 ) the deep attention based rnn model outperforms state - of - the -",
        "this work is the first to overcome this limitation by interpreting the correlation filter learner , which has a closed - form solution , as a differentiable layer in a deep neural network .",
        "this enables learning deep features that are tightly coupled to the correlation filter .",
        "during the development stage , a deep neural network ( dnn ) that will be used to extract j - vector , is initialized and trained with the speech frames as input and the actual side information of the utterance as flat output block - wise one - hot labels .",
        "our method uses deep residual bidirectional lstms to compare questions and relation names via different hierarchies of abstraction .",
        "in this paper , we propose a new clustering model , called deep embedded regularized clustering ( depict ) , which efficiently maps data into a discriminative embedding subspace and precisely predicts cluster assignments .",
        "furthermore , we employ the reconstruction loss functions in our autoencoder , as a data - dependent regularization term , to prevent the deep embedding function from overfitting .",
        "although many decision - making problems like developing urban areas require such perception and reasoning , existing methods in this field usually neglect the deep knowledge mined from geographic databases and are based on pure statistical methods .",
        "in this work we present a method for using deep q - networks ( dqns ) in multi - objective tasks .",
        "deep q - networks provide remarkable performance in single objective tasks learning from high - level visual perception .",
        "we are using deep convolutional neural networks to represent complex features .",
        "we present a deep neural architecture that parses sentences into three semantic dependency graph formalisms .",
        "this demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision , including semantic segmentation or scene understanding .",
        "this paper provides a review on deep learning methods for semantic segmentation applied to various application areas .",
        "at last , we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques .",
        "we name it as deep keyphrase generation since it attempts to capture the deep semantic meaning of the content with a deep learning method .",
        "recent works have explored deep architectures for learning multimodal speech representation ( e .",
        "a deep q - network algorithm was applied and improved to develop an agent capable of learning to play different games in the framework .",
        "several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel .",
        "our approach is data - driven and simple to use in that it learns complex behavior of the vehicles from the massive amount of trajectory data through deep neural network model .",
        "to learn about the consequences of such different conceptualizations of claim for practical applications , we carried out extensive experiments using state - of - the - art feature - rich and deep learning systems , to identify claims in a cross - domain fashion .",
        "exponential linear units ( elus ) are a useful rectifier for constructing deep learning architectures , as they may speed up and otherwise improve learning by virtue of not have vanishing gradients and by having mean activations near zero .",
        "there is a wide gap between symbolic reasoning and deep learning .",
        "in this research , we explore the possibility of using deep learning to improve symbolic reasoning .",
        "briefly , in a reasoning system , a deep feedforward neural network is used to guide rewriting processes after learning from algebraic reasoning examples produced by humans .",
        "given recent deep learning results that demonstrate the ability to effectively optimize high - dimensional non - convex functions with gradient descent optimization on gpus , we ask in this paper whether symbolic gradient optimization tools such as tensorflow can be effective for planning in hybrid ( mixed discrete and continuous ) nonlinear domains with high dimensional state and action spaces ?",
        "we study unsupervised learning by developing introspective generative modeling ( igm ) that attains a generator using progressively learned deep convolutional neural networks .",
        "deep reinforcement learning ( rl ) recently emerged as one of the most competitive approaches for learning in sequential decision making problems with fully observable environments , e .",
        "however , very little work has been done in deep rl to handle partially observable environments .",
        "we propose a new architecture called action - specific deep recurrent q - network ( adrqn ) to enhance learning performance in partially observable domains .",
        "the time series of action - observation pairs are then integrated by an lstm layer that learns latent states based on which a fully connected layer computes q - values as in conventional deep q - networks ( dqns ) .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "while the optimization problem behind deep neural networks is highly non - convex , it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points .",
        "in recent years , deep learning based on artificial neural network ( ann ) has achieved great success in pattern recognition .",
        "a number of deep learning models have been proposed for this task .",
        "the recent remarkable growth and outstanding performance of deep learning have attracted considerable esearch attention .",
        "however , even in state - of - the - art drug analyses , deep learning continues to be used only as a classifier .",
        "in this paper , we propose the first end - to - end learning method for cci , named deepcci .",
        "the performance of deepcci was compared with a plain deep classifier and conventional machine learning methods .",
        "the proposed deepcci showed the",
        "among the suitable models for the framework , splice junction classification using deep recurrent neural networks ( rnns ) is most appropriate for performing dna steganalysis .",
        "despite the recent success of deep - learning based semantic segmentation , deploying a pre - trained road scene segmenter to a city whose images are not presented in the training set would not achieve satisfactory performance due to dataset biases .",
        "in recent years , deep neural networks have been used with great success in determining emotional states .",
        "to this purpose , we utilize a convolutional neural network ( cnn ) to extract features from the speech , while for the visual modality a deep residual network ( resnet ) of 50 layers .",
        "we study the problem of face deblurring by inserting weak supervision in the form of alignment in a deep network .",
        "we introduce parseval networks , a form of deep neural networks in which the lipschitz constant of linear , convolutional and aggregation layers is constrained to be smaller than 1 .",
        "parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation .",
        "recent advances in combining deep neural network architectures with reinforcement learning techniques have shown promising potential results in solving complex control problems with high dimensional state and action spaces .",
        "inspired by these successes , in this paper , we build two kinds of reinforcement learning algorithms : deep policy - gradient and value - function based agents which can predict the best possible traffic signal for a traffic intersection .",
        "in this paper , we propose a deep multi - view convolutional neural network to classify glitches automatically .",
        "the suggested classifier is a multi - view deep neural network that exploits four different views for classification .",
        "we discuss several modifications and extensions over the previous proposed cnvlutin ( cnv ) accelerator for convolutional and fully - connected layers of deep learning network .",
        "meanwhile , although recent work in deep learning has achieved impressive results in many fields , the knowledge is encoded in a subsymbolic representation which cannot be directly used by symbolic systems such as planners .",
        "we propose latplan , an integrated architecture combining deep learning and a classical planner .",
        "deep latent variable models have been shown to facilitate the response generation for open - domain dialog systems .",
        "deep learning refers to a set of machine learning techniques that utilize neural networks with many hidden layers for tasks , such as image classification , speech recognition , language understanding .",
        "deep learning has been proven to be very effective in these domains and is pervasively used by many internet services .",
        "in this paper , we describe different automotive uses cases for deep learning in particular in the domain of computer vision .",
        "\\ gpus and clouds ) for implementing , training and deploying deep neural networks .",
        "we describe an end - to - end deep learning application utilizing a mobile app for data collection and process support , and an amazon - based cloud backend for storage and training .",
        "two methods are studied : an end to end , deep neural network that directly uses audio waveforms as input versus a pipelined approach that performs asr ( automatic speech recognition ) on the question , followed by text - based visual question answering .",
        "compared with existing deep cnn based methods , our method achieves much better results with fewer training examples and model parameters .",
        "while artificial intelligence ( ai ) has become widespread , many commercial ai systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them .",
        "we show that this hybrid approach can improve a text - only deep learning model .",
        "using an implementation based on deep neural networks , we demonstrate that phantom sampling dramatically avoids catastrophic forgetting .",
        "we apply these strategies to competitive multi - class incremental learning of deep neural networks .",
        "deep neural networks ( dnns ) have provably enhanced the state - of - the - art neural machine translation ( nmt ) with their capability in modeling complex functions and capturing complex linguistic structures .",
        "however nmt systems with deep architecture in their encoder or decoder rnns often suffer from severe gradient diffusion due to the non - linear recurrent activations , which often make the optimization much more difficult .",
        "we explore the effectiveness of using deep reinforcement learning to handle intersection problems .",
        "combining several recent advances in deep rl , were we able to learn policies that surpass the performance of a commonly - used heuristic approach in several metrics including task completion time and goal success rate .",
        "the fact that deep rl policies resulted in collisions , although rarely , combined with the limitations of the policy to generalize well to out - of - sample scenarios suggest a need for further research .",
        "we analyze how the knowledge to autonomously handle one type of intersection , represented as a deep q - network , translates to other types of intersections ( tasks ) .",
        "we view intersection handling as a deep reinforcement learning problem , which approximates the state action q function as a deep neural network .",
        "such networks are often used in deep learning and have been shown to be hard to verify for modern satisfiability modulo theory ( smt ) and integer linear programming ( ilp ) solvers .",
        "recently , artificial neural networks , so called deep - learning approaches , have been proposed to address this challenge .",
        "this demo paper describes a software application that applies the tensorflow deep - learning framework to process prediction .",
        "popular deep learning frameworks require users to fine - tune their memory usage so that the training data of a deep neural network ( dnn ) fits within the gpu physical memory .",
        "we introduce a series of deep stochastic point processes , and contrast them with previous computational , simulation - based approaches .",
        "this paper introduces an sld - resolution technique based on deep learning .",
        "it includes a prolog library of deep feedforward neural networks and some essential functions of resolution .",
        "the driving force behind convolutional networks - the most successful deep learning architecture to date , is their expressive power .",
        "we present deep speaker , a neural speaker embedding system that maps utterances to a hypersphere where speaker similarity is measured by cosine similarity .",
        "the embeddings generated by deep speaker can be used for many tasks , including speaker identification , verification , and clustering .",
        "experiments on three distinct datasets suggest that deep speaker outperforms a dnn - based i - vector baseline .",
        "for example , deep speaker reduces the verification equal error rate by 50 % ( relatively ) and improves the identification accuracy by 60 % ( relatively ) on a text - independent dataset .",
        ", loosely labeled ) can be used to facilitate the data - hungry deep learning paradigms in building truly large - scale high precision computer - aided diagnosis ( cad ) systems .",
        "for the accurate detection of trafficking advertisements , we designed and trained a deep multimodal model called the human trafficking deep network ( htdn ) .",
        "we investigate gpu - based parallelization of iterative - deepening a * ( ida * ) .",
        "we argue that the optimization plays a crucial role in generalization of deep learning models through implicit regularization .",
        "we do so by studying the geometry of the parameter space of deep networks , and devising an optimization algorithm attuned to this geometry .",
        "we outperform the accuracy of the deep lstm setup of wu et al .",
        "deep neural models , particularly the lstm - rnn model , have shown great potential in language identification ( lid ) .",
        "we present a phone - aware neural lid architecture , which is a deep lstm - rnn lid system but accepts output from an rnn - based asr system .",
        "inspired by the deep learning approaches in natural language processing , we propose a recurrent neural network model with multiple attention layers for ddi classification .",
        "the experiments show that our model classifies most of the drug pairs into correct ddi categories , which outperforms the existing nlp or deep learning method .",
        "in this paper , we promote a novel deep learning model , omnirank , which comprehends multi - dimensional features of p2p platforms for risk quantification and produces scores for ranking .",
        "then we extract deep features of p2p platforms via text comprehension , topic modeling , knowledge graph and sentiment analysis , which are delivered",
        "deeptingle is a text prediction and classification system trained on the collected works of the renowned fantastic gay erotica author chuck tingle .",
        "whereas the writing assistance tools you use everyday ( in the form of predictive text , translation , grammar checking and so on ) are trained on generic , purportedly \" neutral \" datasets , deeptingle is trained on a very specific , internally consistent but externally arguably eccentric dataset .",
        "deeptingle is realized as a web application based on lstm networks and the glove word embedding , implemented in javascript with keras - js .",
        "we propose a novel evolutionary deep radiomic sequencer discovery approach based on evolutionary deep intelligence .",
        "motivated by patient privacy concerns and the idea of operational artificial intelligence , the evolutionary deep radiomic sequencer discovery approach organically evolves increasingly more efficient deep radiomic sequencers that produce significantly more compact yet similarly descriptive radiomic sequences over multiple generations .",
        "we evaluated the evolved deep radiomic sequencer ( edrs ) discovered via the proposed evolutionary deep radiomic sequencer discovery framework against state - of - the - art radiomics - driven and discovery radiomics methods using clinical lung ct data with pathologically - proven diagnostic data .",
        "the paper presents a novel concept for collaborative descriptors between deeply learned and hand - crafted features .",
        "relation extraction is an important sub - task of information extraction which has the potential of employing deep learning ( dl ) models with the creation of large datasets using distant supervision .",
        "recently deep neural networks ( dnns ) have been used to learn speaker features .",
        "this paper presents a convolutional time - delay deep neural network structure ( ct - dnn ) for speaker feature learning .",
        "the second part of this survey details the different approaches for vqa , classified into four types : non - deep learning models , deep learning models without attention , deep learning models with attention , and other models which do not fit into the first three .",
        "we present net2vec , a flexible high - performance platform that allows the execution of deep learning algorithms in the communication network .",
        "the intel collaborative research institute for computational intelligence ( icri - ci ) has been heavily supporting machine learning and deep learning research from its foundation in 2012 .",
        "we have asked six leading icri - ci deep learning researchers to address the challenge of \" why & amp ; when deep learning works \" , with the goal of looking inside deep learning , providing insights on how deep networks function , and uncovering key observations on their expressiveness , limitations , and potential .",
        "the output of this challenge resulted in five papers that address different facets of deep learning .",
        "these different facets include a high - level understating of why and when deep networks work ( and do not work ) , the impact of geometry on the expressiveness of deep networks , and making deep networks interpretable .",
        "in this paper , we take a deep look at the application of distant supervision in relation extraction .",
        "we also give an extensive empirical study on using common deep learning models for vietnamese ner , at both word and character level .",
        "bridging this gap , we develop a method to predict human impressions of faces in 40 subjective social dimensions , using deep representations from state - of - the - art neural networks .",
        "replacing hand - engineered pipelines with end - to - end deep learning systems has enabled strong results in applications like speech and object recognition .",
        "we then provide evidence for deeper limitations of the parallelogram model based on the intrinsic geometric constraints of vector spaces , paralleling classic results for first - order similarity .",
        "the recent success of deep learning in image recognition , natural language processing , and machine translation indicates a potential solution for stabilizing the malware detection effectiveness .",
        "deep learning usually involves a large number of parameters that cannot be learned from only a small dataset .",
        "we propose a novel framework for efficient parallelization of deep reinforcement learning algorithms , enabling these algorithms to learn from multiple actors on a single machine .",
        "also , in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments .",
        "this paper introduces an end - to - end fine - tuning method to improve hand - eye coordination in modular deep visuo - motor policies ( modular networks ) where each module is trained independently .",
        "we bridge this gap for models that exhibit a bipartite structure , including , most notably , the restricted / deep boltzmann machine .",
        "in recent years , the deep neural network has enjoyed a great success in large - scale image and video recognitions .",
        "in this paper , we propose and experiment using deep convolutional neural network to imitate how human brain processes hierarchical structures in the auditory signals , such as music , speech , etc .",
        "deep learning , iterative solvers , astrophysics , computational fluid dynamics , quantum chemistry ) .",
        "this article also tries to connect various research directions emerged out of the fnn optimization practices , such as evolving neural network ( nn ) , cooperative coevolution nn , complex - valued nn , deep learning , extreme learning machine , quantum n",
        "this paper presents experiments illustrating how formal language theory can shed light on deep learning .",
        "there is no need for a deep memory hierarchy as in a gpu , nor a fine - grain mesh as in a systolic array .",
        "good parameter settings are crucial to achieve high performance in many areas of artificial intelligence ( ai ) , such as satisfiability solving , ai planning , scheduling , and machine learning ( in particular deep learning ) .",
        "we present a practical approach for processing mobile sensor time series data for continual deep learning predictions .",
        "deep learning ( dl ) systems are increasingly deployed in security - critical domains including self - driving cars and malware detection , where the correctness and predictability of a system ' s behavior for corner - case inputs are of great importance .",
        "however , given the fact that deep reinforcement learning often deals with interpreting visual information , a large part of the train and inference time is spent performing convolutions .",
        "recently , deep convolutional neural network ( dcnn ) achieved increasingly remarkable success and rapidly developed in the field of natural image recognition .",
        "in this paper , we use deep learning methods , and in particular employ the multilayer perceptron , to build an algorithm that can predict flow pattern in twophase flow from fluid properties and pipe conditions .",
        "there are many applications scenarios for which the computational performance and memory footprint of the prediction phase of deep neural networks ( dnns ) needs to be optimized .",
        "deep neural networks ( dnns ) are presently the state - of - the - art for image classification tasks .",
        "in this paper , we derive inspiration from recent advances in the field of cybersecurity and multi - agent systems and propose to use the concept of moving target defense ( mtd ) for increasing the robustness of well - known deep networks trained on the imagenet dataset towards such adversarial attacks .",
        "the basic setup consists of two deep networks playing against each other in a zero - sum game setting .",
        "ultimately , the proposed framework provides an effective and scalable graph - based solution which is natural to the operational mechanism of deep neural networks .",
        "deep reinforcement learning ( drl ) methods have performed well in an increasing numbering of high - dimensional visual decision making domains .",
        "we propose a new learning paradigm , factored action space representations ( far ) wherein we decompose a control policy learned using a deep reinforcement learning algorithm into independent components , analogous to decomposing a vector in terms of some orthogonal basis vectors .",
        "we address the problem of reconstructing sparse signals from noisy and compressive measurements using a feed - forward deep neural network ( dnn ) with an architecture motivated by the iterative shrinkage - thresholding algorithm ( ista ) .",
        "the resulting architecture turns out to be a deep residual network , which has recently been shown to exhibit superior performance in several visual recognition tasks .",
        "while lambda - returns have been extensively studied in rl , they haven ' t been explored a lot in deep rl .",
        "the method introduced in this paper aims at helping deep learning practitioners faced with an overfit problem .",
        "how to develop slim and accurate deep neural networks has become crucial for real - world applications , especially for those employed in embedded systems .",
        "though previous work along this research line has shown some promising results , most existing methods either fail to significantly compress a well - trained deep network or require a heavy retraining process for the pruned deep network to re - boost its prediction performance .",
        "in this paper , we propose a new layer - wise pruning method for deep neural networks .",
        "recent advances in deep learning have enabled rl algorithms to achieve impressive performance in restricted domains such as playing atari video games ( mnih et al .",
        "the rise of graph - structured data such as social networks , regulatory networks , citation graphs , and functional brain networks , in combination with resounding success of deep learning in various applications , has brought the interest in generalizing deep learning models to non - euclidean domains .",
        "in this paper , we introduce a new spectral domain convolutional architecture for deep learning on graphs .",
        "transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data , where there are limited computational resources , or when tuning the hyper - parameters needed for training is not an option .",
        "while previous contributions to feature extraction propose embeddings based on a single layer of the network , in this paper we propose a full - network embedding which successfully integrates convolutional and fully connected features , coming from all layers of a deep convolutional neural network .",
        "deep neural networks have been shown to succeed at a range of natural language tasks such as machine translation and text summarization .",
        "as first solutions , we design a set of deep neural models that learn to represent the context of each variable location and variable usage in a data flow - sensitive way .",
        "in this work , we propose terngrad that uses ternary gradients to accelerate distributed deep learning in data parallelism .",
        "experiments show significant speed gains for various deep neural networks .",
        "in this paper , we show that deep learning techniques can be leveraged to automatically generate code given a graphical user interface screenshot as input .",
        "in this work , we focus on one important aspect of communication systems , the detection algorithms , and demonstrate that by borrowing tools from deep learning , it is possible to train detectors that perform well , without any knowledge of the underlying channel models .",
        "we show that deep learning algorithms perform significantly better than a simple detector that was used in previous works , which also did not assume any knowledge of the channel .",
        "this work is a first thorough study of memory structures for deep - neural - network - based robot navigation , and offers novel tools to train such networks from supervision and quantify their ability to generalize to unseen scenarios .",
        "the reported method can be applied to deep learning problems beyond robotics .",
        "to ensure cross - task generalization , we develop a deep predictive model based on successor representations .",
        "applying deep reinforcement learning ( rl ) on real systems suffers from slow data sampling .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "in this work , we propose a new approach to deduce optimal treatment policies for septic patients by using continuous state - space models and deep reinforcement learning .",
        "we introduce an architecture in which internal representations , learned by end - to - end optimization in a deep neural network performing a textual question - answering task , can be interpreted using basic concepts from linguistic theory .",
        "planning new policies is performed by tree search , while a deep neural network generalises those plans .",
        "in contrast , standard deep reinforcement learning algorithms rely on a neural network not only to generalise plans , but to discover them too .",
        "we then analyze the effects of using second - order embeddings as input features in two deep natural language processing models , for named entity recognition and recognizing textual entailment , as well as a linear model for paraphrase recognition .",
        "we achieve state - of - the - art results on our predictive tasks using deep architectures .",
        "selective classification techniques ( also known as reject option ) have not yet been considered in the context of deep neural networks ( dnns ) .",
        "inspired by the success of using deep convolutional features for natural image analysis and multi - instance learning ( mil ) for labeling a set of instances / patches , we propose end - to - end trained deep multi - instance networks for mass classification based on whole mammogram without the aforementioned rois .",
        "we explore three different schemes to construct deep multi - instance networks for whole mammogram classification .",
        "generative moment matching network ( gmmn ) is a deep generative model that differs from generative adversarial network ( gan ) by replacing the discriminator in gan with a two - sample test based on kernel maximum mean discrepancy ( mmd ) .",
        "inspired by the generative nature of hippocampus as a short - term memory system in primate brain , we propose the deep generative replay , a novel framework with a cooperative dual model architecture consisting of a deep generative model ( \" generator \" ) and a task solving model ( \" solver \" ) .",
        "this paper is a deep investigation of cross - language plagiarism detection methods on a new recently introduced open dataset , which contains parallel and comparable collections of documents with multiple characteristics ( different genres , languages and sizes of texts ) .",
        "we investigate cross - language plagiarism detection methods for 6 language pairs on 2 granularities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages .",
        "as a starting point , we show improvements over the two state - ofthe - art approaches for single - speaker neural tts : deep voice 1 and tacotron .",
        "we introduce deep voice 2 , which is based on a similar pipeline with deep voice 1 , but constructed with higher performance building blocks and demonstrates a significant audio quality improvement over deep voice 1 .",
        "we then demonstrate our technique for multi - speaker speech synthesis for both deep voice 2 and tacotron on two multi - speaker tts datasets .",
        "we introduce a class of deep recurrent neural operations and formally characterize their associated kernel spaces .",
        "we report results for learning the cdprs with a deep neural network and using them to solve two tasks with deep reinforcement learning .",
        "deep learning has shown promising results on hard perceptual problems in recent years .",
        "however , deep learning systems are found to be vulnerable to small adversarial perturbations that are nearly imperceptible to human .",
        "such specially crafted perturbations cause deep learning systems to output incorrect decisions , with potentially disastrous consequences .",
        "these vulnerabilities hinder the deployment of deep learning systems where safety or security is important .",
        "attempts to secure deep learning systems either target specific attacks or have been shown to be ineffective .",
        "the deep neural network outperforms other state of the art shallow classification models in predicting labels derived from three different dental plaque assessment scores .",
        "there have been many approaches to attempt learning patterns of motion directly from data using a wide variety of techniques ranging from hand - crafted features to sophisticated deep learning models for unsupervised feature learning .",
        "we propose an end to end deep learning model to learn the motion patterns of humans using different navigational modes directly from data using the much popular sequence to sequence model coupled with a soft attention mechanism .",
        "we propose a hierarchical multi - view deep learning approach to contextualise citizen observations of various city systems and services .",
        "a deep , classification - specific attention mechanism improves further the overall performance of the rnn .",
        "deep learning approaches are still not very common in the speaker verification field .",
        "we investigate the possibility of using deep residual convolutional neural network with spectrograms as an input features in the text - dependent speaker verification task .",
        "the parser is implemented as a deep neural network whose only input is orthographic representations of words .",
        "in this paper we report on results using a language model approach , and outline our plans for using methods from deep learning .",
        "in this work , we present a novel approach to ontology reasoning that is based on deep learning rather than logic - based formal reasoning .",
        "to this end , we introduce a new model for statistical relational learning that is built upon deep recursive neural networks , and give experimental evidence that it can easily compete with , or even outperform , existing logic - based reasoners on the task of ontology reasoning .",
        "we show that a modular neural network ( mnn ) can combine various speech enhancement modules , each of which is a deep neural network ( dnn ) specialized on a particular enhancement job .",
        "we see this as collaborative deep learning ( cdl ) , because it can reuse various already - trained dnn models without any further refining .",
        "recent advances in combining deep learning and reinforcement learning have shown a promising path for designing new control agents that can learn optimal policies for challenging control tasks .",
        "this paper proposes a cs scheme that exploits the representational power of restricted boltzmann machines and deep learning architectures to model the prior distribution of the sparsity pattern of signals belonging to the same class .",
        "despite the success of deep learning on many fronts especially image and speech , its application in text classification often is still not as good as a simple linear svm on n - gram tf - idf representation especially for smaller datasets .",
        "deep learning tends to emphasize on sentence level semantics when learning a representation with models like recurrent neural network or recursive neural network , however from the success of tf - idf representation , it seems a bag - of - words type of representation has its strength .",
        "we also demonstrate that this model beats traditional linear models on tf - idf vectors on small and polished datasets like news article in which typically deep learning",
        "by incorporating automatic syntactic features with word embeddings as input for bidirectional long short - term memory ( bi - lstm ) , our system , although simpler than some deep learning architectures , achieves a much better result for vietnamese ner .",
        "adversarial learning has been successfully embedded into deep networks to learn transferable features for domain adaptation , which reduce distribution discrepancy between the source and target domains and improve generalization performance .",
        "in this paper , we present randomized multilinear adversarial networks ( rman ) , which exploit multiple feature layers and the classifier layer based on a randomized multilinear adversary to enable both deep and discriminative adversarial adaptation .",
        "in this short note , we report on recent results showing that simple feature squeezing techniques also make deep learning models significantly more robust against the carlini / wagner attacks , which are the best known adversarial methods discovered to date .",
        "deep neural networks trained on large supervised datasets have led to impressive results in recent years .",
        "in this paper , we investigate the behavior of deep neural networks on training sets with massively noisy labels .",
        "however , data - driven based supervised approaches , particularly the ones designed with deep learning , have recently emerged as potential alternatives .",
        "in this light , we are going to comprehensively summarise the recently developed and most representative deep learning approaches to deal with the raised problem in this article , with the aim of providing guidelines for those who are going deeply into the field of environmentally robust speech recognition .",
        "recent progress in reinforcement learning ( rl ) , fueled by its combination , with deep learning has enabled impressive results in learning to interact with complex virtual environments , yet real - world applications of rl are still scarce .",
        "we propose an algorithm to automatically learn learning rates using neural network based actor - critic methods from deep reinforcement learning ( rl ) .",
        "however , the lack of an efficient way to calculate the importance still hinders its application to deep learning .",
        "in this paper , we show that the loss value can be used as an alternative importance metric , and propose a way to efficiently approximate it for a deep model , using a small model trained for that purpose in parallel .",
        "in appendix , with knowledge of learning machine , we try to view deep learning from a different angle , i .",
        "we present an optimized image generation process based on a deep convolutional generative adversarial networks ( dcgans ) , in order to create photorealistic high - resolution images ( up to 1024x1024 pixels ) .",
        "deep neural network ( dnn ) are currently of great inter - est in research and application .",
        "we perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity .",
        "our experiments on a benchmark dataset of 16k annotated tweets show that such deep learning methods outperform state - of - the - art char / word n - gram methods by ~ 18 f1 points .",
        "off - policy model - free deep reinforcement learning methods using previously collected data can improve sample efficiency over on - policy policy gradient techniques .",
        "this paper examines , both theoretically and empirically , approaches to merging on - and off - policy updates for deep reinforcement learning .",
        "the final algorithm provides a generalization and unification of existing deep policy gradient techniques , has theoretical guarantees on the bias introduced by off - policy updates , and improves on the state - of - the - art model - free deep rl methods on a number of openai gym continuous control benchmarks .",
        "a deep convolutional neural network approach is developed to model the voxel - wise spatio - temporal tumor progression .",
        "the deep features are combined with the time intervals and the clinical factors to feed a process of feature selection .",
        "stripes is a deep neural network ( dnn ) accelerator that uses bit - serial computation to offer performance that is proportional to the fixed - point precision of the activation values .",
        "deep neural networks are able to solve tasks across a variety of domains and modalities of data .",
        "we demonstrate the effectiveness of our framework on a variety of deep neural network architectures in domains from computer vision , natural language processing , and reinforcement learning .",
        "yet , a unifying perspective that could embrace both these branches of research is of great importance as it enables a deeper understanding of all involved methods and principles and creates room for their cross - fertilisation , ripening and further development .",
        "though the recent progress is substantial , deep learning methods can be vulnerable to the elaborately crafted adversarial samples .",
        "in training , we propose to minimize the reverse cross - entropy , which encourages a deep network to learn latent representations that better distinguish adversarial samples from normal ones .",
        "exploiting the great expressive power of deep neural network architectures , relies on the ability to train them .",
        "training a deep convolutional neural network ( cnn ) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence .",
        "in this paper , we seek to answer the following central question in the context of medical image analysis : \\ emph { can the use of pre - trained deep cnns with sufficient fine - tuning eliminate the need for training a deep cnn from scratch ? }",
        "to address this question , we considered 4 distinct medical imaging applications in 3 specialties ( radiology , cardiology , and gastroenterology ) involving classification , detection , and segmentation from 3 different imaging modalities , and investigated how the performance of deep cnns trained from scratch compared with the pre - trained cnns fine - tuned in a layer - wise manner .",
        "recent advances in deep learning motivate the use of deep neutral networks in sensing applications , but their excessive resource needs on constrained embedded devices remain an important impediment .",
        "a recently explored solution space lies in compressing ( approximating or simplifying ) deep neural networks in some manner before use on the device .",
        "we propose a new compression solution , called deepiot , that makes two key contributions in that space .",
        "first , unlike current solutions geared for compressing specific types of neural networks , deepiot presents a unified approach that compresses all commonly used deep learning structures for sensing applications , including fully - connected , convolutional , and recurrent neural networks , as well as their combinations .",
        "second , unlike solutions that either sparsify weight matrices or assume linear structure within weight matrices , deepiot compresses neural network structures into smaller dense matrices by finding the minimum number of non - redundant hidden elements , such as filters and dimensions required by each layer , while keeping the performance of sensing applications the same .",
        "we demonstrate that with the help of existing ' deep ' linguistic processing technology we are able to create challenging abstract datasets , which enable us to investigate the language understanding abilities of multimodal deep learning models in detail .",
        "our work shows how a deep learning architecture equipped with an rn module can implicitly discover and learn to reason about entities and their relations .",
        "in this regard , we design a multimodal biometric authentication system named deepkey which uses both gait and electroencephalography ( eeg ) signals to provide better protection against such risks .",
        "deepkey consists of three key components : an invalid id filter model to block invalid subjects , a gait identification model to recognize gait ids and an eeg identification model to recognize eeg ids .",
        "in particular , the first two models employ a one - class svm algorithm and a recurrent neural network based deep learning model , respectively .",
        "deepkey is trained with a gait dataset of 160 , 000 samples and an eeg dataset of 108 , 000 samples .",
        "experimental results show deepkey outperforms",
        "it is challenging to develop stochastic gradient based scalable inference for deep discrete latent variable models ( lvms ) , due to the difficulties in not only computing the gradients , but also adapting the step sizes to different latent factors and hidden layers .",
        "for the poisson gamma belief network ( pgbn ) , a recently proposed deep discrete lvm , we derive an alternative representation that is referred to as deep latent dirichlet allocation ( dlda ) .",
        "we propose a web - based visualization tool , \\ textit { adversarial - playground } , to demonstrate the efficacy of common adversarial methods against a deep neural network ( dnn ) model , built on top of the tensorflow library .",
        "in this paper , we demonstrated that the speaker factor is also a short - time spectral pattern and can be largely identified with just a few frames using a simple deep neural network ( dnn ) .",
        "this discovery motivated a cascade deep factorization ( cdf ) framework that infers speech factors in a sequential way , and factors previously inferred are used as conditional variables when inferring other factors .",
        "increasingly , cognitive scientists have demonstrated interest in applying tools from deep learning .",
        "one use for deep learning is in language acquisition where it is useful to know if a linguistic phenomenon can be learned through domain - general means .",
        "to assess whether unsupervised deep learning is appropriate , we first pose a smaller question : can unsupervised neural networks apply linguistic rules productively , using them in novel situations ?",
        "further , this work helps lay the foundations for future collaboration between the deep learning and cognitive science communities .",
        "four runs were submitted , with approaches ranging from a trivial system that selected the first $ n $ snippets , to the use of deep learning approaches under a regression framework .",
        "the basic features of some of the most versatile and popular open source frameworks for machine learning ( tensorflow , deep learning4j , and h2o ) are considered and compared .",
        "the performance tests for the de facto standard mnist data set were carried out on h2o framework for deep learning algorithms designed for cpu and gpu platforms for single - threaded and multithreaded modes of operation .",
        "our model is able to select syntactically plausible candidates and - if disregarding syntax - discriminates candidates using deeper features .",
        "deeper inspection shows that the model is able to learn a relation between the anaphor in the anaphoric sentence and its antecedent .",
        "we explore deep reinforcement learning methods for multi - agent domains .",
        "the paradigm shift from shallow classifiers with hand - crafted features to end - to - end trainable deep learning models has shown significant improvements on supervised learning tasks .",
        "despite the promising power of deep neural networks ( dnn ) , how to alleviate overfitting during training has been a research topic of interest .",
        "deep neural networks ( dnn ) have been successfully applied for music classification including music tagging .",
        "in this article , we investigate specific aspects of neural networks to deepen our understanding of their properties .",
        "we propose a deep dynamic neural network model built on a dynamic vision network , a motor generation network , and a higher - level network .",
        "deep learning requires data .",
        "deep learning thrives with large neural networks and large datasets .",
        "the encoder is a deep convolutional neural network ( cnn ) based on the vgg network .",
        "as part of this development , we examine the parallels between latent variable trajectories operating across multiple time - scales during optimization , and the activations within deep network structures designed to adaptively model such characteristic sequences .",
        "deep convolutional neural networks are being actively investigated in a wide range of speech and audio processing applications including speech recognition , audio event detection and computational paralinguistics , owing to their ability to reduce factors of variations , such as speaker and environment information in signals , for speech recognition .",
        "however , studies have suggested to favor a certain type of convolutional operations when building a deep convolutional neural network for speech applications although there has been promising results using different types of convolutional operations .",
        "since affective behavioral information has been shown to reflect temporally varying of mental state and convolutional operation are applied locally in time , all deep neural networks share a deep recurrent sub - network architecture for further temporal modeling .",
        "finally we show that all of our deep neural networks provide state - of - the",
        "this paper aims at one - shot learning of deep neural nets , where a highly parallel setting is considered to address the algorithm calibration problem - selecting the best neural architecture and learning hyper - parameter values depending on the dataset at hand .",
        "the selection of hyper - parameters is critical in deep learning .",
        "we show that such methods have theoretical properties that make them appealing for performing hyperparameter search , and demonstrate that , when applied to the selection of hyperparameters of complex deep learning models ( such as state - of - the - art lstm language models and image classification models ) , they yield suitable hyperparameters values with much fewer runs than random search .",
        "we focus on progressive neural networks and compare these networks to the conventional deep learning method of pre - training and fine - tuning .",
        "we adopted an approach we dub \" deep optimization \" , taking a data - driven , highly parametric , and computationally intensive approach to solver design .",
        "in this thesis , we consider the problem of using probabilistic deep learning model to learn the topological map , which is essentially a sparse undirected graph where nodes represent places annotated with their semantic attributes ( e .",
        "we propose to use a novel probabilistic deep model , sum - product networks ( spns ) , due to their unique properties .",
        "in this work , we initiate the exploration of the use of tools from deep learning on this topic .",
        "we conclude by demonstrating the potential of deep learning for deriving optimal auctions with high revenue for poorly understood problems .",
        "popular independent ensembles ( ie ) relying on naive averaging / voting scheme have been of typical choice for most applications involving deep neural networks , but they do not consider advanced collaboration among ensemble models .",
        "in this paper , we propose new ensemble methods specialized for deep neural networks , called confident multiple choice learning ( cmcl ) : it is a variant of multiple choice learning ( mcl ) via addressing its overconfidence issue .",
        "we design an enriched deep recurrent visual attention model ( edram ) - an improved attention - based architecture for multiple object recognition .",
        "factoid question answering ( qa ) has recently benefited from the development of deep learning ( dl ) systems .",
        "while going deeper has been witnessed to improve the performance of convolutional neural networks ( cnn ) , going smaller for cnn has received increasing attention recently due to its attractiveness for mobile / embedded applications .",
        "it remains an active and important topic how to design a small network while retaining the performance of large and deep cnns ( e .",
        "first , we propose a simple yet powerful method for compressing the size of deep cnns based on parameter binarization .",
        "by doing this , we show that previous deep cnns such as googlenet and inception - type nets can be compressed dramatically",
        "we analyze this phenomenon and devise provably good initialization strategies for dual optimization as well as heuristics for the non - convex case , relevant for deep learning .",
        "recommendation algorithms that incorporate techniques from deep learning are becoming increasingly popular .",
        "monte carlo tree search ( mcts ) is extremely popular in computer go which determines each action by enormous simulations in a broad and deep search tree .",
        "the first part is a novel deep alternative neural network ( dann ) used to generate candidates of next move .",
        "compared with existing deep convolutional neural network ( dcnn ) , dann inserts recurrent layer after each convolutional layer and stacks them in an alternative manner .",
        "in typical deep rl methods this is achieved by approximating the optimal value function with a low - dimensional representation using a deep network .",
        "the recent adaptation of deep neural network - based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks .",
        "one of the constraints that limits full exploration of deep learning technologies for semantic parsing is the lack of sufficient annotation training data .",
        "in particular , in the context of deep learning , we empirically show that the spectrum of the hessian is composed of two parts : ( 1 ) the bulk centered near zero , ( 2 ) and outliers away from the bulk .",
        "at the heart of deep learning we aim to use neural networks as function approximators - training them to produce outputs from inputs in emulation of a ground truth function or data creation process .",
        "the state - of - the - art solutions to the vocabulary mismatch in information retrieval ( ir ) mainly aim at leveraging either the relational semantics provided by external resources or the distributional semantics , recently investigated by deep neural approaches .",
        "guided by the intuition that the relational semantics might improve the effectiveness of deep neural approaches , we propose the deep semantic resource inference model ( dsrim ) that relies on : 1 ) a representation of raw - data that models the relational semantics of text by jointly considering objects and relations expressed in a knowledge resource , and 2 ) an end - to - end neural architecture that learns the query - document relevance by leveraging the distributional and relational semantics of documents and queries .",
        "the experimental evaluation carried out on two trec datasets from trec terabyte and trec cds tracks relying respectively on wordnet and mesh resources , indicates that our model outperforms state - of - the - art semantic and deep neural ir models .",
        "deep neural networks are known to be difficult to train due to the instability of back - propagation .",
        "a deep \\ emph { residual network } ( resnet ) with identity loops remedies this by stabilizing gradient computations .",
        "therefore , we introduce an alternative deep resnet training algorithm , \\ emph { boostresnet } , which is particularly suitable in non - differentiable architectures .",
        "inspired by the recent success of deep learning models in solving various vision problems ( e .",
        "variational autoencoders ( vae ) represent a popular , flexible form of deep generative model that can be stochastically fit to samples from a given random process using an information - theoretic variational bound on the true underlying distribution .",
        "we examine the role of memorization in deep learning , drawing connections to capacity , generalization , and adversarial robustness .",
        "while deep networks are capable of memorizing noise data , our results suggest that they tend to prioritize learning simple patterns first .",
        "in our experiments , we expose qualitative differences in gradient - based optimization of deep neural networks ( dnns ) on noise vs .",
        "our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization .",
        "adaptive gradient methods have become recently very popular , in particular as they have been shown to be useful in the training of deep neural networks .",
        "in this paper we have analyzed rmsprop , originally proposed for the training of deep neural networks , in the context of online convex optimization and show $ \\ sqrt { t } $ - type regret bounds .",
        "finally , we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or stochastic gradient descent in the optimization of strongly convex functions as well as in training of deep neural networks .",
        "convolution is a critical component in modern deep neural networks , thus several algorithms for convolution have been developed .",
        "deep neural networks ( dnns ) have advanced performance on a wide range of complex tasks , rapidly outpacing our understanding of the nature of their solutions .",
        "inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task .",
        "specifically , safetynets develops and implements a specialized interactive proof ( ip ) protocol for verifiable execution of a class of deep neural networks , i .",
        "our empirical results on three - and four - layer deep neural networks demonstrate the run - time costs of safetynets for both the client and server are low .",
        "we propose a novel deep neural networks ( dnn ) based model , canonical correlated autoencoder ( c2ae ) , for solving this task .",
        "aiming at better relating feature and label domain data for improved classification , we uniquely perform joint feature and label embedding by deriving a deep latent space , followed by the introduction of label - correlation sensitive loss function for recovering the predicted label outputs .",
        "we propose a deep network , which not only achieves competitive accuracy for text classification , but also exhibits compositional behavior .",
        "in contrast , the higher layers compose meaningful phrases and clauses , whose lengths increase as the networks get deeper until fully composing the sentence .",
        "deep generative models have recently shown great promise in imitation learning for motor control .",
        "this paper proposes a novel deep reinforcement learning ( rl ) architecture , called value prediction network ( vpn ) , which integrates model - free and model - based rl methods into a single neural network .",
        "furthermore , vpn outperforms deep q - network ( dqn ) on several atari games even with short - lookahead planning , demonstrating its potential as a new way of learning a good state representation .",
        "in this paper , we propose a novel deep learning method named projection - recovery network ( prnet ) to blindly calibrate sensor measurements online .",
        "the prnet first projects the drifted data to a feature space , and uses a powerful deep convolutional neural network to recover the estimated drift - free measurements .",
        "we also provide helpful insights for designing deep neural networks for sensor calibration .",
        "in this paper , we propose a novel deep neural network architecture which allows it to learn without any significant increase in number of parameters .",
        "we investigate the compositional structure of message vectors computed by a deep network trained on a communication game .",
        "domain adaptation is an important open problem in deep reinforcement learning ( rl ) .",
        "darla significantly outperforms conventional baselines in zero - shot domain adaptation scenarios , an effect that holds across a variety of rl environments ( jaco arm , deepmind lab ) and base rl algorithms ( dqn , a3c and ec ) .",
        "by contrast , logical semantic representations capture deeper levels of sentence semantics , but their symbolic nature does not offer graded notions of textual similarity .",
        "deep residual learning ( resnet ) is a new method for training very deep neural networks using identity map - ping for shortcut connections .",
        "in contradictory to popular beliefs that resnet only works well for very deep networks , we found that even with 9 layers of cnns , using identity mapping could significantly improve the performance for distantly - supervised relation extraction .",
        "we show that small and shallow feed - forward neural networks can achieve near state - of - the - art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models .",
        "this paper presents an attention - based deep learning approach ; we call attentivechrome , that uses a unified architecture to model and to interpret dependencies among chromatin factors for controlling gene regulation .",
        "we propose a new framework for abstractive text summarization based on a sequence - to - sequence oriented encoder - decoder model equipped with a deep recurrent generative decoder ( drgn ) .",
        "we propose a dynamic ranking paradigm , named as dnn - mab , that is composed of a pairwise deep neural network ( dnn ) $ \\ mathit { pre } $ - ranker connecting a revised multi - armed bandit ( mab ) dynamic $ \\ mathit { post } $ - ranker .",
        "this paper introduces a corpus for text - based emotion detection on multiparty dialogue as well as deep neural models that outperform the existing approaches for document classification .",
        "this paper proposes a text summarization approach for factual reports using a deep learning model .",
        "we investigate carefully functional segment identification in two approaches : ( 1 ) machine learning approach using maximum entropy ( me ) and conditional random fields ( crfs ) ; ( 2 ) deep learning approach using bidirectional long short - term memory ( lstm ) with a crf layer ( bi - lstm - crf ) on two different conversational datasets : ( 1 ) facebook messages ( message data ) ; ( 2 ) transcription from phone conversations ( phone data ) .",
        "to the best of our knowledge , this is the first work that applies deep learning based approach to dialog act segmentation .",
        "as the results show , deep learning approach performs appreciably better as to compare",
        "existing works based on deep neural network ( dnn ) mostly construct one common space for different modalities to find the latent alignments between them , which lose their exclusive modality - specific characteristics .",
        "finally , we present initial baseline results for canonical deep reinforcement learning agents applied to the starcraft ii domain .",
        "given a set of sentences from a book or even a fan - fiction written in the same universe , we employ deep learning models to visualize the input by stitching together relevant frames from the movie .",
        "in this paper , we propose to use deep 3 - dimensional convolutional networks ( 3d cnns ) in order to address the challenge of modelling spectro - temporal dynamics for speech emotion recognition ( ser ) .",
        "we found that 1 ) shallow temporal and moderately deep spectral kernels of a homogeneous architecture are optimal for the task ; and 2 ) our 3d cnns are more effective for spectro - temporal feature learning compared to other methods .",
        "inspired by recent advances in using deep memory networks for question answering ( qa ) , we propose a new approach which considers emotion cause identification as a reading comprehension task in qa .",
        "in this paper we describe a deep learning system that has been designed and built for the wassa 2017 emotion intensity shared task .",
        "we present ladder , the first deep reinforcement learning agent that can successfully learn control policies for large - scale real - world problems directly from raw inputs composed of high - level semantic information .",
        "the agent is based on an asynchronous stochastic variant of dqn ( deep q network ) named dasqn .",
        "preprocessing for deep learning is characterized by pipelines that lazily load data and perform data transformation , augmentation , batching and logging .",
        "here we introduce a novel software framework named nuts - flow / ml that encapsulates common preprocessing operations as components , which can be flexibly arranged to rapidly construct efficient preprocessing pipelines for deep learning .",
        "in this paper , we show that an adversary can automate the feature engineering process , and thus automatically deanonymize tor traffic by applying our novel method based on deep learning .",
        "we evaluate our approach on a dataset comprised of more than three million network traces , which is the largest dataset of web traffic ever gathered for website fingerprinting , and find that the performance achieved by deep learning techniques is comparable to known approaches which include various research efforts spanning over multiple years .",
        "the deployment of deep convolutional neural networks ( cnns ) in many real world applications is largely hindered by their high computational cost .",
        "deep learning - based techniques have achieved state - of - the - art performance on a wide variety of recognition and classification tasks .",
        "in this paper we introduce a deep learning framework for learning koopman operators of nonlinear dynamical systems .",
        "we show that this novel method automatically selects efficient deep dictionaries , outperforming state - of - the - art methods .",
        "the techniques from the literature that are presented herein have great performances , however , instead of the machine learning techniques employed in these works , we propose to use deep learning techniques such as long - short term memory ( lstm ) recurrent neural network ( rnn ) , and show the improved performance .",
        "deep neural networks are generally trained using iterative gradient updates .",
        "second , deep neural networks can be used to automatically combine input features , and including non - local features that capture semantic patterns that cannot be expressed using discrete indicator features .",
        "for such domains , we propose to use deep neural networks in learning for planning , based on learning a reactive policy that imitates execution traces produced by a planner .",
        "we investigate architectural properties of deep networks that are suitable for learning long - horizon planning behavior , and explore how to learn , in addition to the policy , a heuristic function that can be used with classical planners or search algorithms such as a * .",
        "in this paper , we present algorithms for converting a deep representation of a story into a dialogic storytelling , that can vary aspects of the telling , including the personality of the storytellers .",
        "in particular , the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance .",
        "this article provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years .",
        "in particular , we show that layered learning approaches such as deep belief networks excel along these dimensions .",
        "recent advances in deep neural networks ( dnns ) have led to the development of dnn - driven autonomous cars that , using sensors like camera , lidar , etc .",
        "we first explain how a simple annotation tool allows naive annotators to easily create a deep representation of fabula called a story intention graph , and show how we use this representation to generate story tellings automatically .",
        "the basic features of some of the most versatile and popular open source frameworks for machine learning ( tensorflow , deep learning4j , and h2o ) are considered and compared .",
        "the performance tests for the de facto standard mnist data set were carried out on h2o framework for deep learning algorithms designed for cpu and gpu platforms for single - threaded and multithreaded modes of operation also , we present the results of testing neural networks architectures on h2o platform for various activation functions , stopping metrics , and other parameters of machine learning algorithm .",
        "compared to current poisoning strategies , our approach is able to target a wider class of learning algorithms , trained with gradient - based procedures , including neural networks and deep learning architectures .",
        "with the development of deep learning , new ideas have appeared to address har problems .",
        "here , a deep network architecture using residual bidirectional long short - term memory ( lstm ) cells is proposed .",
        "generally , the proposed network shows improvements on both the temporal ( using bidirectional cells ) and the spatial ( residual connections stacked deeply ) dimensions , aiming to enhance the recognition rate .",
        "we present a new corpus , personabank , consisting of 108 personal stories from weblogs that have been annotated with their story intention graphs , a deep representation of the fabula of a story .",
        "to jointly answer the questions of \" where do people live \" and \" how many people live there , \" we propose a deep learning model for creating high - resolution population estimations from satellite imagery .",
        "the usefulness of this concept is illustrated over a number of applied areas , including generalized regression and classification ( support tensor machines , canonical correlation analysis , higher order partial least squares ) , generalized eigenvalue decomposition , riemannian optimization , and in the optimization of deep neural networks .",
        "we evaluate state - of - the - art deep convolutional neural network ( cnns ) on this novel dataset with its different spectral bands .",
        "we also evaluate deep cnns on existing remote sensing datasets and compare the obtained results .",
        "we propose seq2sql , a deep neural network for translating natural language questions to corresponding sql queries .",
        "in this paper , we present the first deep learning architecture designed to capture metaphorical composition .",
        "an approach to incorporate deep learning within an iterative image reconstruction framework to reconstruct images from severely incomplete measurement data is presented .",
        "the structure of the method was inspired by the proximal gradient descent method , where the proximal operator is replaced by a deep cnn and the gradient descent step is generalized by use of a linear reconstruction operator .",
        "we combine a generative model parameterized by deep neural networks with non - linear embedding technique .",
        "our study suggests that the non - linear embedding based on a deep generative model can efficiently regularize a complex model with deep architectures while achieving high prediction accuracy that is far less sensitive to the availability of health status information .",
        "with the fast development of deep learning , supervised separation has become the most important direction in speech separation area in recent years .",
        "in this paper , we use the optimal ratio mask as the training target of the deep neural network ( dnn ) for speech separation .",
        "for computer vision applications , prior works have shown the efficacy of reducing numeric precision of model parameters ( network weights ) in deep neural networks .",
        "in this context , exploiting deep neural network ( dnn ) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for hmm based decoding .",
        "deep neural networks are state of the art methods for many learning tasks due to their ability to extract increasingly better features at each network layer .",
        "however , the improved performance of additional layers in a deep network comes at the cost of added latency and energy usage in feedforward inference .",
        "as networks continue to get deeper and larger , these costs become more prohibitive for real - time and energy - sensitive applications .",
        "to address this issue , we present branchynet , a novel deep network architecture that is augmented with additional side branch classifiers .",
        "deep neural networks ( dnn ) have been successfully applied for music classification tasks including music tagging .",
        "we analyze the challenges of the problem , and present rule - based , machine learning and deep learning approaches to detect sarcasm in numerical portions of text .",
        "our deep learning approach outperforms four past works for sarcasm detection and rule - based and machine learning approaches on a dataset of tweets , obtaining an f1 - score of 0 .",
        "in an attempt to better understand generalization in deep learning , we study several possible explanations .",
        "we show that implicit regularization induced by the optimization method is playing a key role in generalization and success of deep learning models .",
        "we empirically investigate the ability of these measures to explain different observed phenomena in deep learning .",
        "to tackle such a complicated control problem , we propose to apply deep reinforcement learning ( drl ) techniques for finding an optimal driving policy by maximizing the long - term reward in an interactive environment .",
        "specifically , we apply a long short - term memory ( lstm ) architecture to model the interactive environment , from which an internal state containing historical driving information is conveyed to a deep q - network ( dqn ) .",
        "the patch extracted around this object is subsequently fed through an off - the - shelf deep convolutional neural network to obtain a high level feature representation , which is then combined with traditional surface electromyography in the classification stage .",
        "we approach the query answering problems by combining ideas from the areas of kg embedding learning and deep learning for computer vision .",
        "an extensive set of experiments shows that the proposed deep neural networks are able to answer the visual - relational queries efficiently and accurately .",
        "we created a grid to simulate various conditions including stimuli like generator supply , weather and load demand using siemens pss / e software and this data is trained using deep learning methods and subsequently tested .",
        "as per our knowledge , this is the first paper to propose a working and scalable deep learning model for this problem .",
        "the expressive power of neural networks is important for understanding deep learning .",
        "that is , there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an \\ emph { exponential } bound .",
        "kernel methods have recently attracted resurgent interest , matching the performance of deep neural networks in tasks such as speech recognition .",
        "in contrast , in this study , we propose a deep learning based approach which integrate both feature extraction and classification phases into one system .",
        "our proposed scheme , called \" deep packet , \" can handle both traffic categorization in which the network traffic is categorize into major classes ( e .",
        "contrary to most of the current methods , deep packet can identify encrypted traffic and also distinguishes between vpn and non - vpn network traffic .",
        "after initial pre - processing phase on data , packets are fed to deep packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic .",
        "deep packet with cnn as its classification model achieved $ f _ { 1 } $ score of $ 0 .",
        "recent advances in deep learning have led various applications to unprecedented achievements , which could potentially bring higher intelligence to a broad spectrum of mobile and ubiquitous applications .",
        "although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices , they overlooked the reliability of mobile computing models .",
        "in this work , we propose rdeepsense , the first deep learning model that provides well - calibrated uncertainty estimations for resource - constrained mobile and embedded devices .",
        "rdeepsense enables the predictive uncertainty by adopting a tunable proper scoring rule as the training criterion and dropout as the implicit bayesian approximation , which theoretically proves its correctness .",
        "to reduce the computational complexity , rdeepsense employs efficient dropout and predictive distribution estimation instead of model ensemble or sampling - based method for inference operations .",
        "we evaluate rdeepsense with four mobile sensing applications using intel edison devices .",
        "results show that rdeepsense can reduce around 90 % of the energy consumption while producing superior uncertainty estimations and preserving at least the same model accuracy compared with other state - of - the - art methods .",
        "in this article , we propose a method based on deep reinforcement learning which only requires low - resolution images taken from a down - looking camera in order to identify the position of the marker and land the quadrotor on it .",
        "the proposed approach is based on a hierarchy of deep q - networks ( dqns ) which are used as high - level control policy for the navigation toward the marker .",
        "medical image analysis and computer - assisted intervention problems are increasingly being addressed with deep - learning - based solutions .",
        "this work presents the open - source niftynet platform for deep learning in medical imaging .",
        "this tensorflow - based infrastructure provides a complete modular deep learning pipeline for a range of medical imaging applications including segmentation , regression , image generation and representation learning applications with data loading , data augmentation , network architectures , loss functions and evaluation metrics that are tailored to , and take advantage of , the idiosyncracies of medical image analysis and computer - assisted interventions .",
        "in this paper , we show that the incorporation of deeper knowledge systematically boosts accuracy and compare knowner with state - of - the - art ner approaches across three languages ( i .",
        "vulnerability of state - of - the - art deep neural networks to adversarial attacks has been attracting a lot of attention recently .",
        "emergency response applications for nuclear or radiological events can be significantly improved via deep feature learning due to the hidden complexity of the data and models involved .",
        "in this paper we present a novel methodology for rapid source estimation during radiological releases based on deep feature extraction and weather clustering .",
        "we juxtapose these results with deep classification convolution networks and discuss advantages and disadvantages .",
        "recently , deep neural networks ( dnns ) have been demonstrated to achieve superior object detection performance compared to other approaches , with yolov2 ( an improved you only look once model ) being one of the state - of - the - art in dnn - based object detection methods in terms of both speed and accuracy .",
        "first , we leverage the evolutionary deep intelligence framework to evolve the yolov2 network architecture and produce an optimized architecture ( referred to as o - yolov2 here ) that has 2 .",
        "it supports a variety of different problem settings and it has been receiving increasing attention from the scientific community , leading to some high - profile success stories such as the much publicized deep q - networks ( dqn ) .",
        "we demonstrate the application of minimum probability flow learning to parameter estimation in ising models , deep belief networks , multivariate gaussian distributions and a continuous model with a highly general energy function defined as a power series .",
        "recursive neural networks are non - linear adaptive models that are able to learn deep structured information .",
        "in this paper , we developed an adaptive beamforming based on least mean squared error algorithm and null deepening to combat co - channel interference ( cci ) for the space - time coded ofdm ( stc - ofdm ) system .",
        "the problem of deciding whether csp instances admit solutions has been deeply studied in the literature , and several structural tractability results have been derived so far .",
        "recently we were able to significantly improve this result , using graphics cards to greatly speed up training of simple but deep mlps , which achieved 0 .",
        "in this talk i will present my project of extending traditional nlp techniques to radicals and strokes , aiming to obtain a deeper understanding of the way ideographic languages model the world .",
        "the deep boltzmann machine ( dbm ) has been an important development in the quest for powerful \" deep \" probabilistic models .",
        "we demonstrate that this regularization can be easily combined with standard stochastic maximum likelihood to yield an effective training strategy for the simultaneous training of all layers of the deep boltzmann machine .",
        "this approach has many advantages and has led to a deep and beautiful theory .",
        "this task essentially requires deep understanding of clauses structures .",
        "an efficient way to learn deep density models that have many layers of latent variables is to learn one layer at a time using a model that has only one layer of latent variables .",
        "in this paper , we present a greedy layer - wise learning algorithm for deep mixtures of factor analysers ( dmfas ) .",
        "combining deep belief nets with the lambertian reflectance assumption , our model can learn good priors over the albedo from 2d images .",
        "the properties of this graph separation as well as of local independence are investigated in detail within a framework of asymmetric ( semi ) graphoids allowing a deeper insight into what information can be read off these graphs .",
        "it has previously been hypothesized , and supported with some experimental evidence , that deeper representations , when well trained , tend to do a better job at disentangling the underlying factors of variation .",
        "these advances have been motivated by and related to the optimization issues surrounding deep learning .",
        "recent studies have shown that deep neural networks ( dnns ) perform significantly better than shallow networks and gaussian mixture models ( gmms ) on large vocabulary speech recognition tasks .",
        "a key characteristic of work on deep learning and neural networks in general is that it relies on representations of the input that support generalization , robust inference , domain adaptation and other desirable functionalities .",
        "in its time - unfolded form , the network can be seen as a very deep multi - layer network in which the weights are shared between the hidden layers .",
        "the depth allows the system to exhibit all the power of deep network while substantially reducing the number of trainable parameters .",
        "the main advantage of a deep semantic analyse is too represent meaning by logical formulae that can be easily used e .",
        "a modification of the algorithm takes advantage of an iterative deepening scheme to trade off inference time and the quality of the computed strategy .",
        "our project aims for a deeper understanding of hardness of sat problems that arise in practice .",
        "deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations , with higher levels representing more abstract concepts .",
        "although the study of deep learning has already led to impressive theoretical results , learning algorithms and breakthrough experiments , several challenges lie ahead .",
        "this paper proposes to examine some of these challenges , centering on the questions of scaling deep learning algorithms to much larger models and datasets , reducing optimization difficulties due to ill - conditioning or local minima , designing more efficient and powerful inference and sampling procedures , and learning to disentangle the factors of variation underlying the observed data .",
        "stochastic neurons can be useful for a number of reasons in deep learning models , but in many cases they pose a challenging problem : how to estimate the gradient of a loss function with respect to the input of such stochastic neurons , i .",
        "we demonstrate that there is significant redundancy in the parameterization of several deep learning models .",
        "as a consequence , one can define deep architectures similar to deep boltzmann machines in that units are stochastic , that the model can learn to generate a distribution similar to its training distribution , that it can easily handle missing inputs , but without the troubling problem of intractable partition function and intractable inference as stumbling blocks for both training and using these models .",
        "the sp theory promises deeper insights and better solutions in several areas of application , including natural language processing , autonomous robots , computer vision , intelligent databases , structuring of documents , software engineering , information compression , the economical transmission of data , big data , the semantic web , medical diagnosis , the detection of computer viruses , data fusion , and new kinds of computer .",
        "experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these \" deep and wide multiscale recursive \" ( dawmr ) networks lead to new levels of image labeling performance .",
        "moreover , unlike the original nade , our training procedure scales to deep models .",
        "empirically , ensembles of deep nade models obtain state of the art density estimation performance .",
        "we give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by hinton and others .",
        "we introduce a multilayer deep generative model capable of learning hierarchies of sparse distributed representations from data .",
        "besides describing effective model and features , we will discuss about the lessons we learned while using deep learning in this competition .",
        "however , like many deep models , there is little guidance on how the architecture of the model should be selected .",
        "we find that for a given parameter budget , deeper models are preferred over shallow ones , and models with more parameters are preferred to those with fewer .",
        "this suggests that , computational efficiency considerations aside , parameter sharing within deep networks may not be so beneficial as previously supposed .",
        "for any deep computational processing of language we need evidences , and one such set of evidences is corpus .",
        "in this this work , we extend the mixture of experts to a stacked model , the deep mixture of experts , with multiple sets of gating and experts .",
        "on a randomly translated version of the mnist dataset , we find that the deep mixture of experts automatically learns to develop location - dependent ( \" where \" ) experts at the first layer , and class - specific ( \" what \" ) experts at the second layer .",
        "the deep nin is thus implemented as stacking of multiple sliding micro neural networks .",
        "in this paper , we propose an extremely simple deep model for the unsupervised nonlinear dimensionality reduction - - deep distributed random samplings , which performs like a stack of unsupervised bootstrap aggregating .",
        "experimental results on nonlinear dimensionality reduction show that the proposed method can learn abstract representations on both large - scale and small - scale problems , and meanwhile is much faster than deep neural networks on large - scale problems .",
        "scalability properties of deep neural networks raise key research questions , particularly as the problems considered become larger and more challenging .",
        ", where the nodes of a deep network are augmented by a set of gating units that determine when a node should be calculated .",
        "experimental results using the mnist and svhn data sets with a fully - connected deep neural network demonstrate the performance robustness of the proposed scheme with respect to the error introduced by the conditional computation process .",
        "deep learning embeddings have been successfully used for many natural language processing ( nlp ) problems .",
        "when deep learning is applied to visual object recognition , data augmentation is often used to generate additional training data without extra labeling cost .",
        "although deep learning is not really necessary for generating good word embeddings , we show that it can provide an easy way to adapt embeddings to specific tasks .",
        "there are two main approaches to the distributed representation of words : low - dimensional deep learning embeddings and high - dimensional distributional models , in which each dimension corresponds to a context word .",
        "in this paper , we combine these two approaches by learning embeddings based on distributional - model vectors - as opposed to one - hot vectors as is standardly done in deep learning .",
        "we present the first deep learning model to successfully learn control policies directly from high - dimensional sensory input using reinforcement learning .",
        "in this paper , we propose a new unsupervised feature learning framework , namely deep sparse coding ( deepsc ) , that extends sparse coding to a multi - layer architecture for visual object recognition tasks .",
        "combining the feature representations from multiple layers , deepsc achieves the state - of - the - art performance on multiple object recognition tasks .",
        "this paper explores the complexity of deep feed forward networks with linear presynaptic couplings and rectified linear activations .",
        "this is a contribution to the growing body of work contrasting the representational power of deep and shallow network architectures .",
        "in particular , we offer a framework for comparing deep and shallow models that belong to the family of piece - wise linear functions based on computational geometry .",
        "we look at a deep ( two hidden layers ) rectifier multilayer perceptron ( mlp ) with linear outputs units and compare it with a single layer version of the model .",
        "there are a number of methods used for this task such as deep belief networks ( dbns ) and discrete fourier transforms ( dfts ) .",
        "we applied these two methods to a deep belief network trained for a face recognition task .",
        "deep belief networks which are hierarchical generative models are effective tools for feature representation and extraction .",
        "the system uses a deep learning architecture ( dla ) composed of two input / output channels formed from stacked restricted boltzmann machines ( rbm ) and an associative memory network that combines the two channels .",
        "currently , deep neural networks are the state of the art on problems such as speech recognition and computer vision .",
        "in this extended abstract , we show that shallow feed - forward networks can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models .",
        "moreover , the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model .",
        "we evaluate our method on timit phoneme recognition task and are able to train shallow fully - connected nets that perform similarly to complex , well - engineered , deep convolutional architectures .",
        "our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed - forward nets than those currently available .",
        "deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks .",
        "we show through experiments that for low - dimensional graphs it is possible to learn convolutional layers with $ o ( 1 ) $ parameters , resulting in efficient deep architectures .",
        "though deep convolutional networks have proven to be a competitive approach for image classification , a question remains : have these models have solved the dataset bias problem ?",
        "in general , training or fine - tuning a state - of - the - art deep model on a new domain requires a significant amount of data , which for many applications is simply not available .",
        "in this paper , we pose the following question : is a single image dataset , much larger than previously explored for adaptation , comprehensive enough to learn general deep models that may be effectively applied to new image domains ?",
        "in other words , are deep cnns trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be ?",
        "we show that a generic supervised deep cnn model trained on a large dataset reduces , but does not remove , dataset bias .",
        "furthermore , we propose several methods for adaptation with deep models that are able to operate with little ( one example per category ) or no labeled domain specific data .",
        "our experiments show that adaptation of deep models on benchmark visual domain adaptation data",
        "we investigate the use of deep neural networks for the novel task of class generic object detection .",
        "the main contribution of this paper is showing , for the first time , that a specific variation of deep learning is able to outperform all existing traditional architectures on this task .",
        "we propose two novel zero - shot learning methods for semantic utterance classification ( suc ) using deep learning .",
        "both approaches rely on learning deep semantic embeddings from a large amount of query click log data obtained from a search engine .",
        "a rooted tree exhibits an ultrametric property ; that is , for any three leaves of the tree it must be that one pair has a deeper most recent common ancestor than the other pairs , or that all three have the same most recent common ancestor .",
        "we marry ideas from deep neural networks and approximate bayesian inference to derive a generalised class of deep , directed generative models , endowed with a new algorithm for scalable inference and learning .",
        ", the automatic derivation of meaning representation such as an instantiated predicate - argument structure for a sentence , plays a critical role in deep processing of natural language .",
        "meanwhile , in recent years , deep neural networks ( dnns ) have shown state - of - the - art performance on various asr tasks .",
        "pdnn is a lightweight deep learning toolkit developed under the theano environment .",
        "applying our approach to training sigmoid belief networks and deep autoregressive networks , we show that it outperforms the wake - sleep algorithm on mnist and achieves state - of - the - art results on the reuters rcv1 document dataset .",
        "we then extend the algorithm to deep models and demonstrate the relevance of ordered representations to a number of applications .",
        "we study the complexity of functions computable by deep feedforward neural networks with piece - wise linear activations in terms of the number of regions of linearity that they have .",
        "deep networks are able to sequentially map portions of each layer ' s input space to the same output .",
        "in this way , deep models compute functions with a compositional structure that is able to re - use pieces of computation exponentially often in terms of their depth .",
        "in this paper , we propose a simple but effective coupled neural network , called deeply coupled autoencoder networks ( dcan ) , which seeks to build two deep neural networks , coupled with each other in every corresponding layers .",
        "in dcan , each deep structure is developed via stacking multiple discriminative coupled auto - encoders , a denoising auto - encoder trained with maximum margin criterion consisting of intra - class compactness and inter - class penalty .",
        "to achieve acceptable performance for ai tasks , one can either use sophisticated feature extraction methods as the first layer in a two - layered supervised learning model , or learn the features directly using a deep ( multi - layered ) model .",
        "we propose exact and inexact learning strategies for wide learning and show that wide learning with single layer outperforms single layer as well as deep architectures of finite width for some benchmark datasets .",
        "here we present a new supervised generative stochastic network ( gsn ) based method to predict local secondary structure with deep hierarchical representations .",
        "gsn is a recently proposed deep learning technique ( bengio & amp ; thibodeau - laufer , 2013 ) to globally train deep generative model .",
        "such personal data is used to enhance the quality of service via personalization of content and to maximize revenues via better targeting of advertisements and deeper engagement of users on sites .",
        "we present a method for training a deep neural network containing sinusoidal activation functions to fit to time - series data .",
        "we show how deeper layers can be utilized to model the observed sequence using a sparser set of sinusoid units , and how non - uniform regularization can improve generalization by promoting the shifting of weight toward simpler units .",
        "here we argue , based on results from statistical physics , random matrix theory , and neural network theory , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep neural network training , and provide preliminary numerical evidence for its superior performance .",
        "focusing on a large set of web portals owned and managed by a private communications company , we propose methods by which these sites ' clickstream data can be used to provide a deep understanding of their visitors , as well as their interests and preferences .",
        "our results underscore the value of the proposed measures to offer a deeper insight into models ' behavior and their impact on real applications , which benefit both data mining researchers and practitioners .",
        "we also show that types of noise other than dropout improve performance in a deep network through sparsifying , decorrelating , and spreading information across representations .",
        "we propose several simple approaches to training deep neural networks on data with noisy labels .",
        "the parameters of this noise layer can be estimated as part of the training process and involve simple modifications to current training infrastructures for deep networks .",
        "we introduce a deep scattering network , which computes invariants with iterated contractions adapted to training data .",
        "it defines a deep convolution network model , whose contraction properties can be analyzed mathematically .",
        "here we argue , based on results from statistical physics , random matrix theory , neural network theory , and empirical evidence , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep or recurrent neural network training , and provide numerical evidence for its superior optimization performance .",
        "these random views are then used to train a deep convolutional neural network ( cnn ) classifier .",
        "deep convolutional neural networks have recently proven extremely competitive in challenging image recognition tasks .",
        "this paper proposes the epitomic convolution as a new building block for deep neural networks .",
        "an epitomic convolution layer replaces a pair of consecutive convolution and max - pooling layers found in standard deep convolutional neural networks .",
        "training deep directed graphical models with many hidden variables and performing inference remains a major challenge .",
        "helmholtz machines and deep belief networks are such models , and the wake - sleep algorithm has been proposed to train them .",
        "we propose an heterogeneous multi - task learning framework for human pose estimation from monocular image with deep convolutional neural network .",
        "in particular , we simultaneously learn a pose - joint regressor and a sliding - window body - part detector in a deep network architecture .",
        "we show that deep generative models and approximate bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements , making generative approaches highly competitive for semi - supervised learning .",
        "it uses a deep layered architecture , parts of which are borrowed from recent work on neural network learning , and parts of which incorporate computations that are specific to image deconvolution .",
        "moreover , we show that advanced neural networks and deep learning methods can be compressed as privileged information .",
        "in recent years the performance of deep learning algorithms has been demonstrated in a variety of application domains .",
        "the goal of this paper is to enrich deep learning to be able to predict a set of random variables while taking into account their dependencies .",
        "so does our deep attention selective network ( dasnet ) architecture .",
        "dropout training , originally designed for deep neural networks , has been successful on high - dimensional single - layer natural language tasks .",
        "caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state - of - the - art deep learning algorithms and a collection of reference models .",
        "the framework is a bsd - licensed c + + library with python and matlab bindings for training and deploying general - purpose convolutional neural networks and other deep models efficiently on commodity architectures .",
        "we explore combining the benefits of convolutional architectures and autoencoders for learning deep representations in an unsupervised manner .",
        "learning is computationally efficient and we show that our method can be used to train shallow and deep convolutional autoencoders whose representations can be used to achieve classification rates on the mnist , cifar - 10 and norb datasets that are competitive with the state of the art .",
        "this approach enables us to send the detected ambiguous records to another discrimination method for a deeper investigation , thus increasing the accuracy by lowering the error rate .",
        "deep neural networks ( dnns ) are powerful models that have achieved excellent performance on difficult learning tasks .",
        "our method uses a multilayered long short - term memory ( lstm ) to map the input sequence to a vector of a fixed dimensionality , and then another deep lstm to decode the target sequence from the vector .",
        "deep learning has made significant breakthroughs in various fields of artificial intelligence .",
        "advantages of deep learning include the ability to capture highly complicated features , weak involvement of human engineering , etc .",
        "however , it is still virtually impossible to use deep learning to analyze programs since deep architectures cannot be trained effectively with pure back propagation .",
        "in this pioneering paper , we propose the \" coding criterion \" to build program vector representations , which are the premise of deep learning for program analysis .",
        "our representation learning approach directly makes deep learning a reality in this new field .",
        "to evaluate whether deep learning is beneficial for program analysis , we feed the representations to deep neural networks , and achieve higher accuracy in the program classification task than \" shallow \" methods , such as logistic regression and the support vector machine .",
        "this result confirms the feasibility of deep learning to analyze programs .",
        "we believe deep learning will become an outstanding technique for program analysis in the near future .",
        "another popular approach to model the multimodal data is through deep neural networks , such as the deep boltzmann machine ( dbm ) .",
        "second , we propose a deep extension of our model and provide an efficient way of training the deep model .",
        "unconstrained video recognition and deep convolution network ( dcn ) are two active topics in computer vision recently .",
        "the same lack - of - training - sample problem limits the usage of deep models on a wide range of computer vision problems where obtaining training data are difficult .",
        "deep neural networks have made significant breakthroughs in many fields of artificial intelligence .",
        "to our best knowledge , this paper is the first to analyze programs with deep neural networks ; we extend the scope of deep learning to the field of programming language processing .",
        "top - performing deep architectures are trained on massive amounts of labeled data .",
        "here , we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain ( no labeled target - domain data is necessary ) .",
        "in this paper , we use deep learning algorithms to investigate a data - driven parameterization technique that is designed for the specific requirements of synthesis .",
        "existing deep convolutional neural network ( cnn ) architectures are trained as n - way classifiers to distinguish between n output classes .",
        "towards this end , we introduce hierarchical branching cnns , named as hierarchical deep cnn ( hd - cnn ) , wherein classes that can be easily distinguished are classified in the higher layer coarse category cnn , while the most difficult classifications are done on lower layer fine category cnn .",
        "we present a library that provides optimized implementations for deep learning primitives .",
        "deep learning workloads are computationally intensive , and optimizing the kernels of deep learning workloads is difficult and time - consuming .",
        "however , there is no analogous library for deep learning .",
        "without such a library , researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels , and this work must be repeated as new parallel processors emerge .",
        "to address this problem , we have created a library similar in intent to blas , with optimized routines for deep learning workloads .",
        "we present a deep layered architecture that generalizes classical convolutional neural networks ( convnets ) .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "recently proposed neural network activation functions such as rectified linear , maxout , and local winner - take - all have allowed for faster and more effective training of deep neural architectures on large and complex datasets .",
        "neural machine translation ( nmt ) has recently attracted a lot of attention due to the very high performance achieved by deep neural networks in other domains .",
        "we propose a deep learning framework for modeling complex high - dimensional densities via non - linear independent component estimation ( nice ) .",
        "we parametrize this transformation so that computing the determinant of the jacobian and inverse jacobian is trivial , yet we maintain the ability to learn complex non - linear transformations , via a composition of simple building blocks , each based on a deep neural network .",
        "we carried out experiments using the switchboard corpus , with both mel frequency cepstral coefficient features and bottleneck feature derived from a deep neural network .",
        "reductions in word error rate were obtained by using tied plda , compared with the plda mixture model , subspace gaussian mixture models , and deep neural networks .",
        "many deep neural networks trained on natural images exhibit a curious phenomenon in common : on the first layer they learn features similar to gabor filters and color blobs .",
        "in this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results .",
        "nowadays this is very popular to use deep architectures in machine learning .",
        "deep belief networks ( dbns ) are deep architectures that use stack of restricted boltzmann machines ( rbm ) to create a powerful generative model using training data .",
        "we disambiguate the input word vectors before they are fed into a compositional deep net .",
        "a series of evaluations shows the positive effect of prior disambiguation for such deep models .",
        "the method transforms it into a graph representing the deep semantic structure of a natural language phrase .",
        "compared to image representation based on low - level local descriptors , deep neural activations of convolutional neural networks ( cnns ) are richer in mid - level representation , but poorer in geometric invariance properties .",
        "to overcome these challenges in large scale in synonym extraction , we proposed ( 1 ) a new cost function to accommodate the unbalanced learning problem , and ( 2 ) a feature learning based deep neural network to model the complicated relationships in synonym pairs .",
        "we propose a multimodal deep learning framework that can transfer the knowledge obtained from a single - modal neural network to a network with a different modality .",
        "the field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images .",
        "in this paper , we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure .",
        "al , 2012 ) in a deep neural network trains a pseudo - ensemble of child subnetworks generated by randomly masking nodes in the parent network .",
        "recent work has shown deep neural networks ( dnns ) to be highly susceptible to well - designed , small perturbations at the input layer , or so - called adversarial examples .",
        "as a solution , we propose deep contractive network , a model with a new end - to - end training procedure that includes a smoothness penalty inspired by the contractive autoencoder ( cae ) .",
        "we present a state - of - the - art speech recognition system developed using end - to - end deep learning .",
        "our system , called deepspeech , outperforms previously published results on the widely studied switchboard hub5 ' 00 , achieving 16 .",
        "deepspeech also handles challenging noisy environments better than widely used , state - of - the - art commercial speech systems .",
        "since the advent of deep learning , it has been used to solve various problems using many different architectures .",
        "we thus propose a new generic architecture called the deep belief network - bidirectional long short - term memory ( dbn - blstm ) network that models sequences by keeping track of the temporal information while enabling deep representations in the data .",
        "deep convolutional neural networks ( cnn ) has become the most promising method for object recognition , repeatedly demonstrating record breaking results for image classification and object detection in recent years .",
        "however , a very deep cnn generally involves many layers with millions of parameters , making the storage of the network model to be extremely large .",
        "this prohibits the usage of deep cnns on resource limited hardware , especially cell phones or other embedded devices .",
        "in this paper , we introduce a novel deep learning framework , termed purine .",
        "in purine , a deep network is expressed as a bipartite graph ( bi - graph ) , which is composed of interconnected operators and data tensors .",
        "stacked denoising auto encoders ( daes ) are well known to learn useful deep representations , which can be used to improve supervised training by initializing a deep network .",
        "we investigate a training scheme of a deep dae , where dae layers are gradually added and keep adapting as additional layers are added .",
        "recently researchers have also started to show interest in the generative aspects of cnns in order to gain a deeper understanding of what they have learned and how to further improve them .",
        "methods of deep machine learning enable to to reuse low - level representations efficiently for generating more abstract high - level representations .",
        "originally , deep learning has been applied passively ( e .",
        "although \" flat \" connectionist methods have already been used for model - based rl , up to now , only model - free variants of rl have been equipped with methods from deep learning .",
        "we propose a variant of deep model - based rl that enables an agent to learn arbitrarily abstract hierarchical representations of its environment .",
        "while depth tends to improve network performances , it also makes gradient - based training more difficult since deeper networks tend to be more non - linear .",
        "in this paper , we extend this idea to allow the training of a student that is deeper and thinner than the teacher , using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student .",
        "this allows one to train deeper students that can generalize better or run faster , a trade - off that is controlled by the chosen student capacity .",
        "for example , on cifar - 10 , a deep student network with almost 10 .",
        "in this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge .",
        "by augmenting deep autoencoders with a supervised cost and an additional unsupervised cost , we create a semi - supervised model that can discover and explicitly represent factors of variation beyond those relevant for categorization .",
        "current state - of - the - art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting .",
        "we consider a prediction consistent if the same prediction is made given similar percepts , where the notion of similarity is between deep network features computed from the input data .",
        "on a set of deep learning benchmarks , we also demonstrate their effectiveness for single and multi - label classification .",
        "among these , the restricted boltzmann machine ( rbm ) has been the prototype for some recent advancements in the unsupervised training of deep neural networks .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "we study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints .",
        "we empirically demonstrate that in the deep learning setting , due to the existence of many local optima , allowing more exploration can lead to the improved performance .",
        "yet , it is highly correlated to the classification network and offers some in - deep review of cnn structures .",
        "we develop a deep learning method that takes multiple channels of heterogeneous data , to detect the misalignment of the lidar - video inputs .",
        "to the best of our knowledge the use of multi - modal deep convolutional neural networks for dynamic real - time lidar - video registration has not been presented .",
        "we trained a deep convolutional neural network ( cnn ) to identify occlusion edges in images and videos with both rgb - d and rgb inputs .",
        "we present results comparing our model to state - of - the - art in fine - grained categorization as well as state - of - the - art deep visual models .",
        "deep convolutional neural networks ( dcnns ) have recently shown state of the art performance in high level vision tasks , such as image classification and object detection .",
        "we overcome this poor localization property of deep networks by combining the responses at the final dcnn layer with a fully connected conditional random field ( crf ) .",
        "qualitatively , our \" deeplab \" system is able to localize segment boundaries at a level of accuracy which is beyond previous methods .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "additionally , we hope that ordering parameters may provide additional insights into optimization of deep convolutional neural networks and how the network architecture impacts performance .",
        "this paper proposes a novel framework for unsupervised audio source separation using a deep autoencoder .",
        "deep neural networks have been extremely successful at various image , speech , video recognition tasks because of their ability to model deep structures within the data .",
        "in this study , we propose a deep temporal convolutional neural network architecture for brain decoding task in order to reduce dimensionality of feature space along with improved classification performance .",
        "back - propagation has been the workhorse of recent successes of deep learning but it relies on infinitesimal effects ( partial derivatives ) in order to perform credit assignment .",
        "this could become a serious issue as one considers deeper and more non - linear functions , e .",
        "in this spirit , we explore a novel approach to credit assignment in deep networks that we call target propagation .",
        "recently , deep machine learning has shown unique abilities to address hard problems that resisted machine algorithms for long .",
        "this motivated us to explore the use of deep learning in the context of photo editing .",
        "our experiments demonstrate that our deep learning formulation applied using these descriptors successfully capture sophisticated photographic styles .",
        "the proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image .",
        "a process centric view of robust pca ( rpca ) allows its fast approximate implementation based on a special form o a deep neural network with weights shared across all layers .",
        "deep networks have inspired a renaissance in neural network use , and are becoming the default option for difficult tasks on large datasets .",
        "in this report we show that published deep network results on the mnist handwritten digit dataset can straightforwardly be replicated ( error rates below 1 % , without use of any distortions ) with shallow ' extreme learning machine ' ( elm ) networks , with a very rapid training time ( ~ 10 minutes ) .",
        "to achieve this performance , we introduce several methods for enhancing elm implementation , which individually and in combination can significantly improve performance , to the point where it is nearly indistinguishable from deep network performance .",
        "we present a method for gesture detection and localisation based on multi - scale and multi - modal deep learning .",
        "introduced the skip - gram model into the study of social network for the first time , and designed an algorithm named deepwalk for learning node embedding on a graph .",
        "we prove that the deepwalk algorithm is actually factoring a matrix m where each entry m _ { ij } is logarithm of the average probability that node i randomly walks to node j in fix steps .",
        "the sparse snnm modules are further stacked to build a sparse deep stacking network ( s - dsn ) .",
        "fortunately , recent advances in deep learning can learn unsupervised features effectively , and have yielded state of the art performance in many classification problems , such as character recognition , object recognition and document categorization .",
        "however , little attention has been paid to the potential of deep learning for unsupervised clustering problems .",
        "in this paper , we propose a deep belief network with nonparametric clustering .",
        "as an unsupervised method , our model first leverages the advantages of deep learning for feature representation and dimension reduction .",
        "lastly model parameters are refined in the deep belief network .",
        "in this paper , we present methods in deep multimodal learning for fusing speech and visual modalities for audio - visual automatic speech recognition ( av - asr ) .",
        "first , we study an approach where uni - modal deep networks are trained separately and their final hidden layers fused to obtain a joint feature space in which another deep network is built .",
        "second , we present a new deep network architecture that uses a bilinear softmax layer to account for class specific correlations between modalities .",
        "fortunately , deep learning has led to great success on feature learning recently .",
        "inspired by the advances of deep learning , we propose a deep transductive semi - supervised maximum margin clustering approach .",
        "we pretrain the deep network structure with restricted boltzmann machines ( rbms ) layer by layer greedily , and optimize our objective function with gradient descent .",
        "by checking the most violated constraints , our approach updates the model parameters through error backpropagation , in which deep features are learned automatically .",
        "this paper describes maxdnn , a computationally efficient convolution kernel for deep learning with the nvidia maxwell gpu .",
        "3 \\ % computational efficiency on typical deep learning network architectures using a single kernel .",
        "in this work , we investigate smbo to identify architecture hyper - parameters of deep convolution networks ( dcns ) object recognition .",
        "this article demontrates that we can apply deep learning to text understanding from character - level inputs all the way up to abstract text concepts , using temporal convolutional networks ( convnets ) .",
        "our empirical evaluation of different rnn units , revealed that in both tasks , the gf - rnn outperforms the conventional approaches to build deep stacked rnns .",
        "training of large - scale deep neural networks is often constrained by the available computational resources .",
        "our results show that deep networks can be trained using only 16 - bit wide fixed - point number representation when using stochastic rounding , and incur little to no degradation in the classification accuracy .",
        "we consider the problem of learning deep generative models from data .",
        "recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation .",
        "however , as deep features eventually transition from general to specific along the network , the feature transferability drops significantly in higher layers with increasing domain discrepancy .",
        "in this paper , we propose a new deep adaptation network ( dan ) architecture , which generalizes deep convolutional neural network to the domain adaptation scenario .",
        "training deep neural networks is complicated by the fact that the distribution of each layer ' s inputs changes during training , as the parameters of the previous layers change .",
        "experimental results show that our method , which uses deep learning , mobile cloud computing , distance estimation and size calibration inside a mobile device , leads to an accuracy improvement to 95 % on average compared to previous work",
        "we present a work - in - progress snapshot of learning with a 15 billion parameter deep learning network on hpc architectures applied to the largest publicly available natural image and video dataset released to - date .",
        "recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers .",
        "we train our three - layer deep neural network on the yahoo !",
        "our simple framework can be applied to multiple architectures , including deep ones .",
        "deep neural networks ( dnn ) are the state of the art on many engineering problems such as computer vision and audition .",
        "in this study we applied the word2vec deep learning toolkit to medical corpora to test its potential for identifying relationships from unstructured text .",
        "we introduce deep neural programs ( dnp ) , a novel programming paradigm for writing adaptive controllers for cy - ber - physical systems ( cps ) .",
        "inspired by the brain , deep neural networks ( dnn ) are thought to learn abstract representations through their hierarchical architecture .",
        "in this paper , we explore joint optimization of masking functions and deep recurrent neural networks for monaural source separation tasks , including the monaural speech separation task , monaural singing voice separation task , and speech denoising task .",
        "the joint optimization of the deep recurrent neural networks with an extra masking layer enforces a reconstruction constraint .",
        "neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology .",
        "we explore more biologically plausible versions of deep representation learning , focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised , unsupervised and reinforcement learning .",
        "parameter - specific adaptive learning rate methods are computationally efficient ways to reduce the ill - conditioning problems encountered when training large deep networks .",
        "the fgrn paradigm provides great flexibility and modularity and appears as a promising candidate for building deep networks : the system can be easily extended by introducing new and different ( in cardinality and in type ) variables .",
        "here , we train a deep neural network to re - synthesize its inputs at its output layer for a given class of data .",
        "we then exploit the fact that this abstract transformation , which we call a deep transform ( dt ) , inherently rejects information ( errors ) existing outside of the abstract feature space .",
        "this paper introduces the deep recurrent attentive writer ( draw ) neural network architecture for image generation .",
        "available publications show that the problem of rule generation from ontologies based on inductive learning is not investigated deeply enough .",
        "in recent years multilayer perceptrons ( mlps ) with many hid - den layers deep neural network ( dnn ) has performed sur - prisingly well in many speech tasks , i .",
        "in this paper , deep belief network ( dbn ) , a class of dnn family has been employed and applied to model the f0 contour of synthesized speech which was generated by hmm - based speech synthesis system .",
        "this scheme provides a direct method for transferring ideas between the fields of deep learning and computational neuroscience .",
        "for this task we use a deep learning approach with restricted boltzmann machines .",
        "we present a deep network that , in an empirical evaluation , outperforms a number of competitive methods from the literature",
        "for pretraining of deep networks on mnist , rectangle data , convex shapes , norb , and cifar , rfns were superior to restricted boltzmann machines ( rbms ) and denoising autoencoders .",
        "on cifar - 10 and cifar - 100 , rfn pretraining always improved the results of deep networks for different architectures like alexnet , deep supervised net ( dsn ) , and a simple \" network in network \" architecture .",
        "this paper presents a new state - of - the - art for document image classification and retrieval , using features learned by deep convolutional neural networks ( cnns ) .",
        "in object and scene analysis , deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations .",
        "however , literature defines a general error - correcting capability for ecocs without analyzing how it distributes among classes , hindering a deeper analysis of pair - wise error - correction .",
        "in this paper , we propose a new approach which uses deep neural network to learn features automatically from data .",
        "we then refine this alignment using a state - of - the - art visual food detector , based on a deep convolutional neural network .",
        "in this paper we present our approach to learning several specialist models using deep learning techniques , each focusing on one modality .",
        "among these are a convolutional neural network , focusing on capturing visual information in detected faces , a deep belief net focusing on the representation of the audio stream , a k - means based \" bag - of - mouths \" model , which extracts visual features around the mouth region and a relational autoencoder , which addresses spatio - temporal aspects of videos .",
        "deep neural networks have recently achieved state of the art performance thanks to new training algorithms for rapid parameter estimation and new regularization methods to reduce overfitting .",
        "this representation , together with target language words , are fed to a deep neural network ( dnn ) to form a stronger nnjm .",
        "we present a bayesian approach to adapting parameters of a well - trained context - dependent deep - neural - network hid - den markov models ( cd - dnn - hmms ) to improve automatic speech recognition performance .",
        "deep neural networks ( dnns ) are analyzed via the theoretical framework of the information bottleneck ( ib ) principle .",
        "we believe that this new insight can lead to new optimality bounds and deep learning algorithms .",
        "this paper presents the deep convolution inverse graphics network ( dc - ign ) that aims to learn an interpretable representation of images that is disentangled with respect to various transformations such as object out - of - plane rotations , lighting variations , and texture .",
        "this approach allows us to rapidly learn , sample from , and evaluate probabilities in deep generative models with thousands of layers or time steps .",
        "2 % ) image classification databases , with very fast training times compared to standard deep network approaches .",
        "we highlight and discuss our findings in light of a cross - lingual approach : while we discover differences in evoked emotions and corresponding viral effects , we provide preliminary evidence of a generalized explanatory model rooted in the deep structure of emotions : the valence - arousal - dominance ( vad ) circumplex .",
        "successful experiments are conducted , validating these theoretical results , on two image datasets and with a particular architecture that mimics the deep boltzmann machine gibbs sampler but allows training to proceed with backprop , without the need for layer",
        "here , we train a convolutional deep neural network to re - synthesize input time - domain speech signals at its output layer .",
        "we then use this abstract transformation , which we call a deep transform ( dt ) , to perform probabilistic re - synthesis on further speech ( of the same speaker ) which has been degraded .",
        "here , we trained two separate convolutive autoencoder deep neural networks ( dnn ) to separate monaural and binaural mixtures of two concurrent speech streams .",
        "we then used these dnns as convolutive deep transform ( cdt ) devices to perform probabilistic re - synthesis .",
        "our ratiolog project addresses the problem of rational reasoning in deep question answering by methods from automated deduction and cognitive computing .",
        "here , we train a convolutional deep neural network , on a two - speaker cocktail party problem , to make probabilistic predictions about binary masks .",
        "our results approach ideal binary mask performance , illustrating that relatively simple deep neural networks are capable of robust binary mask prediction .",
        "in particular , we propose ( 1 ) a multi - output deep regression model to project an image into a semantic word space , which explicitly exploits the correlations in the intermediate semantic layer of word vectors ; ( 2 ) a novel zero - shot learning algorithm for multi - label data that exploits the unique compositionality property of semantic word vector representations ; and ( 3 ) a transductive learning strategy to enable the regression model learned from seen classes to generalise well to unseen classes .",
        "our models are also competitive to most state - of - the - art results , including rnns based on long short term memory and deep cnns / rnns .",
        "stacked denoising auto encoders ( daes ) are well known to learn useful deep representations , which can be used to improve supervised training by initializing a deep network .",
        "we investigate a training scheme of a deep dae , where dae layers are gradually added and keep adapting as additional layers are added .",
        "as deep nets are increasingly used in applications suited for mobile devices , a fundamental dilemma becomes apparent : the trend in deep learning is to grow models to absorb ever - increasing data set sizes ; however mobile devices are designed with very little memory and cannot store such large models .",
        "deep generative models ( dgms ) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability .",
        "in this paper , we present max - margin deep generative models ( mmdgms ) , which explore the strongly discriminative principle of max - margin learning to improve the discriminative power of dgms , while retaining the generative capability .",
        "deep learning has shown state - of - art classification performance on datasets such as imagenet , which contain a single object in each image .",
        "we present a unified framework which leverages the strengths of multiple machine learning methods , viz deep learning , probabilistic models and kernel methods to obtain state - of - art performance on microsoft coco , consisting of non - iconic images .",
        "this paper proposes an architecture for deep neural networks with hidden layer branches that learn targets of lower hierarchy than final layer targets .",
        "however , network training becomes more difficult with increasing depth and training of very deep networks remains an open problem .",
        "in this extended abstract , we introduce a new architecture designed to ease gradient - based training of very deep networks .",
        "highway networks with hundreds of layers can be trained directly using stochastic gradient descent and with a variety of activation functions , opening up the possibility of studying extremely deep and efficient architectures .",
        "for example , deep neural networks have been more successful than shallow networks because they can perform a greater number of sequential computational steps ( each highly parallel ) .",
        "we present an interleaved text / image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital ' s picture archiving and communication system .",
        "set functions , and specifically submodular set functions , characterize a wide variety of naturally occurring optimization problems , and the property of submodularity of set functions has deep theoretical consequences with wide ranging applications .",
        "we propose an object detection system that relies on a multi - region deep convolutional neural network ( cnn ) that also encodes semantic segmentation - aware features .",
        "we exploit the above properties of our recognition module by integrating it on an iterative localization mechanism that alternates between scoring a box proposal and refining its location with a deep cnn regression model .",
        "this report provides an overview of the current state of the art deep learning architectures and optimisation techniques , and uses the adni hippocampus mri dataset as an example to compare the effectiveness and efficiency of different convolutional architectures on the task of patch - based 3 - dimensional hippocampal segmentation , which is important in the diagnosis of alzheimer ' s disease .",
        "deep neural networks have recently achieved state - of - the - art results in many machine learning problems , e .",
        "in this paper , we present a fully automatic brain tumor segmentation method based on deep neural networks ( dnns ) .",
        "in this paper , we propose a novel unsupervised deep learning model , called pca - based convolutional network ( pcn ) .",
        "the results show that pcn performs competitive with or even better than state - of - the - art deep learning models .",
        "more importantly , since there is no back propagation for supervised finetuning , pcn is much more efficient than existing deep networks .",
        "nowadays , represented by deep learning techniques , the field of machine learning is experiencing unprecedented prosperity and its influence is demonstrated in academia , industry and civil society . \"",
        "our approach is based on the charwnn deep neural network , which uses word - level and character - level representations ( embeddings ) to perform sequential classification .",
        "although deep neural networks ( dnn ) are able to scale with direct advances in computational power ( e .",
        "recent research shows that deep neural networks ( dnns ) can be used to extract deep speaker vectors ( d - vectors ) that preserve speaker characteristics and can be used in speaker verification .",
        "this paper aims to accelerate the test - time computation of convolutional neural networks ( cnns ) , especially very deep cnns that have substantially impacted the computer vision community .",
        "for the widely used very deep vgg - 16 model , our method achieves a whole - model speedup of 4x with merely a 0 .",
        "this paper proposes boosting - like deep learning ( bdl ) framework for pedestrian detection .",
        "due to overtraining on the limited training samples , overfitting is a major problem of deep learning .",
        "we incorporate a boosting - like technique into deep learning to weigh the training samples , and thus prevent overtraining in the iterative process .",
        "81 % reduction in the average miss rate compared with acf and jointdeep on the largest caltech benchmark dataset , respectively .",
        "in this work , we explore whether such tests can be solved automatically by artificial intelligence technologies , especially the deep learning technologies that are recently developed and successfully applied in a number of fields .",
        "inspired by deep learning , the authors propose a supervised framework for learning vector representation of words to provide additional supervised fine tuning after unsupervised learning .",
        "recently , deep learning has achieved great success in many fields , such as image , sounds and text processing .",
        "in this paper , deep learning method has been used for feature extraction and feature selection .",
        "experiments using joint - embedding and deep learning methods show promising results on these tasks .",
        "this paper proposes an ros learning approach based on deep neural networks ( dnn ) , which involves an ros feature as the input of the dnn model and so the spectrum distortion caused by ros can be learned and compensated for .",
        "this article presents a deep analysis of the influence of context information on dialogue act recognition .",
        "our general - purpose methods may have wide applications for understanding compositionality and other semantic properties of deep networks , and also shed light on why lstms outperform simple recurrent nets ,",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning algorithm , learning to find the best structured object ( such as a label sequence ) given a structured input ( such as a vector sequence ) by globally considering the mapping relationships between the structure rather than item by item .",
        "it is known that the learning rate is the most important hyper - parameter to tune for training deep convolutional neural networks ( i .",
        "deep learning refers to a shining branch of machine learning that is based on learning levels of representations .",
        "convolutional neural networks ( cnn ) is one kind of deep neural network .",
        "deep structured output learning shows great promise in tasks like semantic image segmentation .",
        "we proffer a new , efficient deep structured model learning scheme , in which we show how deep convolutional neural networks ( cnns ) can be used to estimate the messages in message passing inference for structured prediction with conditional random fields ( crfs ) .",
        "deep neural networks trained on large - scale dataset can learn transferable features that promote learning multiple tasks for inductive transfer and labeling mitigation .",
        "as deep features eventually transition from general to specific along the network , a fundamental problem is how to exploit the relationship structure across different tasks while accounting for the feature transferability in the task - specific layers .",
        "in this work , we propose a novel deep relationship network ( drn ) architecture for multi - task learning by discovering correlated tasks based on multiple task - specific layers of a deep convolutional neural network .",
        "deep learning tools have recently gained much attention in applied machine learning .",
        "we call this iterative system the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) which generates high quality features for track 1 of the challenge and acoustic tokens for track 2 of the challenge .",
        "deep learning with a convolutional neural network ( cnn ) has been proved to be very effective in feature extraction and representation of images .",
        "for image classification problems , this work aim at finding which classifier is more competitive based on high - level deep features of images .",
        "in this report , we have discussed the nearest neighbor , support vector machines and extreme learning machines for image classification under deep convolutional activation feature representation .",
        "the deep features of the object dataset are obtained by a well - trained cnn with five convolutional layers and three fully - connected layers on the challenging imagenet .",
        "recently , strong results have been demonstrated by deep recurrent neural networks on natural language transduction problems .",
        "we show that these architectures exhibit superior generalisation performance to deep rnns and are often able to learn the underlying generating algorithms in our transduction experiments .",
        "in this context , we deeply study the effects of restart , branching heuristics and clauses learning .",
        "we revisit the choice of sgd for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights .",
        "while our theoretical guarantees assume convexity , we discuss the applicability of our method to deep neural networks , and experimentally demonstrate its merits .",
        "this paper proposes a set of new error criteria and learning approaches , adaptive normalized risk - averting training ( anrat ) , to attack the non - convex optimization problem in training deep neural networks ( dnns ) .",
        "in practice , we show how this method improves training of deep neural networks to solve visual recognition tasks on the mnist and cifar - 10 datasets .",
        "performance on deep / shallow multilayer perceptrons and denoised auto - encoders is also explored .",
        "finally we show that nasmc is able to train a neural network - based deep recurrent generative model achieving results that compete with the state - of - the -",
        "this allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure .",
        "meanwhile , feed - forward neural network is a traditional classifier , which is very hot at present with a deeper architecture .",
        "discrete fourier transforms provide a significant speedup in the computation of convolutions in deep learning .",
        "unsupervised training of deep generative models containing latent variables and performing inference remains a challenging problem for complex , high dimen - sional distributions .",
        "inspired by the recent successes of deep learning methods , we propose an end - to - end learning approach for the place classification problem .",
        "with the deep architectures , this methodology automatically discovers features and contributes in general to higher classification accuracies .",
        "secondly , each layer of data is fed into a deep neural network model for classification , where a graph regularization is imposed to the deep architecture for keeping local consistency between adjacent samples .",
        "we consider the problem of bayesian parameter estimation for deep neural networks , which is important in problem settings where we may have little data , and / or where we need accurate posterior predictive densities , e .",
        "we present a novel network architecture , frequency - sensitive hashed nets ( freshnets ) , which exploits inherent redundancy in both convolutional layers and fully - connected layers of a deep learning model , leading to dramatic savings in memory and storage consumption .",
        "the online learning of deep neural networks is an interesting problem of machine learning because , for example , major it companies want to manage the information of the massive data uploaded on the web daily , and this technology can contribute to the next generation of lifelong learning .",
        "we aim to train deep models from new data that consists of new classes , distributions , and tasks at minimal computational cost , which we call online deep learning .",
        "unfortunately , deep neural network learning through classical online and incremental methods does not work well in both theory and practice .",
        "in this paper , we introduce dual memory architectures for online incremental deep learning .",
        "the proposed architecture consists of deep representation learners and fast learnable shallow kernel networks , both of which synergize to track the information of new data .",
        "performing inference and learning of deep generative networks in a bayesian setting is desirable , where a sparsity - inducing prior can be adopted on model parameters or a nonparametric bayesian process can be used to infer the network structure .",
        "however , posterior inference for such deep models is an extremely challenging task , which has largely not been well - addressed .",
        "in this paper , we present doubly stochastic gradient - based mcmc , a simple and effective method that can be widely applied for bayesian inference of deep generative models in continuous parameter spaces .",
        "we demonstrate the effectiveness on learning deep sigmoid belief networks ( dsbns ) .",
        "deep directed generative models have attracted much attention recently due to their expressive representation power and the ability of ancestral sampling .",
        "qualitative and quantitative evaluations of our model against state of the art deep models on benchmark datasets demonstrate the effectiveness of the proposed algorithm in data representation and reconstruction .",
        "deep learning ' s recent successes have mostly relied on convolutional networks , which exploit fundamental statistical properties of images , sounds and video data : the local stationarity and multi - scale compositional structure , that allows expressing long range interactions in terms of shorter , localized interactions .",
        "deep neural networks ( dnn ) have achieved huge practical success in recent years .",
        "this paper proposes a deep denoising auto - encoder technique to extract better acoustic features for speech synthesis .",
        "ntram is broad enough to subsume the state - of - the - art neural translation model in [ 2 ] as its special case , while significantly improves upon the model with its deeper architecture .",
        "recent years have produced great advances in training large , deep neural networks ( dnns ) , including notable successes in training convolutional neural networks ( convnets ) to recognize natural images .",
        "in this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market .",
        "e2c consists of a deep generative model , belonging to the family of variational autoencoders , that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear .",
        "a deep learning approach has been proposed recently to derive speaker identifies ( d - vector ) by a deep neural network ( dnn ) .",
        "this paper presents two improvements for the deep learning approach : a phonedependent dnn structure to normalize phone variation , and a new scoring approach based on dynamic time warping ( dtw ) .",
        "we employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback .",
        "the network differs from existing deep lstm architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data .",
        "it therefore provides a unified way of using lstm for both deep and sequential computation .",
        "to exploit both deep learning and linguistic structures , we propose a tree - based convolutional neural network model which exploit various long - distance relationships between words .",
        "we introduce a new framework for unsupervised learning of deep representations based on a novel hierarchical decomposition of information .",
        "we combine supervised learning with unsupervised learning in deep neural networks .",
        "however , training becomes more difficult as depth increases , and training of very deep networks remains an open problem .",
        "this enables the study of extremely deep and efficient architectures .",
        "while not composed of natural scenes , frames in atari games are high - dimensional in size , can involve tens of objects with one or more objects being controlled by the actions directly and many other objects being influenced indirectly , can involve entry and departure of objects , and can involve deep partial observability .",
        "we propose and evaluate two deep neural network architectures that consist of encoding , action - conditional transformation , and decoding layers based on convolutional neural networks and recurrent neural networks .",
        "the central challenge arises from two compounding factors : the broader domain results in an open - ended set of relations , and the deeper compositionality results in a combinatorial explosion in the space of logical forms .",
        "deep compositional models of meaning acting on distributional representations of words in order to produce vectors of larger text constituents are evolving to a popular area of nlp research .",
        "distinctive features and advantages of the sp system compared with alternatives in : minimum length encoding and related concepts ; deep learning in neural networks ; universal search ; bayesian networks and other models for ai ; analysis and production of natural language ; learning natural language ; exact and inexact reasoning ; representation and processing of diverse forms of knowledge ; ibm ' s watson ; problems associated with big data , and in the development of intelligence in autonomous robots .",
        "the success of deep learning often derives from well - chosen operational building blocks .",
        "regularisation of deep neural networks ( dnn ) during training is critical to performance .",
        "we propose a method combining relational - logic representations with deep neural network learning .",
        "the relational rule - set serves as a template for unfolding possibly deep neural networks whose structures also reflect the structure of given training or testing examples .",
        "contemporary deep neural networks exhibit impressive results on practical problems .",
        "we analyze this behavior in the context of deep , infinite neural networks .",
        "we show that deep infinite layers are naturally aligned with gaussian processes and kernel methods , and devise stochastic kernels that encode the information of these networks .",
        "deep neural networks is a branch in machine learning that has seen a meteoric rise in popularity due to its powerful abilities to represent and model high - level abstractions in highly complex data .",
        "one area in deep neural networks that is ripe for exploration is neural connectivity formation .",
        "motivated by this intriguing finding , we introduce the concept of stochasticnet , where deep neural networks are formed via stochastic connectivity between neurons .",
        "such stochastic synaptic formations in a deep neural network architecture can potentially allow for efficient utilization of neurons for performing specific tasks .",
        "to evaluate the feasibility of such a deep neural network architecture , we train a stochasticnet using three image datasets .",
        "experimental results show that a stochasticnet can be formed that provides comparable accuracy and reduced overfitting when compared to conventional deep neural networks with more than two times the number of neural connections .",
        "neural reasoner has 1 ) a specific interaction - pooling mechanism , allowing it to examine multiple facts , and 2 ) a deep architecture , allowing it to model the complicated logical relations in reasoning tasks .",
        "this thesis describes the design and implementation of a smile detector based on deep convolutional neural networks .",
        "despite the promise of brain - inspired machine learning , deep neural networks ( dnn ) have frustratingly failed to bridge the deceptively large gap between learning and memory .",
        "deep learning has demonstrated the power of detailed modeling of complex high - order ( multivariate ) interactions in data .",
        "for some learning tasks there is power in learning models that are not only deep but also broad .",
        "in this paper , we propose an algorithm for deep broad learning called dbl .",
        "comparisons are offered against traditional models such as bag of words , n - grams and their tfidf variants , and deep learning models such as word - based convnets and recurrent neural networks .",
        "evolution of visual object recognition architectures based on convolutional neural networks & amp ; convolutional deep belief networks paradigms has revolutionized artificial vision science .",
        "we propose a two level hierarchical deep learning architecture inspired by divide & amp ; conquer principle that decomposes the large scale recognition architecture into root & amp ; leaf level model architectures .",
        "each of the root & amp ; leaf level models is trained exclusively to provide superior results than possible by any 1 - level deep learning architecture prevalent today .",
        "this paper proposes so - called deep attribute framework to alleviate this issue from three aspects .",
        "as soft - max layer directly corresponds to semantic concepts , this representation is named \" deep attributes \" .",
        "in this paper , we present a system that employs a wearable acoustic sensor and a deep convolutional neural network for detecting coughs .",
        "in this work , we investigate a deep - learning approach to learning the representation of states in partially observable tasks , with minimal prior knowledge of the domain .",
        "in particular , we study reinforcement learning with deep neural networks , including rnn and lstm , which are equipped with the desired property of being able to capture long - term dependency on history , and thus providing an effective way of learning the representation of hidden states .",
        "in a recent article we described a new type of deep neural network - a perpetual learning machine ( plm ) - which is capable of learning ' on the fly ' like a brain by existing in a state of perpetual stochastic gradient descent ( psgd ) .",
        "the performance of mdrnn is improved by further increasing its depth , and the difficulty of learning the deeper network is overcome by hessian - free ( hf ) optimization .",
        "automatic speech recognition ( asr ) is achieved by two multi - pass deep neural network systems with adaptation and rescoring techniques .",
        "in this paper , we investigate whether distributional semantics in the form of word embeddings can enable a deeper , i .",
        "with the impressive capability to capture visual content , deep convolutional neural networks ( cnn ) have demon - strated promising performance in various vision - based ap - plications , such as classification , recognition , and objec - t detection .",
        "in this paper , to address this problem , we proposed a new kernelized deep convolutional neural network .",
        "rectified linear units ( relu ) seem to have displaced traditional ' smooth ' nonlinearities as activation - function - du - jour in many - but not all - deep neural network ( dnn ) applications .",
        "stochastic gradient descent ( sgd ) is arguably the most popular of the machine learning methods applied to training deep neural networks ( dnn ) today .",
        "to make use of such noisy machine labeled data , we employ a progressive strategy to fine - tune the deep network .",
        "in the back - end , several techniques are taken advantage to improve the noisy automatic speech recognition ( asr ) performance including deep neural network ( dnn ) , convolutional neural network ( cnn ) and long short - term memory ( lstm ) using medium vocabulary , lattice rescoring with a big vocabulary language model finite state transducer , and rover scheme .",
        "in this work we more deeply investigate the direct utility of using clustering to improve prediction accuracy and provide explanations for why this may be so .",
        "in particular , we first show that the recent dqn algorithm , which combines q - learning with a deep neural network , suffers from substantial overestimations in some games in the atari 2600 domain .",
        "deep neural networks currently demonstrate state - of - the - art performance in several domains .",
        "in particular , for the very deep vgg networks we report the compression factor of the dense weight matrix of a fully - connected layer up to 200000 times leading to the compression factor of the whole network up to 7 times .",
        "borrowing techniques from the literature on training deep generative models , we present the wake - sleep recurrent attention model , a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients .",
        "deep dynamic generative models are developed to learn sequential dependencies in time - series data .",
        "in this paper , we evaluate convolutional neural network ( cnn ) features using the alexnet architecture and very deep convolutional network ( vggnet ) architecture .",
        "deep neural network architectures have recently produced excellent results in a variety of areas in artificial intelligence and visual recognition , well surpassing traditional shallow architectures trained using hand - designed features .",
        "the power of deep networks stems both from their ability to perform local computations followed by pointwise non - linearities over increasingly larger receptive fields , and from the simplicity and scalability of the gradient - descent training procedure based on backpropagation .",
        "log - tangent space metrics defined over the manifold of symmetric positive definite matrices ) while preserving the validity and efficiency of an end - to - end deep training framework .",
        "in this paper we propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures .",
        "we perform segmentation experiments using the bsds and mscoco benchmarks and demonstrate that deep networks relying on second - order pooling and normalized cuts layers , trained end - to -",
        "the recent great improvements on benchmark data sets achieved by increasingly complex unsupervised learning methods and deep learning models with lots of parameters usually requires many tedious tricks and much expertise to tune .",
        "in addition , some beneficial methods such as local contrast normalization and whitening are added to the proposed deep trans - layer networks to further boost performance .",
        "compared to traditional deep learning methods , the implemented feature learning method has much less parameters and is validated in several typical experiments , such as digit recognition",
        "this note provides a family of classification problems , indexed by a positive integer $ k $ , where all shallow networks with fewer than exponentially ( in $ k $ ) many nodes exhibit error at least $ 1 / 3 $ , whereas a deep network with 2 nodes in each of $ 2k $ layers achieves zero error , as does a recurrent network with 3 distinct nodes iterated $ k $ times .",
        "this paper provides a new approach for scalable optimisation of the mutual information by merging techniques from variational inference and deep learning .",
        "because of their performance , deep neural networks are increasingly used for object recognition .",
        "we also conducted a deep analysis of provided polish data as preparatory work for the automatic data correction and cleaning phase .",
        "recently , represented by deep learning techniques , the field of machine learning is experiencing unprecedented prosperity and some applications with near human - level performance bring researchers confidence to imply that their approaches are the promising candidate for understanding the mechanism of human brain .",
        "however , cnns in lvcsr have not kept pace with recent advances in other domains where deeper neural networks provide superior performance .",
        "first , we introduce a very deep convolutional network architecture with up to 14 weight layers .",
        "we then evaluate the very deep cnns on the hub5 ' 00 benchmark ( using the 262 hours of swb - 1 training data )",
        "an orthogonal haar scattering transform is a deep network , computed with a hierarchy of additions , subtractions and absolute values , over pairs of coefficients .",
        "it provides a simple mathematical model for unsupervised deep network learning .",
        "furthermore , the proposed modeling and synthesis platform outperforms a leading - edge , vocoded , deep bidirectional long short - term memory recurrent neural network ( dblstm - rnn ) - based baseline system in various objective evaluation metrics conducted .",
        "we consider the task of building compact deep learning pipelines suitable for deployment on storage and power constrained mobile devices .",
        "we make use of visual features extracted from product images using ( pre - trained ) deep networks , on top of which we learn an additional layer that uncovers the visual dimensions that best explain the variation in people ' s feedback .",
        "deep cca is a recently proposed deep neural network extension to the traditional canonical correlation analysis ( cca ) , and has been successful for multi - view representation learning in several domains .",
        "however , stochastic optimization of the deep cca objective is not straightforward , because it does not decouple over training examples .",
        "previous optimizers for deep cca are either batch - based algorithms or stochastic optimization using large minibatches , which can have high memory consumption .",
        "in this paper , we tackle the problem of stochastic optimization for deep cca with small minibatches , based on an iterative solution to the cca objective , and show that we can achieve as good performance as previous optimizers and thus alleviate the memory requirement .",
        "when training deep neural networks , it is typically assumed that the training examples are uniformly difficult to learn .",
        "in this article , using a deep neural network to encode a video , we show that oddball sgd can be used to enforce uniform error across the training set .",
        "special attention is paid to the deep learning techniques and architectures implemented from scratch using python and numpy for this competition .",
        "this project is mainly focused on the solution to the issues above , combining deep learning algorithm with cloud computing platform to deal with large - scale data .",
        "careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data , how mapreduce is implemented on deep learning neural network , and why this combination accelerates computation .",
        "this observation could be an element of a theory for explaining how brains perform credit assignment in deep hierarchies as efficiently as back - propagation does .",
        "we propose adaapt : a deep architecture for adaptive policy transfer , which addresses these challenges .",
        "for most deep learning algorithms training is notoriously time consuming .",
        "we also executed a deep analysis of polish data as preparatory work before automatized data processing such as true casing or punctuation normalization phase .",
        "the increasing complexity of deep learning architectures is resulting in training time requiring weeks or even months .",
        "this slow training is due in part to vanishing gradients , in which the gradients used by back - propagation are extremely large for weights connecting deep layers ( layers near the output layer ) , and extremely small for shallow layers ( near the input layer ) ; this results in slow learning in the shallow layers .",
        "additionally , it has also been shown that in highly non - convex problems , such as deep neural networks , there is a proliferation of high - error low curvature saddle points , which slows down learning dramatically .",
        "in this paper , we attempt to overcome the two above problems by proposing an optimization method for training deep neural networks which uses learning rates which are both specific to each layer in the network and adaptive to the curvature of the function , increasing the learning rate at low curvature points .",
        "the purpose of this paper is to research the application of deep learning techniques to this problem to identify at the beginning of a drive cycle the driver specific vehicle speed profile for an individual driver repeated drive cycle , which can be used in an optimization algorithm to minimize the amount of fossil fuel energy used during the trip .",
        "in this paper , a framework for testing deep neural network ( dnn ) design in python is presented .",
        "in this paper we explore deep learning models with memory component or attention mechanism for question answering task .",
        "we train spiking deep networks using leaky integrate - and - fire ( lif ) neurons , and achieve state - of - the - art results for spiking networks on the cifar - 10 and mnist datasets .",
        "this demonstrates that biologically - plausible spiking lif neurons can be integrated into deep networks can perform as well as other spiking models ( e .",
        "it also provides new methods for training deep networks to run on neuromorphic hardware , with the aim of fast , power - efficient image classification for robotics applications .",
        "in this paper , we extend the deep long short - term memory ( dlstm ) recurrent neural networks by introducing gated direct connections between memory cells in adjacent layers .",
        "these direct links , called highway connections , enable unimpeded information flow across different layers and thus alleviate the gradient vanishing problem when building deeper lstms .",
        "experiments on the ami distant speech recognition ( dsr ) task indicate that we can train deeper lstms and achieve better improvement from sequence training with highway lstms ( hlstms ) .",
        "we introduce a novel schema for sequence to sequence learning with a deep q - network ( dqn ) , which decodes the output sequence iteratively .",
        "deep neural networks ( dnn ) have achieved state - of - the - art results in a wide range of tasks , with the best results obtained with large training sets and large models .",
        "as a result , there is much interest in research and development of dedicated hardware for deep learning ( dl ) .",
        "we present a novel and practical deep fully convolutional neural network architecture for semantic pixel - wise segmentation termed segnet .",
        "recent works have highlighted scale invariance or symmetry present in the weight space of a typical deep network and the adverse effect it has on the euclidean gradient based stochastic gradient descent optimization .",
        "in this work , we show that a commonly used deep network , which uses convolution , batch normalization , relu , max - pooling , and sub - sampling pipeline , possess more complex forms of symmetry arising from scaling - based reparameterization of the network weights .",
        "we com - pare the outcomes of regularization methods that are popularly used to train deep neural networks and study how different context functions can affect the classification performance .",
        "this paper is an empirical study of the distributed deep learning for a question answering subtask : answer selection .",
        "recent works have highlighted scale invariance or symmetry that is present in the weight space of a typical deep network and the adverse effect that it has on the euclidean gradient based stochastic gradient descent optimization .",
        "in this work , we show that these and other commonly used deep networks , such as those which use a max - pooling and sub - sampling layer , possess more complex forms of symmetry arising from scaling based reparameterization of the network weights .",
        "we study hierarchical variational models on a variety of deep discrete latent variable models .",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning framework .",
        "in this paper , we have proposed a system based on matrix factorization ( mf ) and deep recurrent neural networks ( drnns ) for genotype imputation and phenotype sequences prediction .",
        "this paper reports a novel deep architecture referred to as maxout network in network ( min ) , which can enhance model discriminability and facilitate the process of information abstraction within the receptive field .",
        "this paper proposes a new framework of spectral - spatial feature extraction for hsi classification , in which for the first time the concept of deep learning is introduced .",
        "this paper presents a new method for pre - training neural networks that can decrease the total training time for a neural network while maintaining the final performance , which motivates its use on deep neural networks .",
        "following the recent successes of deep convolutional neural networks ( dcnn ) for large scale image classification , descriptors extracted from dcnns are increasingly used in place of the traditional hand crafted descriptors such as fisher vectors ( fv ) with better retrieval performances .",
        "uth consists of two successive deep learning steps .",
        "first , stacked restricted boltzmann machines ( srbm ) , a type of unsupervised deep",
        "then we demonstrate a straightforward and effective deep supervision strategy in which we replicate targets at each sequence step .",
        "in spite of its simplicity , universum prescription obtained competitive results in training deep convolutional networks for cifar - 10 , cifar - 100 and stl - 10 datasets .",
        "we build upon the success of recent deep reinforcement learning and develop a system for learning target reaching with a three - joint robot manipulator using external visual observation .",
        "a deep q network ( dqn ) was demonstrated to perform target reaching after training in simulation .",
        "we present a large - scale study , exploring the capability of temporal deep neural networks in interpreting natural human kinematics and introduce the first method for active biometric authentication with mobile inertial sensors .",
        "the run - time of computing the gradient of the proposed surrogate objective with respect to each training exemplar is quadratic in the the tree depth , and thus training deep trees is feasible .",
        "in this paper , we apply a general deep learning ( dl ) framework for the answer selection task , which does not depend on manually defined features or linguistic tools .",
        "we use multi - layered recurrent neural networks ( rnns ) with long short - term memory ( lstm ) units which are deep both spatially and temporally .",
        "recent work has shown that deep neural networks are capable of approximating both value functions and policies in reinforcement learning domains featuring continuous state and action spaces .",
        "however , to the best of our knowledge no previous work has succeeded at using deep neural networks in structured ( parameterized ) continuous action spaces .",
        "as such , this paper represents a successful extension of deep reinforcement learning to the class of parameterized action space mdps .",
        "we introduce and compare several strategies for learning discriminative features from electroencephalography ( eeg ) recordings using deep learning techniques .",
        "hydra - nets allow for separate processing pathways adapting to subsets of a dataset and thus combine the advantages of individual feature learning ( better adaptation of early , low - level processing ) with group model training ( better generalization of higher - level processing in deeper layers ) .",
        "first a siamese network is trained with deep supervision on the labeled text of training dataset which project texts in a similarity manifold .",
        "the deeply supervised siamese network learn the visual similarity of texts .",
        "the creation of practical deep learning data - products often requires the parallelization across processors and computers to make deep learning feasible on large data sets , but bottlenecks in communication bandwidth make it difficult to attain good speedups through parallelism .",
        "in this paper , we propose the deep reinforcement relevance network ( drrn ) , a novel deep architecture , for handling an unbounded action space with applications to language understanding for text - based games .",
        "therefore , it is very difficult to pre - define the action set as in the deep q - network ( dqn ) .",
        "we consider the problem of human activity recognition using triaxial accelerometers and deep learning paradigms .",
        "this paper shows that deep activity recognition models ( a ) provide better recognition accuracy of human activities , ( b ) avoid the expensive design of handcrafted features in existing systems , and ( c ) utilize the massive unlabeled acceleration samples for unsupervised feature extraction .",
        "moreover , a hybrid approach of deep learning and hidden markov models ( dl - hmm ) is presented for sequential activity recognition .",
        "this hybrid approach integrates the hierarchical representations of deep activity recognition models with the stochastic modeling of temporal sequences in the hidden markov models .",
        "we introduce deep linear discriminant analysis ( deeplda ) which learns linearly separable latent representations in an end - to - end fashion .",
        "the central idea of this paper is to put lda on top of a deep neural network .",
        "deeplda produces competitive results on all three datasets and sets a new state of the art on stl - 10 with a test set accuracy of 81 .",
        "several nonlinear extensions of the classical linear cca method have been proposed , including kernel and deep neural network methods .",
        "have shown that the use of a deep learning approach that jointly learns and computes the features , is very promising for the steganalysis .",
        "we investigated how the application of deep learning , specifically the use of convolutional networks trained with gpus , can help to build better predictive models in telecommunication business environments , and fill this gap .",
        "this paper presents a new method for the discovery of latent domains in diverse speech data , for the use of adaptation of deep neural networks ( dnns ) for automatic speech recognition .",
        "we show that the internal representations of an image in a deep neural network ( dnn ) can be manipulated to mimic those of other natural images with only minor , imperceptible perturbations to the original image .",
        "with the rise of deep architectures , the prime focus has been on object category recognition .",
        "deep learning methods have achieved wide success in this task .",
        "in this paper we show how deep architectures , specifically convolutional neural networks ( cnn ) , can be adapted to the task of simultaneous categorization and pose estimation of objects .",
        "deep neural networks are powerful parametric models that can be trained efficiently using the backpropagation algorithm .",
        "our findings also build a better understanding of certain deep architectures , which contain randomly weighted and untrain",
        "deep neural networks with millions of parameters are at the heart of many state of the art machine learning models today .",
        "in this paper , we apply deep learning techniques to detect the broad absorption bump .",
        "the success of deep learning based method inspires us to generalize a common methodology for the broader science discovery problems .",
        "we present our on - going work to build the deepdis system for such kind of applications .",
        "a lbn decomposes into a deep linear network where each linear unit can be turned on or off by non - deterministic binary latent units .",
        "in this paper , we introduce a new deep convolutional neural network ( convnet ) module that promotes competition among a set of multi - scale convolutional filters .",
        "we show that the use of our proposed module in typical deep convnets produces classification results that are either better than or comparable to the state of the art on the following benchmark datasets : mnist , cifar - 10 , cifar - 100 and svhn .",
        "our net2net technique accelerates the experimentation process by instantaneously transferring the knowledge from a previous network to each new deeper or wider network .",
        "as a result , the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution .",
        "generative model approaches to deep learning are of interest in the quest for both better understanding as well as training methods requiring fewer labeled samples .",
        "the linear layer is one of the most pervasive modules in deep learning representations .",
        "here , we introduce a deep , differentiable , fully - connected neural network module composed of diagonal matrices of parameters , $ \\ mathbf { a } $ and $ \\ mathbf { d } $ , and the discrete cosine transform $ \\ mathbf { c } $ .",
        "we present theoretical results showing how deep cascades of acdc layers approximate linear layers .",
        "we use prioritized experience replay in the deep q - network ( dqn ) algorithm , which achieved human - level performance in atari games .",
        "recent advances in neural variational inference have spawned a renaissance in deep latent variable models .",
        "recent advance in deep learning shows that transfer learning becomes much easier and more effective with high - level abstract features learned by deep models , and the ` transfer ' can be conducted not only between data distributions and data types , but also between model structures ( e .",
        ", shallow nets and deep nets ) or even model types ( e .",
        "we present a new supervised architecture termed mediated mixture - of - experts ( mmoe ) that allows us to improve classification accuracy of deep convolutional networks ( dcn ) .",
        "the recent promising achievements of deep learning rely on the large amount of labeled data .",
        "in this work , we revisit graph - based semi - supervised learning algorithms and propose an online graph construction technique which suits deep convolutional neural network better .",
        "we consider an em - like algorithm for semi - supervised learning on deep neural networks : in forward pass , the graph is constructed based on the network output , and the graph is then used for loss calculation to help update the network by back propagation in the backward pass .",
        "the task of labeling data for training deep neural networks is daunting and tedious , requiring millions of labels to achieve the current state - of - the - art results .",
        "in this work , we propose to train a deep convolutional network based on an enhanced version of the k - means clustering algorithm , which reduces the number of correlated parameters in the form of similar filters , and thus increases test categorization accuracy .",
        "we further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data .",
        "a deep belief network ( dbn ) requires large , multiple hidden layers with high number of hidden units to learn good features from the raw pixels of large images .",
        "policies for complex visual tasks have been successfully learned with deep reinforcement learning , using an approach called deep q - networks ( dqn ) , but relatively large ( task - specific ) networks and extensive training are needed to achieve good performance .",
        "deep learning has become the state - of - art tool in many applications , but the evaluation and training of deep models can be time - consuming and computationally expensive .",
        "our model is parameterized by only a mean and variance per pixel which simplifies computations and makes our method scalable to a deep architecture .",
        "unregularized deep neural networks ( dnns ) can be easily overfit with a limited sample size .",
        "in this paper , we propose deep embedded clustering ( dec ) , a method that simultaneously learns feature representations and cluster assignments using deep neural networks .",
        "this method , termed \" actor - mimic \" , exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers .",
        "we then show that the representations learnt by the deep policy network are capable of generalizing to new tasks , speeding up learning in novel environments .",
        "combined with the inherent nature of medical images that make them ideal for deep - learning , further application of such systems to medical image classification holds much promise .",
        "a deep architecture is used to define an energy function of candidate labels , and then predictions are produced by using back - propagation to iteratively optimize the energy with respect to the labels .",
        "this deep architecture captures dependencies between labels that would lead to intractable graphical models , and performs structure learning by automatically learning discriminative features of the structured output .",
        "overall , deep learning provides remarkable tools for learning features of the inputs to a prediction problem , and this work extends these techniques to learning features of the outputs .",
        "learning meaningful representations using deep neural networks involves designing efficient training schemes and well - structured networks .",
        "in recent years increasingly complex architectures for deep convolution networks ( dcns ) have been proposed to boost the performance on image recognition tasks .",
        "deep networks are increasingly being applied to problems involving image synthesis , e .",
        "we compare the consequences of using ssim versus se loss on representations formed in deep autoencoder and recurrent neural network architectures .",
        "a pure pattern - matching approach , based on a deep convolutional neural network ( dcnn ) that predicts the next move , can perform as well as monte carlo tree search ( mcts ) - based open source go engines such as pachi [ baudis & amp ; gailly ( 2012 ) ] if its search budget is limited .",
        "supervised training of deep neural nets typically relies on minimizing cross - entropy .",
        "in this paper we proposed a direct loss minimization approach to train deep neural networks , taking into account the application - specific loss functions .",
        "layer - sequential unit - variance ( lsuv ) initialization - a simple strategy for weight initialization for deep net learning - is proposed .",
        "we show that with the strategy , learning of very deep nets via standard stochastic gradient descent is at least as fast as the complex schemes proposed specifically for very deep nets such as fitnets ( romero et al .",
        "our method relies on percepts that are extracted from all level of a deep convolutional network trained on the large imagenet dataset .",
        "we show that a deep convolutional network with an architecture inspired by the models used in image recognition can yield accuracy similar to a long - short term memory ( lstm ) network , which achieves the state - of - the - art performance on the standard switchboard automatic speech recognition task .",
        "we introduce a class of cnns called deep convolutional generative adversarial networks ( dcgans ) , that have certain architectural constraints , and demonstrate that they are a strong candidate for unsupervised learning .",
        "training on various image datasets , we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator .",
        "deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation .",
        "this paper presents a comparative study of four deep learning frameworks , namely caffe , neon , theano , and torch , on three aspects : extensibility , hardware utilization , and speed .",
        "the study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both ( multi - threaded ) cpu and gpu ( nvidia titan x ) settings .",
        "the speed performance metrics used here include the gradient computation time , which is important during the training phase of deep networks , and the forward time , which is important from the deployment perspective of trained networks .",
        "we observe that torch is best suited for any deep architecture on cpu , followed by theano .",
        "next , we train a deep recurrent - convolutional network inspired by state - of - the - art video classification to learn robust representations from the sequence of images .",
        "although deep convolutional neural networks ( cnns ) have achieved remarkable results on object detection and segmentation , pre - and post - processing steps such as region proposals and non - maximum suppression ( nms ) , have been required .",
        "in this work , we propose a novel end - to - end trainable deep neural network architecture that generates the correct number of object instances and their bounding boxes ( or segmentation masks ) given an image , using only a single network evaluation without any pre - or post - processing steps .",
        "we study a theoretical model that connects deep learning to finding the ground state of the hamiltonian of a spherical spin glass .",
        "existing results motivated from statistical physics show that deep networks have a highly non - convex energy landscape with exponentially many local minima and energy barriers beyond which gradient descent algorithms cannot make progress .",
        "we show that a number of regularization schemes in deep learning can benefit from this phenomenon .",
        "the complexity of deep neural network algorithms for hardware implementation can be much lowered by optimizing the word - length of weights and signals .",
        "in this work , the effects of retraining are analyzed for a feedforward deep neural network ( ffdnn ) and a convolutional neural network ( cnn ) .",
        "we propose a method for integration of features extracted using deep representations of convolutional neural networks ( cnns ) each of which is learned using a different image dataset of objects and materials for material recognition .",
        "experimental results show that the proposed method achieves state - of - the - art performance by integrating deep features .",
        "although the latest high - end smartphone has powerful cpu and gpu , running deeper convolutional neural networks ( cnns ) for complex tasks such as imagenet classification on mobile devices is challenging .",
        "to deploy deep cnns on mobile devices , we present a simple and effective scheme to compress the entire cnn , which we call one - shot whole network compression .",
        "in recent years there have been many successes of using deep representations in reinforcement learning .",
        "dracula learns a dictionary of $ n $ - grams that efficiently compresses a given corpus and recursively compresses its own dictionary ; in effect , dracula is a ` deep ' extension of compressive feature learning .",
        "we here apply , for the first time , deep learning methods to mobile phone metadata using a convolutional network .",
        "these results show great potential for deep learning approaches for prediction tasks using standard mobile phone metadata .",
        "we propose a method for hand pose estimation based on a deep regressor trained on two different kinds of input .",
        "traditionally in deep learning , one makes a static trade - off between the needs of early and late optimization .",
        "for example , we can gradually transition from linear to non - linear networks , deterministic to stochastic computation , shallow to deep architectures , or even simple downsampling to fully differentiable attention mechanisms .",
        "two novel deep hybrid architectures , the deep hybrid boltzmann machine and the deep hybrid denoising auto - encoder , are proposed for handling semi - supervised learning problems .",
        "we propose a structured prediction architecture for images centered around deep recurrent neural networks .",
        "on theone hand , can deep directed models be success - fully trained without intractable posterior infer - ence and difficult optimization of very deep neu - ral networks in inference and generative mod - els ?",
        "we introduce the \" exponential linear unit \" ( elu ) which speeds up learning in deep neural networks and leads to higher classification accuracies .",
        "in this work we show that deep convolutional neural networks can outperform humans on the task of boundary detection , as measured on the standard berkeley segmentation dataset .",
        "recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers .",
        "this paper describes a successful application of deep reinforcement learning ( drl ) for training intelligent agents with strategic conversational skills , in a situated dialogue setting .",
        "existing deep models rely on a single sentence representation or multiple granularity representations for matching .",
        "to tackle this problem , we present a new deep architecture to match two sentences with multiple positional sentence representations .",
        "recently , dropout has seen increasing use in deep learning .",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "we use deep q - learning based on feature representations of both the state and action to learn the value of whole slates .",
        "mxnet is a multi - language machine learning ( ml ) library to ease the development of ml algorithms , especially for deep neural networks .",
        "in this article , considering arbitrary and monotone missing data patterns , we hypothesize that the use of deep neural networks built using autoencoders and denoising autoencoders in conjunction with genetic algorithms , swarm intelligence and maximum likelihood estimator methods as novel data imputation techniques will lead to better imputed values than existing techniques .",
        "we also intend to use fuzzy logic in tandem with deep neural networks to perform the missing data imputation tasks , as well as different building blocks for the deep neural networks like stacked restricted",
        "recently , dropout has seen increasing use in deep learning .",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "the recently introduced deep q - networks ( dqn ) algorithm has gained attention as one of the first successful combinations of deep neural networks and reinforcement learning .",
        "we advance the state of the art in biomolecular interaction extraction with three contributions : ( i ) we show that deep , abstract meaning representations ( amr ) significantly improve the accuracy of a biomolecular interaction extraction system when compared to a baseline that relies solely on surface - and syntax - based features ; ( ii ) in contrast with previous approaches that infer relations on a sentence - by - sentence basis , we expand our framework to enable consistent predictions over sets of sentences ( documents ) ; ( iii ) we further modify and expand a graph kernel learning framework to enable concurrent exploitation of automatically induced amr ( semantic ) and dependency structure ( syntactic ) representations .",
        "the development of a deep ( stacked ) convolutional auto - encoder in the caffe deep learning framework is presented in this paper .",
        "a deep learning approach to reinforcement learning led to a general learner able to train on visual input to play a variety of arcade games at the human and superhuman levels .",
        "its creators at the google deepmind ' s team called the approach : deep q - network ( dqn ) .",
        "tests of the proposed deep attention recurrent q - network ( darqn ) algorithm on multiple atari 2600 games show level of performance superior to that of dqn .",
        "this paper presents a restricted visual turing test ( vtt ) for story - line based deep understanding in long - term and multi - camera captured videos .",
        "we also study different graph construction mechanisms for natural language applications and propose a robust graph augmentation strategy trained using state - of - the - art unsupervised deep learning architectures that yields further significant quality gains .",
        "while emerging deep - learning systems have outclassed knowledge - based approaches in many tasks , their application to detection tasks for autonomous technologies remains an open field for scientific exploration .",
        "boltzmann machine , as a fundamental construction block of deep belief network and deep boltzmann machines , is widely used in deep learning community and great success has been achieved .",
        "using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real - world complexity .",
        "using these results as a benchmark , we discuss the role that the discount factor may play in the quality of the learning process of a deep q - network ( dqn ) .",
        "the promising performance of deep learning ( dl ) in speech recognition has motivated the use of dl in other speech technology applications such as speaker recognition .",
        "given i - vectors as inputs , the authors proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on deep belief networks ( dbn ) and deep neural networks ( dnn ) to discriminatively model each target speaker .",
        "we show that an end - to - end deep learning approach can be used to recognize either english or mandarin chinese speech - - two vastly different languages .",
        "for speech recognition , deep neural network ( dnn ) have significantly improved the recognition accuracy in most of benchmark datasets and application domains .",
        "in this paper , we study the application of the recently proposed highway network to train small - footprint dnns , which are thinner and deeper and have significantly smaller number of model parameters compared to conventional dnns .",
        "it is expected these methods will now be widely used for the training of neural networks for deep learning not only because of their non - iterative and deterministic nature but also because of their efficiency and speed and will supercede other classification methods which are iterative in nature and rely on error minimization .",
        "we first show that this unexpected equivalence can actually be generalized to other example / rado losses , with necessary and sufficient conditions for the equivalence , exemplified on four losses that bear popular names in various fields : exponential ( boosting ) , mean - variance ( finance ) , linear hinge ( on - line learning ) , relu ( deep learning ) , and unhinged ( statistics ) .",
        "in this paper , we propose a deep convolutional neural network for active object recognition that simultaneously predicts the object label , and selects the next action to perform on the object with the aim of improving recognition performance .",
        "a network pretrained in a different domain with abundant data is used as a feature extractor , while a subsequent classifier is trained on a small target dataset ; and a deep architecture trained with heavy augmentation and equipped with sophisticated regularization methods .",
        "deep learning ( dl ) has achieved notable successes in many machine learning tasks .",
        "a number of frameworks have been developed to expedite the process of designing and training deep neural networks ( dnns ) , such as caffe , torch and theano .",
        "in this paper , we present a novel deep learning method dealing with the surface material classification problem based on a fully convolutional network ( fcn ) , which takes as input the aforementioned acceleration signal and a corresponding image of the surface texture .",
        "compared to previous surface material classification solutions , which rely on a careful design of hand - crafted domain - specific features , our method automatically extracts discriminative features utilizing the advanced deep learning methodologies .",
        "deep neural networks have proved very successful in domains where large training sets are available , but when the number of training samples is small , their performance suffers from overfitting .",
        "this is the document of multimodal deep learning library , mdl , which is written in c + + .",
        "it explains principles and implementations with details of restricted boltzmann machine , deep neural network , deep belief network , denoising autoencoder , deep boltzmann machine , deep canonical correlation analysis , and modal prediction model .",
        "so mdl could be used as a frame for testings in deep learning .",
        "in the last few years , deep learning has lead to very good performance on a variety of problems , such as object recognition , speech recognition and natural language processing .",
        "among different types of deep neural networks , convolutional neural networks have been most extensively studied .",
        "the recently released stanford natural language inference ( snli ) corpus has made it possible to develop and evaluate learning - centered methods such as deep neural networks for the nli task .",
        "experimental results show that the proposed keyword spotter significantly outperforms the deep neural network ( dnn ) and hidden markov model ( hmm ) based keyword - filler model even with less computations .",
        "to tackle the issue , we propose two novel models using deep neural networks ( dnns ) to automatically learn effective patterns from categorical feature interactions and make predictions of users ' ad clicks .",
        "although recent studies have demonstrated that lstms can achieve significantly better performance on spss than deep feed - forward neural networks , little is known about why .",
        "we propose a novel deep neural network architecture for speech recognition that explicitly employs knowledge of the background environmental noise within a deep neural network acoustic model .",
        "a deep neural network is used to predict the acoustic environment in which the system in being used .",
        "the discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model .",
        "we formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point - cloud , natural language , and manipulation trajectory data into a shared embedding space using a deep neural network .",
        "in term of learning method , we also experience a method to learn the parameter of smoothing from unannotated data with a deep analysis and comparision between different learning methods .",
        "in this paper , we propose deep recurrent neural networks ( drnns ) to tackle this challenge .",
        "first , we show how some seemingly disconnected mechanisms used in deep learning such as smart initialization , annealed learning rate , layerwise pretraining , and noise injection ( as done in dropout and sgd ) arise naturally and automatically from this framework , without manually crafting them into the algorithms .",
        "in this paper , we design a deep dual - domain ( $ \\ mathbf { d ^ 3 } $ ) based fast restoration model to remove artifacts of jpeg compressed images .",
        "it leverages the large learning capacity of deep networks , as well as the problem - specific expertise that was hardly incorporated in the past design of deep architectures .",
        "specifically , our best model is capable of outperforming the latest deep model for around 1 db in psnr , and is 30 times faster .",
        "being extensively inspired by the scientific advances in the human visual perception and neuroaesthetics , we design the brain - inspired deep networks ( bdn ) for this task .",
        "this paper presents ' simpleds ' , a simple and publicly available dialogue system trained with deep reinforcement learning .",
        "i provide a fairly thorough treatment of the method of normalized graph cuts , a deeply original method due to shi and malik , including complete proofs .",
        "in the context of speech processing , a deep neural network ( dnn ) is an effective computational method to infer the probability of individual phonological classes from a short segment of speech signal .",
        "however , of late , deep learning techniques have offered a compelling alternative - - that of automatically learning problem - specific features .",
        "with this new paradigm , every problem in computer vision is now being re - examined from a deep learning perspective .",
        "therefore , it has become important to understand what kind of deep networks are suitable for a given problem .",
        "deep - networks ) exist , a survey specific to computer vision is missing .",
        "we specifically consider one form of deep networks widely used in computer vision - convolutional neural networks ( cnns ) .",
        "we hope that our recipe - style survey will serve as a guide , particularly for novice practitioners intending to use deep - learning techniques for computer vision .",
        "we present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions .",
        "architectural novelties include fast two - dimensional recurrent layers and an effective use of residual connections in deep recurrent networks .",
        "we present datagrad , a general back - propagation style training procedure for deep neural architectures that uses regularization of a deep jacobian - based penalty .",
        "it can be viewed as a deep extension of the layerwise contractive auto - encoder penalty .",
        "more importantly , it unifies previous proposals for adversarial training of deep neural nets - - this list includes directly modifying the gradient , training on a mix of original and adversarial examples , using contractive penalties , and approximately optimizing constrained adversarial objective functions .",
        "in an experiment using a deep sparse rectifier network , we find that the deep jacobian regularization of datagrad ( which also has l1 and l2 flavors of regularization ) outperforms traditional l1 and l2 regularization both on the original dataset as well as on adversarial examples .",
        "in the last two years , there have been numerous papers that have looked into using deep neural networks to replace the acoustic model in traditional statistical parametric speech synthesis .",
        "inspired by recent successes of deep learning in computer vision , we propose a novel application of deep convolutional neural networks to facial expression recognition , in particular smile recognition .",
        "in this paper , we propose a novel hashing approach based on unsupervised deep learning to hierarchically transform features into hash codes .",
        "within the heterogeneous deep hashing framework , the autoencoder layers with specific constraints are considered to model the nonlinear mapping between features and binary codes .",
        "the multiple sets of token labels are then used as the targets of a multi - target deep neural network ( mdnn ) trained on low - level acoustic features .",
        "we call this iterative deep learning framework the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) , which generates both high quality speech features for the track 1 of the challenge and acoustic tokens for the track 2 of the challenge .",
        "the increasing popularity of http adaptive video streaming services has dramatically increased bandwidth requirements on operator networks , which attempt to shape their traffic through deep packet inspection ( dpi ) .",
        "we achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks .",
        "previous work on this problem has proposed several techniques based on deep neural networks , typically involving either autoencoder - like networks with a reconstruction objective or paired feedforward networks with a batch - style correlation - based objective .",
        "we find an advantage for correlation - based representation learning , while the best results on most tasks are obtained with our new variant , deep canonically correlated autoencoders ( dccae ) .",
        "the average loss is more popular , particularly in deep learning , due to three main reasons .",
        "we propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers .",
        "in this paper , we present a new model that added memory cells to gate the feeding of image features to the deep neural network .",
        "given the i - vectors , several classifiers are adopted for the language detection task including support vector machines ( svm ) , multi - class logistic regression ( mclr ) , probabilistic linear discriminant analysis ( plda ) and deep neural networks ( dnn ) .",
        "dropout has been witnessed with great success in training deep neural networks by independently zeroing out the outputs of neurons at random .",
        "to tackle the issue of evolving distribution of neurons in deep learning , we propose an efficient adaptive dropout ( named \\ textbf { evolutional dropout } ) that computes the sampling probabilities on - the - fly from a mini - batch of examples .",
        "we propose three advances in training algorithms of variational autoencoders , for the first time allowing to train deep models of up to five stochastic layers , ( 1 ) using a structure similar to the ladder network as the inference model , ( 2 ) warm - up period to support stochastic units staying active in early training , and ( 3 ) use of batch normalization .",
        "we show how deep learning methods can be applied in the context of crowdsourcing and unsupervised ensemble learning .",
        "next , to address the more general case , where classifiers may strongly violate the conditional independence assumption , we propose to apply rbm - based deep neural net ( dnn ) .",
        "in this work we introduce a binarized deep neural network ( bdnn ) model .",
        "we propose a class of loss functions , which we call deep perceptual similarity metrics ( deepsim ) , that mitigate this problem .",
        "instead of computing distances in the image space , we compute distances between image features extracted by deep neural networks .",
        "we show three applications : autoencoder training , a modification of a variational autoencoder , and inversion of deep convolutional networks .",
        "in recent years there is a growing interest in using deep representations for reinforcement learning .",
        "in this paper , we present a methodology and tools to analyze deep q - networks ( dqns ) in a non - blind matter .",
        "moreover we are able to understand and describe the policies learned by dqns for three different atari2600 games and suggest ways to interpret , debug and optimize of deep neural networks in reinforcement learning .",
        "we propose deep distributed recurrent q - networks ( ddrqn ) , which enable teams of agents to learn to solve communication - based coordination tasks .",
        "to our knowledge , this is the first time deep reinforcement learning has succeeded in learning communication protocols .",
        "deep learning is increasingly used in several machine learning tasks as deep neural networks ( dnns ) frequently outperform other techniques .",
        "at run - time , binarynet drastically reduces memory usage and replaces most multiplications by 1 - bit exclusive - not - or ( xnor ) operations , which might have a big impact on both general - purpose and dedicated deep learning hardware .",
        "deep artificial neural networks have made remarkable progress in different tasks in the field of computer vision .",
        "in this work , we show that deep learning models cannot generalize to atypical images that are substantially different from training images .",
        "deeper , more complex models are preferable for representations to be used in supervised systems , but shallow log - linear models work best for building representation spaces that can be decoded with simple spatial distance metrics .",
        "we show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task .",
        "deep gaussian processes ( dgps ) are multi - layer hierarchical generalisations of gaussian processes ( gps ) and are formally equivalent to neural networks with multiple , infinitely wide hidden layers .",
        "dgps are nonparametric probabilistic models and as such are arguably more flexible , have a greater capacity to generalise , and provide better calibrated uncertainty estimates than alternative deep models .",
        "we start with the best - performing approaches from prior work , based on tandem models and segmental conditional random fields ( scrfs ) , with features based on deep neural network ( dnn ) classifiers of letters and phonological features .",
        "experiments show that habcnn outperforms prior deep learning approaches by a big margin .",
        "the recent success of deep neural networks relies on massive amounts of labeled data .",
        "in this paper , we propose a new approach to domain adaptation in deep networks that can simultaneously learn adaptive classifiers and transferable features from labeled data in the source domain and unlabeled data in the target domain .",
        "we enable classifier adaptation by plugging several layers into the deep network to explicitly learn the residual function with reference to the target classifier .",
        "unlike dithering strategies such as epsilon - greedy exploration , bootstrapped dqn carries out temporally - extended ( or deep ) exploration ; this can lead to exponentially faster learning .",
        "the results presented here make it more biologically plausible that a mechanism similar to back - propagation may take place in brains in order to achieve credit assignment in deep networks .",
        "deep generative models parameterized by neural networks have recently achieved state - of - the - art performance in unsupervised and semi - supervised learning .",
        "we extend deep generative models with auxiliary variables which improves the variational approximation .",
        "our findings suggest that more expressive and properly specified deep generative models converge faster with better results .",
        "the identification accuracy is up to 93 \\ % among nine different devices , and shows the method of getting feature vector from the noise of each device and identifying with deeplearning techniques is viable , and well - preformed .",
        "we develop a general duality between neural networks and compositional kernels , striving towards a better understanding of deep learning .",
        "it has been generally believed that training deep neural networks is hard with saturated activation functions , including sigmoid and tanh .",
        "recent works shows that deep tanh networks are able to converge with careful model initialization while deep sigmoid networks still fail .",
        "our preliminary results on deep convolution networks shown that , even without stabilization technologies such as batch normalization and sophisticated initialization , the \" re - scaled sigmoid \" converges to local optimality robustly .",
        "multilayer networks have seen a resurgence under the umbrella of deep learning .",
        "current deep learning algorithms train the layers of the network sequentially , improving algorithmic performance as well as providing some regularization .",
        "we present a new training algorithm for deep networks which trains \\ emph { each node in the network } sequentially .",
        "we explore the use of deep learning hierarchical models for problems in financial prediction and classification .",
        "applying deep learning methods to these problems can produce more useful results than standard methods in finance .",
        "in particular , deep learning can detect and exploit interactions in the data that are , at least currently , invisible to any existing financial economic theory .",
        "thereafter we attempt to democratize deep - learning by training on an ethernet based aws cluster and show ~ 14x scaling on 16 nodes .",
        "recent progress in deep latent variable models has largely been driven by the development of flexible and scalable variational inference methods .",
        "we propose two novel techniques - - - stacking bottleneck features and minimum trajectory error training criterion - - - to improve the performance of deep neural network ( dnn ) - based speech synthesis .",
        "this article presents an overview and brief tutorial of deep learning in mbd analytics and discusses a scalable learning framework over apache spark .",
        "specifically , a distributed deep learning is executed as an iterative mapreduce computing on many spark workers .",
        "each spark worker learns a partial deep model on a partition of the overall mbd , and a master deep model is then built by averaging the parameters of all partial models .",
        "this spark - based framework speeds up the learning of deep models consisting of many hidden layers and millions of parameters .",
        "deep learning researchers commonly suggest that converged models are stuck in local minima .",
        "recent research on deep neural networks has focused primarily on improving accuracy .",
        "recently , the deep neural network ( derived from the artificial neural network ) has attracted many researchers ' attention by its outstanding performance .",
        "in order to improve the deep neural network , many trials have been made by refining the network structure or training strategy .",
        "unlike those trials , in this paper , we focused on the basic propagation function of the artificial neural network and proposed the binarized deep neural network .",
        "in this paper , we propose an automatic detection pipeline based on deep learning for identifying and counting pests in images taken inside field traps .",
        "memory units have been widely used to enrich the capabilities of deep networks on capturing long - term dependencies in reasoning and prediction tasks , but little investigation exists on deep generative models ( dgms ) which are good at inferring high - level invariant representations from unlabeled data .",
        "this paper presents a deep generative model with a possibly large external memory and an attention mechanism to capture the local detail information that is often lost in the bottom - up abstraction process in representation learning .",
        "it can be combined with any learning algorithm and any non - linear function approximation , including the important special case of deep learning .",
        "previous work on applying deep learning to this domain relied on clipping the rewards to make learning in different games more homogeneous , but this uses the domain - specific knowledge that in these games counting rewards is often almost as informative as summing these .",
        "this means that our method can also be applied successfully to recurrent models such as lstms and to noise - sensitive applications such as deep reinforcement learning or generative models , for which batch normalization is less well suited .",
        "we demonstrate the usefulness of our method on applications in supervised image recognition , generative modelling , and deep reinforcement learning .",
        "we illustrate the parallel clones method and hierarchical conflict propagation with a character - level deep rnn tasked with memorizing a paragraph of moby dick ( by herman melville ) .",
        "this typically requires deep knowledge on which skills are typically needed for the position , what are their alternatives , which companies are likely to have such candidates , etc .",
        "the increasing complexity of deep neural networks ( dnns ) has made it challenging to exploit existing large - scale data process pipelines for handling massive data and parameters involved in dnn training .",
        "in this paper , we propose deepspark , a distributed and parallel deep learning framework that simultaneously exploits apache spark for large - scale distributed data management and caffe for gpu - based acceleration .",
        "deepspark directly accepts caffe input specifications , providing seamless compatibility with existing designs and network structures .",
        "to support parallel operations , deepspark automatically distributes workloads and parameters to caffe - running nodes using spark and iteratively aggregates training results by a novel lock - free asynchronous variant of the popular elastic averaging stochastic gradient descent ( sgd ) update scheme , effectively complementing the synchronized processing capabilities of spark .",
        "deepspark is an on - going project , and the current release is available at",
        "to enhance the performance of affective models and reduce the cost of acquiring physiological signals for real - world applications , we adopt multimodal deep learning approach to construct affective models from multiple physiological signals .",
        "11 % on seed dataset is achieved with shared representations generated by deep autoencoder ( dae ) model .",
        "for multimodal facilitation tasks , we demonstrate that the bimodal deep autoencoder ( bdae ) achieves the mean accuracies of 91 .",
        "despite its simplicity , analyzing its running time and quality of approximation is surprisingly difficult and can lead to deep insights that can be used to improve the algorithm .",
        "with the deployment of deep packet inspection ( dpi ) in telecom networks , it is possible for the telco operators to obtain user online preference .",
        "convolutional neural networks with rectified linear activation and max or average pooling , are the cornerstone of modern deep learning .",
        "specifically , it is known that convolutional arithmetic circuits posses the property of \" complete depth efficiency \" , meaning that besides a negligible set , all functions that can be implemented by a deep network of polynomial size , require exponential size in order to be implemented ( or even approximated ) by a shallow network .",
        "in this paper , we explore algorithms and representations to reduce the sample complexity of deep reinforcement learning for continuous control tasks .",
        "while shallow methods like information extraction techniques are robust to data scarcity , they are less expressive than deep understanding methods , thereby failing at answering questions involving multiple constraints .",
        "while the universal approximation property holds both for hierarchical and shallow networks , we prove that deep ( hierarchical ) networks can approximate the class of compositional functions with the same accuracy as shallow networks but with exponentially lower vc - dimension as well as the number of training parameters .",
        "this leads to the question of approximation by sparse polynomials ( in the number of independent parameters ) and , as a consequence , by deep networks .",
        "for example , it is now well - known that the arithmetic operations of deep networks can be encoded down to 8 - bit fixed - point without significant deterioration in performance .",
        "our method combines fictitious self - play with deep reinforcement learning .",
        "in this paper , we explore the ability of deep feed - forward models to learn such intuitive physics .",
        "while the authors of batch normalization ( bn ) identify and address an important problem involved in training deep networks - - \\ textit { internal covariate shift } - - the current solution has multiple drawbacks .",
        "we exploit the observation that the pre - activation before rectified linear units follow a gaussian distribution in deep networks , and that once the first and second order statistics of any given dataset are normalized , we can forward propagate this normalization without the need for recalculating the approximate",
        "thanks to the size of these datasets , the associated text comprehension task is well suited for deep - learning techniques that currently seem to outperform all alternative approaches .",
        "in the specific case of musical harmony , defining the salient features of chord transitions and evaluating invented harmonic spaces requires deep musicological background knowledge .",
        "our work is based on both deep generative model for semi - supervised learning \\ cite { kingma2014semi } and variational auto - encoder for sequence modeling \\ cite { bowman2015generating } .",
        "we introduce the drow detector , a deep learning based detector for 2d range data .",
        "deep neural networks are capable of modelling highly non - linear functions by capturing different levels of abstraction of data hierarchically .",
        "while training deep networks , first the system is initialized near a good optimum by greedy layer - wise unsupervised pre - training .",
        "in this paper a synchronized parallel algorithm for pre - training deep networks on multi - core machines has been proposed .",
        "deep learning consists in training neural networks to perform computations that sequentially unfold in many steps over a time dimension or an intrinsic depth dimension .",
        "effective learning in this setting is usually accomplished by specialized network architectures that are designed to mitigate the vanishing gradient problem of naive deep networks .",
        "many of these architectures , such as lstms , grus , highway networks and deep residual network , are based on a single structural principle : the state passthrough .",
        "we propose the method of deep shifting , which remembers previously calculated results of convolution operations in order to minimize the number of calculations .",
        "it is able to retrieve a deep semantic meaning representation for the discourse from the memory .",
        "previous studies exploit discriminative models that are built on either powerful manual features or deep discourse representations .",
        "we use deep neural networks to address both tasks , quantitatively and qualitatively measure the results in a variety of novel manners , and present a thorough investigation of the weaknesses and strengths of the approach .",
        "the system is flexible and can be used to express a wide variety of algorithms , including training and inference algorithms for deep neural network models , and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields , including speech recognition , computer vision , robotics , information retrieval , natural language processing , geographic information extraction , and computational drug discovery .",
        "coreference resolution is one of the first stages in deep language understanding and its importance has been well recognized in the natural language processing community .",
        "deep neural networks ( dnn ) have shown unprecedented success in various computer vision applications such as image classification and object detection .",
        "in this work we present a deep learning framework for video compressive sensing .",
        "we then extend the linear formulation to deep fully - connected networks and explore the performance gains using deeper architectures .",
        "we develop machine learning systems with this important capacity by developing new deep generative models , models that combine the representational power of deep learning with the inferential power of bayesian reasoning .",
        "many deep convolutional neural networks ( cnn ) make incorrect predictions on adversarial samples obtained by imperceptible perturbations of clean samples .",
        "our proposed task offers a new challenge to the community which we hope can spur further interest in exploring deeper connections between vision & amp ; language .",
        "in this paper we propose a technique for domain adaptation in stacked autoencoder ( sae ) based deep neural networks ( dnn ) performed in two stages : ( i ) unsupervised weight adaptation using systematic dropouts in mini - batch training , ( ii ) supervised fine - tuning with limited number of labeled samples in target domain .",
        "the resulting deep shading simulates all screen - space effects as well as arbitrary combinations thereof at competitive quality and speed while not being programmed by human experts but learned from example images .",
        "we present a deep learning approach for speeding up constrained procedural modeling .",
        "we present a deep hierarchical recurrent neural network for sequence tagging .",
        "given a sequence of words , our model employs deep gated recurrent units on both character and word levels to encode morphology and context information , and applies a conditional random field layer to predict the tags .",
        "combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce unpredictability of the neural models .",
        "in this paper we present architectures based on deep neural nets for gesture recognition in videos , which are invariant to local scaling .",
        "we present a new action recognition deep neural network which adaptively learns the best action velocities in addition to the classification .",
        "while deep neural networks have reached maturity for image understanding tasks , we are still exploring network topologies and features to handle the richer environment of video clips .",
        "in this paper , we revisit the algorithm introduced in [ 1 ] and present a deep interpretation of this framework that achieves state - of - the - art under such challenging scenarios .",
        "in our deep network architecture the global and local constraints that define a face can be efficiently modeled and learned end - to - end using training data .",
        "we optimize the deep network using a new loss function for super - resolution that combines reconstruction error with a learned face quality measure in adversarial setting , producing improved visual results .",
        "here , we present a tutorial of deep neural networks ( dnns ) , and some insights about the origin of the term \" deep \" ; references to deep learning are also given .",
        "deep belief networks ( dbns ) , which are used to build networks with more than two layers , are also described .",
        "this system has the capability to process key machine learning algorithms such as deep neural network , autoencoder , and k - means clustering .",
        "in this paper , we present deep extreme feature extraction ( defe ) , a new ensemble mva method for searching $ \\ tau ^ { + } \\ tau ^ { - } $ channel of higgs bosons in high energy physics .",
        "defe can be viewed as a deep ensemble learning scheme that trains a strongly diverse set of neural feature learners without explicitly encouraging diversity and penalizing correlations .",
        "this is achieved by adopting an implicit neural controller ( not involved in feedforward compuation ) that directly controls and distributes gradient flows from higher level deep prediction network .",
        "defe makes the ensembles ' deep ' in the sense that it allows deep post - process of these features that tries to learn to select and abstract the ensemble of neural feature learners .",
        "in comparison of the classic deep neural network , defe shows a state - of - the - art performance : the error rate has decreased by about 37 \\ % , the accuracy has broken through 90",
        "in this paper , we propose a new deep learning approach , called neural association model ( nam ) , for probabilistic reasoning in artificial intelligence .",
        "in this work , as two case studies , we have investigated two nam structures , namely deep neural networks ( dnns ) and relation modulated neural nets ( rmnns ) , on several probabilistic reasoning tasks in ai , including recognizing textual entailment , triple classification in multirelational knowledge bases and common - sense reasoning .",
        "considering that recurrent neural networks ( rnns ) with long short - term memory ( lstm ) can learn feature representations and model long - term temporal dependencies automatically , we propose an end - to - end fully connected deep lstm network for skeleton based action recognition .",
        "to train the deep lstm network effectively , we propose a new dropout algorithm which simultaneously operates on the gates , cells , and output responses of the lstm neurons .",
        "as a consequence , the deep learning tool - chain can perform as an early detection framework for combustion instabilities that will have a transformative impact on the safety and performance of modern engines .",
        "recently , deep learning techniques have enjoyed success in various multimedia applications , such as image classification and multi - modal data analysis .",
        "large deep learning models are developed for learning rich representations of complex data .",
        "there are two challenges to overcome before deep learning can be widely adopted in multimedia and other applications .",
        "the other is scalability , that is the deep learning system must be able to provision for a huge demand of computing resources for training large models with massive datasets .",
        "to address these two challenges , in this paper , we design a distributed deep learning platform called singa which has an intuitive programming model based on the common layer abstraction of deep learning models .",
        "singa runs on gpus as well as on cpus , and we show that it outperforms many other state - of - the - art deep learning systems .",
        "our experience with developing and training deep learning models for real - life multimedia applications in singa shows that the platform is both usable and scalable .",
        "we employ a deep q - network , trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort .",
        "meanwhile , the abundant online review resources concerning academic books can be used to mine deeper information and content utilizing altmetric perspectives .",
        "the problem of rare and unknown words is an important issue that can potentially effect the performance of many nlp systems , including both traditional count based models and deep learning models .",
        "this paper introduces the visually informed embedding of word ( view ) , a continuous vector representation for a word extracted from a deep neural model trained using the microsoft coco data set to forecast the spatial arrangements between visual objects , given a textual description .",
        "the model is composed of a deep multilayer perceptron ( mlp ) stacked on the top of a long short term memory ( lstm ) network , the latter being preceded by an embedding layer .",
        "deep neural networks ( dnns ) are powerful types of artificial neural networks ( anns ) that use several hidden layers .",
        "we report an implementation of a clinical information extraction tool that leverages deep neural network to annotate event spans and their attributes from raw clinical notes and pathology reports .",
        "to address this challenge , we propose a new deep neural network architecture that jointly leverage pre - trained word embedding and auxiliary character embedding to learn sentence meanings .",
        "deep learning has dramatically improved the performance of speech recognition systems through learning hierarchies of features optimized for the task at hand .",
        "we present a deep neural network ( dnn ) acoustic model including parametrised and differentiable pooling operators .",
        "this work , concerning paraphrase identification task , on one hand contributes to expanding deep learning embeddings to include continuous and discontinuous linguistic phrases .",
        "this work presents an end - to - end trainable deep bidirectional lstm ( long - short term memory ) model for image captioning .",
        "our model builds on a deep convolutional neural network ( cnn ) and two separate lstm networks .",
        "two novel deep bidirectional variant models , in which we increase the depth of nonlinearity transition in different way , are proposed to learn hierarchical visual - language embeddings .",
        "data augmentation techniques such as multi - crop , multi - scale and vertical mirror are proposed to prevent overfitting in training deep models .",
        "the recent success of deep learning approaches for domains like speech recognition ( hinton et al .",
        "while a single gpu often provides algorithmic simplicity and speed up to a given scale of data and model , there exist an operating point where a distributed implementation of training algorithms for deep architectures becomes necessary .",
        "residual learning has recently surfaced as an effective means of constructing very deep neural networks for object recognition .",
        "we propose a novel extension of residual learning for deep networks that enables intuitive learning across multiple related tasks using cross - connections called cross - residuals .",
        "we investigate the $ \\ ell _ \\ infty $ - constrained representation which demonstrates robustness to quantization errors , utilizing the tool of deep learning .",
        "based on the alternating direction method of multipliers ( admm ) , we formulate the original convex minimization problem as a feed - forward neural network , named \\ textit { deep $ \\ ell _ \\ infty $ encoder } , by introducing the novel bounded linear unit ( blu ) neuron and modeling the lagrange multipliers as network biases .",
        "we then investigate the effective use of the proposed model in the application of hashing , by coupling the proposed encoders under a supervised pairwise loss , to develop a \\ textit { deep siamese $ \\ ell _ \\ infty $ network } , which can be optimized from end to end .",
        "representation and learning of commonsense knowledge is one of the foundational problems in the quest to enable deep language understanding .",
        "we discuss these implications for script and story learning , and offer suggestions for deeper language understanding .",
        "very deep cnns with small 3x3 kernels have recently been shown to achieve very strong performance as acoustic models in hybrid nn - hmm speech recognition systems .",
        "in this paper , we demonstrate that the accuracy gains of these deep cnns are retained both on larger scale data , and after sequence training .",
        "our very deep cnn model sequence trained on the 2000h switchboard dataset obtains 9 .",
        "as recurrent neural networks become larger and deeper , training times for single networks are rising into weeks or even months .",
        "this tension has recently surfaced in the realm of educational data mining , where a deep learning approach to predicting students ' performance as they work through a series of exercises - - - termed deep knowledge tracing or dkt - - - has demonstrated a stunning performance advantage over the mainstay of the field , bayesian knowledge tracing or bkt .",
        "the success of deep neural networks is mostly due their ability to learn meaningful features from the data .",
        "features learned in the hidden layers of deep neural networks trained in computer vision tasks have been shown to be similar to mid - level vision features .",
        "in this paper , we describe a novel deep convolutional neural networks ( cnn ) based approach called contextual deep cnn that can jointly exploit spatial and spectral features for hyperspectral image classification .",
        "the contextual deep cnn first concurrently applies multiple 3 - dimensional local convolutional filters with different sizes jointly exploiting spatial and spectral features of a hyperspectral image .",
        "we begin with the observation that a shallow rnn is exactly equivalent to a very deep resnet with weight sharing among the layers .",
        "we propose 1 ) a generalization of both rnn and resnet architectures and 2 ) the conjecture that a class of moderately deep rnns is a biologically - plausible model of the ventral stream in visual cortex .",
        "in contrast , most deep learning architectures are computationally wasteful in that they consider every part of the input when performing an image processing task .",
        "the deep slow local representations are learned offline on unlabeled data and transferred to the observational model of our proposed tracker .",
        "specifically , deep recurrent neural networks were used for improving joint positions and velocities of kinect skeleton , and three methods were proposed to integrate the refined positions and velocities for further enhancement .",
        "here we propose a simple initial seed selection algorithm for k - means clustering along one attribute that draws initial cluster boundaries along the ' deepest valleys ' or greatest gaps in dataset .",
        "an architecture which implements reflexivity may be based on the interaction of one or several modules of deep learning , which may be specialized or not , and interconnected in a relevant way .",
        "we present hierarchical - dqn ( h - dqn ) , a framework to integrate hierarchical value functions , operating at different temporal scales , with intrinsically motivated deep reinforcement learning .",
        "secondly , we build a deep learning - based dp generator for input sentences in decoding when no corresponding references exist .",
        "recently , researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning .",
        "the agent learns reusable skills using deep q networks ( mnih et .",
        "these reusable skills , which we refer to as deep skill networks ( dsns ) , are then incorporated into our novel hierarchical deep reinforcement learning network ( h - drln ) architecture .",
        "the h - drln is a hierarchical version of deep qnetworks and learns to efficiently solve tasks by reusing knowledge from previously learned dsns .",
        "the h - drln exhibits superior performance and lower learning sample complexity ( by taking advantage of temporal extension ) compared to the regular deep q network ( mnih et .",
        "this paper applies a deep convolutional / highway mlp framework to classify genomic sequences on the transcription factor binding site task .",
        "we show that our system , deep motif ( demo ) , extracts motifs that are similar to , and in some cases outperform the current well known motifs .",
        "in addition , we find that a deeper model consisting of multiple convolutional and highway layers can outperform a single convolutional and fully connected layer in the previous state - of - the - art .",
        "deep learning is a very powerful machine learning model .",
        "deep learning trains a large number of parameters for multiple layers and is very slow when data is in large scale and the architecture size is large .",
        "inspired from the shrinking technique used in accelerating computation of support vector machines ( svm ) algorithm and screening technique used in lasso , we propose a shrinking deep learning with recall ( sdlr ) approach to speed up deep learning computation .",
        "we experiment shrinking deep learning with recall ( sdlr ) using deep neural network ( dnn ) , deep belief network ( dbn ) and convolution neural network ( cnn ) on 4 data sets .",
        "results show that the speedup using shrinking deep learning with recall ( sdlr ) can reach more than 2 .",
        "consequently , a lengthy sequence of algorithm iterations can be viewed as a deep network with shared , hand - crafted layer weights .",
        "in contrast , we demonstrate both theoretically and empirically the potential for a trained deep network to recover minimal $ \\ ell _ 0 $ - norm representations in regimes where existing methods fail .",
        "here we present deeplift ( learning important features ) , an efficient and effective method for computing importance scores in a neural network .",
        "deeplift compares the activation of each neuron to its ' reference activation ' and assigns contribution scores according to the difference .",
        "we apply deeplift to models trained on natural images and genomic data , and show significant advantages over gradient - based methods .",
        "the recent advances in deep neural networks have led to effective vision - based reinforcement learning methods that have been employed to obtain human - level controllers in atari 2600 games from pixel data .",
        "using convolutional deep neural networks with q - learning and experience replay , for both scenarios , we were able to train competent bots , which exhibit human - like behaviors .",
        "we study the problem of how to distribute the training of large - scale deep learning models in the parallel computing environment .",
        "an asynchronous and momentum variant of the easgd method is applied to train deep convolutional neural networks for image classification on the cifar and imagenet datasets .",
        "we also present how deep nade models can be trained to be agnostic to the ordering of input dimensions used by the autoregressive product rule decomposition .",
        "finally , we also show how to exploit the topological structure of pixels in images using a deep convolutional architecture for nade .",
        "lightnet is a lightweight , versatile and purely matlab - based deep learning framework .",
        "the aim of the design is to provide an easy - to - understand , easy - to - use and efficient computational platform for deep learning research .",
        "the implemented framework supports major deep learning architectures such as multilayer perceptron networks ( mlp ) , convolutional neural networks ( cnn ) and recurrent neural networks ( rnn ) .",
        "recently , a few deep learning models have surpassed the traditional window based multilayer perceptron .",
        "taking inspiration from the image classification domain we propose a deep convolutional neural network architecture , must - cnn , to predict protein properties .",
        "\\ cite { hermann2015teaching } therefore release a large scale news article dataset and propose a deep lstm reader system for machine comprehension .",
        "in recent years , deep architectures have been used for transfer learning with state - of - the - art performance in many datasets .",
        "in this work , we present an extensive analysis of the resiliency of feature vectors extracted from deep models , with special focus on the trade - off between performance and compression rate .",
        "by introducing perturbations to image descriptions extracted from a deep convolutional neural network , we change their precision and number of dimensions , measuring how it affects the final score .",
        "we show that deep features are more robust to these disturbances when compared to classical approaches , achieving a compression rate of 98 .",
        "our deep learning algorithm significantly outperforms the previous state - of - the - art .",
        "she will get \" smarter \" and more empathetic through its deep learning algorithms , and by gathering more data and learning from it .",
        "in this paper , we present our work so far in the areas of deep learning of emotion and sentiment recognition , as well as humor recognition .",
        "predictions of prominent ai researchers vary broadly from very pessimistic predictions of andrew ng to much more moderate predictions of geoffrey hinton and optimistic predictions of shane legg , deepmind cofounder .",
        "in this paper we present deeplearningkit - an open source framework that supports using pretrained deep learning models ( convolutional neural networks ) for ios , os x and tvos .",
        "deeplearningkit is developed in metal in order to utilize the gpu efficiently and swift for integration with applications , e .",
        "the goal is to support using deep learning models trained with popular frameworks such as caffe , torch , tensorflow , theano , pylearn , deeplearning4j and mocha .",
        "given the massive gpu resources and time required to train deep learning models we suggest an app store like model to distribute and download pretrained and reusable deep learning models .",
        "linkedin search is deeply personalized - for the same queries , different searchers expect completely different results .",
        "deep learning algorithm display powerful ability in computer vision area , in recent year , the cnn has been applied to solve problems in the subarea of image - generating , which has been widely applied in areas such as photo editing , image design , computer animation , real - time rendering for large scale of scenes and for visual effects in movies .",
        "the state - of - art cnn can not capture the spatial location of texture in image , lead to significant distortion after texture synthesize , we propose a new way to generating - image by adding the semantic segment step with deep learning algorithm as pre - processing and analyze the outcome .",
        "deep neural networks are typically represented by a much larger number of parameters than shallow models , making them prohibitive for small footprint devices .",
        "recent research shows that there is considerable redundancy in the parameter space of deep neural networks .",
        "in this paper , we propose a method to compress deep neural networks by using the fisher information metric , which we estimate through a stochastic optimization method that keeps track of second - order information in the network .",
        "in this paper , a deep neural network is proposed to incorporate background knowledge for conversation modeling .",
        "finally , we present our attempts to extend the automated skills acquisition framework to complex tasks such as learning to play video games where we use deep learning techniques for representation learning to aid our spatio -",
        "deep reinforcement learning methods have achieved state of the art performance in learning control policies for the games in the atari 2600 domain .",
        "the current state of the art architectures like deep q - network ( dqn ) and dueling network architectures ( dudqn ) consist of a framework with a static frame skip rate , where the action output from the network is repeated for a fixed number of frames regardless of the current state .",
        "in this paper , we propose a new architecture , dynamic frame skip deep q - network ( dfdqn ) which makes the frame skip rate a dynamic learnable parameter .",
        "deep learning ( dl ) became the method of choice in recent years for solving problems ranging from object recognition and speech recognition to robotic perception and human disease prediction .",
        "the learning of stage - wise transformations provides deep insights into the physical flow deformation .",
        "recently , there is rising interest in modelling the interactions of two sentences with deep neural networks .",
        "in this paper , we propose a deep architecture to model the strong interaction of sentence pair with two coupled - lstms .",
        "despite recent breakthroughs in the applications of deep neural networks , one setting that presents a persistent challenge is that of \" one - shot learning . \"",
        "we show that our method achieves reasonably competitive performance on some standard \" deep learning \" image classification datasets such as cifar - 10 and svhn , and also state - of - the - art results for image super - resolution , demonstrating",
        "here , we first propose a new intuitive principle of unsupervised deep learning from time series which uses the nonstationary structure of the data .",
        "this setting is considered shallow in the era of deep learning .",
        "in this paper , we present a new deep multi - task representation learning framework that learns cross - task sharing structure at every layer in a deep network .",
        "our approach is based on generalising the matrix factorisation techniques explicitly or implicitly used by many conventional mtl algorithms to tensor factorisation , to realise automatic learning of end - to - end knowledge sharing in deep networks .",
        "this is in contrast to existing deep learning approaches that need a user - defined multi - task sharing strategy .",
        "experiments demonstrate the efficacy of our deep multi - task representation learning in terms of both higher accuracy and fewer design choices .",
        "deep neural networks can capture complex non - linear features ; however this ability comes at the cost of high computational and memory requirements .",
        "to enable embedded devices such as smartphones , google glasses and monitoring cameras with the astonishing power of deep learning , dedicated hardware accelerators can be used to decrease both execution time and power consumption .",
        "many hardware accelerators for deep neural networks have been proposed recently .",
        "a first important step of accelerator design is hardware - oriented approximation of deep networks , which enables energy - efficient inference .",
        ", only 10 - 34 layers deep .",
        "our sparse connection structure facilitates a significant reduction in computational cost and number of parameters of state - of - the - art deep cnns without compromising accuracy .",
        "for the deeper resnet 200 our model has 25 % fewer floating point operations and 44 % fewer parameters , while maintaining state - of - the - art accuracy .",
        "large knowledge bases ( kbs ) are useful in many tasks , but it is unclear how to integrate this sort of knowledge into \" deep \" gradient - based learning systems .",
        "as the complexity of deep neural networks ( dnns ) trend to grow to absorb the increasing sizes of data , memory and energy consumption has been receiving more and more attentions for industrial applications , especially on mobile devices .",
        "for each entry in a deep net , funhashnn uses multiple low - cost hash functions to fetch values in the compression space , and then employs a small reconstruction network to recover that entry .",
        "deep networks rely on massive amounts of labeled data to learn powerful models .",
        "this paper addresses deep transfer learning under a more general scenario that the joint distributions of features and labels may change substantially across domains .",
        "transfer learning is enabled in deep convolutional networks , where the dataset shifts may linger in multiple task - specific feature layers and the classifier layer .",
        "by embracing deep neural networks , we are able to demonstrate end - to - end learning of protocols in complex environments inspired by communication riddles and multi - agent computer vision problems with partial observability .",
        "the former uses deep q - learning , while the latter exploits the fact that , during learning , agents can propagate error derivatives through ( noisy ) communication channels .",
        "deep conditional generative models are developed to simultaneously learn the temporal dependencies of multiple sequences .",
        "we show that a polynomially sized deep network supports exponentially high separation ranks for certain input partitions , while being limited to polynomial separation ranks for others .",
        "in addition to analyzing deep networks , we show that shallow ones support only linear separation ranks , and by this gain insight into the benefit of functions brought forth by depth - they are able to efficiently model strong correlation under favored partition",
        "as the emerging field of machine learning , deep learning shows excellent ability in solving complex learning problems .",
        "however , the size of the networks becomes increasingly large scale due to the demands of the practical applications , which poses significant challenge to construct a high performance implementations of deep learning neural networks .",
        "in order to improve the performance as well to maintain the low power cost , in this paper we design dlau , which is a scalable accelerator architecture for large - scale deep learning networks using fpga as the hardware prototype .",
        "the dlau accelerator employs three pipelined processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications .",
        "recent advances in deep learning have enabled the extraction of high - level features from raw sensor data which has opened up new possibilities in many different fields , including computer generated choreography .",
        "at the core of chor - rnn is a deep recurrent neural network trained on raw motion capture data and that can generate new dance sequences for a solo dancer .",
        "recent progress on many imaging and vision tasks has been driven by the use of deep feed - forward neural networks , which are trained by propagating gradients of a loss defined on the final output , back through the network up to the first layer that operates directly on the image .",
        "for an expected loss function of a deep nonlinear neural network , we prove the following statements under the independence assumption adopted from recent work : 1 ) the function is non - convex and non - concave , 2 ) every local minimum is a global minimum , 3 ) every critical point that is not a global minimum is a saddle point , and 4 ) the property of saddle points differs for shallow networks ( with three layers ) and deeper networks ( with more than three layers ) .",
        "moreover , we prove that the same four statements hold for deep linear neural networks with any depth , any widths and no unrealistic assumptions .",
        "as a result , we present an instance , for which we can answer to the following question : how difficult to directly train a deep model in theory ?",
        "we note that even though we have advanced the theoretical foundations of deep learning , there is still a",
        "deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance .",
        "however , each fraction of a percent of improved accuracy costs nearly doubling the number of layers , and so training very deep residual networks has a problem of diminishing feature reuse , which makes these networks very slow to train .",
        "we call the resulting network structures wide residual networks ( wrns ) and show that these are far superior over their commonly used thin and very deep counterparts .",
        "for example , we demonstrate that even a simple 16 - layer - deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks , including thousand - layer - deep networks , achieving new state - of - the - art results on cifar - 10 , cifar - 100 and svhn .",
        "we show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the mnist and cifar - 10 datasets .",
        "in this paper , we attack the anomaly detection problem by directly modeling the data distribution with deep architectures .",
        "we propose deep structured energy based models ( dsebms ) , where the energy function is the output of a deterministic deep neural network with structure .",
        "large labeled training sets are the critical building blocks of supervised learning methods and are key enablers of deep learning techniques .",
        "we present a new framework of applying deep neural networks ( dnn ) to devise a universal discrete denoiser .",
        "to the best of our knowledge , this is the first work to apply deep learning to open ie .",
        "further , we are proposing \" deepsurvey \" as a mechanism embodying the entire process from the reading through all the papers , the generation of ideas , and to the writing of paper .",
        "first steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made - - - for the continuous - time case - - - in mallat , 2012 , and wiatowski and b \\ \" olcskei , 2015 .",
        "we develop a scalable and extendable training framework that can utilize gpus across nodes in a cluster and accelerate the training of deep learning models based on data parallelism .",
        "finally , we release the framework as open - source for further research on distributed deep learning",
        "apart from traditional approach , including named entity recognition ( ner ) solutions , a novel technique , called deep entity recognition ( deeper ) , is introduced and implemented .",
        "deeper also provides automatic evaluation , which makes possible numerous experiments , including over a thousand questions from a quiz tv show answered on the grounds of polish wikipedia .",
        "the final results of a manual evaluation on a separate question set show that the strength of deeper approach lies in its ability to answer questions that demand answers beyond the traditional categories of named entities .",
        "we introduce a deep memory network for aspect level sentiment classification .",
        "the deep memory network with 9 layers is 15 times faster than lstm with a cpu implementation .",
        "we then use these tasks to systematically compare and contrast existing deep reinforcement learning ( drl ) architectures with our new memory - based drl architectures .",
        "in the original mvso release , adjective - noun pair ( anp ) detectors were trained for the six languages using an alexnet - styled architecture by fine - tuning from deepsentibank .",
        "this paper presents research in progress investigating the viability and adaptation of reinforcement learning using deep neural network based function approximation for the task of radio control and signal detection in the wireless domain .",
        "deep neural networks ( dnns ) have demonstrated state - of - the - art results on many pattern recognition tasks , especially vision classification problems .",
        "here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful , learned prior : a deep generator network ( dgn ) .",
        "the activation function of deep neural networks ( dnns ) has undergone many changes during the last decades .",
        "auto - encoders are often used as building blocks of deep network classifier to learn feature extractors , but task - irrelevant information in the input data may lead to bad extractors and result in poor generalization performance of the network .",
        "finally , cf - nade can be extended to a deep model , with only moderately increased computational complexity .",
        "this paper proposes an approach that predicts the road course from camera sensors leveraging deep learning techniques .",
        "attention mechanisms have recently been introduced in deep learning for various tasks in natural language processing and computer vision .",
        "while there are methods with optimality guarantees in the setting of discrete state and action spaces , these methods cannot be applied in high - dimensional deep rl scenarios .",
        "non - linear extensions based on kernels and ( deep ) neural networks are derived , achieving better performance than the linear ones .",
        "the maturity of deep learning techniques has led in recent years to a breakthrough in object recognition in visual media .",
        "furthermore , we evaluated the performances of the architectures with varying the number of layers on a larger dataset ( million song dataset ) , and found that deeper models outperformed the 4 - layer architecture .",
        "our system does not rely on handwritten rules or engineered features ; instead , we train deep neural networks on a large conversational dataset .",
        "general game playing artificial intelligence has recently seen important advances due to the various techniques known as ' deep learning ' .",
        "on the other hand , deep learning systems which do beat human champions , such as in go , do not generalise well .",
        "the power of deep learning simultaneously exposes its weakness .",
        "given that deep learning is mostly clever reconfigurations of well - established methods , moving beyond the state of art calls for forward - thinking visionary solutions , not just more of the same .",
        "pretraining is widely used in deep neutral network and one of the most famous pretraining models is deep belief network ( dbn ) .",
        "in this paper , we pretrained deep neutral network by different pretraining models and hence investigated the difference between dbn and stacked denoising autoencoder ( sda ) when used as pretraining model .",
        "in recent year , parallel implementations have been used to speed up the training of deep neural networks ( dnn ) .",
        "this paper presents an universal framework for exploiting these multi - typed treebanks to improve parsing with deep multi - task learning .",
        "we propose a simple duality between this dense associative memory and neural networks commonly used in deep learning .",
        "on the deep learning side of the duality , this family corresponds to feedforward neural networks with one hidden layer and various activation functions , which transmit the activities of the visible neurons to the hidden layer .",
        "in this paper , we show that by feeding the weights of a deep neural network ( dnn ) during training into a deep q - network ( dqn ) as its states , this dqn can learn policies to accelerate the training of that dnn .",
        "in this paper , we show how to integrate these goals , applying deep reinforcement learning to model future reward in chatbot dialogue .",
        "in recent years deep neural networks have achieved great success in sentiment classification for english , thanks in part to the availability of copious annotated resources .",
        "to combat this problem , we propose the adversarial deep averaging network ( adan ) to transfer sentiment knowledge learned from labeled english data to low - resource languages where only unlabeled data exists .",
        "in order to capture some of these advantages in machine perception , we ask two questions : whether deep neural networks can learn universal image representations , useful not only for a single task but for all of them , and how the solutions to the different tasks can be integrated in this framework .",
        "we answer by proposing a new architecture , which we call \\ emph { multinet } , in which not only deep image features are shared between tasks , but where tasks can interact in a recurrent manner by encoding the results of their analysis in a common shared representation of the data .",
        "however , these architectures are rather shallow in comparison to the deep convolutional networks which are very successful in computer vision .",
        "to the best of our knowledge , this is the first time that very deep convolutional nets have been applied to nlp .",
        "the purposes of the ssa ontology are to explore the potential for ontology development and engineering to ( i ) represent ssa data , general knowledge , and domain objects , ( ii ) clearly annotate and express the meaning of that orbital , near - earth and deep - space da - ta , and ( iii ) foster ssa data sharing among ssa actors and space object catalogs .",
        "by improving global ssa via actionable data - and knowledge - exchange , we can achieve the broader goals ( and motivations ) of ( iv ) advancing our capacity for planetary defense from near - or deep - space ob - ects , and ( v ) improving spaceflight safety for future generations .",
        "recent results show that deep neural networks achieve excellent performance even when , during training , weights are quantized and projected to a binary representation .",
        "powered by deep recurrent neural networks and neural embeddings , our proposed cfo achieves an accuracy of 75 .",
        "the google deepmind challenge match in march 2016 was a historic achievement for computer go development .",
        "recently there has been an increasing trend to use deep learning frameworks for both 2d consumer images and for 3d medical images .",
        "however , there has been little effort to use deep frameworks for volumetric vascular segmentation .",
        "we demonstrated the use of deep learning framework consisting both 2d and 3d convolutional filters ( convnet ) .",
        "inspired by this connection , we develop deep convolutional networks using a family of structured convolutional matrices and achieve state - of - the - art trade - off between energy efficiency and classification accuracy for well - known image recognition tasks .",
        "we empirically show that ( i ) by modeling uncertainty on the output value , disco nets outperform equivalent non - probabilistic predictive networks and ( ii ) disco nets accurately model the uncertainty of the output , outperforming existing probabilistic models based on deep neural networks .",
        "this paper presents an end - to - end framework for task - oriented dialog systems using a variant of deep recurrent q - networks ( drqn ) .",
        "seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local , next - word distributions .",
        "building systems that possess the sensitivity and intelligence to identify and describe high - level attributes in music audio signals continues to be an elusive goal , but one that surely has broad and deep implications for a wide variety of applications .",
        "we carry this intuition forward in our second approach , and probe deeper into the nature of graph - based systems by designing several summarizers based on centrality measures .",
        "in this paper , we propose to use deep policy networks which are trained with an advantage actor - critic method for statistically optimised dialogue systems .",
        "first , we show that , on summary state and action spaces , deep reinforcement learning ( rl ) outperforms gaussian processes methods .",
        "in order to remove the need to define such summary spaces , we show that deep rl can also be trained efficiently on the original state and action spaces .",
        "we show that a deep rl method based on an actor - critic architecture can exploit a small amount of data very efficiently .",
        "indeed , with only a few hundred dialogues collected with a handcrafted policy , the actor - critic deep learner is considerably bootstrapped from a combination of supervised and batch rl .",
        "in addition , convergence to an optimal policy is significantly sped up compared to other deep rl methods initialized on the data with batch rl .",
        "we also propose the addition of an intermap pooling ( imp ) layer to deep cnns .",
        "potential areas of investigation , including possible architectures for incorporating machine learning into robotic nodes , training approaches , and the possibility of using deep learning approaches for automatic feature extraction , are discussed .",
        "novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub - actions .",
        "in contrast to many deep multi - task learning work , we do not predefine a parameter sharing strategy by tying some ( usually bottom ) layers ' parameters , instead , our framework allows the sharing for all shareable layers thus the sharing strategy is learned from a pure data - driven way .",
        "despite recent advances in important domains such as vision and language , the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data .",
        "in this work , we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories .",
        "deep neural networks have dramatically advanced the state of the art for many areas of machine learning .",
        "in this work , we introduce a new type of linear connections , named fast - forward connections , based on deep long short - term memory ( lstm ) network , together with the interleaved bi - directional way for stacking them .",
        "fast - forward connections play an essential role to propagate the gradients in building the deep topology of depth 16 .",
        "maximum mean discrepancy ( mmd ) has been successfully applied to learn deep generative models for characterizing a joint distribution of variables via kernel mean embedding .",
        "large - scale supervised classification algorithms , especially those based on deep convolutional neural networks ( dcnns ) , require vast amounts of training data to achieve state - of - the - art performance .",
        "the concept is illustrated by a specific knowledge model provided by a deep generative autoencoder .",
        "we show how real logic can be implemented in deep tensor neural networks with the use of google ' s tensorflow primitives .",
        "deep neural networks have recently been shown to lack robustness against adversarially crafted inputs .",
        "to our knowledge , this is the first time deep learning has been applied to theorem proving .",
        "we perform a study of the factors affecting training time in multi - device deep learning systems .",
        "deep neural networks ( dnn ) have shown promise in a wide range of machine learning tasks , but for behavioral signal processing ( bsp ) tasks their application has been constrained due to limited quantity of data .",
        "then , the hidden layers of these classifiers become parts of a deeper network that integrates all feature streams .",
        "deep reinforcement learning has been shown to be a powerful framework for learning policies from complex high - dimensional sensory inputs to actions in complex tasks , such as the atari domain .",
        "in this paper , we explore output representation modeling in the form of temporal abstraction to improve convergence and reliability of deep reinforcement learning approaches .",
        "we offer analysis and explanation for both convergence and final results , revealing a problem deep rl approaches have with sparse reward signals .",
        "in this work , we propose a novel video captioning framework , termed as \\ emph { bidirectional long - short term memory } ( bilstm ) , which deeply captures bidirectional global temporal structure in video .",
        "unsupervised learning is the most challenging problem in machine learning and especially in deep learning .",
        "we present a novel deep recurrent neural network architecture that learns to build implicit plans in an end - to - end manner by purely interacting with an environment in reinforcement learning setting .",
        "deep neural networks ( dnn ) have been successful in en - hancing noisy speech signals .",
        "in this paper we propose a novel deep learning model inspired by insights from human audio visual perception .",
        "to what extent is the success of deep visualization due to the training ?",
        "could we do deep visualization using untrained , random weight networks ?",
        "to address this issue , we explore new and powerful generative models for three popular deep visualization tasks using untrained , random weight convolutional neural networks .",
        "to our knowledge this is the first demonstration of image representations using untrained deep neural networks .",
        "our work provides a new and fascinating tool to study the representation of deep network architecture and sheds light on new understandings on deep visualization .",
        "our goal is to be able to build a generative model from a deep neural network architecture to try to create music that has both harmony and melody and is passable as music composed by humans .",
        "our approach , however , is to perform end - to - end learning and generation with deep neural nets alone .",
        "experimental results show that the proposed method which is based on semi - supervised training of a deep neural network largely outperforms phoneme based continuous speech recognition on the timit dataset .",
        "while this does not seem like a challenging task , many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35 % - 65 % on benchmark sets .",
        "deep reinforcement learning ( drl ) is a trending field of research , showing great promise in challenging problems such as playing atari , solving go and controlling robots .",
        "discriminative methods based on deep learning , which are very effective in other learning scenarios , are ill - suited for one - shot learning as they need large amounts of training data .",
        "in this paper , we propose a method to learn the parameters of a deep model in one shot .",
        "we construct the learner as a second deep network , called a learnet , which predicts the parameters of a pupil network from a single exemplar .",
        "we study the expressivity of deep neural networks with random weights .",
        "we combine riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic , deep neural networks with random weights .",
        "we prove this generic class of deep random functions cannot be efficiently computed by any shallow network , going beyond prior work restricted to the analysis of single functions .",
        "moreover , we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space .",
        "our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities , and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions .",
        "we present a natural language generator based on the sequence - to - sequence approach that can be trained to produce natural language strings as well as deep syntax dependency trees from input dialogue acts , and we use it to directly compare two - step generation with separate sentence planning and surface realization stages to a joint , one - step approach .",
        "guided by the ranking , recruiters can get deeper insights from candidate profiles and validate why and how the application ranked them .",
        "natural language understanding often requires deep semantic knowledge .",
        "we utilized recent advances in short text categorization using deep learning to create word - level and character - level models .",
        "in conventional deep neural network based speech synthesis , the input text features are repeated for the entire duration of phoneme for mapping text and speech parameters .",
        "we then use this acoustic representation at unit - level to synthesize speech using deep neural network based statistical parametric speech synthesis technique .",
        "in the era of big data and deep learning , there is a common view that machine learning approaches are the only way to cope with the robust and scalable information extraction and summarization .",
        "fisher information and natural gradient provided deep insights and powerful tools to artificial neural networks .",
        "however , the diversity and large - scale data size have posed a significant challenge to construct a flexible and high - performance implementation of deep learning neural networks .",
        "to improve the performance and maintain the scalability , we present cnnlab , a novel deep learning framework using gpu and fpga - based accelerators .",
        "unsupervised learning and supervised learning are key research topics in deep learning .",
        "we present a comprehensive study of deep bidirectional long short - term memory ( lstm ) recurrent neural network ( rnn ) based acoustic models for automatic speech recognition ( asr ) .",
        "in this paper , we introduce a model that employs information retrieval by utilizing convolutional deep structured semantic neural network - based features in the ranker to present human - like responses in ongoing conversation with a user .",
        "in conversations , accounting for context is critical to the retrieval model ; we show that our context - sensitive approach using a convolutional deep structured semantic model ( cdssm ) with character trigrams significantly outperforms several conventional baselines in terms of the relevance of responses retrieved .",
        "current aqp systems either learn models using - a ) various hand - crafted features ( hcf ) or b ) use deep learning ( dl ) techniques which automatically learn the required feature representations .",
        "this latter issue is tackled by recent works dealing with deep representation learn ing of texts .",
        "with this in mind , we argue that embedding kbs within deep neural architectures supporting documentquery matching would give rise to fine - grained latent representations of both words and their semantic relations .",
        "we then propose some avenues to incorporate kbs in deep neural approaches for document ranking .",
        "to address the challenge of detecting dynamic classes of events , we propose a novel deep learning model to classify a given query into a predetermined set of multiple event types .",
        "unlike previous works that optimized mrfs using iterative algorithm , we solve mrf by proposing a convolutional neural network ( cnn ) , namely deep parsing network ( dpn ) , which enables deterministic end - to - end computation in a single forward pass .",
        "recently , a number of deep - learning based models have been proposed for the task of visual question answering ( vqa ) .",
        "we propose a novel approach based on deep neural networks for modeling the dynamics of robot ' s interactions directly from images , by jointly estimating forward and inverse models of dynamics .",
        "we propose a deep learning - based framework to automatically : ( 1 ) tag the images available in a review dataset , ( 2 ) generate a caption for each image that does not have one , and ( 3 ) enhance each review by recommending relevant images that might not be uploaded by the corresponding reviewer .",
        "recent work in information retrieval ( ir ) using deep learning models has yielded state of the art results on a variety of ir tasks .",
        "deep neural networks ( dnn ) are capable of learning ideal representations of data during the training process , removing the need for independently extracting features .",
        "in this paper we propose to use a fully deep neural network ( dnn ) framework to handle the multi - label classification task in a regression way .",
        "a deep pyramid structure was also designed to extract more robust high - level features related to the target tags .",
        "deep feedforward neural networks with many hidden layers also suffer from this effect .",
        "we propose novel object captioner ( noc ) , a deep visual semantic captioning model that can describe a large number of object categories not present in existing image - caption datasets .",
        "here we propose a power - efficient approach for real - time inference , in which deep neural networks ( dnns ) are implemented through low - power analog circuits .",
        "we propose a framework that exploits the power of deep learning to compensate for this mismatch by incorporating the measured variations of the devices as constraints in the dnn training process .",
        "in this work , we pose the task of producing multiple outputs as a learning problem over an ensemble of deep networks - - introducing a novel stochastic gradient descent based approach to minimize the loss with respect to an oracle .",
        "our approach achieves lower oracle error compared to existing methods on a wide range of tasks and deep architectures .",
        "in addition , we dive into open information extraction and deep learning , two emerging and influential techniques and envision next generation of bioie .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "in this paper , we present subgraph2vec , a novel approach for learning latent representations of rooted subgraphs from large graphs inspired by recent advancements in deep learning and graph kernels .",
        "also , we show that the subgraph vectors could be used for building a deep learning variant of weisfeiler - lehman graph kernel .",
        "one is a recent deep reinforcement learning method based on an actor - critic algorithm , deep deterministic policy gradient ( ddpg ) , that has been shown to perform well on various control benchmarks .",
        "neural machine translation ( nmt ) , like many other deep learning domains , typically suffers from over - parameterization , resulting in large storage sizes .",
        "numerical experiments on mnist and 20news demonstrate the ability of this novel deep learning system to learn local , stationary , and compositional features on graphs , as long as the graph is well - constructed .",
        "a catastrophic forgetting problem makes deep neural networks forget the previously learned information , when learning data collected in new environments , such as by different sensors or in different light conditions .",
        "finally , we show our less - forgetting learning method is also helpful to improve the performance of deep neural networks in terms of recognition rates .",
        "we propose a novel deep learning model , which supports permutation invariant training ( pit ) , for speaker independent multi - talker speech separation , commonly known as the cocktail - party problem .",
        "different from most of the prior arts that treat speech separation as a multi - class regression problem and the deep clustering technique that considers it a segmentation ( or clustering ) problem , our model optimizes for the separation regression error , ignoring the order of mixing sources .",
        "this strategy cleverly solves the long - lasting label permutation problem that has prevented progress on deep learning based techniques for speech separation .",
        "however , from gaussian mixture models hmms ( gmm - hmm ) to deep neural network hmms ( dnn - hmm ) , the underlying markovian chain of state - of - the - art models did not changed much .",
        "however , recurrent neural networks with such ' deep ' transition functions remain difficult to train , even when using long short - term memory networks .",
        "guided policy search algorithms can be used to optimize complex nonlinear policies , such as deep neural networks , without directly computing policy gradients in the high - dimensional parameter space .",
        "we propose a technique that tackles these problems by de - conflating the representations of words based on the deep knowledge it derives from a semantic network .",
        "the task contains a rich variety of challenging classification and extraction sub - tasks , making it well - suited for end - to - end models such as deep neural networks ( dnns ) .",
        "high demand for computation resources severely hinders deployment of large - scale deep neural networks ( dnn ) in resource constrained devices .",
        "the results show that for cifar - 10 , regularization on layer depth can reduce 20 layers of a deep residual network ( resnet ) to 18 layers while improve the accuracy from 91 .",
        "the sentence vectors are used as features for subsequent machine learning tasks or for pre - training in the context of deep learning .",
        "the ability of deep convolutional neural networks ( cnn ) to learn discriminative spectro - temporal patterns makes them well suited to environmental sound classification .",
        "this study has two primary contributions : first , we propose a deep convolutional neural network architecture for environmental sound classification .",
        "we show that the improved performance stems from the combination of a deep , high - capacity model and an augmented training set : this combination outperforms both the proposed cnn without augmentation and a \" shallow \" dictionary learning model with augmentation .",
        "unsupervised neural networks , such as restricted boltzmann machines ( rbms ) and deep belief networks ( dbns ) , are powerful tools for feature selection and pattern recognition tasks .",
        "we demonstrate that overfitting occurs in such models just as in deep feedforward neural networks , and discuss possible regularization methods to reduce overfitting .",
        "deep learning has become a ubiquitous technology to improve machine intelligence .",
        "however , most of the existing deep models are structurally very complex , making them difficult to be deployed on the mobile platforms with limited computational power .",
        "the different types of features are integrated in a neural network that uses a novel architecture to learn latent modes of discussion structure that perform as well as deep neural networks but are more interpretable .",
        "the optimization of deep neural networks can be more challenging than traditional convex optimization problems due to the highly non - convex nature of the loss function , e .",
        "in order to cope with a wide range of reverberations in real - world situations , we present novel approaches for acoustic modeling including an ensemble of deep neural networks ( dnns ) and an ensemble of jointly trained dnns .",
        "stacked auto - encoder ( sae ) is a kind of deep learning algorithm for unsupervised learning .",
        "these methods first convert the ascii text to a phonetic script , and then learn a deep neural network to synthesize speech from that .",
        "their inherent deep feedforward structure allows learning complex sequential patterns .",
        "this paper emphasizes the significance to jointly exploit the problem structure and the parameter structure , in the context of deep modeling .",
        "as a specific and interesting example , we describe the deep double sparsity encoder ( ddse ) , which is inspired by the double sparsity model for dictionary learning .",
        "deep learning has been popularized by its recent successes on challenging artificial intelligence problems .",
        "we believe the first step is to examine the characteristics of cutting edge models from across the deep learning community .",
        "our approach is based on deep contextual sequence learning and utilizes stacked bidirectional lstm networks .",
        "recent work has shown that convolutional networks can be substantially deeper , more accurate and efficient to train if they contain shorter connections between layers close to the input and those close to the output .",
        "deep learning has been shown as a successful machine learning method for a variety of tasks , and its popularity results in numerous open - source deep learning software tools coming to public .",
        "training a deep network is usually a very time - consuming process .",
        "to address the huge computational challenge in deep learning , many tools exploit hardware features such as multi - core cpus and many - core gpus to shorten the training time .",
        "however , different tools exhibit different features and running performance when training different types of deep networks on different hardware platforms , which makes it difficult for end users to select an appropriate pair of software and hardware .",
        "in this paper , we aim to make a comparative study of the state - of - the - art gpu - accelerated deep learning software tools , including caffe , cntk , tensorflow , and torch .",
        "first , for deep learning end users , our benchmarking results can serve as a guide to selecting appropriate software tool and hardware platform .",
        "second , for deep learning software developers , our in - depth analysis points out possible future directions to further optimize the",
        "we compare two learning approaches on the ms - coco dataset : a state - of - the - art recurrent network based on an lstm ( show , attend and tell ) , and a simple structured prediction model on top of a deep network .",
        "deep learning techniques have been paramount in the last years , mainly due to their outstanding results in a number of applications , that range from speech recognition to face - based user identification .",
        "despite other techniques employed for such purposes , deep boltzmann machines are among the most used ones , which are composed of layers of restricted boltzmann machines ( rbms ) stacked on top of each other .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "we perform experiments and show that the derived bounds provide very accurate estimates when applied to various state - of - the - art deep neural networks and datasets .",
        "deep neural networks have shown striking progress and obtained state - of - the - art results in many ai research fields in the recent years .",
        "the computation and storage requirements for deep neural networks ( dnns ) are usually high .",
        "in this paper , we propose ternary neural networks ( tnns ) in order to make deep learning more resource - efficient .",
        "when we use our predictive model to analyze millions of other reddit posts , we find evidence that suggests dogmatism is a deeper personality trait , present for dogmatic users across many different domains , and that users who engage on dogmatic comments tend to show increases in dogmatic posts themselves .",
        "compared with deep models pre - trained on word embedding ( we ) strategy , our character - sequential representation ( csr ) based method shows a much simpler procedure and more stable performance across different benchmarks .",
        "the method was evaluated on several deep learning tasks , demonstrating promising results .",
        "for learning deeper networks , we train ccnns in a layer - wise manner .",
        "our approach effectively captures the multimodal semantics of queries and videos using state - of - the - art deep neural networks and creates a summary that is both semantically coherent and visually attractive .",
        "this formulation combines the expressive power of deep neural networks and the cyclic dependency structure of mrf in a unified model , bringing the modeling capability to a new level .",
        "though deep learning has pushed the boundaries of classification forward , in recent years hints of the limits of standard classification have begun to emerge .",
        "our approach is based on a deep neural network architecture that ingests curated article information such as tags and images , and is trained to predict sales for a large set of frequent customers .",
        "this paper describes our deep learning - based approach to sentiment analysis in twitter as part of semeval - 2016 task 4 .",
        "this paper describes our deep learning - based approach to multilingual aspect - based sentiment analysis as part of semeval 2016 task 5 .",
        "our constrained system ( unconstrained for english ) achieves competitive results across all languages and domains , placing first or second in 5 and 7 out of 11 language - domain pairs for aspect category detection ( slot 1 ) and sentiment polarity ( slot 3 ) respectively , thereby demonstrating the viability of a deep learning - based approach for multilingual aspect - based sentiment analysis .",
        "we describe a novel approach to stride length estimation that uses deep convolutional neural networks to map stride - specific inertial sensor data to the resulting stride length .",
        "to overcome this , we present a method to translate the abstract information provided by wearable sensors to context - related expert features based on deep convolutional neural networks .",
        "by reference to a node threshold three features are described 1 ) a mechanism for primary reinforcement , capable of solving linearly inseparable problems 2 ) the learning scheme is extended to include a mechanism for conditioned reinforcement , capable of forming long term strategy 3 ) the learning scheme is modified to use a threshold - based deep learning algorithm , providing a robust and biologically inspired alternative to backpropagation .",
        "we present a dependency parser implemented as a single deep neural network that reads orthographic representations of words and directly generates dependencies and their labels .",
        "this paper introduces wavenet , a deep neural network for generating raw audio waveforms .",
        "since deep neural networks are powerful models that have achieved excellent performance over many difficult tasks , in this paper , we propose to use the long short - term memory ( lstm ) encoder - decoder model for sentence level ts , which makes minimal assumptions about word sequence .",
        "recent trends to solve this problem have seen a shift to end - to - end solutions using deep reinforcement learning to learn policies from visual input , rather than relying on a handcrafted , modular pipeline .",
        "building upon the recent success of deep q - networks , we present an approach which uses three - dimensional simulations to train a 7 - dof robotic arm in a robot arm control task without any prior knowledge .",
        "our results demonstrate that deep q - networks can be used to learn policies for a task that involves locating a cube , grasping , and then finally lifting .",
        "we also highlight the superiority of classification approaches over regression approaches , quantify the benefits of deeper architectures and extended training data , and demonstrate that synthetic data is beneficial even when using imagenet training data .",
        "while it holds a great promise to produce a better accuracy than non - collective classifiers , collective classification is computational challenging and has not leveraged on the recent breakthroughs of deep learning .",
        "we present column network ( cln ) , a novel deep learning model for collective classification in multi - relational domains .",
        "cln has many desirable theoretical properties : ( i ) it encodes multi - relations between any two instances ; ( ii ) it is deep and compact , allowing complex functions to be approximated at the network level with a small set of free parameters ; ( iii ) local and relational features are learned simultaneously ; ( iv ) long - range , higher - order dependencies between instances are supported naturally ; and ( v ) crucially , learning and inference are efficient , linear in the size of the network and the number of relations .",
        "many success stories involving deep neural networks are instances of supervised learning , where available labels power gradient - based learning methods .",
        "building on recent advances in image caption generation and optical character recognition ( ocr ) , we present a general - purpose , deep learning - based system to decompile an image into presentational markup .",
        "in this paper , we propose to use deep - q - learning techniques instead to determine the machine actions for interactive spoken content retrieval .",
        "deep - q - learning bypasses the need for estimation of the hand - crafted states , and directly determine the best action base on the present retrieval status even without any human knowledge .",
        "we are interested in exploring the possibility and benefits of structure learning for deep models .",
        "deep reinforcement learning ( drl ) brings the power of deep neural networks to bear on the generic task of trial - and - error learning , and its effectiveness has been convincingly demonstrated on tasks such as atari video games and the game of go .",
        "however , contemporary drl systems inherit a number of shortcomings from the current generation of deep learning techniques .",
        "advances in deep reinforcement learning have allowed autonomous agents to perform well on atari games , often outperforming humans , using only raw pixels to make their decisions .",
        "typically , deep reinforcement learning methods only utilize visual input for training .",
        "inspired by the recent success of deep reinforcement learning , we present neural - based models that jointly learn a policy and the behavior of opponents .",
        "instead of explicitly predicting the opponent ' s action , we encode observation of the opponents into a deep q - network ( dqn ) ; however , we retain explicit modeling ( if desired ) using multitasking .",
        "we instead propose to build graphs over the scene objects and over the question words , and we describe a deep neural network that exploits the structure in these representations .",
        "to this end , we study the application of deep conditional generative models in generating realistic galaxy images .",
        "deep neural networks have achieved remarkable results across many language processing tasks , however these methods are highly sensitive to noise and adversarial attacks .",
        "this paper presents an overview of political event data , including methods and ontologies , and a set of experiments to determine the applicability of deep neural networks to the extraction of political events from news text .",
        "deep neural networks are learning models with a very high capacity and therefore prone to over - fitting .",
        "we propose a novel semantic tagging task , semtagging , tailored for the purpose of multilingual semantic parsing , and present the first tagger using deep residual networks ( resnets ) .",
        "these are scalar - valued ( potentially deep ) neural networks with constraints on the network parameters such that the output of the network is a convex function of ( some of ) the inputs .",
        "in this paper , we propose two deep architectures which can be trained jointly on multiple related tasks .",
        "in this work we explore deep generative models of text in which the latent representation of a document is itself drawn from a discrete language model distribution .",
        "implementing an accurate and fast activation function with low cost is a crucial aspect to the implementation of deep neural networks ( dnns ) on fpgas .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "our model consists of a deep lstm network with 8 encoder and 8 decoder layers using attention and residual connections .",
        "this paper proposes new nonnegative ( shallow and multi - layer ) autoencoders by combining the model of spiking random neural network ( rnn ) , the network architecture in the deep - learning area and the training technique in the nonnegative matrix factorization ( nmf ) area .",
        "with the fast development of deep learning , people have started to train very big neural networks using massive data .",
        "these difficulties are tackled in this work , presenting a deep autoencoder that maps the audio spectrogram of bird vocalizations to its corresponding binary mask that encircles the spectral blobs of vocalizations while suppressing other audio sources .",
        "based on the database and another two free data resources ( thchs30 and the cmu dictionary ) , a speech recognition ( asr ) baseline was constructed with the deep neural network - hidden markov model ( dnn - hmm ) hybrid system .",
        "experimental results show that the proposed method delivers substantial performance improvement over the baseline system , especially when a deep neural network ( dnn ) is used as the decision maker , and the dnn input involves some statistical features derived from the cohort scores .",
        "the system uses only byte representations in a deep residual network ( resnet ) .",
        "the focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks , where hypernetworks can be viewed as relaxed form of weight - sharing across layers .",
        "specifically , we focused on papers and works developed by the teamcore of university of southern california , which deepened different directions in this field .",
        "inspired by the recently presented deeptracking approach [ ondruska , 2016 ] , we employ a recurrent neural network ( rnn ) to capture the temporal evolution of the state of the environment , and propose to use spatial transformer modules to exploit estimates of the egomotion of the vehicle .",
        "training a deep neural network for segmentation typically requires a large amount of training data .",
        "the system drastically improves learning in a range of deep neural networks on various data - sets in comparison to non - cpn neural networks .",
        "we introduce a unified algorithm to efficiently learn a broad class of linear and non - linear state space models , including variants where the emission and transition distributions are modeled by deep neural networks .",
        "in this paper , we propose a deep - learning - based approach , called st - resnet , to collectively forecast the in - flow and out - flow of crowds in each and every region through a city .",
        "it provides new and fruitful perspectives on a number of machine learning areas , including cluster analysis , topic detection , and deep probabilistic modeling .",
        "in this work , we propose very deep convolutional neural networks ( cnns ) that directly use time - domain waveforms as inputs .",
        "we demonstrate the performance gains with the deeper models .",
        "by applying deep recurrent neural networks we learn to discriminate between several application layer traffic types on top of a constant envelope modulation without using an expert demodulation algorithm .",
        "in this paper , we develop a chinese event extraction system that uses word embedding vectors to represent language , and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering .",
        "in this paper , we propose to use deep neural network ( dnn ) to address two types of information needs of response organizations : 1 ) identifying informative tweets and 2 ) classifying them into topical classes .",
        "we hope that after reading this tutorial , the reader will be able to use deep learning frameworks , such as keras and introduced kraino , to build various architectures that will lead to a further performance improvement on this challenging task .",
        "we establish rigorous error bounds showing that deep relu networks are significantly more expressive than shallow ones as long as approximations of smooth functions are concerned .",
        "deep learning is a branch of artificial intelligence employing deep neural network architectures that has significantly advanced the state - of - the - art in computer vision , speech recognition , natural language processing and other domains .",
        "in november 2015 , google released $ \\ textit { tensorflow } $ , an open source deep learning software library for defining , training and deploying machine learning models .",
        "in this paper , we review tensorflow and put it in context of modern deep learning concepts and software .",
        "and then we investigate the advancement of multi - view representation learning that ranges from shallow methods including multi - modal topic learning , multi - view sparse coding , and multi - view latent space markov networks , to deep methods including multi - modal restricted boltzmann machines , multi - modal autoencoders , and multi - modal recurrent neural networks .",
        "sample complexity and safety are major challenges when learning policies with reinforcement learning for real - world tasks - - especially when the policies are represented using rich function approximators like deep neural networks .",
        "as another improvement , it uses deep neural networks for joint - speaker identification and gain estimation which makes these two steps easier than before producing competitive results for these steps .",
        "a state - of - the - art technology , deep learning , even fails to perform well in these scenarios .",
        "visual question answering ( vqa ) is a recent problem in computer vision and natural language processing that has garnered a large amount of interest from the deep learning , computer vision , and natural language processing communities .",
        "based on new deep learning technologies we developed , the virtual agent is capable of learning how to interact with users , how to answer user questions , what is the next question to ask , and what to recommend when chatting with a human user .",
        "we propose a deep reinforcement learning method for the exploration of mobile robots in an indoor environment with the depth information from an rgb - d sensor only .",
        "based on the deep q - network framework , the raw depth image is taken as the only input to estimate the q values corresponding to all moving commands .",
        "besides , through analysis of receptive fields of feature representations , deep reinforcement learning motivates the convolutional networks to estimate the traversability of the scenes .",
        "the test results are compared with the exploration strategies separately based on deep learning or reinforcement learning .",
        "the main idea is to combine the generative capability of deep belief network ( dbn ) with a discriminative ability and sequence pattern recognizing capability of long short - term memory ( lstm ) .",
        "the word denoising embeddings are obtained by strengthening salient information and weakening noise in the original word embeddings , based on a deep feed - forward neural network filter .",
        "the second technique involves two deep network classifiers , i .",
        ", dbn ( deep belief networks ) , and sae ( stacked denoising",
        "however , implementation strategy of metaheuristic for accuracy improvement on convolution neural networks ( cnn ) , a famous deep learning method , is still rarely investigated .",
        "deep learning relates to a type of machine learning technique , where its aim is to move closer to the goal of artificial intelligence of creating a machine that could successfully perform any intellectual tasks that can be carried out by a human .",
        "deep neural networks have proven to be quite effective in a wide variety of machine learning tasks , ranging from improved speech recognition systems to advancing the development of autonomous vehicles .",
        "addressing this weakness is of utmost importance if deep neural architectures are to be applied to critical applications , such as those in the domain of cybersecurity .",
        "more importantly , we present a unifying framework for protecting deep neural models using a non - invertible data transformation - - developing two adversary - resilient architectures utilizing both linear and nonlinear dimensionality reduction .",
        "the compared feature extractors are deep belief networks ( dbn ) and fuzzy c - means ( fcm ) clustering .",
        "parallel implementations of stochastic gradient descent ( sgd ) have received significant research attention , thanks to excellent scalability properties of this algorithm , and to its efficiency in the context of training deep neural networks .",
        "in this paper , we present a simple and efficient method for training deep neural networks in a semi - supervised setting where only a small portion of training data is labeled .",
        "the first is the success of deep learning , which often requires frequent transfers of big data for training .",
        "this thesis report studies methods to solve visual question - answering ( vqa ) tasks with a deep learning framework .",
        "we propose deep optimistic linear support learning ( dol ) to solve high - dimensional multi - objective decision problems where the relative importances of the objectives are not known a priori .",
        "to our knowledge , this is the first time that deep reinforcement learning has succeeded in learning multi - objective policies .",
        "in addition , we provide a testbed with two experiments to be used as a benchmark for deep multi - objective reinforcement learning .",
        "in our work , we successively train very deep convolutional networks to add more expressive power and better generalization for end - to - end asr models .",
        "we apply network - in - network principles , batch normalization , residual connections and convolutional lstms to build very deep recurrent and convolutional structures .",
        "5 \\ % word error rate without any dictionary or language using a 15 layer deep network .",
        "to the best of our knowledge , this work is the first to explore deep learning models for paraphrase generation .",
        "this allows for efficient training of deep lstms .",
        "we evaluate our model and other state - of - the - art deep learning models on three different datasets : ppdb , wikianswers and mscoco .",
        "on the other hand , the convolutional neural networks ( cnns ) have brought significant improvements to deep feed - forward neural networks ( ffnns ) , as they are able to better reduce spectral variation in the input signal .",
        "based on this novel skip connections , we successfully train deep stacked bidirectional lstm models and obtain state - of - the - art results on ccg supertagging and comparable results on pos tagging .",
        "recently , attempts have been made to remove gaussian mixture models ( gmm ) from the training process of deep neural network - based hidden markov models ( hmm / dnn ) .",
        "we present deep variational canonical correlation analysis ( vcca ) , a deep multi - view learning model that extends the latent variable model interpretation of linear cca ~ \\ citep { bachjordan05a } to nonlinear observation models parameterized by deep neural networks ( dnns ) .",
        "during execution , at each time step our approach computes what the simulation - based control policy would do , but then , rather than executing these controls on the real robot , our approach computes what the simulation expects the resulting next state ( s ) will be , and then relies on a learned deep inverse dynamics model to decide which real - world action is most suitable to achieve those next states .",
        "deep models are only as good as their training data , and we also propose an approach for data collection to ( incrementally )",
        "question generation has been a research topic for a long time , where a big challenge is how to generate deep and natural questions .",
        "this paper presents a deep learning architecture for the semantic decoder component of a statistical spoken dialogue system .",
        "recently there has been much interest in understanding why deep neural networks are preferred to shallow networks .",
        "in this paper , we show that , for a large class of piecewise smooth functions , the number of neurons needed by a shallow network to approximate a function is exponentially larger than the corresponding number of neurons needed by a deep network for a given degree of function approximation .",
        ", networks whose depth does not depend on $ \\ varepsilon $ ) require $ \\ omega ( \\ text { poly } ( 1 / \\ varepsilon ) ) $ neurons while deep networks ( i .",
        "deep reinforcement learning algorithms are too slow to achieve performance on a real robot , but their potential has been demonstrated in simulated environments .",
        "moreover , rather than relying on model - based trajectory optimisation , the task learning is accomplished using only deep reinforcement learning and sparse rewards .",
        "to recover the ` clustering - friendly ' latent representations and to better cluster the data , we propose a joint dr and k - means clustering approach in which dr is accomplished via learning a deep neural network ( dnn ) .",
        "the motivation is to keep the advantages of jointly optimizing the two tasks , while exploiting the deep neural network ' s ability to approximate any nonlinear function .",
        "the proposed methods are evaluated on the application of training a deep neural network to perform image classification .",
        "recently , er has contributed to improving the performance of deep reinforcement learning .",
        "for several plays of disputed co - authorship , a deeper analysis is performed by attributing every act and scene separately , in which we both corroborate existing breakdowns and provide evidence of new assignments .",
        "conventional deep neural networks ( dnn ) for speech acoustic modeling rely on gaussian mixture models ( gmm ) and hidden markov model ( hmm ) to obtain binary class labels as the targets for dnn training .",
        "however , compared to the conventional gaussian mixture models , deep neural network ( dnn ) based acoustic models usually have much larger number of model parameters , making it challenging for their applications in resource constrained platforms such as mobile devices .",
        "in this paper , we study the application of the recently proposed highway deep neural network ( hdnn ) for training small - footprint acoustic models .",
        "we solve these two problems with the recent advances in deep learning : 1 ) rnn - based autoencoders ( rnn - aes ) can automatically learn low - dimensional representation of a malware from its raw api call sequence .",
        "i ) structured matrices under consideration can either be fully - randomized or learned , ii ) our structured family contains as special cases all previously considered structured schemes , iii ) the setting extends to the non - linear case where the projections are followed by non - linear functions , and iv ) the method finds numerous applications including kernel approximations via random feature maps , dimensionality reduction algorithms , new fast cross - polytope lsh techniques , deep learning , convex optimization algorithms via newton sketches , quantization with random projection trees , and more .",
        "to this end , our method sequentially constructs an ensemble of deep belief nets ( dbns ) with varying depths .",
        "we validate our models with experiments on deep learning training and belief propagation .",
        "there exist many approaches to vqa , the majority of which do not exhibit deeper semantic understanding of the candidate answers they produce .",
        "experiments on synthetic data and deep neural networks validate our theory , demonstrating the effectiveness and scalability of sg - mcmc with stale gradients .",
        "in this paper we describe a deep network architecture that maps visual input to control actions for a robotic planar reaching task with 100 % reliability in real - world trials .",
        "we quantify a source of ineffectual computations when processing the multiplications of the convolutional layers in deep neural networks ( dnns ) and propose pragmatic ( pra ) , an architecture that exploits it improving performance and energy efficiency .",
        "these models have broad applications in image registration , and they are a fundamental aspect of novel machine vision or deep learning algorithms , such as convolutional neural networks ( cnn ) , which perform shift and scale invariant functions followed by classification .",
        "deconvolutional networks fully exploit the advantage the powerful expressiveness of deep neural networks in the manner of unsupervised learning .",
        "in this work we investigate the construction of a single , scalable deep network that can parsimoniously capture the artistic style of a diversity of paintings .",
        "in this paper , we focus on discussing the indispensable role of knowledge for deeper understanding of complex text and multimodal data in situations where ( i ) large amounts of training data ( labeled / unlabeled ) are not available or labor intensive to create , ( ii ) the objects ( particularly text ) to be recognized are complex ( i .",
        "we investigate how well generic deep - learning approaches adapt to these tasks , and how they perform in comparison with established and more specialized methods , including our own adaptation of pruned crfs .",
        "we explore the suitability of a deep neural network architecture for this task , particularly a deep bi - lstm network applied on a character level .",
        "several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years .",
        "sarcasm , however , can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp .",
        "existing deep embedding methods in vision tasks are capable of learning a compact euclidean space from images , where euclidean distances correspond to a similarity metric .",
        "in this paper , we introduce a position - dependent deep metric ( pddm ) unit , which is capable of learning a similarity metric adaptive to local feature structure .",
        "the metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner .",
        "while the method can in principle be applied to deep networks , we restrict ourselves for simplicity in this paper to one and two hidden layer networks .",
        "this paper presents a generalized haar filter based deep network which is suitable for the object detection tasks in traffic scene .",
        "then , we handle the local regression tasks by using several tiny deep networks which simultaneously output the bounding boxes , categories and confidence scores of detected objects .",
        "to reduce the consumption of storage and computing resources , the weights of the deep networks are constrained to the form of generalized haar filter in training phase .",
        "we propose feature map and kernel level pruning for reducing the computational complexity of a deep convolutional neural network .",
        "the remarkable successes of deep learning models across various applications have resulted in the design of deeper networks that can solve complex problems .",
        "however , the increasing depth of such models also results in a higher storage and runtime complexity , which restricts the deployability of such very deep models on mobile and portable devices , which have limited storage and battery capacity .",
        "while many methods have been proposed for deep model compression in recent years , almost all of them have focused on reducing storage complexity .",
        "in this work , we extend the teacher - student framework for deep model compression , since it has the potential to address runtime and train time complexity too .",
        "building large models with parameter sharing accounts for most of the success of deep convolutional neural networks ( cnns ) .",
        "practically , a dcnn can be easily implemented by a two - step convolution procedure , which is supported by most modern deep learning libraries .",
        "this paper investigates the use of deep reinforcement learning for runtime parameters of cloud databases under latency constraints .",
        "in this work , we use continuous deep reinforcement learning to learn optimal cache expirations for http caching in content delivery networks .",
        "we model the output vocabulary of about 100 , 000 words directly using deep bi - directional lstm rnns with ctc loss .",
        "in this way , even a simple linear readout from the ts representation can implement a highly expressive deep - network - like function .",
        "we develop several methods to train the ts network , including equivalent kernels for infinitely wide and deep ts networks , a one - pass linear learning algorithm , and two backpropagation - inspired representation learning algorithms .",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "we apply the proposedmethod for object recognition with temporal context in videos and obtain better results than comparable methods in the literature , including the deep predictive coding networks previously proposed by chalasani and principe .",
        "our contributions can be summarized as a scalable reinterpretation of the deep predictive coding networks trained end - to - end with backpropagation through time , an extension of the previously proposed winner - take - all autoencoders to sequences in time , and a new technique for initializing and regularizing convolutional - recurrent neural networks .",
        "in practice , the current deep embedding methods use the euclidean distance for the training and test .",
        "deep models like deep neural networks , on the other hand , cannot be directly applied for the high - dimensional input because of the huge feature space .",
        "despite outstanding success in vision amongst other domains , many of the recent deep learning approaches have evident drawbacks for robots .",
        "this manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain , either as means of estimation or as a tool to resolve motor commands directly from raw percepts .",
        "we suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence .",
        "deep kernel learning combines the non - parametric flexibility of kernel methods with the inductive biases of deep learning architectures .",
        "we propose a novel deep kernel learning model and stochastic variational inference procedure which generalizes deep kernel learning approaches to enable classification , multi - task learning , additive covariance structures , and stochastic gradient training .",
        "specifically , we apply additive base kernels to subsets of output features from deep neural architectures , and jointly learn the parameters of the base kernels and deep network through a gaussian process marginal likelihood objective .",
        "we show improved performance over stand alone deep networks , svms , and state of the art scalable gaussian processes on several classification benchmarks , including an airline delay dataset containing 6 million training points , cifar , and imagenet .",
        "we introduce a multiple input deep regression model to predict the cf latent embedding vectors of items based on their textual description and metadata .",
        "the model generalizes recent advances in recurrent deep learning from i .",
        "we present torchcraft , an open - source library that enables deep learning research on real - time strategy ( rts ) games such as starcraft : brood war , by making it easier to control these games from a machine learning framework , here torch .",
        "despite their advantages in terms of computational resources , latency , and power consumption , event - based implementations of neural networks have not been able to achieve the same performance figures as their equivalent state - of - the - art deep network models .",
        "we show how inference carried out in deep counter networks converges to the same accuracy levels as are achieved with state - of - the - art conventional networks .",
        "the paper reviews an emerging body of theoretical results on deep learning including the conditions under which it can be exponentially better than shallow learning .",
        "deep convolutional networks represent an important special case of these conditions , though weight sharing is not the main reason for their exponential advantage .",
        "recent research in the deep learning field has produced a plethora of new architectures .",
        "at the same time , a growing number of groups are applying deep learning to new applications and problems .",
        "many of these groups might be composed of inexperienced deep learning practitioners who are baffled by the dizzying array of architecture choices and therefore use an older architecture , such as alexnet .",
        "here , we are attempting to bridge this gap by mining the collective knowledge contained in recent deep learning research to discover underlying principles for designing neural network architectures .",
        "many models such as svm , random forest , and deep neural nets have been proposed and achieved great success .",
        "the use of deep reinforcement learning allows for high - dimensional state descriptors , but little is known about how the choice of action representation impacts the learning difficulty and the resulting performance .",
        "we apply modern deep reinforcement learning methods to build a truly adaptive traffic signal control agent in the traffic microsimulator sumo .",
        "the discrete traffic state encoding is used as input to a deep convolutional neural network , trained using q - learning with experience replay .",
        "this paper presents an actor - critic deep reinforcement learning agent with experience replay that is stable , sample efficient , and performs remarkably well on challenging environments , including the discrete 57 - game atari domain and several continuous control problems .",
        "latent representation learned from multi - layered neural networks via hierarchical feature abstraction enables recent success of deep learning .",
        "under the deep learning framework , generalization performance highly depends on the learned latent representation which is obtained from an appropriate training scenario with a task - specific objective on a designed network model .",
        "recently deep neural networks have received considerable attention due to their ability to extract and represent high - level abstractions in data sets .",
        "deep neural networks such as fully - connected and convolutional neural networks have shown excellent performance on a wide range of recognition and classification tasks .",
        "in fact , they contain most of the deep neural network parameters .",
        "deep networks are successfully used as classification models yielding state - of - the - art results when trained on a large number of labeled samples .",
        "this criterion is based on a deep metric embedding over distance relations within the set of labeled samples , together with constraints over the embeddings of the unlabeled set .",
        "in recent years , model - free methods that use deep learning have achieved great success in many different reinforcement learning environments .",
        "in this paper , we present a model based approach to deep reinforcement learning which we use to solve different tasks simultaneously .",
        "we specifically apply this idea to modify adam , a popular algorithm for training deep neural networks .",
        "we conduct experiments to compare the resulting algorithm , which we call eve , with state of the art methods used for training deep learning models .",
        "more recent deep lipreading approaches are end - to - end trainable ( wand et al .",
        "to the best of our knowledge , lipnet is the first lipreading model to operate at sentence - level , using a single end - to - end speaker - independent deep model to simultaneously learn spatiotemporal visual features and a sequence model .",
        "deep neural network models , though very powerful and highly successful , are computationally expensive in terms of space and time .",
        "experiments on both feedforward and recurrent networks show that the proposed loss - aware binarization algorithm outperforms existing binarization schemes , and is also more robust for wide and deep networks .",
        "several deep learning models have been proposed for question answering .",
        "we explain why this is an alternative approach to deep q - learning , for using deep learning in robotics .",
        "lastly , we argue that this is a big step for deep learning in robotics , as it opens up new possibilities to optimize robots , both in hardware and software .",
        "while deep learning parsing approaches have proven very successful at finding the structure of sentences , most neural dependency parsers use neural networks only for feature extraction , and then use those features in traditional parsing algorithms .",
        "in this paper we present a domain adaptation technique for formant estimation using a deep network .",
        "we first train a deep learning network on a small read speech dataset .",
        "we describe a framework for multitask deep reinforcement learning guided by policy sketches .",
        "in this paper , we study deep generative models for effective unsupervised learning .",
        "recently deeplearning models have been shown to be capable of making remarkable performance in sentences and documents classification tasks .",
        "regularization is key for deep learning since it allows training more complex models while keeping lower levels of overfitting .",
        "in recent years , deep neural networks ( dnns ) based methods have achieved remarkable performance in a wide range of tasks and have been among the most powerful and widely used techniques in computer vision , speech recognition and natural language processing .",
        "we develop a first line of attack for solving programming competition - style problems from input - output examples using deep learning .",
        "model - free deep reinforcement learning ( rl ) methods have been successful in a wide variety of simulated domains .",
        "however , a major obstacle facing deep rl in the real world is the high sample complexity of such methods .",
        "we also achieve almost the same accuracy as a very deep lstm setup on wmt ' 14 english - french translation .",
        "nevertheless , methods from convex optimization such as gradient descent and adam are widely used as building blocks for deep learning algorithms .",
        "nowadays deep learning is dominating the field of machine learning with state - of - the - art performance in various application areas .",
        "recently , spiking neural networks ( snns ) have been attracting a great deal of attention , notably owning to their power efficiency , which can potentially allow us to implement a low - power deep learning engine suitable for real - time / mobile applications .",
        "however , implementing snn - based deep learning remains challenging , especially gradient - based training of snns by error backpropagation .",
        "consequently , most of the previous studies employ a workaround technique , which first trains a conventional weighted - sum deep neural network and then maps the learning weights to the snn under training , instead of training snn parameters directly .",
        "in order to eliminate this workaround , recently proposed is a new class of snn named deep spiking networks ( dsns ) , which can be trained directly ( without a mapping from conventional deep networks ) by error backpropagation with stochastic gradient descent .",
        "embedding and visualizing large - scale high - dimensional data in a two - dimensional space is an important problem since such visualization can reveal deep insights out of complex data .",
        "unfortunately , in nonlinear deep networks , not only individual neurons but also the whole network can saturate , and as a result an important input feature can have a tiny gradient .",
        "we used the latest deep neural network algorithms which provide a leap in performance over the traditional gmm approach , and apply data augmentation methods to improve robustness to noise and speaker variation .",
        "an intriguing property of deep neural networks is the existence of adversarial examples , which can transfer among different architectures .",
        "these transferable adversarial examples may severely hinder deep neural network - based applications .",
        "we propose efficient ways to solve this by augmenting deep q - learning with a cross - entropy reward and deriving novel off - policy methods for rnns from stochastic optimal control ( soc ) .",
        "recent work has demonstrated the effectiveness of employing explicit external memory structures in conjunction with deep neural models for algorithmic learning ( graves et al .",
        "in this work , we propose a training algorithm for an audio - visual automatic speech recognition ( av - asr ) system using deep recurrent neural network ( rnn ) .",
        "first , we train a deep rnn acoustic model with a connectionist temporal classification ( ctc ) objective function .",
        "the frame labels obtained from the acoustic model are then used to perform a non - linear dimensionality reduction of the visual features using a deep bottleneck network .",
        "deep learning research over the past years has shown that by increasing the scope or difficulty of the learning problem over time , increasingly complex learning problems can be addressed .",
        "deep neural networks ( dnns ) have come to outperform humans in visual classifications tasks .",
        "as an alternative we propose to use situated interactions between agents as a driving force for communication , and the framework of deep recurrent q - networks ( drqn ) for learning a common language grounded in the provided environment .",
        "despite their massive size , successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance .",
        "sum - product networks are a class of deep models where , surprisingly , inference remains tractable even when an arbitrary number of hidden layers are present .",
        "842 accuracy on english online debate forum data , which also significantly outperforms results from previous work as well as other deep learning models , showing that utcnn performs well regardless of language or platform .",
        "we present a method for performing hierarchical object detection in images guided by a deep reinforcement learning agent .",
        "our hypothesis is that the performance of using polyphonic sound sequence as features and both lstm and gru as the gating mechanisms for the neural network outperform the traditional mfcc features using a unidirectional deep neural network .",
        "we propose ( cad ) $ ^ 2 $ rl , a flight controller for collision avoidance via deep reinforcement learning that can be used to perform collision - free flight in the real world although it is trained entirely in a 3d cad model simulator .",
        "to obtain accurate predictions , we develop a deep reinforcement learning algorithm for learning indoor navigation , which uses the actual performance of the current policy to construct accurate supervision .",
        "the collision prediction model is represented by a deep convolutional neural network that directly processes raw image inputs .",
        "our collision avoidance system is entirely trained in simulation and thus addresses the high sample complexity of deep reinforcement learning and avoids the dangers of trial - and - error learning in the real world .",
        "we illustrate the distributed nature of the learned representations via output entropy computations for synthetic data , and demonstrate superior performance , compared to standard alternatives such as autoencoders , in training a deep convolutional net on standard image datasets .",
        "to take advantage of traditional methods in ner such as crf , we combine transition probability with deep learning in our model .",
        "a shared component of many powerful generative models is a decoder network , a parametric deep neural net that defines a generative distribution .",
        "we use deep bidirectional lstm embedding models and multi - view contrastive losses .",
        "we present earliness - aware deep convolutional networks ( ea - convnets ) , an end - to - end deep learning framework , for early classification of time series data .",
        "unlike most existing methods for early classification of time series data , that are designed to solve this problem under the assumption of the availability of a good set of pre - defined ( often hand - crafted ) features , our framework can jointly perform feature learning ( by learning a deep hierarchy of \\ emph { shapelets } capturing the salient characteristics in each time series ) , along with a dynamic truncation model to help our deep feature learning architecture focus on the early parts of each time series .",
        "to the best of our knowledge , the proposed framework is the first to perform data - driven ( deep ) feature learning in the context of early classification of time series data .",
        "training time on large datasets for deep neural networks is the principal workflow bottleneck in a number of important applications of deep learning , such as object classification and detection in automatic driver assistance systems ( adas ) .",
        "to minimize training time , the training of a deep neural network must be scaled beyond a single machine to as many machines as possible by distributing the optimization method used for training .",
        "recent deep rl exploration strategies are able to deal with high - dimensional continuous state spaces through complex heuristics , often relying on optimism in the face of uncertainty or intrinsic motivation .",
        "in this work , we describe a surprising finding : a simple generalization of the classic count - based approach can reach near state - of - the - art performance on various high - dimensional and / or continuous deep rl benchmarks .",
        "we further extend the model to deep structures and show that deep models can be used for unsupervised pre - training of rectifier neural networks .",
        "we then consider two interpolation methods for generalizing to a wider range of initial conditions : deep learning , and nearest neighbors .",
        "lstms have become a basic building block for many deep nlp models .",
        "in recent years , many improvements and variations have been proposed for deep sequence models in general , and lstms in particular .",
        "we observe compounding improvements on traditional lstms using monte carlo test - time model averaging , deep vector averaging ( dva ) , and residual connections , along with four other suggested modifications .",
        "various deep neural architectures underperform human baselines on these tasks , suggesting that comics contains fundamental challenges for both vision and language .",
        "we describe a method to train spiking deep networks that can be run using leaky integrate - and - fire ( lif ) neurons , achieving state - of - the - art results for spiking lif networks on five datasets , including the large imagenet ilsvrc - 2012 benchmark .",
        "our method for transforming deep artificial neural networks into spiking networks is scalable and works with a wide range of neural nonlinearities .",
        "in the context of deep neural networks , this idea is often realized by hand - designed network architectures with layers that are shared across tasks and branches that encode task - specific features .",
        "however , the space of possible multi - task deep architectures is combinatorially large and often the final architecture is arrived at by manual exploration of this space subject to designer ' s bias , which can be both error - prone and tedious .",
        "in this work , we propose a principled approach for designing compact multi - task deep learning architectures .",
        "deep reinforcement learning agents have achieved state - of - the - art results by directly maximising cumulative reward .",
        "in this paper we introduce a novel approach which employs deep learning to tackle this problem in any cf based recommendation engine .",
        "we then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow .",
        "the current trend in object detection and localization is to learn predictions with high capacity deep neural networks trained on a very large amount of annotated data and using a high amount of processing power .",
        "we also demonstrate the performance of the relative test of similarity over a broad selection of model comparisons problems in deep generative models .",
        "our analysis provides a deeper understanding of potential trade - offs of using different learning algorithms and between the effort required for featuring ( creating new features ) and labeling ( providing labels for objects ) .",
        "recently , the rapid development of deep learning and representation learning has brought new inspiration to various domains .",
        "researchers have recently started investigating deep neural networks for dialogue applications .",
        "nowadays , the number of layers and of neurons in each layer of a deep network are typically set manually .",
        "while very deep and wide networks have proven effective in general , they come at a high memory and computation cost , thus making them impractical for constrained platforms .",
        "in this paper , we introduce an approach to automatically determining the number of neurons in each layer of a deep network during learning .",
        "the complexity of deep neural network algorithms for hardware implementation can be lowered either by scaling the number of units or reducing the word - length of weights .",
        "for this study , the performances of fully - connected deep neural networks ( fcdnns ) and convolutional neural networks ( cnns ) are evaluated while changing the network complexity and the word - length of weights .",
        "deep neural network architectures with external memory components allow the model to perform inference and capture long term dependencies , by storing information explicitly .",
        "adaptive stochastic gradient methods such as adagrad have gained popularity in particular for training deep neural networks .",
        "deep neural networks with lots of parameters are typically used for large - scale computer vision tasks such as image classification .",
        "we propose a novel deep network architecture for grayscale and color image denoising that is based on a non - local image model .",
        "we build on this concept and introduce deep networks that perform non - local processing and at the same time they significantly benefit from discriminative learning .",
        "it is also worth noting that this increase in performance comes at no extra cost on the capacity of the network compared to existing alternative deep network architectures .",
        "this connection is of significant importance since it allows our models to take full advantage of the latest advances on gpu computing in deep learning and makes them amenable to efficient implementations through their inherent parallelism .",
        "deep neural networks often require good regularizers to generalize well .",
        "dropout is one such regularizer that is widely used among deep learning practitioners .",
        "these information objects and their applications are known as quantified - self , mobile health or personal informatics , and they can be used to provide a deeper insight into our behavior .",
        "performance of end - to - end automatic speech recognition ( asr ) systems can significantly be improved by the increasing large speech corpus and deeper neural network .",
        "given the arising problem of training speed and recent success of deep convolutional neural network in asr , we build a novel deep recurrent convolutional network for acoustic modeling and apply deep residual learning framework to it , our experiments show that it has not only faster convergence speed but better recognition accuracy over traditional deep convolutional recurrent network .",
        "we mainly compare convergence speed of two acoustic models , which are novel deep recurrent convolutional networks and traditional deep convolutional recurrent networks .",
        "with faster convergence speed , our novel deep recurrent convolutional networks can reach the comparable performance .",
        "we further show that applying deep residual learning can boost both convergence speed and recognition accuracy of our novel recurret convolutional networks .",
        "our evaluation results show that our model applied with deep residual learning can reach the best per of 17 .",
        "deep convolutional neural networks have become a widespread tool to address high - level computer vision tasks very successfully .",
        "a new model for video captioning is developed , using a deep three - dimensional convolutional neural network ( c3d ) as an encoder for videos and a recurrent neural network ( rnn ) as a decoder for captions .",
        "many extensions have been invented based on rbm in order to produce deeper architectures with greater power .",
        "the most famous ones among them are deep belief network , which stacks multiple layer - wise pretrained rbms to form a hybrid model , and deep boltzmann machine , which allows connections between hidden units to form a multi - layer structure .",
        "we call the resulted structure deep restricted boltzmann network .",
        "we prototyped deep learning models to establish initial baselines of the introduced tasks .",
        "in this paper we present deep constrained local model ( dclm ) algorithm and the novel dense - projection network ( dpn ) as a local detector .",
        "dpn is a deep neural network that consists of two important layers : template projection layer and dense aggregate layer .",
        "our multimodal deep reinforcement learning agent perceives multimodal features and exhibits verbal and non - verbal actions while playing .",
        "standard deep reinforcement learning methods such as deep q - networks ( dqn ) for multiple tasks ( domains ) face scalability problems .",
        "despite the overwhelming success of deep learning in various speech processing tasks , the problem of separating simultaneous speakers in a mixture remains challenging .",
        "we propose a novel deep learning framework for single channel speech separation by creating attractor points in high dimensional embedding space of the acoustic signals which pull together the time - frequency bins corresponding to each source .",
        "this paper addresses the task of set prediction using deep learning .",
        "we define a likelihood for a set distribution and learn its parameters using a deep neural network .",
        "we show that by using time - dilated convolutions with a very deep vgg - style cnn with batch normalization , we achieve best published single model accuracy result on the switchboard - 2000 benchmark dataset .",
        "currently , heuristically designed features based on the domain knowledge requires tremendous effort in hand - crafting , while features extracted through deep network are difficult for human to interpret .",
        "we train input specific state - of - the - art deep neural networks for each input source , show the potential of forging them together into a multi - modal architecture and train a novel policy network that learns to choose between them .",
        "we study methods for automated parsing of informal mathematical expressions into formal ones , a main prerequisite for deep computer understanding of informal mathematical texts .",
        "we propose a context - based parsing approach that combines efficient statistical learning of deep parse trees with their semantic pruning by type checking and large - theory automated theorem proving .",
        "generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks .",
        "this paper presents a concept of a novel method for adjusting hyper - parameters in deep learning ( dl ) algorithms .",
        "an external agent - observer monitors a performance of a selected deep learning algorithm .",
        "we demonstrate an improved method for building conditional models , the co - embedding deep variational auto encoder .",
        "our model takes graphs as input , performs object - and relation - centric reasoning in a way that is analogous to a simulation , and is implemented using deep neural networks .",
        "recent literature has pointed out that machine learning classifiers , including deep neural networks ( dnn ) , are vulnerable to adversarial samples that are maliciously created inputs that force a machine learning classifier to produce wrong output labels .",
        "deep reinforcement learning ( rl ) can acquire complex behaviors from low - level inputs , such as images .",
        "deep networks are known to achieve remarkable generalization when provided with massive amounts of labeled data , but can we provide this breadth of experience to an rl agent , such as a robot ?",
        "recently it has been shown that policy - gradient methods for reinforcement learning can be utilized to train deep end - to - end systems directly on non - differentiable metrics for the task at hand .",
        "a deep convolutional autoencoder is trained on healthy retinal images .",
        "we present probabilistic neural programs , a framework for program induction that permits flexible specification of both a computational model and inference algorithm while simultaneously enabling the use of deep neural networks .",
        "the success is mostly due to advances in deep learning .",
        "however , deep learning can make mistakes and its generalization abilities to new tasks are questionable .",
        "we ask when and how one can combine network outputs , when ( i ) details of the observations are evaluated by learned deep components and ( ii ) facts and confirmation rules are available in knowledge based systems .",
        "we argue that the combination of sparse outlier detection with deep components that can support each other diminish the fragility of deep methods , an important requirement for engineering applications .",
        "recently , there have been several promising methods to generate realistic imagery from deep convolutional networks .",
        "in this paper , we propose a deep adversarial image synthesis architecture that is conditioned on coarse sketches and sparse color strokes to generate realistic cars , bedrooms , or faces .",
        "to address the issues , we propose an end - to - end deep recurrent neural network with limited contextual dialogue memory by jointly training nlu and sap on dstc4 multi - domain human - human dialogues .",
        "this paper introduces deepbach , a statistical model aimed at modeling polyphonic music and specifically four parts , hymn - like pieces .",
        "a key strength of deepbach is that it is agnostic and flexible .",
        "deepbach ' s generation is fast , making it usable for interactive",
        "deep neural networks are widely used in machine learning applications .",
        "as a proof of concept for the proposed scheme , we designed a system consisting of deep convolutional neural networks , and applied it to successfully learn a computerized agent capable of autonomous highway steering over the",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "network quantization is one of network compression techniques employed to reduce the redundancy of deep neural networks .",
        "we develop a probabilistic framework for deep learning based on the deep rendering mixture model ( drmm ) , a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables .",
        "we demonstrate that max - sum inference in the drmm yields an algorithm that exactly reproduces the operations in deep convolutional neural networks ( dcns ) , providing a first principles derivation .",
        "extensive experiments on four benchmark datasets demonstrate that the deeply - learned features with l - softmax loss become more discriminative , hence significantly boosting the performance on a variety of visual classification and verification tasks .",
        "we present an architecture which lets us train deep , directed generative models with many layers of latent variables .",
        "while depth of representation has been posited as a primary reason for their success , there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer .",
        "the predictron yielded significantly more accurate predictions than conventional deep neural network architectures .",
        "the above limitations can be overcome by using deep cases and neural network .",
        "hence we propose a modified qas in which we create a deep artificial neural network with associative memory from text documents .",
        "in this paper we introduce deepstack , a new algorithm for imperfect information settings such as poker .",
        "it combines recursive reasoning to handle information asymmetry , decomposition to focus computation on the relevant decision , and a form of intuition about arbitrary poker situations that is automatically learned from self - play games using deep learning .",
        "in a study involving dozens of participants and 44 , 000 hands of poker , deepstack becomes the first computer program to beat professional poker players in heads - up no - limit texas hold ' em .",
        "with the advent of deep learning new models of unsupervised learning of features for time - series analysis and forecast have been developed .",
        "such new developments are the topic of this paper : a review of the main deep learning techniques is presented , and some applications on time - series analysis are summaried .",
        "the results make it clear that deep learning has a lot to contribute to the field .",
        "moreover , a taxonomy and survey of shallow and deep networks intrusion detection systems is presented based on previous and current works .",
        "in recent years , deep learning ( dl ) has found great success in domains such as multimedia understanding .",
        "deep reinforcement learning has enabled the learning of policies for complex tasks in partially observable environments , without explicitly learning the underlying model of the tasks .",
        "we propose a deep - learning - based approach , called st - resnet , to collectively forecast two types of crowd flows ( i .",
        "we define this requirement as the \" image - to - image translation \" problem , and propose a general approach to achieve it , based on deep convolutional and conditional generative adversarial networks ( gans ) , which has gained a phenomenal success to learn mapping images from noise input since 2014 .",
        "in this paper , a novel architecture for a deep recurrent neural network , residual lstm is introduced .",
        "the proposed residual lstm architecture provides an additional spatial shortcut path from lower layers for efficient training of deep networks with multiple lstm layers .",
        "on the other hand deep learning is considered to be the new frontier to extract meaningful information out of large amount of raw data in an automated manner .",
        "therefore , we would like to omit it and use deep neural networks that learn from simple features .",
        "most of the current deep neural network ( dnn ) based methods consider these tasks as a sequence labeling problem , in which a word , rather than a chunk , is treated as the basic unit for labeling .",
        "we study characteristics of receptive fields of units in deep convolutional networks .",
        "deep learning classifiers are known to be inherently vulnerable to manipulation by intentionally perturbed inputs , named adversarial examples .",
        "in this work , we establish that reinforcement learning techniques based on deep q - networks ( dqns ) are also vulnerable to adversarial input perturbations , and verify the transferability of adversarial examples across different dqn models .",
        "end - to - end ( e2e ) systems have achieved competitive results compared to conventional hybrid hidden markov model ( hmm ) - deep neural network based automatic speech recognition ( asr ) systems .",
        "our base perception module is based on recent development in object detection and recognition using deep learning .",
        "in this paper , we present a deep model to learn item properties and user behaviors jointly from review text .",
        "the proposed model , named deep cooperative neural networks ( deepconn ) , consists of two parallel neural networks coupled in the last layers .",
        "experimental results demonstrate that deepconn significantly outperforms all baseline recommender systems on a variety of datasets .",
        "this paper presents the development of several models of a deep convolutional auto - encoder in the caffe deep learning framework and their experimental evaluation on the example of mnist dataset .",
        "the paper also discusses practical details of the creation of a deep convolutional auto - encoder in the very popular caffe deep learning framework .",
        "we report up to 128 fold compression of popular architectures without a large loss of accuracy providing additional evidence to the fact that modern deep architectures are very redundant .",
        "introduction to deep neural networks and their history .",
        "this work aims to investigate the use of deep neural network to detect commercial hobby drones in real - life environments by analyzing their sound data .",
        "recently , several deep learning approaches have been presented which automatically extract features from the mouth images and aim to replace the feature extraction stage .",
        "many aspects of people ' s lives are proven to be deeply connected to their jobs .",
        "deep learning techniques lie at the heart of several significant ai advances in recent years including object recognition and detection , image captioning , machine translation , speech recognition and synthesis , and playing the game of go .",
        "here we suggest deep learning based guidance in the proof search of the theorem prover e .",
        "we train and compare several deep neural network models on the traces of existing atp proofs of mizar statements and use them to select processed clauses during proof search .",
        "we give experimental evidence that with a hybrid , two - phase approach , deep learning based guidance can significantly reduce the average number of proof search steps while increasing the number of theorems proved .",
        "using a few proof guidance strategies that leverage deep neural networks , we have found first - order proofs of 7 .",
        "we give an overview of recent exciting achievements of deep reinforcement learning ( rl ) .",
        "we start with background of deep learning and reinforcement learning , as well as introduction of testbeds .",
        "next we discuss deep q - network ( dqn ) and its extensions , asynchronous methods , policy optimization , reward , and planning .",
        "the application of deep neural networks for ranking in search engines may obviate the need for the extensive feature engineering common to current learning - to - rank methods .",
        "however , we show that combining simple relevance matching features like bm25 with existing deep neural net models often substantially improves the accuracy of these models , indicating that they do not capture essential local relevance matching signals .",
        "we describe a novel deep recurrent neural net - based model that we call match - tensor .",
        "standard error backpropagation is used in almost all modern deep network training .",
        "extensive numerical simulations on a toy deep learning model verify its excellent performance .",
        "the reinforced backpropagation can significantly improve test performance of the deep network training , especially when the data are scarce .",
        "proposed approach uses deep recurrent neural network trained on a sequence of acoustic features calculated over small speech intervals .",
        "experiments using deep neural network models trained on social media data show that the combination of visual and textual context can enhance the quality of generated conversational turns .",
        "the recent success of deep convolutional neural networks on image classification and recognition tasks has led to new applications in very diversifying contexts .",
        "several novel and recent approaches have also embedded control policy with efficient perceptual representation using deep learning .",
        "this has led to the emergence of a new branch of dynamic robot control system called deep r inforcement learning ( drl ) .",
        "in this paper , we take a step towards generating sensory data that can pass a deep learning based discriminator model test , and make two specific contributions : first , we present a deep learning based architecture for synthesizing sensory data .",
        "we then define a new class of submodular functions we call { \\ em deep submodular functions } or dsfs .",
        "we show that dsfs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks ( dnns ) .",
        "skip connections made the training of very deep neural networks possible and have become an indispendable component in a variety of neural architectures .",
        "here , we present an explanation for the benefits of skip connections in training very deep neural networks .",
        "we argue that skip connections help break symmetries inherent in the loss landscapes of deep networks , leading to drastically simplified landscapes .",
        "this hypothesis is supported by evidence from a toy model with binary weights and from experiments with fully - connected networks suggesting ( i ) that skip connections do not necessarily improve training unless they help break symmetries and ( ii ) that alternative ways of breaking the symmetries also lead to significant performance improvements in training deep networks , hence there is nothing special about skip connections in this respect .",
        "it is well known that it is challenging to train deep neural networks and recurrent neural networks for tasks that exhibit long term dependencies .",
        "here , we take the first steps in this direction and present a deep learning pipeline that takes as input images of the undeciphered indus script , as found in archaeological artifacts , and returns as output a string of graphemes , suitable for inclusion in a standard corpus .",
        "multiple pcgml methods are covered , including neural networks , long short - term memory ( lstm ) networks , autoencoders , and deep convolutional networks ; markov models , $ n $ - grams , and multi - dimensional markov chains ; clustering",
        "deep learning to hash , which improves retrieval quality by end - to - end representation learning and hash encoding , has received increasing attention recently .",
        "subject to the vanishing gradient difficulty in the optimization with binary activations , existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step , which suffer from substantial loss of retrieval quality .",
        "this paper presents hashnet , a novel deep architecture for deep learning to hash by continuation method , which learns exactly binary hash codes from imbalanced similarity data where the number of similar pairs is much smaller than the number of dissimilar pairs .",
        "the key idea is to attack the vanishing gradient problem in optimizing deep networks with non - smooth binary activations by continuation method , in which we begin from learning an easier network with smoothed activation function and let it evolve during the training , until it eventually goes back to being the original , difficult to optimize , deep network with the sign activation function .",
        "a clearer understanding of the strict link between distributed / distributional representations and symbols will certainly lead to radically new deep learning networks .",
        "we employ a pixelcnn architecture to define a strong prior over natural images and jointly optimize this prior with a deep conditioning convolutional network .",
        "attention networks have proven to be an effective approach for embedding categorical inference within a deep neural network .",
        "in this work , we experiment with incorporating richer structural distributions , encoded using graphical models , within deep networks .",
        "the problem of quantizing the activations of a deep neural network is considered .",
        "the problem of approximating the relu non - linearity , widely used in the recent deep learning literature , is then considered .",
        "deep learning ( dl ) methods show very good performance when trained on large , balanced data sets .",
        "we use a single neural network to model users and products , capturing their correlation and generating customised product representations using a deep memory network , from which customised ratings and reviews are constructed jointly .",
        "in this paper we propose to exploit the automatic quality estimation ( qe ) of asr hypotheses to perform the unsupervised adaptation of a deep neural network modeling acoustic probabilities .",
        "the backbone of our system is a deep convolutional neural network that is not only computationally inexpensive , but also provides state - of - the - art results on several competitive benchmarks .",
        "additionally , our deep network is trained on a large dataset of several million images which are labeled through a semi - automated process .",
        "in addition , our style - based classifier establishes a new state - of - the - art result on the story cloze challenge , substantially higher than previous results based on deep learning models .",
        "deep neural networks ( dnn ) have revolutionized the field of natural language processing ( nlp ) .",
        "previous deep learning - based approaches to domain adaptation need to be trained jointly on source and target domain data and are therefore unappealing in scenarios where models need to be adapted to a large number of domains or where a domain is evolving , e .",
        "in this paper , we propose a new autonomous braking system based on deep reinforcement learning .",
        "the policy used for brake control is learned through computer simulations using the deep reinforcement learning method called deep q - network ( dqn ) .",
        "we combine the advantages of these two methods by training a deep network that learns to synthesize video frames by flowing pixel values from existing ones , which we call deep voxel flow .",
        "to this end , we develop a character - level deep conflation model that encodes the input text strings from character level into finite dimension feature vectors , which are then used to compute the cosine similarity between the text strings .",
        "specifically , we propose two variants of the deep conflation model , based on long - short - term memory ( lstm ) recurrent neural network ( rnn ) and convolutional neural network ( cnn ) , respectively .",
        "we analyze the dynamics of policies learned by multiple self - interested independent learning agents , each using its own deep q - network , on two markov games we introduce here : 1 .",
        "two decades after teasauro ' s td - gammon achieved near top - level human performance in backgammon , the deep reinforcement learning algorithm dqn ( combining q - learning with a deep neural network , experience replay , and a separate target network ) achieved human - level performance in many atari 2600 games .",
        "fully connected network has been widely used in deep learning , and its computation efficiency is highly benefited from the matrix multiplication algorithm with cublas on gpu .",
        "to reduce the impact of nt operation by cublas , we exploit the out - of - place transpose of matrix $ \\ textbf { b } $ to avoid using nt operation , and then we apply our method to caffe , which is a popular deep learning tool .",
        "several machine learning algorithms ( naive bayes , support vector machine and logistic regression ) alongside deep and convolutional neural networks were utilized in our experiments of sentiment analysis on our health dataset .",
        "batch normalization is quite effective at accelerating and improving the training of deep models .",
        "in this work , we propose to train a deep neural network by distributed optimization over a graph .",
        "recently , machine learning methods have provided a broad spectrum of original and efficient algorithms based on deep neural networks ( dnn ) to automatically predict an outcome with respect to a sequence of inputs .",
        "using deep learning for different machine learning tasks such as image classification and word embedding has recently gained many attentions .",
        "in this paper , we use deep learning to embed wikipedia concepts and entities .",
        "in this paper we explore whether or not deep neural architectures can learn to classify boolean satisfiability ( sat ) .",
        "in this paper , we propose a system that uses deep learning techniques for morphological disambiguation .",
        "many of the state - of - the - art results in computer vision , speech recognition and natural language processing have been obtained through deep learning models .",
        "however , applying deep learning techniques to morphologically rich languages is not well studied .",
        "in this paper , we developed a deep neural network ( dnn ) that learns to solve simultaneously the three tasks of the cqa challenge proposed by the semeval - 2016 task 3 , i .",
        "in order to improve the reliability of speaker verification systems , we develop a new filter bank based cepstral feature , deep neural network filter bank cepstral coefficients ( dnn - fbcc ) , to distinguish between natural and spoofed speech .",
        "the deep neural network filter bank is automatically generated by training a filter bank neural network ( fbnn ) using natural and synthetic speech .",
        "the backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive , but also provide state - of - the - art results on several competitive benchmarks .",
        "to power our novel deep networks , we collected large labeled datasets through a semi - supervised pipeline to reduce the annotation effort / time .",
        "previous studies support the idea of merging auditory - based gabor features with deep learning architectures to achieve robust automatic speech recognition , however , the cause behind the gain of such combination is still unknown .",
        "we believe these representations provide the deep learning decoder with more discriminable cues .",
        "this article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input .",
        "the state - of - the - art results provided by deep learning come at the price of an intensive use of computing resources .",
        "in this paper , we ask the following question : is distributed deep learning computation on wan connected devices feasible , in spite of the traffic caused by learning tasks ?",
        "deep neural networks ( dnns ) have set state of the art results in many machine learning and nlp tasks .",
        "uoro is a modification of nobacktrack that bypasses the need for model sparsity and makes implementation easy in current deep learning frameworks , even for complex models .",
        "furthermore , we show that rns can act as a bottleneck that induces the factorization of objects from entangled scene description inputs , and from distributed deep representations of scene images provided by a variational autoencoder .",
        "we propose a deep learning model for identifying structure within experiment narratives in scientific literature .",
        "the paper [ 1 ] shows that simple linear classifier can compete with complex deep learning algorithms in text classification applications .",
        "combining bag of words ( bow ) and linear classification techniques , fasttext [ 1 ] attains same or only slightly lower accuracy than deep learning algorithms [ 2 - 9 ] that are orders of magnitude slower .",
        "this paper focuses on the development of randomized approaches for building deep neural networks .",
        "such a class of randomized leaner models with deep architecture is termed as deep stochastic configuration networks ( deepscns ) , of which the universal approximation property is verified with rigorous proof .",
        "given abundant samples from a continuous distribution , deepscns can speedily produce a learning representation , that is , a collection of random basis functions with the cascaded inputs together with the read - out weights .",
        "deep neural networks are currently among the most commonly used classifiers .",
        "while one can find impressively wide spread of various configurations of almost every aspect of the deep nets , one element is , in authors ' opinion , underrepresented - while solving classification problems , vast majority of papers and applications simply use log loss .",
        "in this paper we try to investigate how particular choices of loss functions affect deep models and their learning dynamics , as well as resulting classifiers robustness to various effects .",
        "in particular we show that l1 and l2 losses are , quite surprisingly , justified classification objectives for deep nets , by providing probabilistic interpretation in terms of expected misclassification .",
        "we also introduce two losses which are not typically used as deep nets objectives and show that they are viable alternatives to the existing ones .",
        "motivated by human collaborative learning , in this paper we propose a collaborative deep reinforcement learning ( cdrl ) framework that performs adaptive knowledge transfer among heterogeneous learning agents .",
        "specifically , the proposed cdrl conducts a novel deep knowledge distillation method to address the heterogeneity among different learning tasks with a deep alignment network .",
        "furthermore , we present an efficient collaborative asynchronous advantage actor - critic ( ca3c ) algorithm to incorporate deep knowledge distillation into the online training of agents , and demonstrate the effectiveness of the cdrl framework using extensive empirical evaluation on openai gym .",
        "distributed training of deep learning models on large - scale training data is typically conducted with asynchronous stochastic optimization to maximize the rate of updates , at the cost of additional noise introduced from asynchrony .",
        "figar can be used for improving any deep reinforcement learning algorithm which maintains an explicit policy estimate by enabling temporal abstractions in the action space .",
        "we empirically demonstrate the efficacy of our framework by showing performance improvements on top of three policy search algorithms in different domains : asynchronous advantage actor critic in the atari 2600 domain , trust region policy optimization in mujoco domain and deep deterministic policy gradients in the torcs car racing domain .",
        ", to learn deep features in an end - to - end manner .",
        "neural networks have been successfully applied to this problem , and in this paper , we propose an attention - based deep neural network which better incorporates different embeddings of the queries and search results with an attention - based mechanism .",
        "many classes of rl tasks , from atari games to motor control to board games , are now solvable by fairly generic algorithms , based on deep learning , that learn to play from experience with minimal knowledge of the specific domain of interest .",
        "specifically , we propose an optimized accelerator architecture tailored for bitwise convolution and normalization that features massive spatial parallelism with deep pipelines stages .",
        "finally , we also research new dropout prediction architectures based on deep , fully - connected , feed - forward neural networks and find that ( 4 ) networks with as many as 5 hidden layers can",
        "in this paper , we explore deep learning techniques for answering multi - step reasoning questions that operate on semi - structured tables .",
        "in this paper , we motivate guided deep list , the first tool for building automated line lists ( in near real - time ) from open source reports of emerging disease outbreaks .",
        "guided deep list uses distributed vector representations ( ala word2vec ) to discover a set of indicators for each line list feature .",
        "we evaluate the performance of guided deep list against a human annotated line list provided by healthmap corresponding to mers outbreaks in saudi arabia .",
        "many enlightening vqa works explore deep into the image and question encodings and fusing methods , of which attention is the most effective and infusive mechanism .",
        "recent studies have shown that deep neural networks ( dnn ) are vulnerable to adversarial samples : maliciously - perturbed samples crafted to yield incorrect model outputs .",
        "to overcome this problem , we introduce a defensive mechanism called deepmask .",
        "by identifying and removing unnecessary features in a dnn model , deepmask limits the capacity an attacker can use generating adversarial samples and therefore increase the robustness against such inputs .",
        "comparing with other defensive approaches , deepmask is easy to implement and computationally efficient .",
        "experimental results show that deepmask can increase the performance of state - of - the - art dnn models against adversarial samples .",
        "limited annotated data is available for the research of estimating facial expression intensities , which makes the training of deep networks for automated expression assessment very challenging .",
        "the proposed transferred deep regressor is applied in estimating the intensity of facial action units ( 2017 emotionnet challenge ) and in particular pain intensity estimation ( unbs - mcmaster shoulder - pain dataset ) .",
        "deep neural nets have caused a revolution in many classification tasks .",
        "the back - propagation ( bp ) algorithm has been considered the de facto method for training deep neural networks .",
        "first , the model generalizes previous methods by incorporating content , network , and deep features learned from social context .",
        "motivated by recent progress in deep learning , we focus on the specific case where agents update their actions according to gradient descent .",
        "the adaptation of the meta - parameters is an open question in reinforcement learning , which arguably has become more of an issue recently with the success of deep reinforcement learning in high - dimensional state spaces .",
        "recently , there was a paradigm shift towards using word embeddings and deep neural networks , where the use of surface features is very limited .",
        "in this paper , we theoretically address three fundamental problems involving deep convolutional networks regarding invariance , depth and hierarchy .",
        "deeper networks are able to model much richer classes of transformations .",
        "our results provide useful insight into these three fundamental problems in deep learning using convnets .",
        "deep neural network ( dnn ) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene .",
        "deep learning approaches have been widely used in automatic speech recognition ( asr ) and they have achieved a significant accuracy improvement .",
        "however , most cnns used in existing work have less than 10 layers which may not be deep enough to capture all human speech signal information .",
        "in this paper , we propose a novel deep and wide cnn architecture denoted as rcnn - ctc , which has residual connections and connectionist temporal classification ( ctc ) loss function .",
        "we present deep voice , a production - quality text - to - speech system constructed entirely from deep neural networks .",
        "deep voice lays the groundwork for truly end - to - end neural speech synthesis .",
        "for the segmentation model , we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification ( ctc ) loss .",
        "deep learning is an important component of big - data analytic tools and intelligent applications , such as , self - driving cars , computer vision , speech recognition , or precision medicine .",
        "modern parallel computing systems provide the capability to reduce the required training time of deep neural networks .",
        "deep learning models are often successfully trained using gradient descent , despite the worst case hardness of the underlying non - convex optimization problem .",
        "motivated by the idea that criticality and universality of phase transitions might play a crucial role in achieving and sustaining learning and intelligent behaviour in biological and artificial networks , we analyse a theoretical and a pragmatic experimental set up for critical phenomena in deep learning .",
        "on the theoretical side , we use results from statistical physics to carry out critical point calculations in feed - forward / fully connected networks , while on the experimental side we set out to find traces of criticality in deep neural networks .",
        "this is our first step in a series of upcoming investigations to map out the relationship between criticality and learning in deep networks .",
        "we employ a model free deep reinforcement learning framework to learn the motoric skills of striking the puck accurately in order to score .",
        "we propose certain improvements to the standard learning scheme which make the deep q - learning algorithm feasible when it might otherwise fail .",
        "fixed - point optimization of deep neural networks plays an important role in hardware based design and low - power implementations .",
        "many deep neural networks show fairly good performance even with 2 - or 3 - bit precision when quantized weights are fine - tuned by retraining .",
        "the experiments are conducted for feed - forward deep neural networks ( ffdnns ) , convolutional neural networks ( cnns ) , and recurrent neural networks ( rnns ) .",
        "we introduce deepnat , a 3d deep convolutional neural network for the automatic segmentation of neuroanatomy in t1 - weighted magnetic resonance images .",
        "deepnat is an end - to - end learning - based approach to brain segmentation that jointly learns an abstract feature representation and a multi - class classification .",
        "multi - task learning ( mtl ) in deep neural networks for nlp has recently received increasing interest due to some compelling benefits , including its potential to efficiently regularize models and to reduce the need for labeled data .",
        "despite this importance , deep reinforcement learning ( drl ) agents have so far used relatively simple memory architectures , with the main methods to overcome partial observability being either a temporal convolution over the past k frames or an lstm layer .",
        "deep - layered models trained on a large number of labeled samples boost the accuracy of many tasks .",
        "deep networks thrive when trained on large scale data collections .",
        "this has given imagenet a central role in the development of deep architectures for visual object classification .",
        "we contribute to this research thread with two findings : ( 1 ) a study correlating a given level of noisily labels to the expected drop in accuracy , for two deep architectures , on two different types of noise , that clearly identifies googlenet as a suitable architecture for learning from web data ; ( 2 ) a recipe for the creation of web datasets with minimal noise and maximum visual variability , based on a visual and natural language processing concept expansion strategy .",
        "however , it is difficult to create a large dataset to train the ability of deep neural network models ( dnns ) .",
        "deep learning , a subfield of machine learning , promises to change this by operating on raw input signals and automating the process of feature design and extraction .",
        "in this paper we propose the expose neural network , which uses a deep learning approach we have developed to take generic , raw short character strings as input ( a common case for security inputs , which include artifacts like potentially malicious urls , file paths , named pipes , named mutexes , and registry keys ) , and learns to simultaneously extract features and classify using character - level embeddings and convolutional neural network .",
        "a long - standing obstacle to progress in deep learning is the problem of vanishing and exploding gradients .",
        "preliminary experiments show the new initialization allows to train very deep networks without the addition of skip - connections .",
        "we used a novel deep regression structure for overall completeness estimation .",
        "these findings represent a paradigm shift especially when it comes to harnessing the power of deep networks for primary and secondary clustering applications in large datasets .",
        "deep neural networks require a large amount of labeled training data during supervised learning .",
        "in this paper , we introduce a source - target selective joint fine - tuning scheme for improving the performance of deep learning tasks with insufficient training data .",
        "deep residual networks have reached the state of the art in many image processing tasks such image classification .",
        "for example , a 152 - layer - deep residual network can be reduced to 106 convolutional layers , i .",
        "therefore , a key challenge is to translate the success of deep learning on single - agent rl to the multi - agent setting .",
        "a key stumbling block is that independent q - learning , the most popular multi - agent rl method , introduces nonstationarity that makes it incompatible with the experience replay memory on which deep rl relies .",
        "we formally study ldr matrices in deep learning .",
        "deep convolutional networks have demonstrated remarkable results for image and video classification tasks .",
        "in particular , images are represented as signals on graphs , which permits to replace classical convolution and pooling layers in deep networks with graph spectral convolution and dynamic graph pooling layers that together contribute to invariance to isometric transformations .",
        "deep reinforcement learning has been successful in various virtual tasks , but it is still rarely used in real world applications especially for continuous control of mobile robots navigation .",
        "we show that , through an asynchronous deep reinforcement learning method , a mapless motion planner can be trained end - to - end without any manually designed features and prior demonstrations .",
        "this paper presents optnet , a network architecture that integrates optimization problems ( here , specifically in the form of quadratic programs ) as individual layers in larger end - to - end trainable deep networks .",
        "we show that the incorporation of sgs does not affect the representational strength of the learning system for a neural network , and prove the convergence of the learning system for linear and deep linear models .",
        "the success of deep learning depends on finding an architecture to fit the task .",
        "as deep learning has scaled up to more challenging tasks , the architectures have become difficult to design by hand .",
        "this paper proposes an automated method , codeepneat , for optimizing deep learning architectures through evolution .",
        "given the anticipated increases in available computing power , evolution of deep networks is promising approach to constructing deep learning applications in the future .",
        "in this work we propose the first wii approach based upon deep convolutional neural networks ( cnns ) .",
        "in deep learning the ubiquitous architecture used for this task is the siamese neural network which maps each entity to a representation through a learnable function and expresses similarity through the distances among the entities in the representation space .",
        "in the task of similarity learning , our simplistic model that does not use any convolutions performs on par with deep convolutional siamese networks and significantly better when convolutional layers are also used .",
        "stochastic gradient algorithms are the main focus of large - scale optimization problems and led to important successes in the recent advancement of the deep learning algorithms .",
        "in our experiments with deep neural networks , we obtained better performance compared to the popular stochastic gradient algorithms .",
        "despite their great success , there is still no com - prehensive theoretical understanding of learning with deep neural networks ( dnns ) or their in - ner organization .",
        "deep neural networks have been successfully applied in applications with a large amount of labeled data .",
        "our results can be directly applied to many machine learning applications , including deep learning .",
        "generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain .",
        "the efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks .",
        "the focus of past machine learning research for reading comprehension tasks has been primarily on the design of novel deep learning architectures .",
        "this paper presents an end - to - end learning framework for task - completion neural dialogue systems , which leverages supervised and reinforcement learning with various deep - learning models .",
        "fully - connected feed - forward neural networks ( dnns ) and deep unidirectional long short - term memory ( lstm ) recurrent neural networks ( rnns ) are successfully trained with proposed method for large vocabulary continuous speech recognition on shenma voice search data in mandarin .",
        ", robotics control , sequential prediction ) with deep neural network models .",
        "we present a new deep learning model : we extend the state - of - the - art convolutional object detection network for the detection of human hands in training videos based on image information , and newly introduce the concept of using a fully convolutional network to regress ( i .",
        "we demonstrate the performance of our proposed system on a range of tasks from the atari suite and also from a 3d deepmind lab environment .",
        "deep reinforcement learning methods have demonstrated the ability to learn with highly general policy classes for complex tasks with high - dimensional inputs , such as raw images .",
        "on the other hand , it is comparatively easy to build discriminative models on top of complex states such as images using standard deep neural networks .",
        "we study the problem of attributing the prediction of a deep network to its input features , a problem previously studied by several other works .",
        "we apply this method to a couple of image models , a couple of text models and a chemistry model , demonstrating its ability to debug networks , to extract rules from a deep network , and to enable users to engage with models better .",
        "we present a new distributed representation in deep neural nets wherein the information is represented in native form as a matrix .",
        "deep convolutional neural networks ( cnn ) have shown their good performances in many computer vision tasks .",
        "this paper presents chain - nn , a novel energy - efficient 1d chain architecture for accelerating deep cnns .",
        "we frame the problem in the context of unsupervised domain adaptation and apply an adversarial framework to train a deep neural network with the additional objective to align features across domains .",
        "recent successes in deep reinforcement learning have been achieved mostly using simple heuristic exploration strategies such as $ \\ epsilon $ - greedy action selection or gaussian control noise , but there are many tasks where these methods are insufficient to make any learning progress .",
        "first , a novel deep learning model codae , in which two mid - layers from separate stack denoising autoencoders are fused into one shared layer .",
        "we show that the nonlinearity of a deep network does not need to be continuous , non expansive or point - wise , to achieve good performance .",
        "we show that increasing the width of our network permits being competitive with very deep networks .",
        "indeed , a 1 - nearest neighbor classifier applied on deep features progressively improves with depth , which indicates that the representation is progressively more regular .",
        "recently , the end - to - end approach that learns hierarchical representations from raw data using deep convolutional neural networks has been successfully explored in the image , text and speech domains .",
        "to this end , we propose sample - level deep convolutional neural networks which learn representations from very small grains of waveforms ( e .",
        "we show how deep architectures with sample - level filters improve the accuracy in music auto - tagging and they provide results that are com - parable to previous state - of - the - art performances for the magnatagatune dataset and million song dataset .",
        "deep neural network is difficult to train and this predicament becomes worse as the depth increases .",
        "equipped with these two ingredients , we propose several novel optimization solutions that can be utilized for training a specific - structured ( repetitively triple modules of conv - bnrelu ) extremely deep convolutional neural network ( cnn ) without any shortcuts / identity mappings from scratch .",
        "deep reinforcement learning methods attain super - human performance in a wide range of environments .",
        "we propose neural episodic control : a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them .",
        "we show across a wide range of environments that our agent learns significantly faster than other state - of - the - art , general purpose deep reinforcement learning agents .",
        "advances in deep learning over the last few years have produced major speech recognition improvements on the representative switchboard conversational corpus .",
        "although there are some experts in vietnam as well as international having deeply researched this problem , there are still no reasonable results meeting the demand , in particular , no treated thoroughly the ambiguous phenomenon , in the process of khmer language processing so far .",
        "recently , triggered by the impressive results in tv - games or game of go by google deepmind , end - to - end reinforcement learning ( rl ) is collecting attentions .",
        "deep neural networks coupled with fast simulation and improved computation have led to recent successes in the field of reinforcement learning ( rl ) .",
        "even though active learning forms an important pillar of machine learning , deep learning tools are not prevalent within it .",
        "deep learning poses several difficulties when used in an active learning setting .",
        "recent advances in deep learning , on the other hand , are notorious for their dependence on large amounts of data .",
        "second , many al acquisition functions rely on model uncertainty , yet deep learning methods rarely represent such model uncertainty .",
        "in this paper we combine recent advances in bayesian deep learning into the active learning framework in a practical way .",
        "to obtain uncertainty estimates with real - world bayesian deep learning models , practical inference approximations are needed .",
        "we prove new upper and lower bounds on the vc - dimension of deep neural networks with the relu activation function .",
        "to capture such global interdependency , we propose a deep variation - structured reinforcement learning ( vrl ) framework to sequentially discover object relationships and attributes in the whole image .",
        "we then make sequential predictions using a deep rl framework , incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector .",
        "deep convolutional neural network ( cnn ) inference requires significant amount of memory and computation , which limits its deployment on embedded devices .",
        "among the main results we show that suppes ' constraints deeply simplify the learning task , by reducing the solution search space and providing a temporal ordering on the variables .",
        "despite recent advances , memory - augmented deep neural networks are still limited when it comes to life - long and one - shot learning , especially in remembering rare events .",
        "we present a large - scale life - long memory module for use in deep learning .",
        "training deep neural networks is a highly nontrivial task , involving carefully selecting appropriate training algorithms , scheduling step sizes and tuning other hyperparameters .",
        "recently , researchers have tried to use deep learning algorithms to exploit the landscape of the loss function of the training problem of interest , and learn how to optimize over it in an automatic way .",
        "our optimizer outperforms generic , hand - crafted optimization algorithms and state - of - the - art learning - to - learn optimizers by deepmind in many tasks .",
        "we demonstrate the effectiveness of our algorithms on a number of tasks , including deep mlps , cnns , and simple lstms .",
        "we introduce a method for learning the dynamics of complex nonlinear systems based on deep generative models over temporal segments of states and actions .",
        "deep learning has led to remarkable advances when applied to problems where the data distribution does not change over the course of learning .",
        "we approach structured output prediction by learning a deep value network ( dvn ) that evaluates different output structures for a given input .",
        "in addition , on image segmentation , the proposed deep value network learns complex shape priors and effectively combines image information with the prior to obtain competitive segmentation results .",
        "terminology is one of the sectors in which the arabic language requires a deep modernization of its classical productivity models .",
        "despite their overwhelming capacity to overfit , deep learning architectures tend to generalize relatively well to unseen data , allowing them to be deployed in practice .",
        "this paper argues that most notions of flatness are problematic for deep models and can not be directly applied to explain generalization .",
        "specifically , when focusing on deep networks with rectifier units , we can exploit the particular geometry of parameter space induced by the inherent symmetries that these architectures exhibit to build equivalent models corresponding to arbitrarily sharper minima .",
        "in this paper , we propose a deep neural networks ( dnn ) based pbe model called neural programming by example ( npbe ) , which can learn from input - output strings and induce programs that solve the string manipulation problems .",
        "deep learning with convolutional neural networks ( deep convnets ) has revolutionized computer vision through end - to - end learning , i .",
        "now , there is increasing interest in using deep convnets for end - to - end eeg analysis .",
        "current deep learning approaches have been very successful using convolutional neural networks ( cnn ) trained on large graphical processing units ( gpu ) - based computers .",
        "in this paper , we evaluate deep learning models using three different computing architectures to address these problems : quantum computing to train complex topologies , high performance computing ( hpc ) to automatically determine network topology , and neuromorphic computing for a low - power hardware implementation .",
        "our results show the feasibility of using the three architectures in tandem to address the above deep learning limitations .",
        "an energy function over candidate structured outputs is given by a deep network , and predictions are formed by gradient - based optimization .",
        "in this paper , we demonstrate that such data can be automatically extracted by deep neural networks ( aka deep learning ) , which is a cutting - edge type of artificial intelligence .",
        "in particular , we use the existing human - labeled images from the snapshot serengeti dataset to train deep convolutional neural networks for identifying 48 species in 3 .",
        "deep learning models ( dlms ) are state - of - the - art techniques in speech recognition .",
        "in this paper we aim at filling this gap by comparing four popular parallel training algorithms in speech recognition , namely asynchronous stochastic gradient descent ( asgd ) , blockwise model - update filtering ( bmuf ) , bulk synchronous parallel ( bsp ) and elastic averaging stochastic gradient descent ( easgd ) , on 1000 - hour librispeech corpora using feed - forward deep neural networks ( dnns ) and convolutional , long short - term memory , dnns ( cldnns ) .",
        "taking advantage of the recent success of unsupervised learning in deep neural networks , we propose an end - to - end learning framework that is able to extract more robust multi - modal representations across domains .",
        "we propose anogan , a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability , accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space .",
        "this strategy effectively solves the label permutation problem observed in deep learning based techniques for speech separation .",
        "we examine the effects of transfer learning for deep hierarchical recurrent networks across domains , applications , and languages , and show that significant improvement can often be obtained .",
        "recently , semantic segmentation of rgb imagery has advanced significantly due to deep learning .",
        "this makes it difficult to directly train a deep neural network for semantic segmentation , because it will be prone to overfitting .",
        "to cope with this , deep learning models typically use convolutional neural networks pre - trained on large - scale image classification datasets , which are then fine - tuned for semantic segmentation .",
        "in this paper , we developed two deep neural networks for semantic segmentation of multispectral remote sensing imagery .",
        "cltune is evaluated on two gpu case - studies inspired by the recent successes in deep learning : 2d convolution and matrix - multiplication ( gemm ) .",
        "additionally , deeper ensemble architectures such as classifier stacking have not been closely evaluated .",
        "we use deep reinforcement learning ( rl ) to learn the policies of these agents end - to - end - - from pixels to multi - agent multi - round dialog to game reward .",
        "expressive efficiency is a concept that allows formally reasoning about the representational capacity of deep network architectures .",
        "a well - known example is the exponential expressive efficiency of depth , namely , that in many cases shallow networks must grow exponentially large in order to represent functions realized by deep networks .",
        "we focus on dilated convolutional networks , a family of deep models gaining increased attention , underlying state of the art architectures like google ' s wavenet and bytenet .",
        "this work thus presents a comparison of several state - of - the - art deep learning models on the ieee challenge on detection and classification of acoustic scenes and events ( dcase ) 2016 challenge task and data , classifying sounds into one of fifteen common indoor and outdoor acoustic scenes , such as bus , cafe , car , city center , forest path , library , train , etc .",
        "on these features , we apply five models : gaussian mixture model ( gmm ) , deep neural network ( dnn ) , recurrent neural network ( rnn ) , convolutional deep neural net - work ( cnn ) and i - vector .",
        "to our knowledge , this is the first successful transfer of a deep neural network trained only on simulated rgb images ( without pre - training on real images ) to the real world for the purpose of robotic control .",
        "we have assumed that using advanced deep machine learning methods may considerably increase the accuracy of predictions .",
        "we started with simple machine learning methods to estimate basic prediction performance and moved further by applying advanced methods based on shallow and deep neural networks .",
        "we believe that applying deep machine learning for psychological profiling may have an enormous impact on the society ( for good or worse ) and providing full source code of our research we hope to",
        "we achieve this using a deep generative model to create novel instances along a 1d line .",
        "in this paper , we proposed a novel deep learning framework , namely long - and short - term time - series network ( lstnet ) , to address this open challenge .",
        "deeper lstm models perform well on large vocabulary continuous speech recognition , because of their impressive learning ability .",
        "however , it is more difficult to train a deeper network .",
        "we introduce a training framework with layer - wise training and exponential moving average methods for deeper lstm models .",
        "it is a competitive framework that lstm models of more than 7 layers are successfully trained on shenma voice search data in mandarin and they outperform the deep lstm models trained by conventional approach .",
        "moreover , in order for online streaming speech recognition applications , the shallow model with low real time factor is distilled from the very deep model .",
        "deep learning has shown promising results in many machine learning applications .",
        "the hierarchical feature representation built by deep networks enable compact and precise encoding of the data .",
        "a kernel analysis of the trained deep networks demonstrated that with deeper layers , more simple and more accurate data representations are obtained .",
        "in this paper , we propose an approach for layer - wise training of a deep network for the supervised classification task .",
        "this paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2d and 3d face alignment datasets .",
        "large - scale deep convolutional neural networks ( cnns ) are widely used in machine learning applications .",
        "we demonstrate a novel method , based on learning deep networks , to model the global landscapes of optimization problems .",
        "to represent the search space concisely and accurately , the deep networks must encode information about the underlying parameter interactions and their contributions to the quality of the solution .",
        "moreover , with the increasing need of deep semantic processing , text - based dialogue understanding is attracting more attention in the community .",
        "in recent years , deep learning has become the go - to solution for a broad range of applications , often outperforming state - of - the - art .",
        "however , it is important , for both theoreticians and practitioners , to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms .",
        "to address both concerns , we propose a novel architecture based on a network of deep neural networks , where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them .",
        "firstly , features of text images are extracted by the cnn network to obtain the deep visual representations .",
        "deep convolutional neural networks are generally regarded as robust function approximators .",
        "while recent work has proposed several techniques for automated option discovery , they do not scale to multi - level hierarchies and to expressive representations such as deep networks .",
        "we present discovery of deep options ( ddo ) , a policy - gradient algorithm that discovers parametrized options from a set of demonstration trajectories , and can be used recursively to discover additional levels of the hierarchy .",
        "we demonstrate that using the discovered options to augment the action space of deep q - network agents can accelerate learning by guiding exploration in tasks where random actions are unlikely to reach valuable states .",
        "to address this concern , a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network .",
        "large - scale deep neural networks ( dnn ) have been successfully used in a number of tasks from image recognition to natural language processing .",
        "specifically , using deep reinforcement learning , this work develops a time - efficient navigation policy that respects common social norms .",
        "we use the scattering network as a generic and fixed initialization of the first layers of a supervised hybrid deep network .",
        "we show that early layers do not necessarily need to be learned , providing the best results to - date with pre - defined representations while being competitive with deep cnns .",
        "in this paper , we present a joint compression and classification approach of eeg and emg signals using a deep learning approach .",
        "specifically , we build our system based on the deep autoencoder architecture which is designed not only to extract discriminant features in the multimodal data representation but also to reconstruct the data from the latent representation using encoder - decoder layers .",
        "we survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition .",
        "in a driving simulator domain where an agent learns an image - to - action deep network policy , our algorithm dart achieves a better performance than dagger with 75 % fewer demonstrations .",
        "recently , deep learning ( dl ) methods have been introduced very successfully into human activity recognition ( har ) scenarios in ubiquitous and wearable computing .",
        "especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real - life har application .",
        "in this paper we tackle such challenges through ensembles of deep long short term memory ( lstm ) networks .",
        "we demonstrate , both formally and empirically , that ensembles of deep lstm learners outperform the individual lstm networks .",
        "multiple different approaches of generating adversarial examples have been proposed to attack deep neural networks .",
        "to circumvent these issues , deep networks are being increasingly used , thanks to their ability to learn complex functions from large example sets .",
        "universal logic reasoning in turn , as envisioned already by leibniz , may support the rigorous formalisation and deep logical analysis of rational arguments within machines .",
        "in this paper , we propose a joint deep network model that combines adversarial training and perceptual feature regression for texture generation , while only random noise and user - defined perceptual attributes are required as input .",
        "our deep framework for the agent is trained end to end : it learns simultaneously the visual representations of the environment , the syntax and semantics of the language , and the action module that outputs actions .",
        "previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima .",
        "however , the practical observation is that , at least for the most successful deep convolutional neural networks ( dcnns ) for visual processing , practitioners can always increase the network size to fit the training data ( an extreme example would be [ 1 ] ) .",
        "to address this issue , we present two structure learning algorithms for deep cnn models .",
        "within hadid , a top - down hierarchical classification is applied , in which we use deep neural networks ( dnns ) method to build a local classifier for every parent node into the hierarchy dialect structure .",
        "an hybrid of a hidden markov model ( hmm ) and a deep neural network ( dnn ) is considered .",
        "in particular , the limitations of hand - designed structures and algorithms currently used in most deep neural networks could be overcome by more flexible and innovative solutions .",
        "deep neural perception and control networks are likely to be a key component of self - driving vehicles .",
        "we proposed a deep learning method for interpretable diabetic retinopathy ( dr ) detection .",
        "we believe this advantage of the proposed deep learning model is highly desired for dr detection because in practice , users are not only interested with high prediction performance , but also keen to understand the insights of dr detection and why the adopted learning model works .",
        "in this paper , we present midinet , a deep convolutional neural network ( cnn ) based generative adversarial network ( gan ) that is intended to provide a general , highly adaptive network structure for symbolic - domain music generation .",
        "we address the simplification problem with an encoder - decoder model coupled with a deep reinforcement learning framework .",
        "we demonstrate that standard deep features , in our case taken from a model trained for object classification , can be used together with a bilinear predictive model to learn an effective visual servo that is robust to visual variation , changes in viewing angle and appearance , and occlusions .",
        "one of the defining properties of deep learning is that models are chosen to have many more parameters than available training data .",
        "one roadblock to explaining these phenomena in terms of implicit regularization , structural properties of the solution , and / or easiness of the data is that many learning bounds are quantitatively vacuous in this \" deep learning \" regime .",
        "by optimizing the pac - bayes bound directly , we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples .",
        "we describe a method to produce a network where current methods such as deepfool have great difficulty producing adversarial samples .",
        "our construction suggests some insights into how deep networks work .",
        "however , training multiple deep networks for model averaging is computationally expensive .",
        "owing to the success of deep learning techniques for tasks such as q / a and text - based dialog , there is an increasing demand for ai agents in several domains such as retail , travel , entertainment , etc .",
        "however , deep learning research is this area has been limited primarily due to the lack of availability of large - scale , open conversation datasets .",
        "we also propose two novel multi - modal deep learning models in the encode - attend - decode paradigm and demonstrate their performance on two of the sub - tasks , namely text response generation and best image response selection .",
        "to overcome this , we explore several auxiliary tasks , including semantic super - sense tagging and identification of multi - word expressions , and cast the task as a multi - task learning problem with deep recurrent neural networks .",
        "in this work we present a new approach to learn compressible representations in deep architectures with an end - to - end training strategy .",
        "deep neural networks ( dnns ) have advanced the state - of - the - art in a variety of machine learning tasks and are deployed in increasing numbers of products and services .",
        "in this work , we propose dynamic variable effort deep neural networks ( dyvedeep ) to reduce the computational requirements of dnns during inference .",
        "complementary to these approaches , dyvedeep is a dynamic approach that exploits the heterogeneity in the inputs to dnns to improve their compute efficiency with comparable classification accuracy .",
        "dyvedeep equips dnns with dynamic effort mechanisms that , in the course of processing an input , identify how critical a group of computations are to classify the input .",
        "dyvedeep dynamically focuses its compute effort only on the critical computa - tions , while skipping or approximating the rest .",
        "although deep neural networks ( dnns ) have achieved great success in many computer vision tasks , recent studies have shown they are vulnerable to adversarial examples .",
        "we propose a novel deep layer cascade ( lc ) method to improve the accuracy and speed of semantic segmentation .",
        "unlike the conventional model cascade ( mc ) that is composed of multiple independent models , lc treats a single deep model as a cascade of several sub - models .",
        "first , lc classifies most of the easy regions in the shallow stage and makes deeper stage focuses on a few hard regions .",
        "second , lc accelerates both training and testing of deep network thanks to early decisions in the shallow stage .",
        "regarding integration , we note that the most impactful recent contributions have been made possible through the integration of recent machine learning methods ( based in particular on deep learning and recurrent neural networks ) with more traditional ones ( e .",
        "this report is targeted to groups who are subject matter experts in their application but deep learning novices .",
        "it contains practical advice for those interested in testing the use of deep neural networks on applications that are novel for deep learning .",
        "end - to - end training of deep learning - based models allows for implicit learning of intermediate representations based on the final task loss .",
        "we hypothesize that using intermediate representations as auxiliary supervision at lower levels of deep networks may be a good way of combining the advantages of end - to - end training and more traditional pipeline approaches .",
        "we explored three different deep learning approaches : a character - level convolutional neural network ( cnn ) , a stacked learner with an mlp meta - classifier , and an attention based bi - lstm .",
        "recently , deep learning methods have been shown to improve the performance of recommender systems over traditional methods , especially when review text is available .",
        "for example , a recent model , deepconn , uses neural nets to learn one latent representation for the text of all reviews written by a target user , and a second latent representation for the text of all reviews for a target item , and then combines these latent representations to obtain state - of - the - art performance on recommendation tasks .",
        "our model , called transnets , extends the deepconn model by introducing an additional latent layer representing the target user - target item pair .",
        "the method exploits the temporal structure of a speech signal and more specifically , it trains deep neural networks ( dnns ) to discriminate temporal events obtained by uniformly segmenting the signal without using any label information , in contrast to conventional dnn based bn feature extraction methods that train dnns using labeled data to discriminate speakers or passphrases or phones or a combination of them .",
        "here we present deeplift ( deep learning important features ) , a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input .",
        "deeplift compares the activation of each neuron to its ' reference activation ' and assigns contribution scores according to the difference .",
        "by optionally giving separate consideration to positive and negative contributions , deeplift can also reveal dependencies which are missed by other approaches .",
        "we apply deeplift to models trained on mnist and simulated genomic data , and show significant advantages over gradient - based methods .",
        "together with the proper choice of graph coarsening , we explore constructing deep neural networks for graph classification .",
        "in particular , we demonstrate the generality of our formulation in point cloud classification , where we set the new state of the art , and on a graph classification dataset , where we outperform other deep learning approaches .",
        "deep reinforcement learning has achieved many impressive results in recent years .",
        "deep learning and reinforcement learning methods have recently been used to solve a variety of problems in continuous control domains .",
        "we introduce two extensions to the deep deterministic policy gradient algorithm ( ddpg ) , a model - free q - learning based method , which make it significantly more data - efficient and scalable .",
        "for computer vision applications , prior works have shown the efficacy of reducing the numeric precision of model parameters ( network weights ) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters .",
        "given such a scenario , a standard deep reinforcement learning based dialogue agent may suffer to find a good policy due to the issues such as : increased state and action spaces , high sample complexity demands , sparse reward and long horizon , etc .",
        "in this paper , we propose to use hierarchical deep reinforcement learning approach which can operate at different temporal scales and is intrinsically motivated to attack these problems .",
        "experiments on both simulations and human evaluation show that our model significantly outperforms flat deep reinforcement learning agents in terms of success rate , rewards and user rating .",
        "it has been believed that stochastic feedforward neural networks ( sfnns ) have several advantages beyond deterministic deep neural networks ( dnns ) : they have more expressive power allowing multi - modal mappings and regularize better due to their stochastic nature .",
        "as the first step to model emotional state of a person , we build sentiment analysis models with existing deep neural network algorithms and compare the models with psychological measurements to enlighten the relationship .",
        "the result shows that although cnn performed the best among other deep neural network algorithms ( lstm , gru ) , its results are not related to the psychological state .",
        "in the meanwhile , deep learning has been widely studied and used in various classification problems includ - ing multi - label classification , however it has not been sufficiently studied in this extreme but practi - cal case , where the label space can be as large as in millions .",
        "in this paper , we propose a practical deep embedding method for extreme multi - label classifi - cation .",
        "deep reinforcement learning ( rl ) has achieved several high profile successes in difficult control problems .",
        "this may be acceptable for a simulator , but it severely limits the applicability of deep rl to many real - world tasks , where the agent must learn in the real environment .",
        "we present an algorithm , deep q - learning from demonstrations ( dqfd ) , that leverages this data to massively accelerate the learning process even from relatively small amounts of demonstration data .",
        "we show that dqfd has better initial performance than deep q - networks ( dqn ) on 40 of 42 atari games and it receives more average rewards than dqn on 27 of 42 atari games .",
        "when you need to enable deep learning on low - cost embedded socs , is it better to port an existing deep learning framework or should you build one from scratch ?",
        "our conclusion is that , on embedded devices , we most likely will use very simple deep learning models for inference , and with well - developed building blocks such as acl , it may be better in both performance and development time to build the engine from scratch .",
        "this paper presents a new 3d point cloud classification benchmark data set with over four billion manually labelled points , meant as input for data - hungry ( deep ) learning methods .",
        "we also discuss first submissions to the benchmark that use deep convolutional neural networks ( cnns ) as a work horse , which already show remarkable performance improvements over state - of - the - art .",
        "with the massive data set presented in this paper , we aim at closing this data gap to help unleash the full potential of deep learning methods for 3d labelling tasks .",
        "recent advances in deep neural networks have substantially improved the performance of this task .",
        "in order to adopt deep learning for ad - hoc information retrieval , it is essential to establish suitable representations of query - document pairs and to design neural architectures that are able to digest such representations .",
        "in this work , we address this gap by encoding the relevance matching in terms of similarity matrices and using a deep model to digest such matrices .",
        "recently , deep learning methods proved suitable to deal with remote sensing data mainly for scene classification ( i .",
        "convolutional neural networks - cnns - on single images ) while only very few studies exist involving temporal deep learning approaches ( i .",
        "in this work , we propose class - enhanced attentive response ( clear ) : an approach to visualize and understand the decisions made by deep neural networks ( dnns ) given a specific input .",
        "in this paper , we present an entity - drivenrecursive deep modelfor the chinese discourse coherence evaluation based on current english discourse coherenceneural network model .",
        "we introduce a novel framework for evaluating multimodal deep learning models with respect to their language understanding and generalization abilities .",
        "we develop direct and highly efficient reconstruction algorithms based on deep - learning .",
        "in this approach image reconstruction is performed with a deep convolutional neural network ( cnn ) , whose weights are adjusted prior to the actual image reconstruction based on a set of training data .",
        "our results demonstrate that the proposed deep learning approach reconstructs images with a quality komparable to state of the art iterative approaches from sparse data .",
        "the agent uses a deep recurrent neural network for function approximation .",
        "we propose a novel deep learning model for joint document - level entity disambiguation , which leverages learned neural representations .",
        "our approach thereby combines benefits of deep learning with more traditional approaches such as graphical models and probabilistic mention - entity maps .",
        "adversarial attack has cast a shadow on the massive success of deep neural networks .",
        "despite being almost visually identical to the clean data , the adversarial images can fool deep neural networks into wrong predictions with very high confidence .",
        "the framework represents the encoder as a deep nonlinear function through which samples from a simple distribution are fed .",
        "unlike recently released datasets , such as deepmind cnn / dailymail and squad , the proposed searchqa was constructed to reflect a full pipeline of general question - answering .",
        "we conduct human evaluation as well as test two baseline methods , one simple word selection and the other deep learning based , on the searchqa .",
        "to learn from the resulting rhetoric structure , we propose a tensor - based , tree - structured deep neural network ( named rst - lstm ) in order to process the complete discourse tree .",
        "this paper introduces a generic framework to train deep networks , end - to - end , with no supervision .",
        "we propose to fix a set of target representations , called noise as targets ( nat ) , and to constrain the deep features to align to them .",
        "we study the performance of faulty implementations of certain deep neural networks based on pessimistic and optimistic models of the effect of hardware faults .",
        "we introduce the first deep reinforcement learning agent that learns to beat atari games with the aid of natural language instructions .",
        "our agent significantly outperforms deep q - networks ( dqns ) , asynchronous advantage actor - critic ( a3c ) agents , and the best agents posted to openai gym on what is often considered the hardest atari 2600 environment : montezuma ' s revenge .",
        "despite being so vital to success of support vector machines , the principle of separating margin maximisation is not used in deep learning .",
        "we show that minimisation of margin variance and not maximisation of the margin is more suitable for improving generalisation in deep architectures .",
        "we propose the halfway loss function that minimises the normalised margin variance ( nmv ) at the output of a deep learning models and evaluate its performance against the softmax cross - entropy loss on the mnist , smallnorb and cifar - 10 datasets .",
        "in this paper , we propose a novel mer method by using deep convolutional neural network ( cnn ) on the music spectrograms that contains both the original time and frequency domain information .",
        "this paper presents an end - to - end deep learning framework using passive wifi sensing to classify and estimate human respiration activity .",
        "based on the results , we conclude that deep learning techniques coupled with passive radars offer great potential for end - to - end human activity recognition .",
        "we further analyze the effect of training iterations , compare networks trained with different initializations , examine the impact of network depth and width , and measure the effect of dropout and batch normalization on the interpretability of deep visual representations .",
        "recent studies have shown that embedding textual relations using deep neural networks greatly helps relation extraction .",
        "this paper presents a deep attention model on the basis of recurrent neural networks ( rnn ) to learn \\ textit { selectively } temporal hidden representations of sequential posts for identifying rumors .",
        "extensive experiments on real datasets collected from social media websites demonstrate that ( 1 ) the deep attention based rnn model outperforms state - of - the -",
        "this work is the first to overcome this limitation by interpreting the correlation filter learner , which has a closed - form solution , as a differentiable layer in a deep neural network .",
        "this enables learning deep features that are tightly coupled to the correlation filter .",
        "during the development stage , a deep neural network ( dnn ) that will be used to extract j - vector , is initialized and trained with the speech frames as input and the actual side information of the utterance as flat output block - wise one - hot labels .",
        "our method uses deep residual bidirectional lstms to compare questions and relation names via different hierarchies of abstraction .",
        "in this paper , we propose a new clustering model , called deep embedded regularized clustering ( depict ) , which efficiently maps data into a discriminative embedding subspace and precisely predicts cluster assignments .",
        "furthermore , we employ the reconstruction loss functions in our autoencoder , as a data - dependent regularization term , to prevent the deep embedding function from overfitting .",
        "although many decision - making problems like developing urban areas require such perception and reasoning , existing methods in this field usually neglect the deep knowledge mined from geographic databases and are based on pure statistical methods .",
        "in this work we present a method for using deep q - networks ( dqns ) in multi - objective tasks .",
        "deep q - networks provide remarkable performance in single objective tasks learning from high - level visual perception .",
        "we are using deep convolutional neural networks to represent complex features .",
        "we present a deep neural architecture that parses sentences into three semantic dependency graph formalisms .",
        "this demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision , including semantic segmentation or scene understanding .",
        "this paper provides a review on deep learning methods for semantic segmentation applied to various application areas .",
        "at last , we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques .",
        "we name it as deep keyphrase generation since it attempts to capture the deep semantic meaning of the content with a deep learning method .",
        "recent works have explored deep architectures for learning multimodal speech representation ( e .",
        "a deep q - network algorithm was applied and improved to develop an agent capable of learning to play different games in the framework .",
        "several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel .",
        "our approach is data - driven and simple to use in that it learns complex behavior of the vehicles from the massive amount of trajectory data through deep neural network model .",
        "to learn about the consequences of such different conceptualizations of claim for practical applications , we carried out extensive experiments using state - of - the - art feature - rich and deep learning systems , to identify claims in a cross - domain fashion .",
        "exponential linear units ( elus ) are a useful rectifier for constructing deep learning architectures , as they may speed up and otherwise improve learning by virtue of not have vanishing gradients and by having mean activations near zero .",
        "there is a wide gap between symbolic reasoning and deep learning .",
        "in this research , we explore the possibility of using deep learning to improve symbolic reasoning .",
        "briefly , in a reasoning system , a deep feedforward neural network is used to guide rewriting processes after learning from algebraic reasoning examples produced by humans .",
        "given recent deep learning results that demonstrate the ability to effectively optimize high - dimensional non - convex functions with gradient descent optimization on gpus , we ask in this paper whether symbolic gradient optimization tools such as tensorflow can be effective for planning in hybrid ( mixed discrete and continuous ) nonlinear domains with high dimensional state and action spaces ?",
        "we study unsupervised learning by developing introspective generative modeling ( igm ) that attains a generator using progressively learned deep convolutional neural networks .",
        "deep reinforcement learning ( rl ) recently emerged as one of the most competitive approaches for learning in sequential decision making problems with fully observable environments , e .",
        "however , very little work has been done in deep rl to handle partially observable environments .",
        "we propose a new architecture called action - specific deep recurrent q - network ( adrqn ) to enhance learning performance in partially observable domains .",
        "the time series of action - observation pairs are then integrated by an lstm layer that learns latent states based on which a fully connected layer computes q - values as in conventional deep q - networks ( dqns ) .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "while the optimization problem behind deep neural networks is highly non - convex , it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points .",
        "in recent years , deep learning based on artificial neural network ( ann ) has achieved great success in pattern recognition .",
        "a number of deep learning models have been proposed for this task .",
        "the recent remarkable growth and outstanding performance of deep learning have attracted considerable esearch attention .",
        "however , even in state - of - the - art drug analyses , deep learning continues to be used only as a classifier .",
        "in this paper , we propose the first end - to - end learning method for cci , named deepcci .",
        "the performance of deepcci was compared with a plain deep classifier and conventional machine learning methods .",
        "the proposed deepcci showed the",
        "among the suitable models for the framework , splice junction classification using deep recurrent neural networks ( rnns ) is most appropriate for performing dna steganalysis .",
        "despite the recent success of deep - learning based semantic segmentation , deploying a pre - trained road scene segmenter to a city whose images are not presented in the training set would not achieve satisfactory performance due to dataset biases .",
        "in recent years , deep neural networks have been used with great success in determining emotional states .",
        "to this purpose , we utilize a convolutional neural network ( cnn ) to extract features from the speech , while for the visual modality a deep residual network ( resnet ) of 50 layers .",
        "we study the problem of face deblurring by inserting weak supervision in the form of alignment in a deep network .",
        "we introduce parseval networks , a form of deep neural networks in which the lipschitz constant of linear , convolutional and aggregation layers is constrained to be smaller than 1 .",
        "parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation .",
        "recent advances in combining deep neural network architectures with reinforcement learning techniques have shown promising potential results in solving complex control problems with high dimensional state and action spaces .",
        "inspired by these successes , in this paper , we build two kinds of reinforcement learning algorithms : deep policy - gradient and value - function based agents which can predict the best possible traffic signal for a traffic intersection .",
        "in this paper , we propose a deep multi - view convolutional neural network to classify glitches automatically .",
        "the suggested classifier is a multi - view deep neural network that exploits four different views for classification .",
        "we discuss several modifications and extensions over the previous proposed cnvlutin ( cnv ) accelerator for convolutional and fully - connected layers of deep learning network .",
        "meanwhile , although recent work in deep learning has achieved impressive results in many fields , the knowledge is encoded in a subsymbolic representation which cannot be directly used by symbolic systems such as planners .",
        "we propose latplan , an integrated architecture combining deep learning and a classical planner .",
        "deep latent variable models have been shown to facilitate the response generation for open - domain dialog systems .",
        "deep learning refers to a set of machine learning techniques that utilize neural networks with many hidden layers for tasks , such as image classification , speech recognition , language understanding .",
        "deep learning has been proven to be very effective in these domains and is pervasively used by many internet services .",
        "in this paper , we describe different automotive uses cases for deep learning in particular in the domain of computer vision .",
        "\\ gpus and clouds ) for implementing , training and deploying deep neural networks .",
        "we describe an end - to - end deep learning application utilizing a mobile app for data collection and process support , and an amazon - based cloud backend for storage and training .",
        "two methods are studied : an end to end , deep neural network that directly uses audio waveforms as input versus a pipelined approach that performs asr ( automatic speech recognition ) on the question , followed by text - based visual question answering .",
        "compared with existing deep cnn based methods , our method achieves much better results with fewer training examples and model parameters .",
        "while artificial intelligence ( ai ) has become widespread , many commercial ai systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them .",
        "we show that this hybrid approach can improve a text - only deep learning model .",
        "using an implementation based on deep neural networks , we demonstrate that phantom sampling dramatically avoids catastrophic forgetting .",
        "we apply these strategies to competitive multi - class incremental learning of deep neural networks .",
        "deep neural networks ( dnns ) have provably enhanced the state - of - the - art neural machine translation ( nmt ) with their capability in modeling complex functions and capturing complex linguistic structures .",
        "however nmt systems with deep architecture in their encoder or decoder rnns often suffer from severe gradient diffusion due to the non - linear recurrent activations , which often make the optimization much more difficult .",
        "we explore the effectiveness of using deep reinforcement learning to handle intersection problems .",
        "combining several recent advances in deep rl , were we able to learn policies that surpass the performance of a commonly - used heuristic approach in several metrics including task completion time and goal success rate .",
        "the fact that deep rl policies resulted in collisions , although rarely , combined with the limitations of the policy to generalize well to out - of - sample scenarios suggest a need for further research .",
        "we analyze how the knowledge to autonomously handle one type of intersection , represented as a deep q - network , translates to other types of intersections ( tasks ) .",
        "we view intersection handling as a deep reinforcement learning problem , which approximates the state action q function as a deep neural network .",
        "such networks are often used in deep learning and have been shown to be hard to verify for modern satisfiability modulo theory ( smt ) and integer linear programming ( ilp ) solvers .",
        "recently , artificial neural networks , so called deep - learning approaches , have been proposed to address this challenge .",
        "this demo paper describes a software application that applies the tensorflow deep - learning framework to process prediction .",
        "popular deep learning frameworks require users to fine - tune their memory usage so that the training data of a deep neural network ( dnn ) fits within the gpu physical memory .",
        "we introduce a series of deep stochastic point processes , and contrast them with previous computational , simulation - based approaches .",
        "this paper introduces an sld - resolution technique based on deep learning .",
        "it includes a prolog library of deep feedforward neural networks and some essential functions of resolution .",
        "the driving force behind convolutional networks - the most successful deep learning architecture to date , is their expressive power .",
        "we present deep speaker , a neural speaker embedding system that maps utterances to a hypersphere where speaker similarity is measured by cosine similarity .",
        "the embeddings generated by deep speaker can be used for many tasks , including speaker identification , verification , and clustering .",
        "experiments on three distinct datasets suggest that deep speaker outperforms a dnn - based i - vector baseline .",
        "for example , deep speaker reduces the verification equal error rate by 50 % ( relatively ) and improves the identification accuracy by 60 % ( relatively ) on a text - independent dataset .",
        ", loosely labeled ) can be used to facilitate the data - hungry deep learning paradigms in building truly large - scale high precision computer - aided diagnosis ( cad ) systems .",
        "for the accurate detection of trafficking advertisements , we designed and trained a deep multimodal model called the human trafficking deep network ( htdn ) .",
        "we investigate gpu - based parallelization of iterative - deepening a * ( ida * ) .",
        "we argue that the optimization plays a crucial role in generalization of deep learning models through implicit regularization .",
        "we do so by studying the geometry of the parameter space of deep networks , and devising an optimization algorithm attuned to this geometry .",
        "we outperform the accuracy of the deep lstm setup of wu et al .",
        "deep neural models , particularly the lstm - rnn model , have shown great potential in language identification ( lid ) .",
        "we present a phone - aware neural lid architecture , which is a deep lstm - rnn lid system but accepts output from an rnn - based asr system .",
        "inspired by the deep learning approaches in natural language processing , we propose a recurrent neural network model with multiple attention layers for ddi classification .",
        "the experiments show that our model classifies most of the drug pairs into correct ddi categories , which outperforms the existing nlp or deep learning method .",
        "in this paper , we promote a novel deep learning model , omnirank , which comprehends multi - dimensional features of p2p platforms for risk quantification and produces scores for ranking .",
        "then we extract deep features of p2p platforms via text comprehension , topic modeling , knowledge graph and sentiment analysis , which are delivered",
        "deeptingle is a text prediction and classification system trained on the collected works of the renowned fantastic gay erotica author chuck tingle .",
        "whereas the writing assistance tools you use everyday ( in the form of predictive text , translation , grammar checking and so on ) are trained on generic , purportedly \" neutral \" datasets , deeptingle is trained on a very specific , internally consistent but externally arguably eccentric dataset .",
        "deeptingle is realized as a web application based on lstm networks and the glove word embedding , implemented in javascript with keras - js .",
        "we propose a novel evolutionary deep radiomic sequencer discovery approach based on evolutionary deep intelligence .",
        "motivated by patient privacy concerns and the idea of operational artificial intelligence , the evolutionary deep radiomic sequencer discovery approach organically evolves increasingly more efficient deep radiomic sequencers that produce significantly more compact yet similarly descriptive radiomic sequences over multiple generations .",
        "we evaluated the evolved deep radiomic sequencer ( edrs ) discovered via the proposed evolutionary deep radiomic sequencer discovery framework against state - of - the - art radiomics - driven and discovery radiomics methods using clinical lung ct data with pathologically - proven diagnostic data .",
        "the paper presents a novel concept for collaborative descriptors between deeply learned and hand - crafted features .",
        "relation extraction is an important sub - task of information extraction which has the potential of employing deep learning ( dl ) models with the creation of large datasets using distant supervision .",
        "recently deep neural networks ( dnns ) have been used to learn speaker features .",
        "this paper presents a convolutional time - delay deep neural network structure ( ct - dnn ) for speaker feature learning .",
        "the second part of this survey details the different approaches for vqa , classified into four types : non - deep learning models , deep learning models without attention , deep learning models with attention , and other models which do not fit into the first three .",
        "we present net2vec , a flexible high - performance platform that allows the execution of deep learning algorithms in the communication network .",
        "the intel collaborative research institute for computational intelligence ( icri - ci ) has been heavily supporting machine learning and deep learning research from its foundation in 2012 .",
        "we have asked six leading icri - ci deep learning researchers to address the challenge of \" why & amp ; when deep learning works \" , with the goal of looking inside deep learning , providing insights on how deep networks function , and uncovering key observations on their expressiveness , limitations , and potential .",
        "the output of this challenge resulted in five papers that address different facets of deep learning .",
        "these different facets include a high - level understating of why and when deep networks work ( and do not work ) , the impact of geometry on the expressiveness of deep networks , and making deep networks interpretable .",
        "in this paper , we take a deep look at the application of distant supervision in relation extraction .",
        "we also give an extensive empirical study on using common deep learning models for vietnamese ner , at both word and character level .",
        "bridging this gap , we develop a method to predict human impressions of faces in 40 subjective social dimensions , using deep representations from state - of - the - art neural networks .",
        "replacing hand - engineered pipelines with end - to - end deep learning systems has enabled strong results in applications like speech and object recognition .",
        "we then provide evidence for deeper limitations of the parallelogram model based on the intrinsic geometric constraints of vector spaces , paralleling classic results for first - order similarity .",
        "the recent success of deep learning in image recognition , natural language processing , and machine translation indicates a potential solution for stabilizing the malware detection effectiveness .",
        "deep learning usually involves a large number of parameters that cannot be learned from only a small dataset .",
        "we propose a novel framework for efficient parallelization of deep reinforcement learning algorithms , enabling these algorithms to learn from multiple actors on a single machine .",
        "also , in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments .",
        "this paper introduces an end - to - end fine - tuning method to improve hand - eye coordination in modular deep visuo - motor policies ( modular networks ) where each module is trained independently .",
        "we bridge this gap for models that exhibit a bipartite structure , including , most notably , the restricted / deep boltzmann machine .",
        "in recent years , the deep neural network has enjoyed a great success in large - scale image and video recognitions .",
        "in this paper , we propose and experiment using deep convolutional neural network to imitate how human brain processes hierarchical structures in the auditory signals , such as music , speech , etc .",
        "deep learning , iterative solvers , astrophysics , computational fluid dynamics , quantum chemistry ) .",
        "this article also tries to connect various research directions emerged out of the fnn optimization practices , such as evolving neural network ( nn ) , cooperative coevolution nn , complex - valued nn , deep learning , extreme learning machine , quantum n",
        "this paper presents experiments illustrating how formal language theory can shed light on deep learning .",
        "there is no need for a deep memory hierarchy as in a gpu , nor a fine - grain mesh as in a systolic array .",
        "good parameter settings are crucial to achieve high performance in many areas of artificial intelligence ( ai ) , such as satisfiability solving , ai planning , scheduling , and machine learning ( in particular deep learning ) .",
        "we present a practical approach for processing mobile sensor time series data for continual deep learning predictions .",
        "deep learning ( dl ) systems are increasingly deployed in security - critical domains including self - driving cars and malware detection , where the correctness and predictability of a system ' s behavior for corner - case inputs are of great importance .",
        "however , given the fact that deep reinforcement learning often deals with interpreting visual information , a large part of the train and inference time is spent performing convolutions .",
        "recently , deep convolutional neural network ( dcnn ) achieved increasingly remarkable success and rapidly developed in the field of natural image recognition .",
        "in this paper , we use deep learning methods , and in particular employ the multilayer perceptron , to build an algorithm that can predict flow pattern in twophase flow from fluid properties and pipe conditions .",
        "there are many applications scenarios for which the computational performance and memory footprint of the prediction phase of deep neural networks ( dnns ) needs to be optimized .",
        "deep neural networks ( dnns ) are presently the state - of - the - art for image classification tasks .",
        "in this paper , we derive inspiration from recent advances in the field of cybersecurity and multi - agent systems and propose to use the concept of moving target defense ( mtd ) for increasing the robustness of well - known deep networks trained on the imagenet dataset towards such adversarial attacks .",
        "the basic setup consists of two deep networks playing against each other in a zero - sum game setting .",
        "ultimately , the proposed framework provides an effective and scalable graph - based solution which is natural to the operational mechanism of deep neural networks .",
        "deep reinforcement learning ( drl ) methods have performed well in an increasing numbering of high - dimensional visual decision making domains .",
        "we propose a new learning paradigm , factored action space representations ( far ) wherein we decompose a control policy learned using a deep reinforcement learning algorithm into independent components , analogous to decomposing a vector in terms of some orthogonal basis vectors .",
        "we address the problem of reconstructing sparse signals from noisy and compressive measurements using a feed - forward deep neural network ( dnn ) with an architecture motivated by the iterative shrinkage - thresholding algorithm ( ista ) .",
        "the resulting architecture turns out to be a deep residual network , which has recently been shown to exhibit superior performance in several visual recognition tasks .",
        "while lambda - returns have been extensively studied in rl , they haven ' t been explored a lot in deep rl .",
        "the method introduced in this paper aims at helping deep learning practitioners faced with an overfit problem .",
        "how to develop slim and accurate deep neural networks has become crucial for real - world applications , especially for those employed in embedded systems .",
        "though previous work along this research line has shown some promising results , most existing methods either fail to significantly compress a well - trained deep network or require a heavy retraining process for the pruned deep network to re - boost its prediction performance .",
        "in this paper , we propose a new layer - wise pruning method for deep neural networks .",
        "recent advances in deep learning have enabled rl algorithms to achieve impressive performance in restricted domains such as playing atari video games ( mnih et al .",
        "the rise of graph - structured data such as social networks , regulatory networks , citation graphs , and functional brain networks , in combination with resounding success of deep learning in various applications , has brought the interest in generalizing deep learning models to non - euclidean domains .",
        "in this paper , we introduce a new spectral domain convolutional architecture for deep learning on graphs .",
        "transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data , where there are limited computational resources , or when tuning the hyper - parameters needed for training is not an option .",
        "while previous contributions to feature extraction propose embeddings based on a single layer of the network , in this paper we propose a full - network embedding which successfully integrates convolutional and fully connected features , coming from all layers of a deep convolutional neural network .",
        "deep neural networks have been shown to succeed at a range of natural language tasks such as machine translation and text summarization .",
        "as first solutions , we design a set of deep neural models that learn to represent the context of each variable location and variable usage in a data flow - sensitive way .",
        "in this work , we propose terngrad that uses ternary gradients to accelerate distributed deep learning in data parallelism .",
        "experiments show significant speed gains for various deep neural networks .",
        "in this paper , we show that deep learning techniques can be leveraged to automatically generate code given a graphical user interface screenshot as input .",
        "in this work , we focus on one important aspect of communication systems , the detection algorithms , and demonstrate that by borrowing tools from deep learning , it is possible to train detectors that perform well , without any knowledge of the underlying channel models .",
        "we show that deep learning algorithms perform significantly better than a simple detector that was used in previous works , which also did not assume any knowledge of the channel .",
        "this work is a first thorough study of memory structures for deep - neural - network - based robot navigation , and offers novel tools to train such networks from supervision and quantify their ability to generalize to unseen scenarios .",
        "the reported method can be applied to deep learning problems beyond robotics .",
        "to ensure cross - task generalization , we develop a deep predictive model based on successor representations .",
        "applying deep reinforcement learning ( rl ) on real systems suffers from slow data sampling .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "in this work , we propose a new approach to deduce optimal treatment policies for septic patients by using continuous state - space models and deep reinforcement learning .",
        "we introduce an architecture in which internal representations , learned by end - to - end optimization in a deep neural network performing a textual question - answering task , can be interpreted using basic concepts from linguistic theory .",
        "planning new policies is performed by tree search , while a deep neural network generalises those plans .",
        "in contrast , standard deep reinforcement learning algorithms rely on a neural network not only to generalise plans , but to discover them too .",
        "we then analyze the effects of using second - order embeddings as input features in two deep natural language processing models , for named entity recognition and recognizing textual entailment , as well as a linear model for paraphrase recognition .",
        "we achieve state - of - the - art results on our predictive tasks using deep architectures .",
        "selective classification techniques ( also known as reject option ) have not yet been considered in the context of deep neural networks ( dnns ) .",
        "inspired by the success of using deep convolutional features for natural image analysis and multi - instance learning ( mil ) for labeling a set of instances / patches , we propose end - to - end trained deep multi - instance networks for mass classification based on whole mammogram without the aforementioned rois .",
        "we explore three different schemes to construct deep multi - instance networks for whole mammogram classification .",
        "generative moment matching network ( gmmn ) is a deep generative model that differs from generative adversarial network ( gan ) by replacing the discriminator in gan with a two - sample test based on kernel maximum mean discrepancy ( mmd ) .",
        "inspired by the generative nature of hippocampus as a short - term memory system in primate brain , we propose the deep generative replay , a novel framework with a cooperative dual model architecture consisting of a deep generative model ( \" generator \" ) and a task solving model ( \" solver \" ) .",
        "this paper is a deep investigation of cross - language plagiarism detection methods on a new recently introduced open dataset , which contains parallel and comparable collections of documents with multiple characteristics ( different genres , languages and sizes of texts ) .",
        "we investigate cross - language plagiarism detection methods for 6 language pairs on 2 granularities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages .",
        "as a starting point , we show improvements over the two state - ofthe - art approaches for single - speaker neural tts : deep voice 1 and tacotron .",
        "we introduce deep voice 2 , which is based on a similar pipeline with deep voice 1 , but constructed with higher performance building blocks and demonstrates a significant audio quality improvement over deep voice 1 .",
        "we then demonstrate our technique for multi - speaker speech synthesis for both deep voice 2 and tacotron on two multi - speaker tts datasets .",
        "we introduce a class of deep recurrent neural operations and formally characterize their associated kernel spaces .",
        "we report results for learning the cdprs with a deep neural network and using them to solve two tasks with deep reinforcement learning .",
        "deep learning has shown promising results on hard perceptual problems in recent years .",
        "however , deep learning systems are found to be vulnerable to small adversarial perturbations that are nearly imperceptible to human .",
        "such specially crafted perturbations cause deep learning systems to output incorrect decisions , with potentially disastrous consequences .",
        "these vulnerabilities hinder the deployment of deep learning systems where safety or security is important .",
        "attempts to secure deep learning systems either target specific attacks or have been shown to be ineffective .",
        "the deep neural network outperforms other state of the art shallow classification models in predicting labels derived from three different dental plaque assessment scores .",
        "there have been many approaches to attempt learning patterns of motion directly from data using a wide variety of techniques ranging from hand - crafted features to sophisticated deep learning models for unsupervised feature learning .",
        "we propose an end to end deep learning model to learn the motion patterns of humans using different navigational modes directly from data using the much popular sequence to sequence model coupled with a soft attention mechanism .",
        "we propose a hierarchical multi - view deep learning approach to contextualise citizen observations of various city systems and services .",
        "a deep , classification - specific attention mechanism improves further the overall performance of the rnn .",
        "deep learning approaches are still not very common in the speaker verification field .",
        "we investigate the possibility of using deep residual convolutional neural network with spectrograms as an input features in the text - dependent speaker verification task .",
        "the parser is implemented as a deep neural network whose only input is orthographic representations of words .",
        "in this paper we report on results using a language model approach , and outline our plans for using methods from deep learning .",
        "in this work , we present a novel approach to ontology reasoning that is based on deep learning rather than logic - based formal reasoning .",
        "to this end , we introduce a new model for statistical relational learning that is built upon deep recursive neural networks , and give experimental evidence that it can easily compete with , or even outperform , existing logic - based reasoners on the task of ontology reasoning .",
        "we show that a modular neural network ( mnn ) can combine various speech enhancement modules , each of which is a deep neural network ( dnn ) specialized on a particular enhancement job .",
        "we see this as collaborative deep learning ( cdl ) , because it can reuse various already - trained dnn models without any further refining .",
        "recent advances in combining deep learning and reinforcement learning have shown a promising path for designing new control agents that can learn optimal policies for challenging control tasks .",
        "this paper proposes a cs scheme that exploits the representational power of restricted boltzmann machines and deep learning architectures to model the prior distribution of the sparsity pattern of signals belonging to the same class .",
        "despite the success of deep learning on many fronts especially image and speech , its application in text classification often is still not as good as a simple linear svm on n - gram tf - idf representation especially for smaller datasets .",
        "deep learning tends to emphasize on sentence level semantics when learning a representation with models like recurrent neural network or recursive neural network , however from the success of tf - idf representation , it seems a bag - of - words type of representation has its strength .",
        "we also demonstrate that this model beats traditional linear models on tf - idf vectors on small and polished datasets like news article in which typically deep learning",
        "by incorporating automatic syntactic features with word embeddings as input for bidirectional long short - term memory ( bi - lstm ) , our system , although simpler than some deep learning architectures , achieves a much better result for vietnamese ner .",
        "adversarial learning has been successfully embedded into deep networks to learn transferable features for domain adaptation , which reduce distribution discrepancy between the source and target domains and improve generalization performance .",
        "in this paper , we present randomized multilinear adversarial networks ( rman ) , which exploit multiple feature layers and the classifier layer based on a randomized multilinear adversary to enable both deep and discriminative adversarial adaptation .",
        "in this short note , we report on recent results showing that simple feature squeezing techniques also make deep learning models significantly more robust against the carlini / wagner attacks , which are the best known adversarial methods discovered to date .",
        "deep neural networks trained on large supervised datasets have led to impressive results in recent years .",
        "in this paper , we investigate the behavior of deep neural networks on training sets with massively noisy labels .",
        "however , data - driven based supervised approaches , particularly the ones designed with deep learning , have recently emerged as potential alternatives .",
        "in this light , we are going to comprehensively summarise the recently developed and most representative deep learning approaches to deal with the raised problem in this article , with the aim of providing guidelines for those who are going deeply into the field of environmentally robust speech recognition .",
        "recent progress in reinforcement learning ( rl ) , fueled by its combination , with deep learning has enabled impressive results in learning to interact with complex virtual environments , yet real - world applications of rl are still scarce .",
        "we propose an algorithm to automatically learn learning rates using neural network based actor - critic methods from deep reinforcement learning ( rl ) .",
        "however , the lack of an efficient way to calculate the importance still hinders its application to deep learning .",
        "in this paper , we show that the loss value can be used as an alternative importance metric , and propose a way to efficiently approximate it for a deep model , using a small model trained for that purpose in parallel .",
        "in appendix , with knowledge of learning machine , we try to view deep learning from a different angle , i .",
        "we present an optimized image generation process based on a deep convolutional generative adversarial networks ( dcgans ) , in order to create photorealistic high - resolution images ( up to 1024x1024 pixels ) .",
        "deep neural network ( dnn ) are currently of great inter - est in research and application .",
        "we perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity .",
        "our experiments on a benchmark dataset of 16k annotated tweets show that such deep learning methods outperform state - of - the - art char / word n - gram methods by ~ 18 f1 points .",
        "off - policy model - free deep reinforcement learning methods using previously collected data can improve sample efficiency over on - policy policy gradient techniques .",
        "this paper examines , both theoretically and empirically , approaches to merging on - and off - policy updates for deep reinforcement learning .",
        "the final algorithm provides a generalization and unification of existing deep policy gradient techniques , has theoretical guarantees on the bias introduced by off - policy updates , and improves on the state - of - the - art model - free deep rl methods on a number of openai gym continuous control benchmarks .",
        "a deep convolutional neural network approach is developed to model the voxel - wise spatio - temporal tumor progression .",
        "the deep features are combined with the time intervals and the clinical factors to feed a process of feature selection .",
        "stripes is a deep neural network ( dnn ) accelerator that uses bit - serial computation to offer performance that is proportional to the fixed - point precision of the activation values .",
        "deep neural networks are able to solve tasks across a variety of domains and modalities of data .",
        "we demonstrate the effectiveness of our framework on a variety of deep neural network architectures in domains from computer vision , natural language processing , and reinforcement learning .",
        "yet , a unifying perspective that could embrace both these branches of research is of great importance as it enables a deeper understanding of all involved methods and principles and creates room for their cross - fertilisation , ripening and further development .",
        "though the recent progress is substantial , deep learning methods can be vulnerable to the elaborately crafted adversarial samples .",
        "in training , we propose to minimize the reverse cross - entropy , which encourages a deep network to learn latent representations that better distinguish adversarial samples from normal ones .",
        "exploiting the great expressive power of deep neural network architectures , relies on the ability to train them .",
        "training a deep convolutional neural network ( cnn ) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence .",
        "in this paper , we seek to answer the following central question in the context of medical image analysis : \\ emph { can the use of pre - trained deep cnns with sufficient fine - tuning eliminate the need for training a deep cnn from scratch ? }",
        "to address this question , we considered 4 distinct medical imaging applications in 3 specialties ( radiology , cardiology , and gastroenterology ) involving classification , detection , and segmentation from 3 different imaging modalities , and investigated how the performance of deep cnns trained from scratch compared with the pre - trained cnns fine - tuned in a layer - wise manner .",
        "recent advances in deep learning motivate the use of deep neutral networks in sensing applications , but their excessive resource needs on constrained embedded devices remain an important impediment .",
        "a recently explored solution space lies in compressing ( approximating or simplifying ) deep neural networks in some manner before use on the device .",
        "we propose a new compression solution , called deepiot , that makes two key contributions in that space .",
        "first , unlike current solutions geared for compressing specific types of neural networks , deepiot presents a unified approach that compresses all commonly used deep learning structures for sensing applications , including fully - connected , convolutional , and recurrent neural networks , as well as their combinations .",
        "second , unlike solutions that either sparsify weight matrices or assume linear structure within weight matrices , deepiot compresses neural network structures into smaller dense matrices by finding the minimum number of non - redundant hidden elements , such as filters and dimensions required by each layer , while keeping the performance of sensing applications the same .",
        "we demonstrate that with the help of existing ' deep ' linguistic processing technology we are able to create challenging abstract datasets , which enable us to investigate the language understanding abilities of multimodal deep learning models in detail .",
        "our work shows how a deep learning architecture equipped with an rn module can implicitly discover and learn to reason about entities and their relations .",
        "in this regard , we design a multimodal biometric authentication system named deepkey which uses both gait and electroencephalography ( eeg ) signals to provide better protection against such risks .",
        "deepkey consists of three key components : an invalid id filter model to block invalid subjects , a gait identification model to recognize gait ids and an eeg identification model to recognize eeg ids .",
        "in particular , the first two models employ a one - class svm algorithm and a recurrent neural network based deep learning model , respectively .",
        "deepkey is trained with a gait dataset of 160 , 000 samples and an eeg dataset of 108 , 000 samples .",
        "experimental results show deepkey outperforms",
        "it is challenging to develop stochastic gradient based scalable inference for deep discrete latent variable models ( lvms ) , due to the difficulties in not only computing the gradients , but also adapting the step sizes to different latent factors and hidden layers .",
        "for the poisson gamma belief network ( pgbn ) , a recently proposed deep discrete lvm , we derive an alternative representation that is referred to as deep latent dirichlet allocation ( dlda ) .",
        "we propose a web - based visualization tool , \\ textit { adversarial - playground } , to demonstrate the efficacy of common adversarial methods against a deep neural network ( dnn ) model , built on top of the tensorflow library .",
        "in this paper , we demonstrated that the speaker factor is also a short - time spectral pattern and can be largely identified with just a few frames using a simple deep neural network ( dnn ) .",
        "this discovery motivated a cascade deep factorization ( cdf ) framework that infers speech factors in a sequential way , and factors previously inferred are used as conditional variables when inferring other factors .",
        "increasingly , cognitive scientists have demonstrated interest in applying tools from deep learning .",
        "one use for deep learning is in language acquisition where it is useful to know if a linguistic phenomenon can be learned through domain - general means .",
        "to assess whether unsupervised deep learning is appropriate , we first pose a smaller question : can unsupervised neural networks apply linguistic rules productively , using them in novel situations ?",
        "further , this work helps lay the foundations for future collaboration between the deep learning and cognitive science communities .",
        "four runs were submitted , with approaches ranging from a trivial system that selected the first $ n $ snippets , to the use of deep learning approaches under a regression framework .",
        "the basic features of some of the most versatile and popular open source frameworks for machine learning ( tensorflow , deep learning4j , and h2o ) are considered and compared .",
        "the performance tests for the de facto standard mnist data set were carried out on h2o framework for deep learning algorithms designed for cpu and gpu platforms for single - threaded and multithreaded modes of operation .",
        "our model is able to select syntactically plausible candidates and - if disregarding syntax - discriminates candidates using deeper features .",
        "deeper inspection shows that the model is able to learn a relation between the anaphor in the anaphoric sentence and its antecedent .",
        "we explore deep reinforcement learning methods for multi - agent domains .",
        "the paradigm shift from shallow classifiers with hand - crafted features to end - to - end trainable deep learning models has shown significant improvements on supervised learning tasks .",
        "despite the promising power of deep neural networks ( dnn ) , how to alleviate overfitting during training has been a research topic of interest .",
        "deep neural networks ( dnn ) have been successfully applied for music classification including music tagging .",
        "in this article , we investigate specific aspects of neural networks to deepen our understanding of their properties .",
        "we propose a deep dynamic neural network model built on a dynamic vision network , a motor generation network , and a higher - level network .",
        "deep learning requires data .",
        "deep learning thrives with large neural networks and large datasets .",
        "the encoder is a deep convolutional neural network ( cnn ) based on the vgg network .",
        "as part of this development , we examine the parallels between latent variable trajectories operating across multiple time - scales during optimization , and the activations within deep network structures designed to adaptively model such characteristic sequences .",
        "deep convolutional neural networks are being actively investigated in a wide range of speech and audio processing applications including speech recognition , audio event detection and computational paralinguistics , owing to their ability to reduce factors of variations , such as speaker and environment information in signals , for speech recognition .",
        "however , studies have suggested to favor a certain type of convolutional operations when building a deep convolutional neural network for speech applications although there has been promising results using different types of convolutional operations .",
        "since affective behavioral information has been shown to reflect temporally varying of mental state and convolutional operation are applied locally in time , all deep neural networks share a deep recurrent sub - network architecture for further temporal modeling .",
        "finally we show that all of our deep neural networks provide state - of - the",
        "this paper aims at one - shot learning of deep neural nets , where a highly parallel setting is considered to address the algorithm calibration problem - selecting the best neural architecture and learning hyper - parameter values depending on the dataset at hand .",
        "the selection of hyper - parameters is critical in deep learning .",
        "we show that such methods have theoretical properties that make them appealing for performing hyperparameter search , and demonstrate that , when applied to the selection of hyperparameters of complex deep learning models ( such as state - of - the - art lstm language models and image classification models ) , they yield suitable hyperparameters values with much fewer runs than random search .",
        "we focus on progressive neural networks and compare these networks to the conventional deep learning method of pre - training and fine - tuning .",
        "we adopted an approach we dub \" deep optimization \" , taking a data - driven , highly parametric , and computationally intensive approach to solver design .",
        "in this thesis , we consider the problem of using probabilistic deep learning model to learn the topological map , which is essentially a sparse undirected graph where nodes represent places annotated with their semantic attributes ( e .",
        "we propose to use a novel probabilistic deep model , sum - product networks ( spns ) , due to their unique properties .",
        "in this work , we initiate the exploration of the use of tools from deep learning on this topic .",
        "we conclude by demonstrating the potential of deep learning for deriving optimal auctions with high revenue for poorly understood problems .",
        "popular independent ensembles ( ie ) relying on naive averaging / voting scheme have been of typical choice for most applications involving deep neural networks , but they do not consider advanced collaboration among ensemble models .",
        "in this paper , we propose new ensemble methods specialized for deep neural networks , called confident multiple choice learning ( cmcl ) : it is a variant of multiple choice learning ( mcl ) via addressing its overconfidence issue .",
        "we design an enriched deep recurrent visual attention model ( edram ) - an improved attention - based architecture for multiple object recognition .",
        "factoid question answering ( qa ) has recently benefited from the development of deep learning ( dl ) systems .",
        "while going deeper has been witnessed to improve the performance of convolutional neural networks ( cnn ) , going smaller for cnn has received increasing attention recently due to its attractiveness for mobile / embedded applications .",
        "it remains an active and important topic how to design a small network while retaining the performance of large and deep cnns ( e .",
        "first , we propose a simple yet powerful method for compressing the size of deep cnns based on parameter binarization .",
        "by doing this , we show that previous deep cnns such as googlenet and inception - type nets can be compressed dramatically",
        "we analyze this phenomenon and devise provably good initialization strategies for dual optimization as well as heuristics for the non - convex case , relevant for deep learning .",
        "recommendation algorithms that incorporate techniques from deep learning are becoming increasingly popular .",
        "monte carlo tree search ( mcts ) is extremely popular in computer go which determines each action by enormous simulations in a broad and deep search tree .",
        "the first part is a novel deep alternative neural network ( dann ) used to generate candidates of next move .",
        "compared with existing deep convolutional neural network ( dcnn ) , dann inserts recurrent layer after each convolutional layer and stacks them in an alternative manner .",
        "in typical deep rl methods this is achieved by approximating the optimal value function with a low - dimensional representation using a deep network .",
        "the recent adaptation of deep neural network - based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks .",
        "one of the constraints that limits full exploration of deep learning technologies for semantic parsing is the lack of sufficient annotation training data .",
        "in particular , in the context of deep learning , we empirically show that the spectrum of the hessian is composed of two parts : ( 1 ) the bulk centered near zero , ( 2 ) and outliers away from the bulk .",
        "at the heart of deep learning we aim to use neural networks as function approximators - training them to produce outputs from inputs in emulation of a ground truth function or data creation process .",
        "the state - of - the - art solutions to the vocabulary mismatch in information retrieval ( ir ) mainly aim at leveraging either the relational semantics provided by external resources or the distributional semantics , recently investigated by deep neural approaches .",
        "guided by the intuition that the relational semantics might improve the effectiveness of deep neural approaches , we propose the deep semantic resource inference model ( dsrim ) that relies on : 1 ) a representation of raw - data that models the relational semantics of text by jointly considering objects and relations expressed in a knowledge resource , and 2 ) an end - to - end neural architecture that learns the query - document relevance by leveraging the distributional and relational semantics of documents and queries .",
        "the experimental evaluation carried out on two trec datasets from trec terabyte and trec cds tracks relying respectively on wordnet and mesh resources , indicates that our model outperforms state - of - the - art semantic and deep neural ir models .",
        "deep neural networks are known to be difficult to train due to the instability of back - propagation .",
        "a deep \\ emph { residual network } ( resnet ) with identity loops remedies this by stabilizing gradient computations .",
        "therefore , we introduce an alternative deep resnet training algorithm , \\ emph { boostresnet } , which is particularly suitable in non - differentiable architectures .",
        "inspired by the recent success of deep learning models in solving various vision problems ( e .",
        "variational autoencoders ( vae ) represent a popular , flexible form of deep generative model that can be stochastically fit to samples from a given random process using an information - theoretic variational bound on the true underlying distribution .",
        "we examine the role of memorization in deep learning , drawing connections to capacity , generalization , and adversarial robustness .",
        "while deep networks are capable of memorizing noise data , our results suggest that they tend to prioritize learning simple patterns first .",
        "in our experiments , we expose qualitative differences in gradient - based optimization of deep neural networks ( dnns ) on noise vs .",
        "our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization .",
        "adaptive gradient methods have become recently very popular , in particular as they have been shown to be useful in the training of deep neural networks .",
        "in this paper we have analyzed rmsprop , originally proposed for the training of deep neural networks , in the context of online convex optimization and show $ \\ sqrt { t } $ - type regret bounds .",
        "finally , we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or stochastic gradient descent in the optimization of strongly convex functions as well as in training of deep neural networks .",
        "convolution is a critical component in modern deep neural networks , thus several algorithms for convolution have been developed .",
        "deep neural networks ( dnns ) have advanced performance on a wide range of complex tasks , rapidly outpacing our understanding of the nature of their solutions .",
        "inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task .",
        "specifically , safetynets develops and implements a specialized interactive proof ( ip ) protocol for verifiable execution of a class of deep neural networks , i .",
        "our empirical results on three - and four - layer deep neural networks demonstrate the run - time costs of safetynets for both the client and server are low .",
        "we propose a novel deep neural networks ( dnn ) based model , canonical correlated autoencoder ( c2ae ) , for solving this task .",
        "aiming at better relating feature and label domain data for improved classification , we uniquely perform joint feature and label embedding by deriving a deep latent space , followed by the introduction of label - correlation sensitive loss function for recovering the predicted label outputs .",
        "we propose a deep network , which not only achieves competitive accuracy for text classification , but also exhibits compositional behavior .",
        "in contrast , the higher layers compose meaningful phrases and clauses , whose lengths increase as the networks get deeper until fully composing the sentence .",
        "deep generative models have recently shown great promise in imitation learning for motor control .",
        "this paper proposes a novel deep reinforcement learning ( rl ) architecture , called value prediction network ( vpn ) , which integrates model - free and model - based rl methods into a single neural network .",
        "furthermore , vpn outperforms deep q - network ( dqn ) on several atari games even with short - lookahead planning , demonstrating its potential as a new way of learning a good state representation .",
        "in this paper , we propose a novel deep learning method named projection - recovery network ( prnet ) to blindly calibrate sensor measurements online .",
        "the prnet first projects the drifted data to a feature space , and uses a powerful deep convolutional neural network to recover the estimated drift - free measurements .",
        "we also provide helpful insights for designing deep neural networks for sensor calibration .",
        "in this paper , we propose a novel deep neural network architecture which allows it to learn without any significant increase in number of parameters .",
        "we investigate the compositional structure of message vectors computed by a deep network trained on a communication game .",
        "domain adaptation is an important open problem in deep reinforcement learning ( rl ) .",
        "darla significantly outperforms conventional baselines in zero - shot domain adaptation scenarios , an effect that holds across a variety of rl environments ( jaco arm , deepmind lab ) and base rl algorithms ( dqn , a3c and ec ) .",
        "by contrast , logical semantic representations capture deeper levels of sentence semantics , but their symbolic nature does not offer graded notions of textual similarity .",
        "deep residual learning ( resnet ) is a new method for training very deep neural networks using identity map - ping for shortcut connections .",
        "in contradictory to popular beliefs that resnet only works well for very deep networks , we found that even with 9 layers of cnns , using identity mapping could significantly improve the performance for distantly - supervised relation extraction .",
        "we show that small and shallow feed - forward neural networks can achieve near state - of - the - art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models .",
        "this paper presents an attention - based deep learning approach ; we call attentivechrome , that uses a unified architecture to model and to interpret dependencies among chromatin factors for controlling gene regulation .",
        "we propose a new framework for abstractive text summarization based on a sequence - to - sequence oriented encoder - decoder model equipped with a deep recurrent generative decoder ( drgn ) .",
        "we propose a dynamic ranking paradigm , named as dnn - mab , that is composed of a pairwise deep neural network ( dnn ) $ \\ mathit { pre } $ - ranker connecting a revised multi - armed bandit ( mab ) dynamic $ \\ mathit { post } $ - ranker .",
        "this paper introduces a corpus for text - based emotion detection on multiparty dialogue as well as deep neural models that outperform the existing approaches for document classification .",
        "this paper proposes a text summarization approach for factual reports using a deep learning model .",
        "we investigate carefully functional segment identification in two approaches : ( 1 ) machine learning approach using maximum entropy ( me ) and conditional random fields ( crfs ) ; ( 2 ) deep learning approach using bidirectional long short - term memory ( lstm ) with a crf layer ( bi - lstm - crf ) on two different conversational datasets : ( 1 ) facebook messages ( message data ) ; ( 2 ) transcription from phone conversations ( phone data ) .",
        "to the best of our knowledge , this is the first work that applies deep learning based approach to dialog act segmentation .",
        "as the results show , deep learning approach performs appreciably better as to compare",
        "existing works based on deep neural network ( dnn ) mostly construct one common space for different modalities to find the latent alignments between them , which lose their exclusive modality - specific characteristics .",
        "finally , we present initial baseline results for canonical deep reinforcement learning agents applied to the starcraft ii domain .",
        "given a set of sentences from a book or even a fan - fiction written in the same universe , we employ deep learning models to visualize the input by stitching together relevant frames from the movie .",
        "in this paper , we propose to use deep 3 - dimensional convolutional networks ( 3d cnns ) in order to address the challenge of modelling spectro - temporal dynamics for speech emotion recognition ( ser ) .",
        "we found that 1 ) shallow temporal and moderately deep spectral kernels of a homogeneous architecture are optimal for the task ; and 2 ) our 3d cnns are more effective for spectro - temporal feature learning compared to other methods .",
        "inspired by recent advances in using deep memory networks for question answering ( qa ) , we propose a new approach which considers emotion cause identification as a reading comprehension task in qa .",
        "in this paper we describe a deep learning system that has been designed and built for the wassa 2017 emotion intensity shared task .",
        "we present ladder , the first deep reinforcement learning agent that can successfully learn control policies for large - scale real - world problems directly from raw inputs composed of high - level semantic information .",
        "the agent is based on an asynchronous stochastic variant of dqn ( deep q network ) named dasqn .",
        "preprocessing for deep learning is characterized by pipelines that lazily load data and perform data transformation , augmentation , batching and logging .",
        "here we introduce a novel software framework named nuts - flow / ml that encapsulates common preprocessing operations as components , which can be flexibly arranged to rapidly construct efficient preprocessing pipelines for deep learning .",
        "in this paper , we show that an adversary can automate the feature engineering process , and thus automatically deanonymize tor traffic by applying our novel method based on deep learning .",
        "we evaluate our approach on a dataset comprised of more than three million network traces , which is the largest dataset of web traffic ever gathered for website fingerprinting , and find that the performance achieved by deep learning techniques is comparable to known approaches which include various research efforts spanning over multiple years .",
        "the deployment of deep convolutional neural networks ( cnns ) in many real world applications is largely hindered by their high computational cost .",
        "deep learning - based techniques have achieved state - of - the - art performance on a wide variety of recognition and classification tasks .",
        "in this paper we introduce a deep learning framework for learning koopman operators of nonlinear dynamical systems .",
        "we show that this novel method automatically selects efficient deep dictionaries , outperforming state - of - the - art methods .",
        "the techniques from the literature that are presented herein have great performances , however , instead of the machine learning techniques employed in these works , we propose to use deep learning techniques such as long - short term memory ( lstm ) recurrent neural network ( rnn ) , and show the improved performance .",
        "deep neural networks are generally trained using iterative gradient updates .",
        "second , deep neural networks can be used to automatically combine input features , and including non - local features that capture semantic patterns that cannot be expressed using discrete indicator features .",
        "for such domains , we propose to use deep neural networks in learning for planning , based on learning a reactive policy that imitates execution traces produced by a planner .",
        "we investigate architectural properties of deep networks that are suitable for learning long - horizon planning behavior , and explore how to learn , in addition to the policy , a heuristic function that can be used with classical planners or search algorithms such as a * .",
        "in this paper , we present algorithms for converting a deep representation of a story into a dialogic storytelling , that can vary aspects of the telling , including the personality of the storytellers .",
        "in particular , the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance .",
        "this article provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years .",
        "in particular , we show that layered learning approaches such as deep belief networks excel along these dimensions .",
        "recent advances in deep neural networks ( dnns ) have led to the development of dnn - driven autonomous cars that , using sensors like camera , lidar , etc .",
        "we first explain how a simple annotation tool allows naive annotators to easily create a deep representation of fabula called a story intention graph , and show how we use this representation to generate story tellings automatically .",
        "the basic features of some of the most versatile and popular open source frameworks for machine learning ( tensorflow , deep learning4j , and h2o ) are considered and compared .",
        "the performance tests for the de facto standard mnist data set were carried out on h2o framework for deep learning algorithms designed for cpu and gpu platforms for single - threaded and multithreaded modes of operation also , we present the results of testing neural networks architectures on h2o platform for various activation functions , stopping metrics , and other parameters of machine learning algorithm .",
        "compared to current poisoning strategies , our approach is able to target a wider class of learning algorithms , trained with gradient - based procedures , including neural networks and deep learning architectures .",
        "with the development of deep learning , new ideas have appeared to address har problems .",
        "here , a deep network architecture using residual bidirectional long short - term memory ( lstm ) cells is proposed .",
        "generally , the proposed network shows improvements on both the temporal ( using bidirectional cells ) and the spatial ( residual connections stacked deeply ) dimensions , aiming to enhance the recognition rate .",
        "we present a new corpus , personabank , consisting of 108 personal stories from weblogs that have been annotated with their story intention graphs , a deep representation of the fabula of a story .",
        "to jointly answer the questions of \" where do people live \" and \" how many people live there , \" we propose a deep learning model for creating high - resolution population estimations from satellite imagery .",
        "the usefulness of this concept is illustrated over a number of applied areas , including generalized regression and classification ( support tensor machines , canonical correlation analysis , higher order partial least squares ) , generalized eigenvalue decomposition , riemannian optimization , and in the optimization of deep neural networks .",
        "we evaluate state - of - the - art deep convolutional neural network ( cnns ) on this novel dataset with its different spectral bands .",
        "we also evaluate deep cnns on existing remote sensing datasets and compare the obtained results .",
        "we propose seq2sql , a deep neural network for translating natural language questions to corresponding sql queries .",
        "in this paper , we present the first deep learning architecture designed to capture metaphorical composition .",
        "an approach to incorporate deep learning within an iterative image reconstruction framework to reconstruct images from severely incomplete measurement data is presented .",
        "the structure of the method was inspired by the proximal gradient descent method , where the proximal operator is replaced by a deep cnn and the gradient descent step is generalized by use of a linear reconstruction operator .",
        "we combine a generative model parameterized by deep neural networks with non - linear embedding technique .",
        "our study suggests that the non - linear embedding based on a deep generative model can efficiently regularize a complex model with deep architectures while achieving high prediction accuracy that is far less sensitive to the availability of health status information .",
        "with the fast development of deep learning , supervised separation has become the most important direction in speech separation area in recent years .",
        "in this paper , we use the optimal ratio mask as the training target of the deep neural network ( dnn ) for speech separation .",
        "for computer vision applications , prior works have shown the efficacy of reducing numeric precision of model parameters ( network weights ) in deep neural networks .",
        "in this context , exploiting deep neural network ( dnn ) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for hmm based decoding .",
        "deep neural networks are state of the art methods for many learning tasks due to their ability to extract increasingly better features at each network layer .",
        "however , the improved performance of additional layers in a deep network comes at the cost of added latency and energy usage in feedforward inference .",
        "as networks continue to get deeper and larger , these costs become more prohibitive for real - time and energy - sensitive applications .",
        "to address this issue , we present branchynet , a novel deep network architecture that is augmented with additional side branch classifiers .",
        "deep neural networks ( dnn ) have been successfully applied for music classification tasks including music tagging .",
        "we analyze the challenges of the problem , and present rule - based , machine learning and deep learning approaches to detect sarcasm in numerical portions of text .",
        "our deep learning approach outperforms four past works for sarcasm detection and rule - based and machine learning approaches on a dataset of tweets , obtaining an f1 - score of 0 .",
        "in an attempt to better understand generalization in deep learning , we study several possible explanations .",
        "we show that implicit regularization induced by the optimization method is playing a key role in generalization and success of deep learning models .",
        "we empirically investigate the ability of these measures to explain different observed phenomena in deep learning .",
        "to tackle such a complicated control problem , we propose to apply deep reinforcement learning ( drl ) techniques for finding an optimal driving policy by maximizing the long - term reward in an interactive environment .",
        "specifically , we apply a long short - term memory ( lstm ) architecture to model the interactive environment , from which an internal state containing historical driving information is conveyed to a deep q - network ( dqn ) .",
        "the patch extracted around this object is subsequently fed through an off - the - shelf deep convolutional neural network to obtain a high level feature representation , which is then combined with traditional surface electromyography in the classification stage .",
        "we approach the query answering problems by combining ideas from the areas of kg embedding learning and deep learning for computer vision .",
        "an extensive set of experiments shows that the proposed deep neural networks are able to answer the visual - relational queries efficiently and accurately .",
        "we created a grid to simulate various conditions including stimuli like generator supply , weather and load demand using siemens pss / e software and this data is trained using deep learning methods and subsequently tested .",
        "as per our knowledge , this is the first paper to propose a working and scalable deep learning model for this problem .",
        "the expressive power of neural networks is important for understanding deep learning .",
        "that is , there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an \\ emph { exponential } bound .",
        "kernel methods have recently attracted resurgent interest , matching the performance of deep neural networks in tasks such as speech recognition .",
        "in contrast , in this study , we propose a deep learning based approach which integrate both feature extraction and classification phases into one system .",
        "our proposed scheme , called \" deep packet , \" can handle both traffic categorization in which the network traffic is categorize into major classes ( e .",
        "contrary to most of the current methods , deep packet can identify encrypted traffic and also distinguishes between vpn and non - vpn network traffic .",
        "after initial pre - processing phase on data , packets are fed to deep packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic .",
        "deep packet with cnn as its classification model achieved $ f _ { 1 } $ score of $ 0 .",
        "recent advances in deep learning have led various applications to unprecedented achievements , which could potentially bring higher intelligence to a broad spectrum of mobile and ubiquitous applications .",
        "although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices , they overlooked the reliability of mobile computing models .",
        "in this work , we propose rdeepsense , the first deep learning model that provides well - calibrated uncertainty estimations for resource - constrained mobile and embedded devices .",
        "rdeepsense enables the predictive uncertainty by adopting a tunable proper scoring rule as the training criterion and dropout as the implicit bayesian approximation , which theoretically proves its correctness .",
        "to reduce the computational complexity , rdeepsense employs efficient dropout and predictive distribution estimation instead of model ensemble or sampling - based method for inference operations .",
        "we evaluate rdeepsense with four mobile sensing applications using intel edison devices .",
        "results show that rdeepsense can reduce around 90 % of the energy consumption while producing superior uncertainty estimations and preserving at least the same model accuracy compared with other state - of - the - art methods .",
        "in this article , we propose a method based on deep reinforcement learning which only requires low - resolution images taken from a down - looking camera in order to identify the position of the marker and land the quadrotor on it .",
        "the proposed approach is based on a hierarchy of deep q - networks ( dqns ) which are used as high - level control policy for the navigation toward the marker .",
        "medical image analysis and computer - assisted intervention problems are increasingly being addressed with deep - learning - based solutions .",
        "this work presents the open - source niftynet platform for deep learning in medical imaging .",
        "this tensorflow - based infrastructure provides a complete modular deep learning pipeline for a range of medical imaging applications including segmentation , regression , image generation and representation learning applications with data loading , data augmentation , network architectures , loss functions and evaluation metrics that are tailored to , and take advantage of , the idiosyncracies of medical image analysis and computer - assisted interventions .",
        "in this paper , we show that the incorporation of deeper knowledge systematically boosts accuracy and compare knowner with state - of - the - art ner approaches across three languages ( i .",
        "vulnerability of state - of - the - art deep neural networks to adversarial attacks has been attracting a lot of attention recently .",
        "emergency response applications for nuclear or radiological events can be significantly improved via deep feature learning due to the hidden complexity of the data and models involved .",
        "in this paper we present a novel methodology for rapid source estimation during radiological releases based on deep feature extraction and weather clustering .",
        "we juxtapose these results with deep classification convolution networks and discuss advantages and disadvantages .",
        "recently , deep neural networks ( dnns ) have been demonstrated to achieve superior object detection performance compared to other approaches , with yolov2 ( an improved you only look once model ) being one of the state - of - the - art in dnn - based object detection methods in terms of both speed and accuracy .",
        "first , we leverage the evolutionary deep intelligence framework to evolve the yolov2 network architecture and produce an optimized architecture ( referred to as o - yolov2 here ) that has 2 .",
        "it supports a variety of different problem settings and it has been receiving increasing attention from the scientific community , leading to some high - profile success stories such as the much publicized deep q - networks ( dqn ) ."
    ],
    "neural": [
        "to overcome such performance limitations , we propose a novel machine learning algorithm , namely boosted subspace probabilistic neural network ( bspnn ) , which integrates an adaptive boosting technique and a semi parametric neural network to obtain good tradeoff between accuracy and generality .",
        "artificial neural network ( ann ) s has widely been used for recognition of optically scanned character , which partially emulates human thinking in the domain of the artificial intelligence .",
        "recursive neural networks are non - linear adaptive models that are able to learn deep structured information .",
        "in this paper , we propose a model of boolean neural network that incorporates these strategies by recurring to global optimization strategies during the learning session .",
        "the model characterizes as well the passage from an unstructured / chaotic attractor neural network typical of data - driven processes to a faster one , forward - only and representative of schema - driven processes .",
        "to overcome such performance limitations , we propose a novel machine learning algorithm , namely boosted subspace probabilistic neural network ( bspnn ) , which integrates an adaptive boosting technique and a semi parametric neural network to obtain good tradeoff between accuracy and generality .",
        "artificial neural network ( ann ) s has widely been used for recognition of optically scanned character , which partially emulates human thinking in the domain of the artificial intelligence .",
        "recursive neural networks are non - linear adaptive models that are able to learn deep structured information .",
        "in this paper , we propose a model of boolean neural network that incorporates these strategies by recurring to global optimization strategies during the learning session .",
        "the model characterizes as well the passage from an unstructured / chaotic attractor neural network typical of data - driven processes to a faster one , forward - only and representative of schema - driven processes .",
        "in this paper , a new content - based method for the purpose of file type detection and file type clustering is proposed that is based on the pca and neural networks .",
        "basic symbols are recognized by neural classifier .",
        "we report recent research on computing with biology - based neural network models by means of physics - based opto - electronic hardware .",
        "the difficulty of the arabic handwriting recognition is that , the accuracy of the character recognition which affects on the accuracy of the word recognition , in additional there is also two or three from for each character , the suggested solution by using artificial neural network can solve the problem and overcome the difficulty of arabic handwriting recognition .",
        "we show that the learning sample complexity of a sigmoidal neural network constructed by sontag ( 1992 ) required to achieve a given misclassification error under a fixed purely atomic distribution can grow arbitrarily fast : for any prescribed rate of growth there is an input distribution having this rate as the sample complexity , and the bound is asymptotically tight .",
        "we propose to use a model called growing neural gas to learn by imitation the topology of the environment .",
        "improvements for the growing neural gas to give more information to the character ' s model are given in the conclusion .",
        "we propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including : part - of - speech tagging , chunking , named entity recognition , and semantic role labeling .",
        "regularization is a well studied problem in the context of neural networks .",
        "we demonstrate the power of complexification through the neuroevolution of augmenting topologies ( neat ) method , which evolves increasingly complex neural network architectures .",
        "nowadays , computer scientists have shown the interest in the study of social insect ' s behaviour in neural networks area for solving different combinatorial and statistical problems .",
        "standard problem solver architectures of personal computers or neural networks tend to generalize by solving numerous tasks outside the self - invented training set ; powerplay ' s ongoing search for novelty keeps fighting to extend beyond the generalization abilities of its present solver .",
        "the proposed semi - supervised method is a model by means of a feed - forward neural network trained by a back propagation algorithm ( multi - layer perceptron ) in order to predict the category of an unknown customer ( potential customers ) .",
        "this paper presents a lcs where each traditional rule is represented by a spiking neural network , a type of network with dynamic internal state .",
        "the cg is considerably depends on initial weights of connections of artificial neural network ( ann ) , so , a metaheuristic algorithm , the so - called modified cuckoo search is applied in order to select the optimal weights .",
        "unlike neural networks , however , these circuits take \" concepts \" or \" percepts \" as inputs and outputs .",
        "we classify digits of real - world house numbers using convolutional neural networks ( convnets ) .",
        "convnets are hierarchical feature learning neural networks whose structure is biologically inspired .",
        "a number of representation schemes have been presented for use within learning classifier systems , ranging from binary encodings to neural networks .",
        "a number of representation schemes have been presented for use within learning classifier systems , ranging from binary encodings to neural networks , and more recently dynamical genetic programming ( dgp ) .",
        "computational analysis of time - course data with an underlying causal structure is needed in a variety of domains , including neural spike trains , stock price movements , and gene expression levels .",
        "this paper deals with the distributed processing in the search for an optimum classification model using evolutionary product unit neural networks .",
        "in order to get the best classification models we use evolutionary algorithms to train and design neural networks , which require a very time consuming computation .",
        "this paper demonstrates the nature of handwritten characters , conversion of handwritten data into electronic data , and the neural network approach to make machine capable of recognizing hand written characters .",
        "this paper demonstrates the use of neural networks for developing a system that can recognize hand - written english alphabets .",
        "in this system , each english alphabet is represented by binary values that are used as input to a simple feature extraction system , whose output is fed to our neural network system .",
        "this paper proposes a method to derive an accurate and optimized schedule for rejuvenation of a web server ( apache ) by using radial basis function ( rbf ) based feed forward neural network , a variant of artificial neural networks ( ann ) .",
        "aging indicators are obtained through experimental setup involving apache web server and clients , which acts as input to the neural network model .",
        "we then continue with the clustering technique that is used to group the similar things together and discuss the machine learning technique called self - organizing maps [ 6 ] or som , which is a data visualization technique that reduces the dimensions of data through the use of self - organizing neural networks .",
        "these methods include various artificial neural network ( ann ) models ( primarily supervised in nature ) , genetic algorithm ( ga ) based techniques , intensity histogram based methods etc .",
        "we introduce a probabilistic model based on distribution estimators conditioned on a recurrent neural network that is able to discover temporal dependencies in high - dimensional sequences .",
        "in spite of their superior performance , neural probabilistic language models ( nplms ) remain far less widely used than n - gram models due to their notoriously long training times , which are measured in weeks even for moderately - sized datasets .",
        "we demonstrate that inhomogeneous markets of agents with isoelastic utilities outperform state of the art aggregate classifiers such as random forests , as well as single classifiers ( neural networks , decision trees ) on a number of machine learning benchmarks , and show that isoelastic combination methods are generally better than their logarithmic counterparts .",
        "we show in experiments that cp turns out to work well in practice , giving very accurate estimates of the hessian of neural networks , for example , with a relatively small amount of work .",
        "the proposed methodology can be applied to a large class of learning problems including the learning of sparse priors in compressed sensing or identification of linear - nonlinear cascade models in dynamical systems and neural spiking processes .",
        "training recurrent neural networks is more troublesome than feedforward ones because of the vanishing and exploding gradient problems detailed in bengio et al .",
        "in this paper , we present new features and efficiency improvements to theano , and benchmarks demonstrating theano ' s performance relative to torch7 , a recently introduced machine learning library , and to rnnlm , a c + + library targeted at recurrent neural networks .",
        "in this paper , first we present a new explanation for the relation between logical circuits and artificial neural networks , logical circuits and fuzzy logic , and artificial neural networks and fuzzy inference systems .",
        "proposed research work uses anfis ( artificial neural network fuzzy inference system ) for image classification and then compares the results with fcm ( fuzzy c means ) and k - nn ( k - nearest neighbor ) .",
        "after a more than decade - long period of relatively little research activity in the area of recurrent neural networks , several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions towards more efficient training of recurrent networks .",
        "rc models are neural networks which a recurrent part ( the reservoir ) that does not participate in the learning process , and the rest of the system where no recurrence ( no neural circuit ) occurs .",
        "some success was also observed with another recently proposed neural network designed using queueing theory , the random neural network ( randnn ) .",
        "artificial neural networks have emerged as an important tool for classification and have been widely used to classify a non - linear separable pattern .",
        "the most popular artificial neural networks model is a multilayer perceptron ( mlp ) as it is able to perform classification task with significant success .",
        "however due to the complexity of mlp structure and also problems such as local minima trapping , over fitting and weight interference have made neural network training difficult .",
        "this paper presents the ability of functional link neural network ( flnn ) to overcome the complexity structure of mlp by using single layer architecture and propose an artificial bee colony ( abc ) optimization for training the flnn .",
        "in this paper , we present a new neural network architecture designed to embed multi - relational graphs into a flexible continuous vector space in which the original data is kept and enhanced .",
        "this article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting .",
        "past research suggest diminishing returns when increasing the size of neural networks .",
        "recent studies have shown that deep neural networks ( dnns ) perform significantly better than shallow networks and gaussian mixture models ( gmms ) on large vocabulary speech recognition tasks .",
        "a neural probabilistic language model ( nplm ) provide an idea to achieve the better perplexity than n - gram language model and their smoothed language models .",
        "we introduce a neural tensor network ( ntn ) model which predicts new relationship entries that can be added to the database .",
        "a key characteristic of work on deep learning and neural networks in general is that it relies on representations of the input that support generalization , robust inference , domain adaptation and other desirable functionalities .",
        "in this paper , we propose an alternative method that is more efficient than prior work and produces representations that have a property we call focality - - a property we hypothesize to be important for neural network representations .",
        "several recent results in machine learning have established formal connections between autoencoders - - - artificial neural network models that attempt to reproduce their inputs - - - and other coding models like sparse coding and k - means .",
        "the quality of these representations is measured in a word similarity task , and the results are compared to the previously best performing techniques based on different types of neural networks .",
        "besides the paper suggests the structure of neural elements , i .",
        "recently , artificial neural networks ( anns ) have found extensive applications in many practical forecasting problems .",
        "in this paper a stochastic version of the algorithm is adapted to probabilistic neural networks describing the associative dependency of variables .",
        "autoencoder is a special kind of neural network based on reconstruction .",
        "we introduce persistent contextual neural networks ( pcnns ) as a probabilistic model for learning symbolic data sequences , aimed at discovering complex algorithmic dependencies in the sequence .",
        "pcnns are similar to recurrent neural networks but feature an architecture inspired by finite automata and a modified time evolution to better model memory effects .",
        "mel frequency cepstral coefficient ( mfcc ) is used as feature extraction method and generalized regression neural network is used as recognizer .",
        "neural network improves the accuracy .",
        "this paper shows how long short - term memory recurrent neural networks can be used to generate complex sequences with long - range structure , simply by predicting one data point at a time .",
        "experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these \" deep and wide multiscale recursive \" ( dawmr ) networks lead to new levels of image labeling performance .",
        "the neural autoregressive distribution estimator ( nade ) and its real - valued version rnade are competitive density models of multidimensional data across a variety of domains .",
        "our generative model is an $ n $ node multilayer neural net that has degree at most $ n ^ { \\ gamma } $ for some $ \\ gamma & lt ; 1 $ and each edge has a random edge weight in $ [ - 1 , 1 ] $ .",
        "the fusion of the images is performed by feed - forward neural network trained on a set of known examples .",
        "the projection is performed by a multi - layer neural network whose weights are learned on parallel training data .",
        "recurrent neural networks ( rnn ) have recently achieved the best performance in off - line handwriting text recognition .",
        "convolutional neural network models have recently been shown to achieve excellent performance on challenging recognition benchmarks .",
        "to address this , we introduce a novel type of recursive neural network that is convolutional in nature .",
        "we show performance of several well - known types of language models , with the best results achieved with a recurrent neural network based language model .",
        "instead , we build micro neural networks with more complex structures to handle the variance of the local receptive fields .",
        "we instantiate the micro neural network with a nonlinear multiple layer structure which is a potent function approximator .",
        "the deep nin is thus implemented as stacking of multiple sliding micro neural networks .",
        "experimental results on nonlinear dimensionality reduction show that the proposed method can learn abstract representations on both large - scale and small - scale problems , and meanwhile is much faster than deep neural networks on large - scale problems .",
        "scalability properties of deep neural networks raise key research questions , particularly as the problems considered become larger and more challenging .",
        "for sparse neural networks , this can result in considerable speed gains .",
        "experimental results using the mnist and svhn data sets with a fully - connected deep neural network demonstrate the performance robustness of the proposed scheme with respect to the error introduced by the conditional computation process .",
        "finally we train a convolutional neural network to discriminate between these surrogate classes .",
        "in this work , we propose to utilize a single - layer neural networks approach in large - scale multi - label text classification tasks with recently proposed learning techniques .",
        "we carried out experiments on six textual datasets with varying characteristics and size , and show that a simple neural networks model equipped with recent advanced techniques for neural networks components such as activation layer , optimization , and generalization algorithms performs as well as or even outperforms the previous state - of - the - art approaches on large - scale datasets with diverse characteristics .",
        "word embeddings resulting from neural language models have been shown to be successful for a large variety of nlp tasks .",
        "the model is a convolutional neural network , trained with a variant of q - learning , whose input is raw pixels and whose output is a value function estimating future rewards .",
        "in this work we evaluate different approaches to parallelize computation of convolutional neural networks across several gpus within the same server .",
        "standard techniques from the neural networks literature are used to learn the tensors , which are tested on a selectional preference - style task with a simple 2 - dimensional sentence space .",
        "currently , deep neural networks are the state of the art on problems such as speech recognition and computer vision .",
        "moreover , the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model .",
        "our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed - forward nets than those currently available .",
        "the ability to train large - scale neural networks has resulted in state - of - the - art performance in many areas of computer vision .",
        "we show using gpu a - sgd it is possible to speed up training of large convolutional neural networks useful for computer vision .",
        "recursive neural network models and their accompanying vector representations for words have seen success in an array of increasingly semantically sophisticated tasks , but almost nothing is known about their ability to accurately capture the aspects of linguistic meaning that are necessary for interpretation or reasoning .",
        "deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks .",
        "convolutional neural networks are extremely efficient architectures in image and audio recognition tasks , thanks to their ability to exploit the local translational invariance of signal classes over their domain .",
        "a new initialization method for hidden parameters in a neural network is proposed .",
        "derived from the integral representation of the neural network , a nonparametric probability distribution of hidden parameters is introduced .",
        "in this paper we have developed an ann ( artificial neural network ) based automated coin recognition system for the recognition of indian coins of denomination rs .",
        "then , the extracted features are passed as input to a trained neural network .",
        "we investigate the use of deep neural networks for the novel task of class generic object detection .",
        "we show that neural networks originally designed for image recognition can be trained to detect objects within images , regardless of their class , including objects for which no bounding box labels have been provided .",
        "in this paper , we will assess the customer credit through a combined classification using artificial neural networks , genetics algorithm and bayesian probabilities simultaneously , and the results obtained from three methods mentioned above would be used to achieve an appropriate and final result .",
        "this paper proposes a revised hybrid model built upon empirical mode decomposition ( emd ) based on the feed - forward neural network ( fnn ) modeling framework incorporating the slope - based method ( sbm ) , which is capable of capturing the complex dynamic of crude oil prices .",
        "reservoir computing ( rc ) is a novel approach to time series prediction using recurrent neural networks .",
        "we marry ideas from deep neural networks and approximate bayesian inference to derive a generalised class of deep , directed generative models , endowed with a new algorithm for scalable inference and learning .",
        "we encode our model for text analysis and game playing in a multi - layer neural network , representing linguistic decisions via latent variables in the hidden layers , and game action quality via the output layer .",
        "meanwhile , in recent years , deep neural networks ( dnns ) have shown state - of - the - art performance on various asr tasks .",
        "using these recipes , we can build up multiple systems including dnn hybrid systems , convolutional neural network ( cnn ) systems and bottleneck feature systems .",
        ", quadratic classifier , k - nearest neighbor algorithm , support vector machine , and artificial neural networks .",
        "hierarchical bayesian networks and neural networks with stochastic hidden units are commonly perceived as two separate types of models .",
        "since the 1950s , different computational techniques related to artificial intelligence have been used for algorithmic composition , including grammatical representations , probabilistic methods , neural networks , symbolic rule - based systems , constraint programming and evolutionary algorithms .",
        "to learn these representations we introduce nested dropout , a procedure for stochastically removing coherent nested sets of hidden units in a neural network .",
        "we study the complexity of functions computable by deep feedforward neural networks with piece - wise linear activations in terms of the number of regions of linearity that they have .",
        "this note investigates the complexity of such compositional maps and contributes new theoretical results regarding the advantage of depth for neural networks with piece - wise linear activation functions .",
        "in this paper , we propose a simple but effective coupled neural network , called deeply coupled autoencoder networks ( dcan ) , which seeks to build two deep neural networks , coupled with each other in every corresponding layers .",
        "recurrent neural networks ( rnns ) have the ability , in theory , to cope with these temporal dependencies by virtue of the short - term memory implemented by their recurrent ( feedback ) connections .",
        "we also provide an application of our methods to a classification task using neural networks and to online bayesian matrix factorization .",
        "we propose a statistical learning model for classifying cognitive processes based on distributed patterns of neural activation in the brain , acquired via functional magnetic resonance imaging ( fmri ) .",
        "in this study , linguistic hedges neural - fuzzy classifier with selected features ( lhnfcsf ) is presented for diagnosis of thyroid diseases .",
        "we describe a convolutional architecture dubbed the dynamic convolutional neural network ( dcnn ) that we adopt for the semantic modelling of sentences .",
        "inspired by these observations , we introduce a novel framework based on recurrent neural networks ( rnn ) .",
        "we present a method for training a deep neural network containing sinusoidal activation functions to fit to time - series data .",
        "we provide a method for automatically detecting change in language across time through a chronologically trained neural language model .",
        "here we argue , based on results from statistical physics , random matrix theory , and neural network theory , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep neural network training , and provide preliminary numerical evidence for its superior performance .",
        "latest results indicate that features learned via convolutional neural networks outperform previous descriptors on classification tasks by a large margin .",
        "in this paper we compare features from various layers of convolutional neural nets to standard sift descriptors .",
        "surprisingly , convolutional neural networks clearly outperform sift on descriptor matching .",
        "the system is based on neural network and simulates the process of visual interpretation from remote sensing images and hence increases the efficiency of image analysis .",
        "in addition to the user survey we check the learnability of the evolved games using an artificial neural network based controller .",
        "in this paper , we propose a novel neural network model called rnn encoder - - decoder that consists of two recurrent neural networks ( rnn ) .",
        "the first of these is a simple n - gram model , the other being a recursive neural - network .",
        "supervised recursive neural network models ( rnns ) for sentence meaning have been successful in an array of sophisticated language tasks , but it remains an open question whether they can learn compositional semantic grammars that support logical deduction .",
        "we address this question directly by for the first time evaluating whether each of two classes of neural model - - - plain rnns and recursive neural tensor networks ( rntns ) - - - can correctly learn relationships such as entailment and contradiction between pairs of sentences , where we have generated controlled data sets of sentences from a logical grammar .",
        "experiments on various benchmark tasks - - - word similarity ranking , analogies , sentence completion , and sentiment analysis - - - demonstrate that the method outperforms or is competitive with state - of - the - art neural network representations .",
        "we propose several simple approaches to training deep neural networks on data with noisy labels .",
        "here we argue , based on results from statistical physics , random matrix theory , neural network theory , and empirical evidence , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep or recurrent neural network training , and provide numerical evidence for its superior optimization performance .",
        "these random views are then used to train a deep convolutional neural network ( cnn ) classifier .",
        "deep convolutional neural networks have recently proven extremely competitive in challenging image recognition tasks .",
        "this paper proposes the epitomic convolution as a new building block for deep neural networks .",
        "an epitomic convolution layer replaces a pair of consecutive convolution and max - pooling layers found in standard deep convolutional neural networks .",
        "our experiments on imagenet indicate improved recognition performance compared to standard convolutional neural networks of similar architecture .",
        "in this paper , we address this goal with a new type of convolutional neural network ( cnn ) whose invariance is encoded by a reproducing kernel .",
        "unlike traditional approaches where neural networks are learned either to represent data or for solving a classification task , our network learns to approximate the kernel feature map on training data .",
        "second , we bridge a gap between the neural network literature and kernels , which are natural tools to model invariance .",
        "we propose an heterogeneous multi - task learning framework for human pose estimation from monocular image with deep convolutional neural network .",
        "we evaluate the following machine learning techniques for green energy ( wind , solar ) prediction : bayesian inference , neural networks , support vector machines , clustering techniques ( pca ) .",
        "applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels .",
        "we present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution .",
        "like convolutional neural networks , the proposed model has a degree of translation invariance built - in , but the amount of computation it performs can be controlled independently of the input image size .",
        "we evaluate our model on several image classification tasks , where it significantly outperforms a convolutional neural network baseline on cluttered images , and on a dynamic visual control problem , where it learns to track a simple object without an explicit training signal for doing so .",
        "current methods for training convolutional neural networks depend on large amounts of labeled samples for supervised training .",
        "in this paper we present an approach for training a convolutional neural network using only unlabeled data .",
        "it uses a deep layered architecture , parts of which are borrowed from recent work on neural network learning , and parts of which incorporate computations that are specific to image deconvolution .",
        "moreover , we show that advanced neural networks and deep learning methods can be compressed as privileged information .",
        "self - organising maps ( som ) are artificial neural networks used in pattern recognition tasks .",
        "traditional convolutional neural networks ( cnn ) are stationary and feedforward .",
        "dropout training , originally designed for deep neural networks , has been successful on high - dimensional single - layer natural language tasks .",
        "the general perception is that kernel methods are not scalable , and neural nets are the methods of choice for nonlinear learning problems .",
        "our approach can readily scale kernel methods up to the regimes which are dominated by neural",
        "the framework is a bsd - licensed c + + library with python and matlab bindings for training and deploying general - purpose convolutional neural networks and other deep models efficiently on commodity architectures .",
        "we report on a series of experiments with convolutional neural networks ( cnn ) trained on top of pre - trained word vectors for sentence - level classification tasks .",
        "we provide a comparative study between neural word representations and traditional vector spaces based on co - occurrence counts , in a number of compositional tasks .",
        "in the more constrained tasks , co - occurrence vectors are competitive , although choice of compositional method is important ; on the larger - scale tasks , they are outperformed by neural word embeddings , which show robust , stable performance across the tasks .",
        "deep neural networks ( dnns ) are powerful models that have achieved excellent performance on difficult learning tasks .",
        "to evaluate whether deep learning is beneficial for program analysis , we feed the representations to deep neural networks , and achieve higher accuracy in the program classification task than \" shallow \" methods , such as logistic regression and the support vector machine .",
        ", has been shown a promising learning algorithm for single - hidden layer feedforward neural networks ( slfns ) .",
        "another popular approach to model the multimodal data is through deep neural networks , such as the deep boltzmann machine ( dbm ) .",
        "recently , a new type of topic model called the document neural autoregressive distribution estimator ( docnade ) was proposed and demonstrated state - of - the - art performance for text document modeling .",
        "deep neural networks have made significant breakthroughs in many fields of artificial intelligence .",
        "in this paper , we propose the tree - based convolutional neural network ( tbcnn ) to model programming languages , which contain rich and explicit tree structural information .",
        "to our best knowledge , this paper is the first to analyze programs with deep neural networks ; we extend the scope of deep learning to the field of programming language processing .",
        "e algorithm is compared against known learning and classification techniques / algorithms such as : the perceptron criterion algorithm , linear support vector machines , the linear fisher discriminant and a simple neural network .",
        "for the comparison with the neural network , the classical xor problem is considered .",
        "this paper presents a new contextual bandit algorithm , neuralbandit , which does not need hypothesis on stationarity of contexts and rewards .",
        "several neural networks are trained to modelize the value of rewards knowing the context .",
        "by means of a preprocessing for word - grouping and time - period related analysis of the common lexicon , we determine a bias reference level for the recurrence frequency of the words within analysed texts , and then train a radial basis neural networks ( rbpnn ) - based classifier to identify the correct author .",
        "neural networks sequentially build high - level features through their successive layers .",
        "we propose here a new neural network model where each layer is associated with a set of candidate mappings .",
        "neural language models learn word representations that capture rich linguistic and conceptual information .",
        "here we investigate the embeddings learned by neural machine translation models .",
        "the findings suggest that , while monolingual models learn information about how concepts are related , neural - translation models better capture their true ontological status .",
        "existing deep convolutional neural network ( cnn ) architectures are trained as n - way classifiers to distinguish between n output classes .",
        "we present a deep layered architecture that generalizes classical convolutional neural networks ( convnets ) .",
        "in this paper , we present a multimodal recurrent neural network ( m - rnn ) model for generating novel sentence descriptions to explain the content of images .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "it is well - known that neural networks are computationally hard to train .",
        "on the other hand , in practice , modern day neural networks are trained efficiently using sgd and a variety of tricks that include different activation functions ( e .",
        "in this paper we revisit the computational complexity of training neural networks from a modern perspective .",
        "we provide both positive and negative results , some of them yield new provably efficient and practical algorithms for training certain types of neural networks .",
        "recently proposed neural network activation functions such as rectified linear , maxout , and local winner - take - all have allowed for faster and more effective training of deep neural architectures on large and complex datasets .",
        "we also show how our insights can be directly useful for efficiently performing retrieval over large datasets using neural networks .",
        "we address this question using two neural network - based models for learning embeddings : plain neural networks and neural tensor networks .",
        "neural machine translation ( nmt ) has recently attracted a lot of attention due to the very high performance achieved by deep neural networks in other domains .",
        "we parametrize this transformation so that computing the determinant of the jacobian and inverse jacobian is trivial , yet we maintain the ability to learn complex non - linear transformations , via a composition of simple building blocks , each based on a deep neural network .",
        "we carried out experiments using the switchboard corpus , with both mel frequency cepstral coefficient features and bottleneck feature derived from a deep neural network .",
        "reductions in word error rate were obtained by using tied plda , compared with the plda mixture model , subspace gaussian mixture models , and deep neural networks .",
        "convolutional neural nets ( convnets ) trained from massive labeled datasets have substantially improved the state - of - the - art in image classification and object detection .",
        "recently convolutional neural networks ( cnns ) have been shown to achieve state - of - the - art performance on various classification tasks .",
        "we use recurrent neural networks ( rnns ) and their variants as music language models ( mlms ) and present a generative architecture for combining these models with predictions from a frame level acoustic classifier .",
        "we also compare different neural network architectures for acoustic modeling .",
        "many deep neural networks trained on natural images exhibit a curious phenomenon in common : on the first layer they learn features similar to gabor filters and color blobs .",
        "in this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results .",
        "our pipeline effectively unifies joint image - text embedding models with multimodal neural language models .",
        "we introduce the structure - content neural language model that disentangles the structure of a sentence to its content , conditioned on representations produced by the encoder .",
        "as an increasing number of researchers would like to experiment with word2vec , i notice that there lacks a material that comprehensively explains the parameter learning process of word2vec in details , thus preventing many people with less neural network experience from understanding how exactly word2vec works .",
        "we propose a new neurally - inspired model that can learn to encode global relationship context of visual events across time and space and to use the contextual information to modulate the analysis by synthesis process in a predictive coding framework .",
        "this paper aims to explore the effect of prior disambiguation on neural network - based compositional models , with the hope that better semantic representations for text compounds can be produced .",
        "we propose learning this mapping using a recurrent neural network .",
        "we train a generative convolutional neural network which is able to generate images of objects given object type , viewpoint , and color .",
        "error backpropagation is an extremely effective algorithm for assigning credit in artificial neural networks .",
        "even though convolutional neural networks ( cnn ) has achieved near - human performance in various computer vision tasks , its ability to tolerate scale variations is limited .",
        "in this paper , we propose a scaleinvariant convolutional neural network ( sicnn ) , a modeldesigned to incorporate multi - scale feature exaction and classification into the network structure .",
        "we study the connection between the highly non - convex loss function of a simple model of the fully - connected feed - forward neural network and the hamiltonian of the spherical spin - glass model under the assumptions of : i ) variable independence , ii ) redundancy in network parametrization , and iii ) uniformity .",
        "these assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from the random matrix theory .",
        "convolutional neural network ( cnn ) is a neural network that can make use of the internal structure of data such as the 2d structure of image data .",
        "when using skip - gram features the models are able to match the state - of - the - art recurrent neural network ( rnn ) lms ; combining the two modeling techniques yields the best known result on the benchmark .",
        "compared to image representation based on low - level local descriptors , deep neural activations of convolutional neural networks ( cnns ) are richer in mid - level representation , but poorer in geometric invariance properties .",
        "neural machine translation , a recently proposed approach to machine translation based purely on neural networks , has shown promising results compared to the existing approaches such as phrase - based statistical machine translation .",
        "despite its recent success , neural machine translation has its limitation in handling a larger vocabulary , as training complexity as well as decoding complexity increase proportionally to the number of target words .",
        "the models trained by the proposed approach are empirically found to outperform the baseline models with a small vocabulary as well as the lstm - based neural machine translation models .",
        "due to imprecision and uncertainties in predicting real world problems , artificial neural network ( ann ) techniques have become increasingly useful for modeling and optimization .",
        "this paper presents an artificial neural network approach for forecasting electric energy consumption .",
        "to overcome these challenges in large scale in synonym extraction , we proposed ( 1 ) a new cost function to accommodate the unbalanced learning problem , and ( 2 ) a feature learning based deep neural network to model the complicated relationships in synonym pairs .",
        "we compare several different approaches based on svms and neural networks , and find out our feature learning based neural network outperforms the methods with hand - assigned features .",
        "the transcription of handwritten text on images is one task in machine learning and one solution to solve it is using multi - dimensional recurrent neural networks ( mdrnn ) with connectionist temporal classification ( ctc ) .",
        "we propose a multimodal deep learning framework that can transfer the knowledge obtained from a single - modal neural network to a network with a different modality .",
        "in this paper we compare different types of recurrent units in recurrent neural networks ( rnns ) .",
        "this paper addresses how a recursive neural network model can automatically leave out useless information and emphasize important evidence , in other words , to perform \" weight tuning \" for higher - level representation acquisition .",
        "we propose two models , weighted neural network ( wnn ) and binary - expectation neural network ( benn ) , which automatically control how much one specific unit contributes to the higher - level representation .",
        "the proposed model can be viewed as incorporating a more powerful compositional function for embedding acquisition in recursive neural networks .",
        "experimental results demonstrate the significant improvement over standard neural models .",
        "in this paper , we train recurrent neural networks with only raw features , and use word embedding to automatically learn meaningful representations .",
        "matconvnet is an implementation of convolutional neural networks ( cnns ) for matlab .",
        "in this paper , we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure .",
        "al , 2012 ) in a deep neural network trains a pseudo - ensemble of child subnetworks generated by randomly masking nodes in the parent network .",
        "we provide a case study in which we transform the recursive neural tensor network of ( socher et .",
        "recent work has shown deep neural networks ( dnns ) to be highly susceptible to well - designed , small perturbations at the input layer , or so - called adversarial examples .",
        "convolutional neural networks ( convnets ) have shown excellent results on many visual classification tasks .",
        "we present flattened convolutional neural networks that are designed for fast feedforward execution .",
        "the redundancy of the parameters , especially weights of the convolutional filters in convolutional neural networks has been extensively studied and different heuristics have been proposed to construct a low rank basis of the filters after training .",
        "deep convolutional neural networks ( cnn ) has become the most promising method for object recognition , repeatedly demonstrating record breaking results for image classification and object detection in recent years .",
        "the convolutional neural networks ( cnns ) have proven to be a powerful tool for discriminative learning .",
        "in this work , we present a novel neural network based architecture for inducing compositional crosslingual word representations .",
        "neural language models learn word representations , or embeddings , that capture rich linguistic and conceptual information .",
        "here we investigate the embeddings learned by neural machine translation models , a recently - developed class of neural language model .",
        "finally , we apply a new method for training neural translation models with very large vocabularies , and show that this vocabulary expansion algorithm results in minimal degradation of embedding quality .",
        "we propose a simple two - step approach for speeding up convolution layers within large convolutional neural networks based on tensor decomposition and discriminative fine - tuning .",
        "we train a large 12 - layer convolutional neural network by supervised learning from a database of human professional games .",
        "we consider learning representations of entities and relations in kbs using the neural - embedding approach .",
        "we show that most existing models , including ntn and transe , can be generalized under a unified learning framework , where entities are low - dimensional vectors learned from a neural network and relations are bilinear and / or linear mapping functions .",
        "convolutional neural networks perform well on object recognition because of a number of recent advances : rectified linear units ( relus ) , data augmentation , dropout , and large labelled datasets .",
        "experiments on a benchmark neural network show that the hot swapping approach leads to consistently better solutions compared to well - known alternatives such as adadelta and stochastic gradient with exhaustive hyperparameter search .",
        "we propose a novel architecture for solving ctr prediction problem by combining artificial neural networks ( ann ) with decision trees .",
        "our method does not require gradient - based training of neural networks , matrix decompositions as with lsa , or convolutions as with beagle .",
        "among these , the restricted boltzmann machine ( rbm ) has been the prototype for some recent advancements in the unsupervised training of deep neural networks .",
        "in this paper , we present a multimodal recurrent neural network ( m - rnn ) model for generating novel image captions .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "it is today acknowledged that neural network language models outperform back - off language models in applications like speech recognition or statistical machine translation .",
        "we present efficient techniques to adapt a neural network language model to new data .",
        "an asynchronous variant of the algorithm is applied to train convolutional neural",
        "most modern convolutional neural networks ( cnns ) used for object recognition are built using the same principles : alternating convolution and max - pooling layers followed by a small number of fully connected layers .",
        "to facilitate the process , the proposed approach leverages with densenet , an efficient implementation of multiscale convolutional neural networks ( cnn ) , to extract an informative feature vector for each pixel and uses an svm classifier to accomplish contour detection .",
        "the convolutional neural network ( cnn ) has achieved great success in image classification .",
        "to the best of our knowledge the use of multi - modal deep convolutional neural networks for dynamic real - time lidar - video registration has not been presented .",
        "we trained a deep convolutional neural network ( cnn ) to identify occlusion edges in images and videos with both rgb - d and rgb inputs .",
        "we simulate the training of a set of state of the art neural networks , the maxout networks ( goodfellow et al .",
        "this paper introduces a greedy parser based on neural networks , which leverages a new compositional sub - tree representation .",
        "composition and tagging is achieved over continuous ( word or tag ) representations , and recurrent neural networks .",
        "( 2014 ) on recurrent neural models for attention into less constrained visual environments , beginning with fine - grained categorization on the stanford dogs data set .",
        "deep convolutional neural networks ( dcnns ) have recently shown state of the art performance in high level vision tasks , such as image classification and object detection .",
        "we propose diverse embedding neural network ( denn ) - a novel architecture for neural network language models ( lms ) .",
        "a denn - lm projects the input word history vector onto multiple diverse low - dimensional sub - spaces instead of a single higher - dimensional sub - space as in conventional feed - forward neural network lms .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "recently , convolutional neural networks have been shown to be able to estimate phoneme conditional probabilities in a completely data - driven manner , i .",
        "this paper presents an in - depth investigation on integrating neural language models in translation systems .",
        "scaling neural language models is a difficult task , but crucial for real - world applications .",
        "we show when explicitly normalising neural models is necessary and what optimisation tricks one should use in such scenarios .",
        "we explore the trade - offs between neural models and back - off n - gram models and find that neural models make strong candidates for natural language applications in memory constrained environments , yet still lag behind traditional models in raw translation quality .",
        "we conclude with a set of recommendations one should follow to build a scalable neural language model for mt .",
        "additionally , we hope that ordering parameters may provide additional insights into optimization of deep convolutional neural networks and how the network architecture impacts performance .",
        "in this paper we study the application of convolutional neural networks for jointly detecting objects depicted in still images and estimating their 3d pose .",
        "deep neural networks have been extremely successful at various image , speech , video recognition tasks because of their ability to model deep structures within the data .",
        "based on the observation that the key computation common to most neural network layers is a vector / matrix product , we propose a fast locality - sensitive hashing technique to approximate the actual dot product enabling us to scale up the training and inference to millions of output classes .",
        "in this study , we propose a deep temporal convolutional neural network architecture for brain decoding task in order to reduce dimensionality of feature space along with improved classification performance .",
        "we examine the performance profile of convolutional neural network training on the current generation of nvidia graphics processing units .",
        "recurrent neural network is a powerful model that learns temporal patterns in sequential data .",
        "this is achieved by using a slight structural modification of the simple recurrent neural network architecture .",
        "the proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image .",
        "a process centric view of robust pca ( rpca ) allows its fast approximate implementation based on a special form o a deep neural network with weights shared across all layers .",
        "deep networks have inspired a renaissance in neural network use , and are becoming the default option for difficult tasks on large datasets .",
        "our model learns to embed image representations ( generated from a previously trained convolutional neural network ) into a multimodal space that is common to the images and the phrases that are used to described them .",
        "artificial neural networks are powerful pattern classifiers ; however , they have been surpassed in accuracy by methods such as support vector machines and random forests that are also easier to use and faster to train .",
        "backpropagation , which is used to train artificial neural networks , suffers from the herd effect problem which leads to long training times and limit classification accuracy .",
        "in this paper , we have used recurrent neural networks to capture and model human motion data and generate motions by prediction of the next immediate data point at each time - step .",
        "a particular case of recurrent neural network ( rnn ) was introduced at the beginning of the 2000s under the name of echo state networks ( esns ) .",
        "luckily , a simplified neural network module ( snnm ) has been proposed to directly learn the discriminative dictionaries for avoiding the expensive inference .",
        "our experiments include a logistic regression , hmm , and bayesian neural net .",
        "this paper investigates the scaling properties of recurrent neural network language models ( rnnlms ) .",
        "more interestingly , we have shown the proposed hope models are closely related to neural networks ( nns ) in a sense that each nn hidden layer can be reformulated as a hope model .",
        "models of multilayer perceptrons , support vector machines , and radial basis function neural networks were trained and tested using the mit - bih arrhythmia database .",
        "in this work , we propose a novel recurrent neural network ( rnn ) architecture .",
        "training of large - scale deep neural networks is often constrained by the available computational resources .",
        "we study the effect of limited precision data representation and computation on neural network training .",
        "recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation .",
        "in this paper , we propose a new deep adaptation network ( dan ) architecture , which generalizes deep convolutional neural network to the domain adaptation scenario .",
        "training deep neural networks is complicated by the fact that the distribution of each layer ' s inputs changes during training , as the parameters of the previous layers change .",
        "recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers .",
        "we train our three - layer deep neural network on the yahoo !",
        "these gradients allow us to optimize thousands of hyperparameters , including step - size and momentum schedules , weight initialization distributions , richly parameterized regularization schemes , and neural network architectures .",
        "there has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples .",
        "we introduce a simple modification for autoencoder neural networks that yields powerful generative models .",
        "neural network based technologies have high ability of adaption as well as generalization .",
        "as per our knowledge , very little work has been done in this field using neural network .",
        "this paper evaluates performance of three supervised learning algorithms of artificial neural network by creating classifiers for the complex problem of latest web spam pattern classification .",
        "in this paper , we present a gaussian mixture neural topic model ( gmntm ) which incorporates both the ordering of words and the semantic meaning of sentences into topic modeling .",
        "deep neural networks ( dnn ) are the state of the art on many engineering problems such as computer vision and audition .",
        "we train a purely bilinear model that learns a metric between an image representation ( generated from a previously trained convolutional neural network ) and phrases that are used to described them .",
        "we introduce deep neural programs ( dnp ) , a novel programming paradigm for writing adaptive controllers for cy - ber - physical systems ( cps ) .",
        "dnp replace if and while statements , whose discontinuity is responsible for undecidability in cps analysis , intractability in cps design , and frailness in cps implementation , with their smooth , neural nif and nwhile counterparts .",
        "to the best of our knowledge , dnp are the first approach linking neural networks to programs , in a way that makes explicit the meaning of the network .",
        "inspired by the brain , deep neural networks ( dnn ) are thought to learn abstract representations through their hierarchical architecture .",
        "finally , the kalman filter updates can be seen as a linear recurrent neural network .",
        "we demonstrate that using the parameters of our model to initialize a non - linear recurrent neural network language model reduces its training time by a day and yields lower perplexity .",
        "in this paper , we explore joint optimization of masking functions and deep recurrent neural networks for monaural source separation tasks , including the monaural speech separation task , monaural singing voice separation task , and speech denoising task .",
        "the joint optimization of the deep recurrent neural networks with an extra masking layer enforces a reconstruction constraint .",
        "moreover , we explore a discriminative training criterion for the neural networks to further enhance the separation performance .",
        ", with approximate rather than exact posteriors , implemented by neural dynamics .",
        "here , we train a deep neural network to re - synthesize its inputs at its output layer for a given class of data .",
        "this paper introduces the deep recurrent attentive writer ( draw ) neural network architecture for image generation .",
        "here , we propose a novel model called temporal embedding - enhanced convolutional neural network ( tenet ) to learn repeatedly - occurring - yet - hidden structural elements in periodical time - series , called abstract snippets , for predicting future changes .",
        "our model uses convolutional neural networks and embeds a time - series with its potential neighbors in the temporal domain for aligning it to the dominant patterns in the dataset .",
        "in recent years multilayer perceptrons ( mlps ) with many hid - den layers deep neural network ( dnn ) has performed sur - prisingly well in many speech tasks , i .",
        "for these tasks , the policies are neural networks with tens of thousands of parameters , mapping from observations to actions .",
        "further to improve the accuracy of classification a hybrid neurosvm model was developed using svm and feed - forward artificial neural network ( ann ) .",
        "a scheme is derived for learning connectivity in spiking neural networks .",
        "this learning scheme is demonstrated using a layered feedforward spiking neural network trained self - supervised on a prediction and classification task for moving mnist images collected using a dynamic vision sensor .",
        "this paper develops a model that addresses sentence embedding using recurrent neural networks ( rnn ) with long short term memory ( lstm ) cells .",
        "this paper presents a new state - of - the - art for document image classification and retrieval , using features learned by deep convolutional neural networks ( cnns ) .",
        "in object and scene analysis , deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations .",
        "in this paper , we propose a new approach which uses deep neural network to learn features automatically from data .",
        "a long short - term memory ( lstm ) network is a type of recurrent neural network architecture which has recently obtained strong results on a variety of sequence modeling tasks .",
        "in this paper , we propose a non - linear modeling for the quality of translation hypotheses based on neural networks , which allows more complex interaction between features .",
        "recursive neural models , which use syntactic parse trees to recursively generate representations bottom - up from parse children , are a popular new architecture , promising to capture structural properties like the scope of negation or long - distance semantic dependencies .",
        "in this paper we benchmark recursive neural models against sequential recurrent neural models , which are structured solely on word sequences .",
        "our results offer insights on the design of neural architectures for representation learning .",
        "we apply a sequential model - based optimization technique and show that our method makes standard linear models competitive with more sophisticated , expensive state - of - the - art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems .",
        "we then refine this alignment using a state - of - the - art visual food detector , based on a deep convolutional neural network .",
        "among these are a convolutional neural network , focusing on capturing visual information in detected faces , a deep belief net focusing on the representation of the audio stream , a k - means based \" bag - of - mouths \" model , which extracts visual features around the mouth region and a relational autoencoder , which addresses spatio - temporal aspects of videos .",
        "deep neural networks have recently achieved state of the art performance thanks to new training algorithms for rapid parameter estimation and new regularization methods to reduce overfitting .",
        "for convolutional neural networks , our method relies on iterative split / merge clustering of convolutional kernels interleaved by stochastic gradient descent .",
        "the recently proposed neural network joint model ( nnjm ) ( devlin et al .",
        "this representation , together with target language words , are fed to a deep neural network ( dnn ) to form a stronger nnjm .",
        "we present a bayesian approach to adapting parameters of a well - trained context - dependent deep - neural - network hid - den markov models ( cd - dnn - hmms ) to improve automatic speech recognition performance .",
        "an artificial neural network ( self - organizing map ) is fitted to train on more than a million data points to predict \" good investments \" given testing stocks from 2013 and after .",
        "convolutional neural networks with many layers have recently been shown to achieve excellent results on many high - level tasks such as image classification , object detection and more recently also semantic segmentation .",
        "we propose a novel method for translation selection in statistical machine translation , in which a convolutional neural network is employed to judge the similarity between a phrase pair in two languages .",
        "we propose neural responding machine ( nrm ) , a neural network - based response generator for short - text conversation .",
        "nrm takes the general encoder - decoder framework : it formalizes the generation of response as a decoding process based on the latent representation of the input text , while both encoding and decoding are realized with recurrent neural networks ( rnn ) .",
        "deep neural networks ( dnns ) are analyzed via the theoretical framework of the information bottleneck ( ib ) principle .",
        "we are proposing an extension of the recursive neural network that makes use of a variant of the long short - term memory architecture .",
        "experimental results show that our composition outperformed the traditional neural - network composition on the stanford sentiment treebank .",
        "it has relations with neural networks but works in a different way , requiring only a single pass through the classifier to generate the weight sets .",
        "also , the high number of factors , incomplete and unbalanced dataset , and black boxing issues as in artificial neural networks and fuzzy logic systems exposes the need for more efficient tools .",
        "as a step toward this goal , we propose convolutional neural network models for matching two sentences , by adapting the convolutional strategy in vision and speech .",
        "recent work on end - to - end neural network - based architectures for machine translation has shown promising results for english - french and english - german translation .",
        "in this work , we focus on applying neural machine translation to challenging / low - resource languages such as chinese and turkish .",
        "compared to multilayer neural networks with real weights , binary multilayer neural networks ( bmnns ) can be implemented more efficiently on dedicated hardware .",
        "the performances of binary neural networks with multiple hidden layers and different numbers of hidden units are examined on mnist .",
        "several variants of the long short - term memory ( lstm ) architecture for recurrent neural networks have been proposed since its inception in 1995 .",
        "we present a neural network architecture and training method designed to enable very rapid training and low implementation complexity .",
        "different from previous work on neural network - based language modeling and generation ( e .",
        "instead , we use a convolutional neural network to predict the next word with the history of words of variable length .",
        "we propose an efficient method for approximating natural gradient descent in neural networks which we call kronecker - factored approximate curvature ( k - fac ) .",
        "k - fac is based on an efficiently invertible approximation of a neural network ' s fisher information matrix which is neither diagonal nor low - rank , and in some cases is completely non - sparse .",
        "in this paper , we propose to solve the corresponding inversion problem by utilizing the disagreements of an ensemble of neural networks to represent the prediction error in the unexplored component space .",
        "here , we train a convolutional deep neural network to re - synthesize input time - domain speech signals at its output layer .",
        "here , we trained two separate convolutive autoencoder deep neural networks ( dnn ) to separate monaural and binaural mixtures of two concurrent speech streams .",
        "our simulations demonstrate that very simple neural networks are capable of exploiting monaural and binaural information available in a cocktail party listening scenario .",
        "here , we train a convolutional deep neural network , on a two - speaker cocktail party problem , to make probabilistic predictions about binary masks .",
        "our results approach ideal binary mask performance , illustrating that relatively simple deep neural networks are capable of robust binary mask prediction .",
        "we propose a new way of incorporating temporal information present in videos into spatial convolutional neural networks ( convnets ) trained on images , that avoids training spatio - temporal convnets from scratch .",
        "this framework includes specific assumptions about the mechanisms that contribute to the evolution of ( artificial ) neural networks to generate topologies that allow the networks to learn large - scale complex problems using only information about the quality of their performance .",
        "in this paper , we refer to convolutional neural networks , and use an adaptation technique based on a stacked convolutional auto - encoder that exploits unlabeled real - world images combined with synthetic data .",
        "we train a recurrent neural network ( rnn ) to map dictionary definitions ( phrases ) to ( lexical ) representations of the words those definitions define .",
        "this strong performance highlights the general effectiveness of both neural language models and definition - based training for training machines to understand phrases and sentences .",
        "this paper proposes a new convolutional neural architecture based on tree - structures , called the tree - based convolutional neural network ( tbcnn ) .",
        "compared with traditional \" flat \" convolutional neural networks ( cnns ) , tbcnns explore explicitly the structural information of sentences ; compared with recursive neural networks , tbcnns have much shorter propagation paths , enabling more effective feature learning and extraction .",
        "based on this theory , we propose a new semi - supervised learning framework that learns a multi - view embedding of small text regions with convolutional neural networks .",
        "to facilitate the process , the proposed approach leverages with densenet , an efficient implementation of multiscale convolutional neural networks ( cnns ) , to extract an informative feature vector for each pixel and uses an svm classifier to accomplish contour detection .",
        "we present a novel network architecture , hashednets , that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes .",
        "our hashing procedure introduces no additional memory overhead , and we demonstrate on several benchmark data sets that hashednets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance .",
        "in this work we tackle the relation classification task using a convolutional neural network that performs classification by ranking ( cr - cnn ) .",
        "this paper presents an approach that reasons about conjunctions of multi - hop relations non - atomically , composing the implications of a path using a recursive neural network ( rnn ) that takes as inputs vector embeddings of the binary relation in the path .",
        "we learn the cltm tree structure using conditional pairwise probabilities for object co - occurrences , estimated through kernel methods , and we learn its node and edge potentials by training a new 3 - layer neural network , which takes fc7 features as input .",
        "this paper proposes an architecture for deep neural networks with hidden layer branches that learn targets of lower hierarchy than final layer targets .",
        "there is plenty of theoretical and empirical evidence that depth of neural networks is a crucial ingredient for their success .",
        "for example , deep neural networks have been more successful than shallow networks because they can perform a greater number of sequential computational steps ( each highly parallel ) .",
        "the neural turing machine ( ntm ) is a model that can compactly express an even greater number of sequential computational steps , so it is even more powerful than a dnn .",
        "we propose an object detection system that relies on a multi - region deep convolutional neural network ( cnn ) that also encodes semantic segmentation - aware features .",
        "the first uses a pipelined process where a set of candidate words is generated by a convolutional neural network ( cnn ) trained on images , and then a maximum entropy ( me ) language model is used to arrange these words into a coherent sentence .",
        "the second uses the penultimate activation layer of the cnn as input to a recurrent neural network ( rnn ) that then generates the caption sequence .",
        "in our work , we propose to use recurrent neural networks and visual semantic embeddings without intermediate stages such as object detection and image segmentation .",
        "deep neural networks have recently achieved state - of - the - art results in many machine learning problems , e .",
        "hitherto , work on rectified linear units ( relu ) provides empirical and theoretical evidence on performance increase of neural networks comparing to typically used sigmoid activation function .",
        "in this paper , we investigate a new manner of improving neural networks by introducing a bunch of copies of the same neuron modeled by the generalized kumaraswamy distribution .",
        "in the experimental study with mnist image corpora we evaluate the kumaraswamy unit applied to single - layer ( shallow ) neural network and report a significant drop in test classification error and test cross - entropy in comparison to sigmoid unit , relu and noisy relu .",
        "in this paper , we present a fully automatic brain tumor segmentation method based on deep neural networks ( dnns ) .",
        "we explore in particular different architectures based on convolutional neural networks ( cnn ) , i .",
        "one is the fully - connected neural network consists of multiple single neurons .",
        "our approach is based on the charwnn deep neural network , which uses word - level and character - level representations ( embeddings ) to perform sequential classification .",
        "our experimental results shade light on the contribution of neural character embeddings for ner .",
        "moreover , we demonstrate that the same neural network which has been successfully applied for pos tagging can also achieve state - of - the - art results for language - independet ner , using the same hyper - parameters , and without any handcrafted features .",
        "it can also work in a batch mode , with reduced training times and can be used as part of a neural network , or classifiers in general .",
        "our model contains four components : a long - short term memory ( lstm ) to extract the question representation , a convolutional neural network ( cnn ) to extract the visual representation , a lstm for storing the linguistic context in an answer , and a fusing component to combine the information from the first three components and generate the answer .",
        "we propose a recursive convolutional neural network ( rcnn ) architecture to capture syntactic and compositional - semantic representations of phrases and words in a dependency tree .",
        "different with the original recursive neural network , we introduce the convolution and pooling layers , which can model a variety of compositions by the feature maps and choose the most informative compositions by the pooling layers .",
        "some of the techniques that were found beneficial are : maxout networks with annealed dropout rates ; networks with a very large number of outputs trained on 2000 hours of data ; joint modeling of partially unfolded recurrent neural networks and convolutional nets by combining the bottleneck and output layers and retraining the resulting model ; and lastly , sophisticated language model rescoring with exponential and neural network lms .",
        "we introduce a neural network method to encode programs as a linear mapping from an embedded precondition space to an embedded postcondition space and propose an algorithm for feedback at scale using these linear maps as features .",
        "although deep neural networks ( dnn ) are able to scale with direct advances in computational power ( e .",
        "recent research shows that deep neural networks ( dnns ) can be used to extract deep speaker vectors ( d - vectors ) that preserve speaker characteristics and can be used in speaker verification .",
        "this paper aims to accelerate the test - time computation of convolutional neural networks ( cnns ) , especially very deep cnns that have substantially impacted the computer vision community .",
        "i used two different methods to predict the fantasy football scores of nfl players : support vector regression ( svr ) and neural networks .",
        "in this paper we present a convolutional neural network ( cnn ) , trained for the first time with the purpose of recognizing revisited locations under severe appearance changes , which maps images to a low dimensional space where euclidean distances represent place dissimilarity .",
        "our primary innovation is a new control structure for sequence - to - sequence neural networks - - - the stack lstm .",
        "recurrent neural networks ( rnns ) have become increasingly popular for the task of language understanding .",
        "we find that the simple side - conditioned generation approach is able to rival the state - of - the - art , and we are able to significantly advance the stat - of - the - art with bi - directional long short - term memory ( lstm ) neural networks that use the same alignment information that is used in conventional approaches .",
        "in this paper , we propose to employ the convolutional neural network ( cnn ) for learning to answer questions from the image .",
        "our method is based on two recently introduced neural network vector representation models for words and sentences .",
        "we present a three - pronged approach to improving statistical machine translation ( smt ) , building on recent success in the application of neural networks to smt .",
        "first , we propose new features based on neural networks to model various non - local translation phenomena .",
        "second , we augment the architecture of the neural network with tensor layers that capture important higher - order interaction among the network units .",
        "third , we apply multitask learning to estimate the neural network parameters jointly .",
        "8 bleu points for arabic - english and chinese - english translation over a state - of - the - art system that already includes neural network features .",
        "this paper proposes an ros learning approach based on deep neural networks ( dnn ) , which involves an ros feature as the input of the dnn model and so the spectrum distortion caused by ros can be learned and compensated for .",
        "we evaluate the reconstructed paragraph using standard metrics like rouge and entity grid , showing that neural models are able to encode texts in a way that preserve syntactic , semantic , and discourse coherence .",
        "while only a first step toward generating coherent text units from neural models , our work has the potential to significantly impact natural language generation and summarization \\ footnote { code for the three models described in this paper can be found at www .",
        "while neural networks have been successfully applied to many nlp tasks the resulting vector - based models are very difficult to interpret .",
        "in this paper we describe four strategies for visualizing compositionality in neural models for nlp , inspired by similar work in computer vision .",
        "a neuromorphic chip that combines cmos analog spiking neurons and memristive synapses offers a promising solution to brain - inspired computing , as it can provide massive neural network parallelism and density .",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning algorithm , learning to find the best structured object ( such as a label sequence ) given a structured input ( such as a vector sequence ) by globally considering the mapping relationships between the structure rather than item by item .",
        "it is known that the learning rate is the most important hyper - parameter to tune for training deep convolutional neural networks ( i .",
        "these methods are practical tools for everyone who trains convolutional neural networks .",
        "in this paper , we propose a universal recurrent neural network language model with user characteristic features , so all users share the same model , except each with different user characteristic features .",
        "convolutional neural networks ( cnn ) is one kind of deep neural network .",
        "in this article , we use convolutional neural network to implement the typical face recognition problem which can overcome the influence of pose or resolution in face recognition .",
        "recurrent neural networks ( rnns ) , and specifically a variant with long short - term memory ( lstm ) , are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data .",
        "we proffer a new , efficient deep structured model learning scheme , in which we show how deep convolutional neural networks ( cnns ) can be used to estimate the messages in message passing inference for structured prediction with conditional random fields ( crfs ) .",
        "deep neural networks trained on large - scale dataset can learn transferable features that promote learning multiple tasks for inductive transfer and labeling mitigation .",
        "in this work , we propose a novel deep relationship network ( drn ) architecture for multi - task learning by discovering correlated tasks based on multiple task - specific layers of a deep convolutional neural network .",
        "in this paper , we explore the inclusion of random variables into the dynamic latent state of a recurrent neural network ( rnn ) by combining elements of the variational autoencoder .",
        "we call this iterative system the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) which generates high quality features for track 1 of the challenge and acoustic tokens for track 2 of the challenge .",
        "we propose a new neural language model incorporating both word order and character order in its embedding .",
        "furthermore , the model includes several parallel training methods , most notably allowing a skip - gram network with 160 billion parameters to be trained overnight on 3 multi - core cpus , 14x larger than the previous largest neural network .",
        "along with this variance - reduction scheme , we use trust region algorithms to optimize the policy and value function , both represented as neural networks .",
        "in contrast to prior work that uses hand - crafted low - dimensional policy representations , our neural network policies map directly from raw kinematics to joint torques .",
        "deep learning with a convolutional neural network ( cnn ) has been proved to be very effective in feature extraction and representation of images .",
        "recently , strong results have been demonstrated by deep recurrent neural networks on natural language transduction problems .",
        "we revisit the choice of sgd for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights .",
        "neural networks are both computationally intensive and memory intensive , making them difficult to deploy on embedded systems .",
        "to address these limitations , we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy , by learning only the important connections .",
        "while our theoretical guarantees assume convexity , we discuss the applicability of our method to deep neural networks , and experimentally demonstrate its merits .",
        "this paper proposes a set of new error criteria and learning approaches , adaptive normalized risk - averting training ( anrat ) , to attack the non - convex optimization problem in training deep neural networks ( dnns ) .",
        "in practice , we show how this method improves training of deep neural networks to solve visual recognition tasks on the mnist and cifar - 10 datasets .",
        "in doing this , we introduce the pioneering concept referred to as neural promotion , where neurons gain prominence in",
        "recurrent neural networks can be trained to produce sequences of tokens given some input , as exemplified by recent results in machine translation and image captioning .",
        "we introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence .",
        "such problems cannot be trivially addressed by existent approaches such as sequence - to - sequence and neural turing machines , because the number of target classes in each step of the output depends on the length of the input , which is variable .",
        "our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention .",
        "this work presents a cognitive system , entirely based on a large - scale neural architecture , which was developed to shed light on how the procedural knowledge involved in language elaboration arises from neural processes .",
        "in our model , the central executive is a neural network that takes as input the neural activation states of the short - term memory and yields as output mental actions , which control the flow of information among the working memory components through neural gating mechanisms .",
        "we use the new framework to adapt powerful proposal distributions with rich parameterisations based upon neural networks leading to neural adaptive sequential monte carlo ( nasmc ) .",
        "finally we show that nasmc is able to train a neural network - based deep recurrent generative model achieving results that compete with the state - of - the -",
        "this allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure .",
        "we analyze the performance in a random matrix setting using results from the statistical mechanics of the hopfield neural network , and show in particular that macbeth efficiently detects the rank $ r $ of a large $ n \\ times m $ matrix from $ c ( r ) r \\ sqrt { nm } $ entries , where $ c ( r ) $ is a constant close to $ 1 $ .",
        ", the space defined by one of the top layers of a convolutional neural network ) .",
        "we construct our models using neural networks and train them using a form of guided policy search .",
        "the outputs of non - linear feed - forward neural network are positive , which could be treated as probability when they are normalized to one .",
        "as this paper defines two processes in feed - forward neural network , our limited condition is the abstracted features of samples which are worked out in the abstraction process .",
        "as entropy - based principle is considered into the feed - forward neural network , a clustering method is born .",
        "meanwhile , feed - forward neural network is a traditional classifier , which is very hot at present with a deeper architecture .",
        "however , the training algorithm of feed - forward neural network is developed and generated from widrow - hoff principle that means to minimize the squared error .",
        "in this paper , we propose a new training algorithm for feed - forward neural networks based on margin - based principle , which could effectively promote the accuracy and generalization ability of neural network classifiers with less labelled samples and flexible network .",
        "in this work , we demonstrate that , beyond its advantages for efficient computation , the spectral domain also provides a powerful representation in which to model and train convolutional neural networks ( cnns ) .",
        "secondly , each layer of data is fed into a deep neural network model for classification , where a graph regularization is imposed to the deep architecture for keeping local consistency between adjacent samples .",
        "our model is an alignment - based long short - term memory recurrent neural network ( attention - based lstm - rnn ) that encodes the free - form navigational instruction sentence and the corresponding representation of the environment state .",
        "we consider the problem of bayesian parameter estimation for deep neural networks , which is important in problem settings where we may have little data , and / or where we need accurate posterior predictive densities , e .",
        "convolutional neural networks ( cnn ) are increasingly used in many areas of computer vision .",
        "the online learning of deep neural networks is an interesting problem of machine learning because , for example , major it companies want to manage the information of the massive data uploaded on the web daily , and this technology can contribute to the next generation of lifelong learning .",
        "unfortunately , deep neural network learning through classical online and incremental methods does not work well in both theory and practice .",
        "distilling knowledge from a well - trained cumbersome network to a small one has become a new research topic recently , as lightweight neural networks with high performance are particularly in need in various resource - restricted systems .",
        "experimental results show our method is better than directly training neural networks with small embeddings .",
        "tree - structured neural networks encode a particular tree geometry for a sentence in the network design .",
        "we hypothesize that neural sequence models like lstms are in fact able to discover and implicitly use recursive compositional structure , at least for tasks with clear cues to that structure in the data .",
        "recurrent neural networks ( rnns ) are very good at modelling the flow of text , but typically need to be trained on a far larger corpus than is available for the pan 2015 author identification task .",
        "in this thesis , two artificial neural network ( ann ) based frameworks are proposed to model sand fraction from multiple seismic attributes without and with well tops information respectively .",
        "deep neural networks ( dnn ) have achieved huge practical success in recent years .",
        "however , its theoretical properties ( in particular generalization ability ) are not yet very clear , since existing error bounds for neural networks cannot be directly used to explain the statistical behaviors of practically adopted dnn models ( which are multi - class in their nature and may contain convolutional layers ) .",
        "to achieve this , we executed supervised training of a convolutional neural network to recover the removed center pixel label of patches sampled from a mdpm .",
        "based on the corpus , we introduce recurrent neural network for the summary generation and achieve promising results , which not only shows the usefulness of the proposed corpus for short text summarization research , but also provides a baseline for further research on this topic .",
        "in this paper we explore the utility of using recurrent neural networks ( rnns ) to model student learning .",
        "using neural networks results in substantial improvements in prediction performance on a range of knowledge tracing datasets .",
        "we present structured perceptron training for neural network transition - based dependency parsing .",
        "we learn the neural network representation using a gold corpus augmented by a large number of automatically parsed sentences .",
        "we propose neural transformation machine ( ntram ) , a novel architecture for sequence - to - sequence learning , which performs the task through a series of nonlinear transformations from the representation of the input sequence ( e .",
        "inspired by the recent neural turing machines [ 8 ] , we store the intermediate representations in stacked layers of memories , and use read - write operations on the memories to realize the nonlinear transformations of those representations .",
        "ntram is broad enough to subsume the state - of - the - art neural translation model in [ 2 ] as its special case , while significantly improves upon the model with its deeper architecture .",
        "remarkably , ntram , being purely neural network - based , can achieve performance comparable to the traditional phrase - based machine translation system ( moses ) with a small vocabulary and a modest parameter size .",
        "our approach applies convolution neural networks ( cnns ) to learning the joint representation of question - answer pair firstly , and then uses the joint representation as input of the long short - term memory ( lstm ) to learn the answer sequence of a question for labeling the matching quality of each answer .",
        "recent years have produced great advances in training large , deep neural networks ( dnns ) , including notable successes in training convolutional neural networks ( convnets ) to recognize natural images .",
        "progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets .",
        "a neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models , allowing the system to take into account previous dialog utterances .",
        "in this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market .",
        "we introduce the dynamic memory network ( dmn ) , a unified neural network framework which processes input sequences and questions , forms semantic and episodic memories , and generates relevant answers .",
        "convolutional neural networks ( cnns ) can be shifted across 2d images or 3d videos to segment them .",
        "previous neural network models often suffer from irrelevant information introduced when subjects and objects are in a long distance .",
        "in this paper , we propose to learn more robust relation representations from the shortest dependency path through a convolution neural network .",
        "we present a complimentary objective for training recurrent neural networks ( rnn ) with gating units that helps with regularization and interpretability of the trained model .",
        "a deep learning approach has been proposed recently to derive speaker identifies ( d - vector ) by a deep neural network ( dnn ) .",
        "this paper studies convolutional neural networks ( cnn ) to learn unsupervised feature representations for 44 different plant species , collected at the royal botanic gardens , kew , england .",
        "this provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data .",
        "we also describe two neural learning architectures suitable for analyzing this dataset , and provide benchmark performance on the task of selecting the best next response .",
        "we introduce natural neural networks , a novel family of algorithms that speed up convergence by adapting their internal representation during training to improve conditioning of the fisher matrix .",
        "in particular , we show a specific example that employs a simple and efficient reparametrization of the neural network weights by implicitly whitening the representation obtained at each layer , while preserving the feed - forward computation of the network .",
        "recent work on language modelling has shifted focus from count - based models to neural models .",
        "in this paper we show how we can improve the performance of the recurrent neural network ( rnn ) language model by incorporating the syntactic dependencies of a sentence , which have the effect of bringing relevant contexts closer to the word being predicted .",
        "47 bits per character on the wikipedia character prediction benchmark , which is state - of - the - art among neural approaches .",
        "in sentence modeling and classification , convolutional neural network approaches have recently achieved state - of - the - art results , but all such efforts process word vectors sequentially and neglect long - distance dependencies .",
        "to exploit both deep learning and linguistic structures , we propose a tree - based convolutional neural network model which exploit various long - distance relationships between words .",
        "we combine supervised learning with unsupervised learning in deep neural networks .",
        "this paper describes a parsing model that combines the exact dynamic programming of crf parsing with the rich nonlinear featurization of neural net approaches .",
        "our model is structurally a crf that factors over anchored rule productions , but instead of linear potential functions based on sparse features , we use nonlinear potentials computed via a feedforward neural network .",
        "using only dense features , our neural crf already exceeds a strong baseline crf model ( hall et al .",
        "to exploit the semantic representation behind the adp structure , we develop dependency - based neural networks ( depnn ) : a recursive neural network designed to model the subtrees , and a convolutional neural network to capture the most important features on the shortest path .",
        "to this end , we extend the recently proposed hierarchical recurrent encoder decoder neural network and demonstrate that this model is competitive with state - of - the - art neural language models and backoff n - gram models .",
        "theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success .",
        "we propose and evaluate two deep neural network architectures that consist of encoding , action - conditional transformation , and decoding layers based on convolutional neural networks and recurrent neural networks .",
        "starting with a high - performance transition - based parser that uses long short - term memory ( lstm ) recurrent neural networks to learn representations of the parser state , we replace look - up based word representations with representations constructed based on the orthographic representations of the words , also using lstms .",
        "in this paper , we present sdp - lstm , a novel neural network to classify the relation of two entities in a sentence .",
        "our neural architecture leverages the shortest dependency path ( sdp ) between two entities ; multichannel recurrent neural networks , with long short term memory ( lstm ) units , pick up heterogeneous information along the sdp .",
        "( 3 ) a customized dropout strategy regularizes the neural network to alleviate overfitting .",
        "this paper aims to compare different regularization strategies to address a common phenomenon , severe overfitting , in embedding - based neural networks for nlp .",
        "we chose two widely studied neural models and tasks as our testbed .",
        "the results provide a picture on tuning hyperparameters for neural nlp models .",
        "most existing word embedding methods can be categorized into neural embedding models and matrix factorization ( mf ) - based methods .",
        "we investigate an extension of continuous online learning in recurrent neural network language models .",
        "an attentional mechanism has been used in neural machine translation ( nmt ) to selectively focus on parts of the source sentence during translation .",
        "the distinctive features and advantages are summarised : simplification and integration of observations and concepts , and of structures and processes in computing systems ; the sp theory is itself a theory of computing ; a central role for information compression via the matching and unification of patterns , and for multiple alignment ; transparency in the representation and processing of knowledge ; the discovery of ' natural ' structures via information compression ( donsvic ) ; interpretation of aspects of mathematics ; interpretation of phenomena in human perception and cognition ; realisation of abstract concepts in terms of neurons and their inter - connections ( \" sp - neural \" ) .",
        "distinctive features and advantages of the sp system compared with alternatives in : minimum length encoding and related concepts ; deep learning in neural networks ; universal search ; bayesian networks and other models for ai ; analysis and production of natural language ; learning natural language ; exact and inexact reasoning ; representation and processing of diverse forms of knowledge ; ibm ' s watson ; problems associated with big data , and in the development of intelligence in autonomous robots .",
        "regularisation of deep neural networks ( dnn ) during training is critical to performance .",
        "neural networks have been shown to improve performance across a range of natural - language tasks .",
        "we also include these models in a machine translation decoder and show that these smaller neural models maintain the significant improvements of their unpruned versions .",
        "we propose a method combining relational - logic representations with deep neural network learning .",
        "the relational rule - set serves as a template for unfolding possibly deep neural networks whose structures also reflect the structure of given training or testing examples .",
        "contemporary deep neural networks exhibit impressive results on practical problems .",
        "we analyze this behavior in the context of deep , infinite neural networks .",
        "this increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models , and it allows a neural network - based model to perform competitively on natural language inference benchmarks for the first time .",
        "deep neural networks is a branch in machine learning that has seen a meteoric rise in popularity due to its powerful abilities to represent and model high - level abstractions in highly complex data .",
        "one area in deep neural networks that is ripe for exploration is neural connectivity formation .",
        "a pivotal study on the brain tissue of rats found that synaptic formation for specific functional connectivity in neocortical neural microcircuits can be surprisingly well modeled and predicted as a random formation .",
        "motivated by this intriguing finding , we introduce the concept of stochasticnet , where deep neural networks are formed via stochastic connectivity between neurons .",
        "such stochastic synaptic formations in a deep neural network architecture can potentially allow for efficient utilization of neurons for performing specific tasks .",
        "to evaluate the feasibility of such a deep neural network architecture , we train a stochasticnet using three image datasets .",
        "experimental results show that a stochasticnet can be formed that provides comparable accuracy and reduced overfitting when compared to conventional deep neural networks with more than two times the number of neural connections .",
        "we propose neural reasoner , a framework for neural network - based reasoning over natural language sentences .",
        "given a question , neural reasoner can infer over multiple supporting facts and find an answer to the question in specific forms .",
        "neural reasoner has 1 ) a specific interaction - pooling mechanism , allowing it to examine multiple facts , and 2 ) a deep architecture , allowing it to model the complicated logical relations in reasoning tasks .",
        "assuming no particular structure exists in the question and facts , neural reasoner is able to accommodate different types of reasoning and different forms of language expressions .",
        "despite the model complexity , neural reasoner can still be trained effectively in an end - to - end manner .",
        "our empirical studies show that neural reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks ( positional reasoning and path finding ) proposed in [ 8 ] .",
        "some novel strategies have recently been proposed for single hidden layer neural network training that set randomly the weights from input to hidden layer , while weights from hidden to output layer are analytically determined by pseudoinversion .",
        "for this reason , a hybrid neuro - fuzzy is used because it takes advantages of the neural networks learning and fuzzy logic human - like reasoning .",
        "this thesis describes the design and implementation of a smile detector based on deep convolutional neural networks .",
        "it starts with a summary of neural networks , the difficulties of training them and new training methods , such as restricted boltzmann machines or autoencoders .",
        "it then provides a literature review of convolutional neural networks and recurrent neural networks .",
        "we study a class of neural nets - gibbs machines - which are a type of variational auto - encoders , designed for gradual learning .",
        "combining them with classifiers gives rise to a brand of universal generative neural nets - stochastic auto - classifier - encoders ( ace ) .",
        "we describe a simple neural language model that relies only on character - level inputs .",
        "our model employs a convolutional neural network ( cnn ) over characters , whose output is given to a long short - term memory ( lstm ) recurrent neural network language model ( rnn - lm ) .",
        "recently proposed methodologies lack a satisfactory discussion of whether they actually produce the correct results according to their definition , especially in the context of convolutional neural networks .",
        "the tools developed in this paper are especially beneficial if convolutional neural networks are employed , but can also be used as a more general framework to validate related approaches to signal scanning .",
        "in this work , the trepan algorithm is enhanced and extended for extracting decision trees from neural networks .",
        "neural machine translation ( nmt ) models typically operate with a fixed vocabulary , so the translation of rare and unknown words is an open problem .",
        "we present an end - to - end , domain - independent neural encoder - aligner - decoder model for selective generation , i .",
        ", in weather forecasting and sportscasting ) via a memory - based recurrent neural network ( lstm ) , then utilizes a novel coarse - to - fine ( hierarchical ) , multi - input aligner to identify the small subset of salient records to talk about , and finally employs a decoder to generate free - form descriptions of the aligned , selected records .",
        "despite the promise of brain - inspired machine learning , deep neural networks ( dnn ) have frustratingly failed to bridge the deceptively large gap between learning and memory .",
        "in the second step , for plant classification , we employed different support vector machine ( svm ) kernels and two hybrid systems of neural networks .",
        "our experimental shows that mnce and gncl improve the efficiency of classical classifiers , however , some svm kernels function has better performance than classifiers based on neural network ensemble method .",
        "in this paper , we propose another version of help - training approach by employing a probabilistic neural network ( pnn ) that improves the performance of the main discriminative classifier in the semi - supervised strategy .",
        "next , we present a recursive neural network over the rst structure , which offers significant improvements over classification - based methods .",
        "comparisons are offered against traditional models such as bag of words , n - grams and their tfidf variants , and deep learning models such as word - based convnets and recurrent neural networks .",
        "the downfall of many supervised learning algorithms , such as neural networks , is the inherent need for a large amount of training data .",
        "evolution of visual object recognition architectures based on convolutional neural networks & amp ; convolutional deep belief networks paradigms has revolutionized artificial vision science .",
        "recently , many researches employ middle - layer output of convolutional neural network models ( cnn ) as features for different visual recognition tasks .",
        "in this paper , we present a system that employs a wearable acoustic sensor and a deep convolutional neural network for detecting coughs .",
        "in particular , we study reinforcement learning with deep neural networks , including rnn and lstm , which are equipped with the desired property of being able to capture long - term dependency on history , and thus providing an effective way of learning the representation of hidden states .",
        "in a recent article we described a new type of deep neural network - a perpetual learning machine ( plm ) - which is capable of learning ' on the fly ' like a brain by existing in a state of perpetual stochastic gradient descent ( psgd ) .",
        "recurrent neural network ( rnn ) is one of the most popular and simple approach to model the dynamics as well as to infer correct dependencies among genes .",
        "this work presents and analyzes three convolutional neural network ( cnn ) models for efficient pixelwise classification of images .",
        "when using convolutional neural networks to classify single pixels in patches of a whole image , a lot of redundant computations are carried out when using sliding window networks .",
        "multidimensional recurrent neural network ( mdrnn ) has shown a remarkable performance in speech and handwriting recognition .",
        "an unbalanced synergetic neural net - work classifies shapes and structures of human objects along with tuning its attention parameter by quantum particle swarm optimization ( qpso ) via initiation of centroidal voronoi tessellations .",
        "two configurations have been proposed for form pathway : applying multi - prototype human action templates using two time synergetic neural network for obtaining uniform template regarding each actions , and second scenario that it uses abstracting human action in four key - frames .",
        "automatic speech recognition ( asr ) is achieved by two multi - pass deep neural network systems with adaptation and rescoring techniques .",
        "with the impressive capability to capture visual content , deep convolutional neural networks ( cnn ) have demon - strated promising performance in various vision - based ap - plications , such as classification , recognition , and objec - t detection .",
        "in this paper , to address this problem , we proposed a new kernelized deep convolutional neural network .",
        "rectified linear units ( relu ) seem to have displaced traditional ' smooth ' nonlinearities as activation - function - du - jour in many - but not all - deep neural network ( dnn ) applications .",
        "we propose a convolutional neural network ( cnn ) architecture for facial expression recognition .",
        "the proposed architecture is independent of any hand - crafted feature extraction and performs better than the earlier proposed convolutional neural network based approaches .",
        "stochastic gradient descent ( sgd ) is arguably the most popular of the machine learning methods applied to training deep neural networks ( dnn ) today .",
        "training a denoising autoencoder neural network requires access to truly clean data , a requirement which is often impractical .",
        "motivated by the needs in leveraging large scale yet noisy training data to solve the extremely challenging problem of image sentiment analysis , we employ convolutional neural networks ( cnn ) .",
        "in the back - end , several techniques are taken advantage to improve the noisy automatic speech recognition ( asr ) performance including deep neural network ( dnn ) , convolutional neural network ( cnn ) and long short - term memory ( lstm ) using medium vocabulary , lattice rescoring with a big vocabulary language model finite state transducer , and rover scheme .",
        "in particular , we first show that the recent dqn algorithm , which combines q - learning with a deep neural network , suffers from substantial overestimations in some games in the atari 2600 domain .",
        "deep neural networks currently demonstrate state - of - the - art performance in several domains .",
        "end - to - end differentiable neural architectures have failed to approach state - of - the - art performance until very recently .",
        "in this paper , we propose a neural model that reads two sentences to determine entailment using long short - term memory units .",
        "we extend this model with a word - by - word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases .",
        "on a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin .",
        "despite their success , convolutional neural networks are computationally expensive because they must examine all image locations .",
        "using the simulation and programming environment netlogo , a software engine for the integrate and fire model was developed , which allowed us to monitor in discrete time steps the dynamics of each single neuron , synapse and spike in the proposed neural networks .",
        "these spiking neural networks ( snn ) served as simple brains for the experimental robots .",
        "in this paper the topological building blocks are presented as well as the neural parameters required to reproduce the experiments .",
        "this paper summarizes the resulting behaviour as well as the observed dynamics of the neural circuits .",
        "an artificial neural network ( ann ) with conjugate - gradient learning algorithm has been used to model the sand fraction .",
        "neural networks have shown its potential to model such nonlinear mappings ; however , uncertainties associated with the model and datasets are still a concern .",
        "more specifically , hybrid variants of artificial neural network ( ann ) and fuzzy logic , i .",
        "the state - of - the - art speech recognition techniques , namely recurrent neural network based acoustic and language modeling , state space minimum bayes risk based discriminative acoustic modeling , and i - vector based acoustic condition modeling , are carefully integrated into the speech recognition back - end .",
        ", in vivo neural recording and electrocorticography ( ecog ) , some measurement artifacts take the form of piecewise exponential transients .",
        "the chip is verified with neural data recorded in monkey finger movements experiment , achieving a decoding accuracy of 99 .",
        "the same co - processor is also used to decode time of movement from asynchronous neural spikes .",
        "we used tiled convolutional neural networks to learn high - level features from individual gaf , mtf , and gaf - mtf images on 12 benchmark time series datasets and two real spatial - temporal trajectory datasets .",
        "in this paper , we evaluate convolutional neural network ( cnn ) features using the alexnet architecture and very deep convolutional network ( vggnet ) architecture .",
        "deep neural network architectures have recently produced excellent results in a variety of areas in artificial intelligence and visual recognition , well surpassing traditional shallow architectures trained using hand - designed features .",
        "we implement the idea by formulating the problem as a single neural network architecture , including the estimation of a speaker model on only a few utterances , and evaluate it on our internal \" ok google \" benchmark for text - dependent speaker verification .",
        "because of their performance , deep neural networks are increasingly used for object recognition .",
        "convolutional neural networks ( cnns ) are a standard component of many current state - of - the - art large vocabulary continuous speech recognition ( lvcsr ) systems .",
        "however , cnns in lvcsr have not kept pace with recent advances in other domains where deeper neural networks provide superior performance .",
        "we introduce a convolutional neural network that operates directly on graphs , allowing end - to - end learning of the feature pipeline .",
        "neural language models are a powerful tool to meaningfully embed words into semantic vector spaces .",
        "over the past few years , neural networks have re - emerged as powerful machine - learning models , yielding state - of - the - art results in fields such as image recognition and speech processing .",
        "more recently , neural network models started to be applied also to textual natural language signals , again with very promising results .",
        "this tutorial surveys neural network models from the perspective of natural language processing research , in an attempt to bring natural - language researchers up to speed with the neural techniques .",
        "our best approach uses side information in the form of known word pairs to train a siamese convolutional neural network ( cnn ) : a pair of tied networks that take two speech segments as input and produce their embeddings , trained with a hinge loss that separates same - word pairs and different - word pairs by some margin .",
        "we propose a novel switching recurrent neural network with word - level regularization , which is able to produce emotional image captions using only 2000 + training sentences containing sentiments .",
        "furthermore , the proposed modeling and synthesis platform outperforms a leading - edge , vocoded , deep bidirectional long short - term memory recurrent neural network ( dblstm - rnn ) - based baseline system in various objective evaluation metrics conducted .",
        "in parallel , in the last few years , language models based on neural networks have been used to cope with complex natural language processing tasks like emotion and paraphrase detection .",
        "based on a recent work that proposed to learn a generic language model that can be modified through a set of document - specific parameters , we explore use of new neural network models that are adapted to ad - hoc ir",
        "deep cca is a recently proposed deep neural network extension to the traditional canonical correlation analysis ( cca ) , and has been successful for multi - view representation learning in several domains .",
        "we present a general technique that uses a neural network mapper with a weighted multiple - loss criterion .",
        "when training deep neural networks , it is typically assumed that the training examples are uniformly difficult to learn .",
        "in this article , using a deep neural network to encode a video , we show that oddball sgd can be used to enforce uniform error across the training set .",
        "we introduce a new structure for memory neural networks , called feedforward sequential memory networks ( fsmn ) , which can learn long - term dependency without using recurrent feedback .",
        "the proposed fsmn is a standard feedforward neural networks equipped with learnable sequential memory blocks in the hidden layers .",
        "experiments have shown that fsmn based language models can significantly outperform not only feedforward neural network ( fnn ) based lms but also the popular recurrent neural network ( rnn ) lms .",
        "faced with continuously increasing scale of data , original back - propagation neural network based machine learning algorithm presents two non - trivial challenges : huge amount of data makes it difficult to maintain both efficiency and accuracy ; redundant data aggravates the system workload .",
        "careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data , how mapreduce is implemented on deep learning neural network , and why this combination accelerates computation .",
        "in this theory , the continuous - valued latent variables correspond to averaged voltage potential ( across time , spikes , and possibly neurons in the same minicolumn ) , and neural computation corresponds to approximate inference and error back - propagation at the same time .",
        "despite being the appearance - based classifier of choice in recent years , relatively few works have examined how much convolutional neural networks ( cnns ) can improve performance on accepted expression recognition benchmarks and , more importantly , examine what it is they actually learn .",
        "since most of the computation in training neural networks is typically spent on floating point multiplications , we investigate an approach to training that eliminates the need for most of these .",
        "experimental results across 3 popular datasets ( mnist , cifar10 , svhn ) show that this approach not only does not hurt classification performance but can result in even better performance than standard stochastic gradient descent training , paving the way to fast , hardware - friendly training of neural networks .",
        "sequence - to - sequence neural network models for generation of conversational responses tend to generate safe , commonplace responses ( e .",
        "instead we propose using maximum mutual information ( mmi ) as objective function in neural models .",
        "we study the improper learning of multi - layer neural networks .",
        "suppose that the neural network to be learned has $ k $ hidden layers and that the $ \\ ell _ 1 $ - norm of the incoming weights of any neuron is bounded by $ l $ .",
        "we present a kernel - based method , such that with probability at least $ 1 - \\ delta $ , it learns a predictor whose generalization error is at most $ \\ epsilon $ worse than that of the neural network .",
        "it implies that any sufficiently sparse neural network is learnable in polynomial time .",
        "the language discriminative phonotactic information in the obtained phone sequences are modeled using statistical and recurrent neural network based language modeling approaches .",
        "convolutional neural networks ( cnns ) have recently achieved remarkably strong performance on sentence classification tasks ( kim , 2014 ; kalchbrenner et al .",
        "neural turing machines ( ntm ) contain memory component that simulates \" working memory \" in the brain to store and retrieve information to ease simple algorithms learning .",
        "additionally , it has also been shown that in highly non - convex problems , such as deep neural networks , there is a proliferation of high - error low curvature saddle points , which slows down learning dramatically .",
        "in this paper , we attempt to overcome the two above problems by proposing an optimization method for training deep neural networks which uses learning rates which are both specific to each layer in the network and adaptive to the curvature of the function , increasing the learning rate at low curvature points .",
        "in this paper we present an approach to multi - language image description bringing together insights from neural machine translation and neural image description .",
        "we approach the problem by learning a similarity measure on small image patches using a convolutional neural network .",
        "the output of the convolutional neural network is used to initialize the stereo matching cost .",
        "bidirectional long short - term memory recurrent neural network ( blstm - rnn ) has been shown to be very effective for tagging sequential data , e .",
        "this paper envisions an end - to - end program generation scenario using recurrent neural networks ( rnns ) : users can express their intention in natural language ; an rnn then automatically generates corresponding code in a characterby - by - character fashion .",
        "in this paper , a framework for testing deep neural network ( dnn ) design in python is presented .",
        "first , big data , machine learning ( ml ) , and artificial neural networks ( anns ) are discussed to familiarize the reader with the importance of such a system .",
        "we combine and compare three models , neural machine translation , neural turing machine , and memory networks for a simulated qa data set .",
        "this paper is the first one that uses neural machine translation and neural turing machines for solving qa tasks .",
        "we present a novel application of lstm recurrent neural networks to multilabel classification of diagnoses given variable - length time series of clinical measurements .",
        "this paper proposes a neural network based approach that models the attention and intention processes .",
        "this work presents an attention mechanism - based neural network approach for tracking objects in video .",
        "a recurrent neural network is trained to predict the position of an object at time t + 1 given a series of selective glimpses into video frames at time steps 1 to t .",
        "in this paper , we extend the deep long short - term memory ( dlstm ) recurrent neural networks by introducing gated direct connections between memory cells in adjacent layers .",
        "in this paper , we investigate the use of prediction - adaptation - correction recurrent neural networks ( pac - rnns ) for low - resource speech recognition .",
        "a pac - rnn is comprised of a pair of neural networks in which a { \\ it correction } network uses auxiliary information given by a { \\ it prediction } network to help estimate the state probability .",
        "our model outperforms other state - of - the - art neural networks ( dnns , lstms ) on iarpa - babel tasks .",
        "in this paper we develop a recurrent neural network ( treernn ) , which is designed to predict a tree rather than a linear sequence as is the case in conventional recurrent neural networks .",
        "we construct the tree incrementally by generating the left and right dependents of a node whose probability is computed using recurrent neural networks with shared hidden layers .",
        "bidirectional long short - term memory recurrent neural network ( blstm - rnn ) has been shown to be very effective for modeling and predicting sequential data , e .",
        "in this paper , we propose to use neural networks to predict prosodic boundary labels directly from chinese characters without any feature engineering .",
        "deep neural networks ( dnn ) have achieved state - of - the - art results in a wide range of tasks , with the best results obtained with large training sets and large models .",
        "- 1 or 1 ) , would bring great benefits to specialized dl hardware by replacing many multiply - accumulate operations by simple accumulations , as multipliers are the most space and power - hungry components of the digital implementation of neural networks .",
        "we present a novel and practical deep fully convolutional neural network architecture for semantic pixel - wise segmentation termed segnet .",
        "in this paper , we explore different neural network architectures that can predict if a speaker of a given utterance is asking a question or making a statement .",
        "we com - pare the outcomes of regularization methods that are popularly used to train deep neural networks and study how different context functions can affect the classification performance .",
        "we also compare the efficacy of gated activation functions that are favorably used in recurrent neural networks and study how to combine multimodal inputs .",
        "then the word embeddings which represent each comment are used as input in different machine learning methods for sentiment classification , including svm , logistic regression , convolutional neural network ( cnn ) and ensemble methods .",
        "we present a new deterministic relational model derived from convolutional neural networks .",
        "search - convolutional neural networks ( scnns ) extend the notion of convolution to graph search to construct a rich latent representation that extracts local behavior from general graph - structured data .",
        "unlike other neural network models that take graph - structured data as input , scnns have a parameterization that is independent of input size , a property that enables transfer learning between datasets .",
        "we show that models which store explicit representations of long - term contexts outperform state - of - the - art neural language models at predicting semantic content words , although this advantage is not observed for syntactic function words .",
        "for this issue , ai models , including supervised brain emotional learning ( bel ) , adaptive neuro - fuzzy inference system ( anfis ) and artificial neural networks ( anns ) , are compared in order to find the best model .",
        "here , we propose a brain - inspired winner - take - all emotional neural network ( wtaenn ) and prove the universal approximation property for the novel architecture .",
        "wtaenn is a single layered feedforward neural network that benefits from the excitatory , inhibitory , and expandatory neural connections as well as the winner - take - all ( wta ) competitions in the human brain s nervous system .",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning framework .",
        "in this paper , we have proposed a system based on matrix factorization ( mf ) and deep recurrent neural networks ( drnns ) for genotype imputation and phenotype sequences prediction .",
        "additionally , a method to measure naturalness can be complementary to convolutional neural network ( cnn ) based features , which are known to be insensitive to the naturalness of images .",
        "based on this assumption , we propose a novel method to evaluate the naturalness by building a variant of recurrent neural network language models on pre - trained cnn representations .",
        "our purpose is to create a rapid prototype of q - learning with neural network approximators for samu .",
        "this paper presents a new method for pre - training neural networks that can decrease the total training time for a neural network while maintaining the final performance , which motivates its use on deep neural networks .",
        "the proposed method is independent of the other aspects of the training , such as architecture of the neural network , training method , and objective , making it compatible with a wide range of existing approaches .",
        "following the recent successes of deep convolutional neural networks ( dcnn ) for large scale image classification , descriptors extracted from dcnns are increasingly used in place of the traditional hand crafted descriptors such as fisher vectors ( fv ) with better retrieval performances .",
        "recurrent neural networks ( rnns ) , particularly those using long short - term memory ( lstm ) hidden units , are powerful and increasingly popular models for learning from sequence data .",
        "we present a character - level recurrent neural network that generates relevant and coherent text given auxiliary information such as a sentiment or topic .",
        "we employ a pair of convolutional neural networks to model visual objects and speech signals at the word level , and tie the networks together with an embedding and alignment model which learns a joint semantic space over both modalities .",
        "in recent years significant progress has been made in successfully training recurrent neural networks ( rnns ) on sequence learning problems involving long range temporal dependencies .",
        "we present a large - scale study , exploring the capability of temporal deep neural networks in interpreting natural human kinematics and introduce the first method for active biometric authentication with mobile inertial sensors .",
        "we ( 1 ) compare several neural architectures for efficient learning of temporal multi - modal data representations , ( 2 ) propose an optimized shift - invariant dense convolutional mechanism ( dcwrnn ) and ( 3 ) incorporate the discriminatively - trained dynamic features in a probabilistic generative framework taking into account temporal characteristics .",
        "to simplify the number of times of optimization in experimental works , here , we use artificial neural network ( ann ) and support vector machine ( svm ) models for the prediction of yields of 3 \\ b { eta } - o - phthalic ester of betulinic acid synthesized by betulinic acid and phthalic anhydride using lipase as biocatalyst .",
        "general regression neural network ( grnn ) , multilayer feed - forward neural network ( mlfn ) and the svm models were trained based on experimental data .",
        "to that end , we introduce a simplified training objective for learning multimodal embeddings using the skip - gram architecture by introducing convolutional ' pseudowords : ' embeddings composed of the additive combination of distributed word representations and image features from convolutional neural networks projected into the multimodal space .",
        "one is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework , the other is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context .",
        "we use multi - layered recurrent neural networks ( rnns ) with long short - term memory ( lstm ) units which are deep both spatially and temporally .",
        "recent work has shown that deep neural networks are capable of approximating both value functions and policies in reinforcement learning domains featuring continuous state and action spaces .",
        "however , to the best of our knowledge no previous work has succeeded at using deep neural networks in structured ( parameterized ) continuous action spaces .",
        "over the past few years , artificial neural networks have seen a dramatic resurgence in popularity as a tool for solving hard learning problems in ai applications .",
        "while it is widely known that neural networks are computationally hard to train in the worst case , in practice , neural networks are trained efficiently using sgd methods and a variety of techniques which accelerate the learning process .",
        "we introduce a neural machine translation model that views the input and output sentences as sequences of characters rather than words .",
        "we present a neural network architecture based on bidirectional lstms to compute representations of words in the sentential contexts .",
        "the central idea of this paper is to put lda on top of a deep neural network .",
        "we propose to use the recently proposed stochastic optimization algorithm for linear cca and its neural - network extension to further alleviate the computation requirements of approximate kcca .",
        "several nonlinear extensions of the classical linear cca method have been proposed , including kernel and deep neural network methods .",
        "these approaches restrict attention to certain families of nonlinear projections , which the user must specify ( by choosing a kernel or a neural network architecture ) , and are computationally demanding .",
        ", and show that , due to intrinsic joint minimization , the results obtained from a convolutional neural network ( cnn ) or a fully connected neural network ( fnn ) , if well parameterized , surpass the conventional use of a rm with an ec .",
        "it accomplishes this goal using an encoder recurrent neural network ( rnn ) that computes features at the same frame rate as the input , and a transducer rnn that operates over blocks of input steps .",
        "this paper presents a new method for the discovery of latent domains in diverse speech data , for the use of adaptation of deep neural networks ( dnns ) for automatic speech recognition .",
        "we present experimental results to corroborate our claims : for pruning neural networks , divnet is seen to be notably superior to competing approaches .",
        "we show that the internal representations of an image in a deep neural network ( dnn ) can be manipulated to mimic those of other natural images with only minor , imperceptible perturbations to the original image .",
        "in this paper we show how deep architectures , specifically convolutional neural networks ( cnn ) , can be adapted to the task of simultaneous categorization and pose estimation of objects .",
        "deep neural networks are powerful parametric models that can be trained efficiently using the backpropagation algorithm .",
        "stochastic neural networks combine the power of large parametric functions with that of graphical models , which makes it possible to learn very complex distributions .",
        "this work shows how using reduced precision data in convolutional neural networks ( cnns ) affects network accuracy during classification .",
        "in this paper , we propose two neural network models targeted to retrieve oov pns relevant to an audio document : ( a ) document level continuous bag of words ( d - cbow ) , ( b ) document level continuous bag of weighted words ( d - cbow2 ) .",
        "this layer learns to assign importance to input words and has the ability to capture ( task specific ) key - words in a bag - of - word neural network model .",
        "deep neural networks with millions of parameters are at the heart of many state of the art machine learning models today .",
        "e ; learning the architecture of a neural network along with weights .",
        "methods of applying neural networks to control plants are considered .",
        "conditional belief networks introduce stochastic binary variables in neural networks .",
        "contrary to a classical neural network , a belief network can predict more than the expected value of the output $ y $ given the input $ x $ .",
        "in this paper , we introduce a new deep convolutional neural network ( convnet ) module that promotes competition among a set of multi - scale convolutional filters .",
        "we introduce techniques for rapidly transferring the information stored in one neural net into another neural net .",
        "the main purpose is to accelerate the training of a significantly larger neural net .",
        "during real - world workflows , one often trains very many different neural networks during the experimentation and design process .",
        "our techniques are based on the concept of function - preserving transformations between neural network specifications .",
        "this differs from previous approaches to to pre - training that altered the function represented by a neural net when adding layers to it .",
        "recently , convolutional and recurrent neural networks has provided very effective mechanisms to capture the hidden structures within sentences via continuous representations , thereby significantly advancing the performance of relation extraction .",
        "the advantage of convolutional neural networks is their capacity to generalize the consecutive k - grams in the sentences while recurrent neural networks are effective to encode long ranges of sentence context .",
        "this paper proposes to combine the traditional feature - based method , the convolutional and recurrent neural networks to simultaneously benefit from their advantages .",
        "towards this direction of modeling clinical bahavior of physicians , we develop a successful application of recurrent neural networks ( rnn ) to jointly forecast the future disease diagnosis and medication prescription along with their timing .",
        "here , we introduce a deep , differentiable , fully - connected neural network module composed of diagonal matrices of parameters , $ \\ mathbf { a } $ and $ \\ mathbf { d } $ , and the discrete cosine transform $ \\ mathbf { c } $ .",
        "in our experiments , we show that it can indeed be successfully interleaved with relu modules in convolutional neural networks for image recognition .",
        "we introduce segmental recurrent neural networks ( srnns ) which define , given an input sequence , a joint probability distribution over segmentations of the input and labelings of the segments .",
        ", contiguous subsequences of the input ) are computed by encoding their constituent tokens using bidirectional recurrent neural nets , and these \" segment embeddings \" are used to define compatibility scores with output labels .",
        "recent advances in neural variational inference have spawned a renaissance in deep latent variable models .",
        "our neural variational document model combines a continuous stochastic document representation with a bag - of - words generative model and achieves the lowest reported perplexities on two standard test corpora .",
        "the neural answer selection model employs a stochastic representation layer within an attention mechanism to extract the semantics between a question and answer pair .",
        ", bayesian models and neural models ) .",
        "although image compression has been actively studied for decades , there has been relatively little research on learning to compress images with modern neural networks .",
        "in this work , we revisit graph - based semi - supervised learning algorithms and propose an online graph construction technique which suits deep convolutional neural network better .",
        "we consider an em - like algorithm for semi - supervised learning on deep neural networks : in forward pass , the graph is constructed based on the network output , and the graph is then used for loss calculation to help update the network by back propagation in the backward pass .",
        "the task of labeling data for training deep neural networks is daunting and tedious , requiring millions of labels to achieve the current state - of - the - art results .",
        "we further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data .",
        "we propose the neural programmer - interpreter ( npi ) : a recurrent and compositional neural network that learns to represent and execute programs .",
        "the visually imperceptible perturbations that result in convolutional neural networks ( cnn ) fail , can be alleviated with a mechanism based on foveations - applying the cnn in a different image region .",
        "then , we corroborate the hypothesis that when the neural responses are in the linear region , applying the foveation mechanism to the adversarial example tends to reduce the effect of the perturbation .",
        "recurrent neural networks are convenient and efficient models for language modeling .",
        "recent studies have shown that convolutional neural networks ( cnns ) are vulnerable to a small perturbation of input called \" adversarial examples \" .",
        "using several variations of neural network classifier , we show that these combined methods lead to improved performance when used as input features for supervised term - matching .",
        "convolutional neural networks have achieved state - of - the - art performance on a wide range of tasks .",
        "unregularized deep neural networks ( dnns ) can be easily overfit with a limited sample size .",
        "in this paper , we propose deep embedded clustering ( dec ) , a method that simultaneously learns feature representations and cluster assignments using deep neural networks .",
        "the use of convolutional neural networks ( cnn ) in natural image classification systems has produced very impressive results .",
        "the standard unsupervised recurrent neural network language model ( rnnlm ) generates sentences one word at a time and does not work from an explicit global distributed sentence representation .",
        "complex - valued neural networks ( cvnns ) are an emerging field of research in neural networks due to their potential representational properties for audio , image , and physiological signals .",
        "learning meaningful representations using deep neural networks involves designing efficient training schemes and well - structured networks .",
        "neural word representations have proven useful in natural language processing ( nlp ) tasks due to their ability to efficiently model complex semantic and syntactic word relationships .",
        "however , recent neural approaches rarely focus on the application to a consuming nlp algorithm .",
        "we further evaluate part - of - speech disambiguated embeddings on neural dependency parsing , yielding a greater than 8 % average error reduction in unlabeled attachment scores across 6 languages .",
        "in this paper , we propose and investigate a new neural network architecture called neural random access machine .",
        "in this work , we present a neural attention network that directly combines multi - channel audio to generate phonetic states without requiring any prior knowledge of the microphone layout or any explicit signal preprocessing for speech enhancement .",
        "we embed an attention mechanism within a recurrent neural network ( rnn ) based acoustic model to automatically tune its attention to a more reliable input source .",
        "we evaluate our neural attention model on a subset of the chime - 3 challenge task , and we show that the model achieve",
        "we compare the consequences of using ssim versus se loss on representations formed in deep autoencoder and recurrent neural network architectures .",
        "a pure pattern - matching approach , based on a deep convolutional neural network ( dcnn ) that predicts the next move , can perform as well as monte carlo tree search ( mcts ) - based open source go engines such as pachi [ baudis & amp ; gailly ( 2012 ) ] if its search budget is limited .",
        "supervised training of deep neural nets typically relies on minimizing cross - entropy .",
        "in this paper we proposed a direct loss minimization approach to train deep neural networks , taking into account the application - specific loss functions .",
        "while the current trend is to increase the depth of neural networks to increase their performance , the size of their training database has to grow accordingly .",
        "in this paper , we present an active learning strategy based on query by committee and dropout technique to train a convolutional neural network ( cnn ) .",
        "although deep convolutional neural networks ( cnns ) have achieved remarkable results on object detection and segmentation , pre - and post - processing steps such as region proposals and non - maximum suppression ( nms ) , have been required .",
        "in this work , we propose a novel end - to - end trainable deep neural network architecture that generates the correct number of object instances and their bounding boxes ( or segmentation masks ) given an image , using only a single network evaluation without any pre - or post - processing steps .",
        "recurrent neural networks ( rnns ) are notoriously difficult to train .",
        "the complexity of deep neural network algorithms for hardware implementation can be much lowered by optimizing the word - length of weights and signals .",
        "in this work , the effects of retraining are analyzed for a feedforward deep neural network ( ffdnn ) and a convolutional neural network ( cnn ) .",
        "we find that the performance gap between the floating - point and the retrain - based ternary ( + 1 , 0 , - 1 ) weight neural networks exists with a fair amount in ' complexity limited ' networks , but the discrepancy almost vanishes in fully complex networks whose capability is limited by the training data , rather than by the number of connections .",
        "we propose a method for integration of features extracted using deep representations of convolutional neural networks ( cnns ) each of which is learned using a different image dataset of objects and materials for material recognition .",
        "although the latest high - end smartphone has powerful cpu and gpu , running deeper convolutional neural networks ( cnns ) for complex tasks such as imagenet classification on mobile devices is challenging .",
        "in this paper , we present a new neural network architecture for model - free reinforcement learning inspired by advantage learning .",
        "recent work on sequence to sequence translation using recurrent neural networks ( rnns ) based on long short term memory ( lstm ) architectures has shown great potential for learning useful representations of sequential data .",
        "these architectures , using one recurrent neural network to encode sequences into fixed - length representations , and one or more network ( s ) to decode representations into new sequences have the advantages of being modular , while also allowing modules to be jointly trained .",
        "neural machine translation ( nmt ) has obtained state - of - the art performance for several language pairs , while only using parallel data for training .",
        "monolingual data plays an important role in boosting fluency for phrase - based statistical machine translation , and we investigate the use of monolingual data for neural machine translation ( nmt ) .",
        "the method is less computationally demanding compared to similar gradient - based approaches to hyperparameter selection , only requires a few trials , and consistently finds solid hyperparameter values which makes it a useful tool for training neural network models .",
        "we propose a new method for creating computationally efficient convolutional neural networks ( cnns ) by using low - rank representations of convolutional filters .",
        "we propose a unified framework for neural net normalization , regularization and optimization , which includes path - sgd and batch - normalization and interpolates between them across two different dimensions .",
        "neural networks , in particular , have enormous expressive power and yet are notoriously challenging to train .",
        "connectionist temporal classification ( ctc ) based supervised sequence training of recurrent neural networks ( rnns ) has shown great success in many machine learning areas including end - to - end speech and handwritten character recognition .",
        "in this paper , we provide a method for understanding the internal representations of convolutional neural networks ( cnns ) trained on objects .",
        "convolutional neural networks spread through computer vision like a wildfire , impacting almost all visual tasks imaginable .",
        "we apply recurrent neural networks ( rnn ) on a new domain , namely recommendation system .",
        "we introduce a recurrent neural network architecture for automated road surface wetness detection from audio of tire - surface interaction .",
        "we propose a structured prediction architecture for images centered around deep recurrent neural networks .",
        "the reseg layer is composed of four recurrent neural networks that sweep the image horizontally and vertically in both directions , along with a final layer that expands the prediction back to the original image size .",
        "we use neural network ( nn ) as a model instance to carry out the study and the analysis shows that increasing the diversity of hidden units in nn would reduce estimation error and increase approximation error .",
        "for the controller , we explore a range of neural network - based models which vary in their ability to abstract the underlying algorithm from training instances and generalize to test examples with many thousands of digits .",
        "we introduce the \" exponential linear unit \" ( elu ) which speeds up learning in deep neural networks and leads to higher classification accuracies .",
        "in this work we show that deep convolutional neural networks can outperform humans on the task of boundary detection , as measured on the standard berkeley segmentation dataset .",
        "we deploy a range of neural models ( fully connected , convolutional network , memory network ) on these games , with and without a procedurally generated curriculum .",
        "convolutional neural networks ( cnns ) have recently emerged as the dominant model in computer vision .",
        "we present a regression framework which models the output distribution of neural networks .",
        "recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers .",
        "in this paper we investigate the extent to which neural networks exhibit what we call convergent learning , which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar low - dimensional spaces .",
        "we begin research into this question using three techniques to approximately align different neural networks on a feature level : a bipartite matching approach that makes one - to - one assignments between neurons , a sparse prediction approach that finds one - to - many mappings , and a spectral clustering approach that finds many - to - many mappings .",
        "this initial investigation reveals a few previously unknown properties of neural networks , and we argue that future research into the question of convergent learning will yield many more .",
        "we introduce the dynamic capacity network ( dcn ) , a neural network that can adaptively assign its capacity across different portions of the input data .",
        "our findings indicate that dcns are able to drastically reduce the number of computations , compared to traditional convolutional neural networks , while maintaining similar performance .",
        "we introduce a multi - resolution convolutional neural network for early detection of multiple diseases from irregularly measured sparse lab values .",
        "we study non - convex empirical risk minimization for learning halfspaces and neural networks .",
        "for loss functions that are $ l $ - lipschitz continuous , we present algorithms to learn halfspaces and multi - layer neural networks that achieve arbitrarily small excess risk $ \\ epsilon & gt ; 0 $ .",
        "we further show that if the data is separable by some neural network with constant margin $ \\ gamma & gt ; 0 $ , then there is a polynomial - time algorithm for learning a neural network that separates the training data with margin $ \\ omega ( \\ gamma ) $ .",
        "we present the interesting result that simple compositional architectures based on updated vector averaging vastly outperform long short - term memory ( lstm ) recurrent neural networks and that these simpler architectures allow us to learn models with superior generalization .",
        "recently it has been addressed using neural networks , in particular by neural turing machines ( ntms ) .",
        "in this paper , we present a novel neural network architecture that automatically detects word - and character - level features using a hybrid bidirectional lstm and cnn architecture , eliminating the need for most feature engineering .",
        "we also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing exact match approaches .",
        "this document provides a brief introduction to convolutional neural networks ( cnns ) , discussing recently published papers and newly form techniques in developing these brilliantly fantastic image recognition models .",
        "this introduction assumes you are familiar with the workings of neural networks and have some background in artificial intelligence .",
        "neural network models have been demon - strated to be capable of achieving remarkable performance in sentence and document mod - eling .",
        "convolutional neural network ( cnn ) and recurrent neural network ( rnn ) are two mainstream architectures for such modeling tasks , which adopt totally different ways of understanding natural languages .",
        "c - lstm utilizes cnn to ex - tract a sequence of higher - level phrase repre - sentations , and are fed into a long short - term memory recurrent neural network ( lstm ) to obtain the sentence representation .",
        "to tackle aspect mapping and sentiment classification , we propose two convolutional neural network ( cnn ) based methods , cascaded cnn and multitask cnn .",
        "in 2013 , our large rl recurrent neural networks ( rnns ) learned from scratch to drive simulated cars from high - dimensional video input .",
        "artificial neural networks are powerful models , which have been widely applied into many aspects of machine translation , such as language modeling and translation modeling .",
        "in this paper , we present a novel neural reordering model that directly models word pairs and alignment .",
        "by utilizing lstm recurrent neural networks , much longer context could be learned for reordering prediction .",
        "experimental results on nist openmt12 arabic - english and chinese - english 1000 - best rescoring task show that our lstm neural reordering feature is robust and achieves significant improvements over various baseline systems .",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "in this paper , a hybrid in - telligent model combining a neural network model integrated with fuzzy model ( neuro - fuzzy model ) has been used to improve the accuracy of estimating software cost .",
        "we proposed neural enquirer as a neural network architecture to execute a sql - like query on a knowledge - base ( kb ) for answers .",
        "basically , neural enquirer finds the distributed representation of a query and then executes it on knowledge - base tables to obtain the answer as one of the values in the tables .",
        "unlike similar efforts in end - to - end training of semantic parser , neural enquirer is fully neuralized : it not only gives distributional representation of the query and the knowledge - base , but also realizes the execution of compositional queries as a series of differentiable operations , with intermediate results ( consisting of annotations of the tables at different levels ) saved on multiple layers of memory .",
        "neural enquirer can be trained with gradient descent , with which not only the parameters of the controlling components and semantic parsing component , but also the embeddings of the tables and query words can be learned from scratch .",
        "neural enquirer is one step towards building neural network systems which",
        "we present a new perspective on neural knowledge base ( kb ) embeddings , from which we build a framework that can model symbolic knowledge in the kb together with its learning process .",
        "we show that this framework well regularizes previous neural kb embedding model for superior performance in reasoning tasks , while having the capabilities of dealing with unseen entities , that is , to learn their embeddings from natural language descriptions , which is very like human ' s behavior of learning semantic concepts .",
        "mxnet is a multi - language machine learning ( ml ) library to ease the development of ml algorithms , especially for deep neural networks .",
        "we demonstrate a convolutional neural network ( cnn ) model that is able perform the same task without the need for landmark features thereby greatly increasing efficiency .",
        "recurrent neural networks have shown excellent performance in many applications , however they require increased complexity in hardware or software based implementations .",
        "this work analyzes the fixed - point performance of recurrent neural networks using a retrain based quantization method .",
        "we suggest an effective architecture of the neural networks for approximating an action - value function with binary vector actions .",
        "the techniques in the domain include amongst others : expectation maximization , neural networks with evolutionary algorithms or optimization techniques and k - nearest neighbor approaches to solve the problem .",
        "in this article , considering arbitrary and monotone missing data patterns , we hypothesize that the use of deep neural networks built using autoencoders and denoising autoencoders in conjunction with genetic algorithms , swarm intelligence and maximum likelihood estimator methods as novel data imputation techniques will lead to better imputed values than existing techniques .",
        "we also intend to use fuzzy logic in tandem with deep neural networks to perform the missing data imputation tasks , as well as different building blocks for the deep neural networks like stacked restricted",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "a general approach to knowledge transfer is introduced in which an agent controlled by a neural network adapts how it reuses existing networks as it learns in a new domain .",
        "networks trained for a new domain can improve their performance by routing activation selectively through previously learned neural structure , regardless of how or for what it was learned .",
        "this approach is more general than previous approaches to neural transfer for reinforcement learning .",
        "the recently introduced deep q - networks ( dqn ) algorithm has gained attention as one of the first successful combinations of deep neural networks and reinforcement learning .",
        "we describe an application of an encoder - decoder recurrent neural network with lstm units and attention to generating headlines from the text of news articles .",
        "furthermore , we study how the neural network decides which input words to pay attention to , and specifically we identify the function of the different neurons in a simplified attention mechanism .",
        "we demonstrate how driverseat can crowdstrap a convolutional neural network on the lane - detection task .",
        "using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real - world complexity .",
        "we relate this phenomenon with the instabilities of neural networks when they are used in an approximate dynamic programming setting .",
        "when evaluated on the challenging vqa dataset [ 2 ] , it shows comparable performance to many recent approaches using recurrent neural networks .",
        "we propose minimum risk training for end - to - end neural machine translation .",
        "experiments on chinese - english and english - french translation show that our approach achieves significant improvements over maximum likelihood estimation on a state - of - the - art neural machine translation system .",
        "given i - vectors as inputs , the authors proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on deep belief networks ( dbn ) and deep neural networks ( dnn ) to discriminatively model each target speaker .",
        "because it replaces entire pipelines of hand - engineered components with neural networks , end - to - end learning allows us to handle a diverse variety of speech including noisy environments , accents and different languages .",
        "the key components include a visual question generation ( vqg ) module and a visual question answering module , in which recurrent neural networks ( rnn ) and convolutional neural network ( cnn ) are used .",
        "for speech recognition , deep neural network ( dnn ) have significantly improved the recognition accuracy in most of benchmark datasets and application domains .",
        "the highway neural networks constantly outperformed their plain dnn counterparts , and the number of model parameters can be reduced significantly without sacrificing the recognition accuracy .",
        "current trends in cv clearly show a rise of neural network - based algorithms , which have recently broken many object detection and localization records .",
        "we extend two related , model - free algorithms for continuous control - - deterministic policy gradient and stochastic value gradient - - to solve partially observed domains using recurrent neural networks trained with backpropagation through time .",
        "by using this new algorithm we show that there are two ways of classification by a neural network , for a large dimension feature space , both of which are non - iterative and deterministic and we apply both these methods to a classical pattern recognition problem and present the results .",
        "it is expected these methods will now be widely used for the training of neural networks for deep learning not only because of their non - iterative and deterministic nature but also because of their efficiency and speed and will supercede other classification methods which are iterative in nature and rely on error minimization .",
        "training neural network language models over large vocabularies is still computationally very costly compared to count - based models such as kneser - ney .",
        "at the same time , neural language models are gaining popularity for many applications such as speech recognition and machine translation whose success depends on scalability .",
        "this work presents a general attention based convolutional neural network ( abcnn ) for modeling a pair of sentences .",
        "in this paper , we propose a deep convolutional neural network for active object recognition that simultaneously predicts the object label , and selects the next action to perform on the object with the aim of improving recognition performance .",
        "this paper explores the performance of fitted neural q iteration for reinforcement learning in several partially observable environments , using three recurrent neural network architectures : long short - term memory , gated recurrent unit and mut1 , a recurrent neural architecture evolved from a pool of several thousands candidate architectures .",
        "our evaluation demonstrates that our model yields 10 \\ % gain over a standard ir baseline , and 6 \\ % over standard neural network architectures ( including cnns and lstms ) trained analogously .",
        "convolutional neural networks demonstrated outstanding empirical results in computer vision and speech recognition tasks where labeled training data is abundant .",
        "we model the problem of inflection generation as a character sequence to sequence learning problem and present a variant of the neural encoder - decoder model for solving it .",
        "a number of frameworks have been developed to expedite the process of designing and training deep neural networks ( dnns ) , such as caffe , torch and theano .",
        "recent language models , especially those based on recurrent neural networks ( rnns ) , make it possible to generate natural language from a learned probability .",
        "deep neural networks have proved very successful in domains where large training sets are available , but when the number of training samples is small , their performance suffers from overfitting .",
        "empirical rademacher complexity is used to connect the generalization error of the neural network to spectral properties of the graph learned from the input data .",
        "it explains principles and implementations with details of restricted boltzmann machine , deep neural network , deep belief network , denoising autoencoder , deep boltzmann machine , deep canonical correlation analysis , and modal prediction model .",
        "among different types of deep neural networks , convolutional neural networks have been most extensively studied .",
        "due to the lack of training data and computing power in early days , it is hard to train a large high - capacity convolutional neural network without overfitting .",
        "recently , with the rapid growth of data size and the increasing power of graphics processor unit , many researchers have improved the convolutional neural networks and achieved state - of - the - art results on various tasks .",
        "in this paper , we provide a broad survey of the recent advances in convolutional neural networks .",
        "besides , we also introduce some applications of convolutional neural networks in computer vision .",
        "first , contextual and semantic information is extracted for each image by employing a convolutional neural networks approach .",
        "recently , the renewed prosperity neural networks has made many improvements in a variety of nlp tasks .",
        "in particular , the tree - based convolutional neural network ( tbcnn ) proposed in our previous work has achieved high performance in several sentence - level classification tasks .",
        "recurrent neural networks ( rnns ) have proven to be powerful models in problems involving sequential data .",
        "we propose a simplified model of attention which is applicable to feed - forward neural networks and demonstrate that it can solve some long - term memory problems ( specifically , those where temporal order doesn ' t matter ) .",
        "the recently released stanford natural language inference ( snli ) corpus has made it possible to develop and evaluate learning - centered methods such as deep neural networks for the nli task .",
        "in this paper , we propose a context - aware keyword spotting model employing a character - level recurrent neural network ( rnn ) for spoken term detection in continuous speech .",
        "experimental results show that the proposed keyword spotter significantly outperforms the deep neural network ( dnn ) and hidden markov model ( hmm ) based keyword - filler model even with less computations .",
        "sequence - to - sequence neural translation models learn semantic and syntactic relations between sentence pairs by optimizing the likelihood of the target given the source , i .",
        "we introduce an alternative objective function for neural mt that maximizes the mutual information between the source and target sentences , modeling the bi - directional dependency of sources and targets .",
        "applied to the wmt german / english and french / english tasks , both mechanisms offer a consistent performance boost on both standard lstm and attention - based neural mt architectures .",
        "the result is the best published performance for a single ( non - ensemble ) neural mt system , as well as the potential application of our diverse decoding algorithm to other nlp re - ranking tasks .",
        "however , we can train a neural network to address the problem if we restrict our attention to specific object categories ( in our case faces and chairs ) for which we can gather ample training data .",
        "using the neural encoder - decoder framework , we explore several combination methods and report up to + 4 .",
        "8 bleu increases on top of a very strong attention - based neural translation model .",
        "we present a novel end - to - end neural model to extract entities and relations between them .",
        "our recurrent neural network based model stacks bidirectional sequential lstm - rnns and bidirectional tree - structured lstm - rnns to capture both word sequence and dependency tree substructure information .",
        "we also show improvements over the state - of - the - art convolutional neural network based model on nominal relation classification ( semeval - 2010 task 8 ) , with 2 .",
        "we propose multi - way , multilingual neural machine translation .",
        "the proposed approach enables a single neural translation model to translate between multiple languages , with a number of parameters that grows only linearly with the number of languages .",
        "neural encoder - decoder models of machine translation have achieved impressive results , rivalling traditional translation models .",
        "in this paper we extend the attentional neural translation model to include structural biases from word based alignment models , including positional bias , markov conditioning , fertility and agreement over translation directions .",
        "we present a novel method to perform multi - class pattern classification with neural networks and test it on a challenging 3d hand gesture recognition problem .",
        "recurrent neural networks ( rnn ) have obtained excellent result in many natural language processing ( nlp ) tasks .",
        "we encode input sentences into vector representations using recurrent neural networks , and generate their logical forms by conditioning the output on the encoding vectors .",
        "recurrent neural network ( rnn ) and one of its specific architectures , long short - term memory ( lstm ) , have been widely used for sequence labeling .",
        "the model uses natural language strings to automatically assemble neural networks from a collection of composable modules .",
        "our approach , which we term a dynamic neural model network , achieves state - of - the - art results on benchmark datasets in both visual and structured domains .",
        "to tackle the issue , we propose two novel models using deep neural networks ( dnns ) to automatically learn effective patterns from categorical feature interactions and make predictions of users ' ad clicks .",
        "recently , recurrent neural networks ( rnns ) as powerful sequence models have re - emerged as a potential acoustic model for statistical parametric speech synthesis ( spss ) .",
        "although recent studies have demonstrated that lstms can achieve significantly better performance on spss than deep feed - forward neural networks , little is known about why .",
        "we propose a novel deep neural network architecture for speech recognition that explicitly employs knowledge of the background environmental noise within a deep neural network acoustic model .",
        "a deep neural network is used to predict the acoustic environment in which the system in being used .",
        "the discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model .",
        "we formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point - cloud , natural language , and manipulation trajectory data into a shared embedding space using a deep neural network .",
        "this work presents a broad study on the adaptation of neural network acoustic models by means of learning hidden unit contributions ( lhuc ) - - a method that linearly re - combines hidden units in a speaker - or environment - dependent manner using small amounts of unsupervised adaptation data .",
        "these include n - grams , justeson & amp ; katz pos tag filter , recurrent neural networks , and latent dirichlet allocation .",
        "neural machine translation has shown very promising results lately .",
        "we present asystem based on a global ranking objective function which uses a combinationof convolutional neural networks ( cnn ) and multi layer perceptrons ( mlp ) .",
        "nowadays , neural networks play an important role in the task of relation classification .",
        "by designing different neural architectures , researchers have improved the performance to a large extent , compared with traditional methods .",
        "however , existing neural networks for relation classification are usually of shallow architectures ( e .",
        ", one - layer convolution neural networks or recurrent networks ) .",
        "in this paper , we propose deep recurrent neural networks ( drnns ) to tackle this challenge .",
        "traditional neural networks assume vectorial inputs as the network is arranged as layers of single line of computing units called neurons .",
        "to address these issues , we propose matrix neural networks ( matnet ) , which takes matrices directly as inputs .",
        "each neuron senses summarised information through bilinear mapping from lower layer units in exactly the same way as the classic feed forward neural networks .",
        "image similarity is computed by a convolutional neural network and incorporated into a target - side translation memory retrieval model where descriptions of most similar images are used to rerank translation outputs .",
        "this work presents a new algorithm for training recurrent neural networks ( although ideas are applicable to feedforward networks as well ) .",
        "in the context of speech processing , a deep neural network ( dnn ) is an effective computational method to infer the probability of individual phonological classes from a short segment of speech signal .",
        "based on the assumption that there exists a neural network that efficiently represents a set of boolean functions between all binary inputs and outputs , we propose a process for developing and deploying neural networks whose weight parameters , bias terms , input , and intermediate hidden layer output signals , are all binary - valued , and require only basic bit logic for the feedforward pass .",
        "the proposed bitwise neural network ( bnn ) is especially suitable for resource - constrained environments , since it replaces either floating or fixed - point arithmetic with significantly more efficient bitwise operations .",
        "the algorithm employs a speech - to - character unidirectional recurrent neural network ( rnn ) , which is end - to - end trained with connectionist temporal classification ( ctc ) , and an rnn - based character - level language model ( lm ) .",
        "we specifically consider one form of deep networks widely used in computer vision - convolutional neural networks ( cnns ) .",
        "we present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions .",
        "convolutional neural networks ( cnns ) are currently state - of - the - art for various classification tasks , but are computationally expensive .",
        "the recurrent neural networks ( rnn ) can be used to solve the sequence to sequence problem , where both the input and the output have sequential structures .",
        "we present datagrad , a general back - propagation style training procedure for deep neural architectures that uses regularization of a deep jacobian - based penalty .",
        "more importantly , it unifies previous proposals for adversarial training of deep neural nets - - this list includes directly modifying the gradient , training on a mix of original and adversarial examples , using contractive penalties , and approximately optimizing constrained adversarial objective functions .",
        "in the last two years , there have been numerous papers that have looked into using deep neural networks to replace the acoustic model in traditional statistical parametric speech synthesis .",
        "in this paper , we investigate the use of recurrent neural networks as a potential postfilter for synthesis .",
        "speech recognition from visual - only recordings of a speaker ' s face , can be achieved with a processing pipeline based solely on neural networks , yielding significantly better accuracy than conventional methods .",
        "feed - forward and recurrent neural network layers ( namely long short - term memory ; lstm ) are stacked to form a single structure which is trained by back - propagating error gradients through all the layers .",
        "6 % using the end - to - end neural network - based solution ( 11 .",
        "inspired by recent successes of deep learning in computer vision , we propose a novel application of deep convolutional neural networks to facial expression recognition , in particular smile recognition .",
        "we propose a neural network architecture that utilizes both convolution and recurrent layers to efficiently encode character inputs .",
        "the multiple sets of token labels are then used as the targets of a multi - target deep neural network ( mdnn ) trained on low - level acoustic features .",
        "we call this iterative deep learning framework the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) , which generates both high quality speech features for the track 1 of the challenge and acoustic tokens for the track 2 of the challenge .",
        "we achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks .",
        "previous work on this problem has proposed several techniques based on deep neural networks , typically involving either autoencoder - like networks with a reconstruction objective or paired feedforward networks with a batch - style correlation - based objective .",
        "we also explore a stochastic optimization procedure for minibatch correlation - based objectives and discuss the time / performance trade - offs for kernel - based and neural network - based implementations .",
        "second - order optimization methods such as natural gradient descent have the potential to speed up training of neural networks by correcting for the curvature of the loss function .",
        "recurrent neural networks ( rnn ) are known to produce state of the art results for language modelling , outperforming their traditional n - gram counterparts in many cases .",
        "second , we model a full trajectory of the agent using a recurrent neural network , where unexplained factors are modeled as ( additive ) input nodes .",
        "we propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers .",
        "we present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor - learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers .",
        "the traditional way is to use the convolutional neural network ( cnn ) to extract image features , followed by recurrent neural network ( rnn ) to generate sentences .",
        "in this paper , we present a new model that added memory cells to gate the feeding of image features to the deep neural network .",
        "the current paper proposes a novel dynamic neural network model , multiple spatio - temporal scales recurrent neural network ( mstrnn ) used for categorization of complex human action pattern in video image .",
        "the mstrnn has been developed by newly introducing recurrent connectivity to a prior - proposed model , multiple spatio - temporal scales neural network ( mstnn ) [ 1 ] such that the model can learn to extract latent spatio - temporal structures more effectively by developing adequate recurrent contextual dynamics .",
        "given the i - vectors , several classifiers are adopted for the language detection task including support vector machines ( svm ) , multi - class logistic regression ( mclr ) , probabilistic linear discriminant analysis ( plda ) and deep neural networks ( dnn ) .",
        "we obtain promising empirical results in multi - label classification problems and in attention - based neural networks for natural language inference .",
        "we introduce and compare different neural network based linear - chain crfs and we present experiments on two complex sequence classification and structured prediction tasks to support this claim .",
        "recurrent neural networks are increasing popular models for sequential learning .",
        "dropout has been witnessed with great success in training deep neural networks by independently zeroing out the outputs of neurons at random .",
        "we evaluate two different agents based on neural networks on the wikinav and provide the human performance .",
        "next , to address the more general case , where classifiers may strongly violate the conditional independence assumption , we propose to apply rbm - based deep neural net ( dnn ) .",
        "one - hot cnn ( convolutional neural network ) has been shown to be effective for text categorization in our previous work .",
        "representation learning is the foundation for the recent success of neural network models .",
        "however , the distributed representations generated by neural networks are far from ideal .",
        "these methods allow neural methods to learn representations which are easy to interpret and reuse , yet they incur little or no penalty to performance .",
        "in this work we explore recent advances in recurrent neural networks for large scale language modeling , a task central to language understanding .",
        "we perform an exhaustive study on techniques such as character convolutional neural networks or long - short term memory , on the one billion word benchmark .",
        "in this work we introduce a binarized deep neural network ( bdnn ) model .",
        "instead of computing distances in the image space , we compute distances between image features extracted by deep neural networks .",
        "moreover we are able to understand and describe the policies learned by dqns for three different atari2600 games and suggest ways to interpret , debug and optimize of deep neural networks in reinforcement learning .",
        "convolutional neural networks are sometimes trained using data augmentation to exploit this , but they are still required to learn the rotation equivariance properties from the data .",
        "we introduce four operations which can be inserted into neural network models as layers , and which can be combined to make these models partially equivariant to rotations .",
        "recurrent neural networks ( rnns ) have proven to be very successful for modelling sequences of data in many areas of machine learning .",
        "we compared different types of rnns that we developed for this work , a model based on a feedforward neural network and a logistic regression model .",
        "deep learning is increasingly used in several machine learning tasks as deep neural networks ( dnns ) frequently outperform other techniques .",
        "deep artificial neural networks have made remarkable progress in different tasks in the field of computer vision .",
        "we focus on convolutional neural networks ( cnn ) as the state - of - the - art models in object recognition and classification ; investigate this problem in more detail , and hypothesize that training cnn models suffer from unstructured loss minimization .",
        "we introduce the value iteration network : a fully differentiable neural network with a ` planning module ' embedded within .",
        "key to our approach is a novel differentiable approximation of the value - iteration algorithm , which can be represented as a convolutional neural network , and trained end - to - end using standard backpropagation .",
        "extreme learning machine ( elm ) classification algorithm is a relatively new learning method built on feed - forward neural - network .",
        "attention mechanisms in neural networks have proved useful for problems in which the input and output do not have fixed dimension .",
        "we introduce an attentional neural network that employs convolution on the input tokens to detect local time - invariant and long - range topical attention features in a context - dependent way .",
        "we demonstrate our convolutional attention neural network ' s performance on 10 popular java projects showing that it achieves better performance compared to previous attentional mechanisms .",
        "in this paper , we propose and investigate a novel memory architecture for neural networks called hierarchical attentive memory ( ham ) .",
        "the convolutional neural network ( convnet or cnn ) is a powerful discriminative learning machine .",
        "in the context of pair - wise ranking or classification with neural networks , ap enables the pooling layer to be aware of the current input pair , in a way that information from the two input items can directly influence the computation of each other ' s representations .",
        "our two - way attention mechanism is a general framework independent of the underlying representation learning , and it has been applied to both convolutional neural networks ( cnns ) and recurrent neural networks ( rnns ) in our studies .",
        "we study the adaptation of convolutional neural networks to the complex temporal radio signal domain .",
        "we show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task .",
        "deep gaussian processes ( dgps ) are multi - layer hierarchical generalisations of gaussian processes ( gps ) and are formally equivalent to neural networks with multiple , infinitely wide hidden layers .",
        "we evaluate the new method for non - linear regression on eleven real - world datasets , showing that it always outperforms gp regression and is almost always better than state - of - the - art deterministic and sampling - based approximate inference methods for bayesian neural networks .",
        "as a by - product , this work provides a comprehensive analysis of six approximate bayesian methods for training neural networks .",
        "we start with the best - performing approaches from prior work , based on tandem models and segmental conditional random fields ( scrfs ) , with features based on deep neural network ( dnn ) classifiers of letters and phonological features .",
        "we come up with a neural network framework , named hierarchical attention - based convolutional neural network ( habcnn ) , to address this task without any manually designed features .",
        "the recent success of deep neural networks relies on massive amounts of labeled data .",
        "using pareto speed - accuracy curves , we show that cte can provide better accuracy than convolutional neural networks ( cnn ) for a certain range of classification time constraints , or alternatively provide similar error rates with 5 - 200x speedup .",
        "recurrent neural network ( rnn ) has been broadly applied to natural language processing ( nlp ) problems .",
        "this kind of neural network is designed for modeling sequential data and has been testified to be quite efficient in sequential tagging tasks .",
        "we show experimentally that energy - based neural networks with several hidden layers can be trained at discriminative tasks by using iterative inference and an stdp - like learning rule .",
        "the main result of this paper is that we can train neural networks with 1 , 2 and 3 hidden layers on the permutation - invariant mnist task and get the training error down to 0 .",
        "in such cases , neural network language models ( nnlms ) , generally outperform the traditional non - parametric n - gram models .",
        "deep generative models parameterized by neural networks have recently achieved state - of - the - art performance in unsupervised and semi - supervised learning .",
        "we develop a general duality between neural networks and compositional kernels , striving towards a better understanding of deep learning .",
        "our dual view also reveals a pragmatic and aesthetic perspective of neural networks and underscores their expressive power .",
        "it has been generally believed that training deep neural networks is hard with saturated activation functions , including sigmoid and tanh .",
        "we propose to train bi - directional neural network language model ( nnlm ) with noise contrastive estimation ( nce ) .",
        "in this paper , we present clstm ( contextual lstm ) , an extension of the recurrent neural network lstm ( long - short term memory ) model , where we incorporate contextual features ( e .",
        "inspired by the success of convolutional neural network in image recognition , where neurons can capture many complicated patterns based on the extracted elementary visual patterns such as oriented edges and corners , we propose to model text matching as the problem of image recognition .",
        "then a convolutional neural network is utilized to capture rich matching patterns in a layer - by - layer way .",
        "we propose two novel techniques - - - stacking bottleneck features and minimum trajectory error training criterion - - - to improve the performance of deep neural network ( dnn ) - based speech synthesis .",
        "the subjective results show that combining the two techniques leads to significantly more natural synthetic speech than from conventional dnn or long short - term memory ( lstm ) recurrent neural network ( rnn ) systems .",
        "in this work , we propose a semi - supervised method for short text clustering , where we represent texts as distributed vectors with neural networks , and use a small amount of labeled data to specify our intention for clustering .",
        "we design a novel objective to combine the representation learning process and the k - means clustering process together , and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps : ( 1 ) assign each short text to its nearest centroid based on its representation from the current neural networks ; ( 2 ) re - estimate the cluster centroids based on cluster assignments from step ( 1 ) ; ( 3 ) update neural networks according to the objective by keeping centroids and cluster assignments fixed .",
        "we introduce a neural network architecture and a learning algorithm to produce factorized symbolic representations .",
        "as neural networks are typically over - complete , it ' s easy to show the existence of vast continuous regions through weight space with equal loss .",
        "in this paper , we build on recent work empirically characterizing the error surfaces of neural networks .",
        "while it ' s trivial to show that neural network error surfaces are globally non - convex , we show that error surfaces are also locally non - convex , even after breaking symmetry with a random initialization and also after partial training .",
        "recent research on deep neural networks has focused primarily on improving accuracy .",
        "recently , the deep neural network ( derived from the artificial neural network ) has attracted many researchers ' attention by its outstanding performance .",
        "in order to improve the deep neural network , many trials have been made by refining the network structure or training strategy .",
        "unlike those trials , in this paper , we focused on the basic propagation function of the artificial neural network and proposed the binarized deep neural network .",
        "new language modeling methods based on neural networks alleviate the curse of dimensionality and usually outperform conventional n - gram methods .",
        "in this paper , we present a novel setup of a neural network language model ( nnlm ) and apply it to a database of text samples from different authors .",
        "we introduce group equivariant convolutional neural networks ( g - cnns ) , a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries .",
        "in this work , we investigate the robustness of the mention detection systems , one of the fundamental tasks in information extraction , via recurrent neural networks ( rnns ) .",
        "we introduce recurrent neural network grammars , probabilistic models of sentences with explicit phrase structure .",
        "we present weight normalization : a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction .",
        "recurrent neural networks ( rnn ) are capable of learning to encode and exploit activation history over an arbitrary timescale .",
        "the increasing complexity of deep neural networks ( dnns ) has made it challenging to exploit existing large - scale data process pipelines for handling massive data and parameters involved in dnn training .",
        "in this paper , we systematically analyse the connecting architectures of recurrent neural networks ( rnns ) .",
        "second , we propose three architecture complexity measures of rnns : ( a ) the recurrent depth , which captures the rnn ' s over - time nonlinear complexity , ( b ) the feedforward depth , which captures the local input - output nonlinearity ( similar to the \" depth \" in feedforward neural networks ( fnns ) ) , and ( c ) the recurrent skip coefficient which captures how rapidly the information propagates over time .",
        "here , we apply this formalism for the first time to multilayer feedforward neural networks .",
        "in experiments on the mnist benchmark classification task for handwritten digits , we show that such information - theoretic regularization successfully prevents overfitting across different architectures and attains state - of - the - art results for both ordinary and convolutional neural networks .",
        "in this paper , we propose the neural knowledge dna , a framework that tailors the ideas underlying the success of neural networks to the scope of knowledge representation .",
        "the proposed neural knowledge dna is designed to support discovering , storing , reusing , improving , and sharing knowledge among machines and organisation .",
        "as the dna produces phenotypes , the neural knowledge dna carries information and knowledge via its four essential elements , namely , networks , experiences , states , and actions .",
        "recently , neural turing machine and memory networks have shown that adding an external memory can greatly ameliorate a traditional recurrent neural network ' s tendency to forget after a long period of time .",
        "an lstm controller performs read and write via specialized structures called read and write heads , following the design of neural turing machine .",
        "for this reason , we name this new model the lie access neural turing machine , or lantm .",
        "convolutional neural networks with rectified linear activation and max or average pooling , are the cornerstone of modern deep learning .",
        "we study the segmental recurrent neural network for end - to - end acoustic modelling .",
        "this model connects the segmental conditional random field ( crf ) with a recurrent neural network ( rnn ) used for feature extraction .",
        "we suggest a compositional vector representation of parse trees that relies on a recursive combination of recurrent - neural network encoders .",
        "common activation functions used in neural networks can yield to training difficulties due to the saturation behavior of the activation function , which may hide dependencies which are not visible to first order ( using only gradients ) .",
        "recursive neural networks ( rnn ) and their recently proposed extension recursive long short term memory networks ( rlstm ) are models that compute representations for sentences , by recursively combining word embeddings according to an externally provided parse tree .",
        "to address the former challenge , we present an algorithm capable of learning arbitrary nonlinear cost functions , such as neural networks , without meticulous feature engineering .",
        "model - free reinforcement learning has been successfully applied to a range of challenging problems , and has recently been extended to handle large neural network policies and value functions .",
        "new state - of - the - art word segmentation systems use neural models to learn representations for predicting word boundaries .",
        "this is all the more surprising that neural networks are able to discover latent variables in large and heterogeneous datasets .",
        "in this paper , we introduce a collaborative filtering neural network architecture aka cfn which computes a non - linear matrix factorization from sparse rating inputs and side information .",
        "we provide an implementation of the algorithm as a reusable plugin for torch , a popular neural network framework .",
        "neural machine translation ( mt ) has reached state - of - the - art results .",
        "however , one of the main challenges that neural mt still faces is dealing with very large vocabularies and morphologically rich languages .",
        "in this paper , we propose a neural mt system using character - based embeddings in combination with convolutional and highway layers to replace the standard lookup - based word representations .",
        "the resulting unlimited - vocabulary and affix aware source word embeddings are tested in a state - of - the - art neural mt based on an attention - based bidirectional recurrent neural network .",
        "however the number of unknowns at the output of the translation network is dramatically reduced ( by a relative 66 % ) with a significant overall improvement over both neural and phrase - based baselines .",
        "in this paper we examine the use of long short - term memory recurrent neural networks ( lstms ) for the purpose of generating levels trained from a corpus of super mario brothers levels .",
        "we first present a novel neural network based relation extractor to retrieve the candidate answers from freebase , and then develop a refinement model to validate answers using wikipedia .",
        "we introduce a novel , simple convolution neural network ( cnn ) architecture - multi - group norm constraint cnn ( mgnc - cnn ) that capitalizes on multiple sets of word embeddings for sentence classification .",
        "while classical methods typically derive gait signatures from sequences of binary silhouettes , in this work we explore the use of convolutional neural networks ( cnn ) for learning high - level descriptors from low - level motion features ( i .",
        "recent advances in convolutional neural networks have considered model complexity and hardware efficiency to enable deployment onto embedded systems and mobile devices .",
        "when applied to leduc poker , neural fictitious self - play ( nfsp ) approached a nash equilibrium , whereas common reinforcement learning methods diverged .",
        "the emergence of collective dynamics in neural networks is a mechanism of the animal and human brain for information processing .",
        "in this paper , we propose a procedure to train multi - domain , recurrent neural network - based ( rnn ) language generators via multiple adaptation steps .",
        "this paper investigates the connections between two state of the art classifiers : decision forests ( dfs , including decision jungles ) and convolutional neural networks ( cnns ) .",
        "in this paper , we introduce two new neural architectures - - - one based on bidirectional lstms and conditional random fields , and the other that constructs and labels segments using a transition - based approach inspired by shift - reduce parsers .",
        "neural network architectures with memory and attention mechanisms exhibit certain reasoning capabilities required for question answering .",
        "we present in this paper a systematic study on how to morph a well - trained neural network to a new one so that its network function can be completely preserved .",
        "to meet this requirement , we first introduce the network morphism equations , and then develop novel morphing algorithms for all these morphing types for both classic and convolutional neural networks .",
        "experimental results on benchmark datasets and typical neural networks demonstrate the effectiveness of the proposed network morphism scheme .",
        "to learn hand - eye coordination for grasping , we trained a large convolutional neural network to predict the probability that task - space motion of the gripper will result in successful grasps , using only monocular camera images and independently of camera calibration or the current robot pose .",
        "we propose a convolutional neural network ( cnn ) based detector for this task .",
        "to exploit the combination of different discourse corpora , we design related discourse classification tasks specific to a corpus , and propose a novel convolutional neural network embedded multi - task learning system to synthesize these tasks by learning both unique and shared representations for each task .",
        "deep neural networks are capable of modelling highly non - linear functions by capturing different levels of abstraction of data hierarchically .",
        "in contrast to that , during the \" night \" phase the stored information is been transferred to the supercomputing system to update the realistic neural network : emotional and behavioral strategies .",
        "deep learning consists in training neural networks to perform computations that sequentially unfold in many steps over a time dimension or an intrinsic depth dimension .",
        "when a convolutional neural network is used for on - the - fly evaluation of continuously updating time - sequences , many redundant convolution operations are performed .",
        "we discuss some modifications needed in order to get training with exploration to work well for a probabilistic neural - network .",
        "recent approaches based on artificial neural networks ( anns ) have shown promising results for short - text classification .",
        "in this work , we present a model based on recurrent neural networks and convolutional neural networks that incorporates the preceding short texts .",
        "inspired by this , we propose a neural recognizer for implicit discourse relation analysis , which builds upon a semantic memory that stores knowledge in a distributed fashion .",
        "using the surface and semantic representations as input , semder finally predicts implicit discourse relations via a neural recognizer .",
        "in this paper , instead , we explore generative models and propose a variational neural discourse relation recognizer .",
        "in order to perform efficient inference and learning , we introduce a neural discourse relation model to approximate the posterior of the latent variable , and employ this approximated posterior to optimize a reparameterized variational lower bound .",
        "we use deep neural networks to address both tasks , quantitatively and qualitatively measure the results in a variety of novel manners , and present a thorough investigation of the weaknesses and strengths of the approach .",
        "convolutional neural networks have been shown to develop internal representations , which correspond closely to semantically meaningful objects and parts , although trained solely on class labels .",
        "recently , several works in the field of natural language processing suggested to learn a latent representation of words using neural embedding algorithms .",
        "in this paper , we show that item - based cf can be cast in the same framework of neural word embedding .",
        "the system is flexible and can be used to express a wide variety of algorithms , including training and inference algorithms for deep neural network models , and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields , including speech recognition , computer vision , robotics , information retrieval , natural language processing , geographic information extraction , and computational drug discovery .",
        "we propose mvcnn , a convolution neural network ( cnn ) architecture for sentence classification .",
        "deep neural networks ( dnn ) have shown unprecedented success in various computer vision applications such as image classification and object detection .",
        "this paper presents a novel approach to recurrent neural network ( rnn ) regularization .",
        "many deep convolutional neural networks ( cnn ) make incorrect predictions on adversarial samples obtained by imperceptible perturbations of clean samples .",
        "we propose a convolutional neural network which splits the input sentence into three parts according to the relation arguments and compare it to state - of - the - art and traditional approaches of relation classification .",
        "recently , convolutional neural networks ( cnns ) have been used as a powerful tool to solve many problems of machine learning and computer vision .",
        "in this paper , we aim to provide insight on the property of convolutional neural networks , as well as a generic method to improve the performance of many cnn architectures .",
        "in this paper , we present a neural aggregation network ( nan ) for video face recognition .",
        "the neural aggregation module is composed of two content based attention blocks which is driven by a memory storing all the features extracted from the face video through the feature embedding module .",
        "tree - structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences .",
        "we address these issues by introducing the stack - augmented parser - interpreter neural network ( spinn ) , which combines parsing and interpretation within a single tree - sequence hybrid model by integrating tree - structured sentence interpretation into the linear sequential structure of a shift - reduce parser .",
        "we introduce a globally normalized transition - based neural network model that achieves state - of - the - art part - of - speech tagging , dependency parsing and sentence compression results .",
        "our model is a simple feed - forward neural network that operates on a task - specific transition system , yet achieves comparable or better accuracies than recurrent models .",
        "in this paper we propose a technique for domain adaptation in stacked autoencoder ( sae ) based deep neural networks ( dnn ) performed in two stages : ( i ) unsupervised weight adaptation using systematic dropouts in mini - batch training , ( ii ) supervised fine - tuning with limited number of labeled samples in target domain .",
        "most of the existing neural machine translation ( nmt ) models focus on the conversion of sequential data and do not directly take syntax into consideration .",
        "we suggest an improved path - based algorithm , in which the dependency paths are encoded using a recurrent neural network , and achieve results comparable to distributional methods .",
        "in computer vision , convolutional neural networks ( cnns ) have recently achieved new levels of performance for several inverse problems where rgb pixel appearance is mapped to attributes such as positions , normals or reflectance .",
        "it is particularly important to neural networks because neural models are very likely to be overfitting .",
        "in some fields like image processing , many studies have shown the effectiveness of neural network - based transfer learning .",
        "for neural nlp , however , existing studies have only casually applied transfer learning , and conclusions are inconsistent .",
        "in this paper , we conduct a series of empirical studies and provide an illuminating picture on the transferability of neural networks in nlp .",
        "we augment procedural models with neural networks : these networks control how the model makes random choices based on what output it has generated thus far .",
        "we call such a model a neurally - guided procedural model .",
        "given a desired quality threshold , neurally - guided models can generate satisfactory results up to 10x faster than unguided models .",
        "the existing machine translation systems , whether phrase - based or neural , have relied almost exclusively on word - level modelling with explicit segmentation .",
        "in this paper , we ask a fundamental question : can neural machine translation generate a character sequence without any explicit segmentation ?",
        "furthermore , the ensembles of neural models with a character - level decoder outperform the state - of - the - art non - neural machine translation systems on en - cs , en - de and en - fi and perform comparably on en - ru .",
        "we present persona - based models for handling the issue of speaker consistency in neural response generation .",
        "we present a deep hierarchical recurrent neural network for sequence tagging .",
        "combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce unpredictability of the neural models .",
        "we propose a general framework capable of enhancing various types of neural networks ( e .",
        "specifically , we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks .",
        "we propose a novel algorithm that allows us to blend and select a subset of the most feasible demonstrations to learn to imitate on the hardware , which we use with an extension of the guided policy search framework to use multiple demonstrations to learn generalizable neural network policies .",
        "in this paper , we incorporate copying into neural network - based seq2seq learning and propose a new model called copynet with encoder - decoder structure .",
        "in this paper we present architectures based on deep neural nets for gesture recognition in videos , which are invariant to local scaling .",
        "we provide superior results over known methods , including recent reported approaches based on neural nets .",
        "in this paper , we propose a scalable bayesian neural word embedding algorithm that can be beneficial to general item similarity tasks as well .",
        "we propose information theoretic - learning ( itl ) divergence measures for variational regularization of neural networks .",
        "in this paper , we propose a novel joint model that integrates recursive neural networks and conditional random fields into a unified framework for aspect - based sentiment analysis .",
        "we present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions .",
        "in this paper we present the 30m factoid question - answer corpus , an enormous question - answer pair corpus produced by applying a novel neural network architecture on the knowledge base freebase to transduce facts into natural language questions .",
        "we present a new action recognition deep neural network which adaptively learns the best action velocities in addition to the classification .",
        "while deep neural networks have reached maturity for image understanding tasks , we are still exploring network topologies and features to handle the richer environment of video clips .",
        "in this paper , we present wsd algorithms which use neural network language models to achieve state - of - the - art precision .",
        "we apply a general recurrent neural network ( rnn ) encoder framework to community question answering ( cqa ) tasks .",
        "further improvements are observed when we extend the rnn encoders with a neural attention mechanism that encourages reasoning over entire sequences .",
        "developing intelligent systems involves artificial intelligence approaches including artificial neural networks .",
        "here , we present a tutorial of deep neural networks ( dnns ) , and some insights about the origin of the term \" deep \" ; references to deep learning are also given .",
        "in this work we propose a data - driven approach based on neural networks and continuous sentence features .",
        "this system has the capability to process key machine learning algorithms such as deep neural network , autoencoder , and k - means clustering .",
        "memristor crossbars are utilized to provide low power high throughput execution of neural networks .",
        "defe can be viewed as a deep ensemble learning scheme that trains a strongly diverse set of neural feature learners without explicitly encouraging diversity and penalizing correlations .",
        "this is achieved by adopting an implicit neural controller ( not involved in feedforward compuation ) that directly controls and distributes gradient flows from higher level deep prediction network .",
        "defe makes the ensembles ' deep ' in the sense that it allows deep post - process of these features that tries to learn to select and abstract the ensemble of neural feature learners .",
        "in comparison of the classic deep neural network , defe shows a state - of - the - art performance : the error rate has decreased by about 37 \\ % , the accuracy has broken through 90",
        "the results reveal that neural embedding based document representations work better on this analogy task than conventional methods , and we provide some preliminary explanations over these observations .",
        "recently , various neural representation learning models such as wsabie and its variants show promising performance , mainly due to compact feature representations learned in a semantic space .",
        "in this work , we propose a neural feedback relevance model for learning tag representations with weighted feature representations .",
        "in this paper , we propose a new deep learning approach , called neural association model ( nam ) , for probabilistic reasoning in artificial intelligence .",
        "we propose to use neural networks to model association between any two events in a domain .",
        "neural networks take one event as input and compute a conditional probability of the other event to model how likely these two events are associated .",
        "in this work , as two case studies , we have investigated two nam structures , namely deep neural networks ( dnns ) and relation modulated neural nets ( rmnns ) , on several probabilistic reasoning tasks in ai , including recognizing textual entailment , triple classification in multirelational knowledge bases and common - sense reasoning .",
        "this paper introduces a neural model for concept - to - text generation that scales to large , rich domains .",
        "our model builds upon recent work on conditional neural language model for text genera - tion .",
        "our neural model significantly out - performs a classical kneser - ney language model adapted to this task by nearly 15 bleu .",
        "considering that recurrent neural networks ( rnns ) with long short - term memory ( lstm ) can learn feature representations and model long - term temporal dependencies automatically , we propose an end - to - end fully connected deep lstm network for skeleton based action recognition .",
        "we study the problem of compressing recurrent neural networks ( rnns ) .",
        "we propose a novel way to deal with the rare and unseen words for the neural network models with attention .",
        "using our proposed model , we observe improvements in two tasks , neural machine translation on the europarl english to french parallel corpora and text summarization on the gigaword dataset .",
        "the long short term memory recurrent neural network ( lstm - rnn ) is employed as the main classification architecture .",
        "sparseness is a useful regularizer for learning in a wide range of applications , in particular in neural networks .",
        "in this paper , we provide a multi - class schema , an annotated dataset , and supervised classifiers based on convolutional neural network ( cnn ) and other models for the task of classifying discussion topics .",
        "this paper introduces the visually informed embedding of word ( view ) , a continuous vector representation for a word extracted from a deep neural model trained using the microsoft coco data set to forecast the spatial arrangements between visual objects , given a textual description .",
        "we achieve this by performing probabilistic inference using a recurrent neural network that attends to scene elements and processes them one at a time .",
        ", decomposing 3d images with various numbers of objects in a single forward pass of a neural network .",
        "deep neural networks ( dnns ) are powerful types of artificial neural networks ( anns ) that use several hidden layers .",
        "we tackle the dataset with a neural approach , harnessing simple neural networks arranged in a parallel hierarchy .",
        "when trained with a methodology designed to help cope with limited training data , our parallel - hierarchical model sets a new state of the art for { \\ it mctest } , outperforming previous feature - engineered approaches slightly and previous neural approaches by a significant margin ( over 15 \\ % absolute ) .",
        "we propose a reparameterization of lstm that brings the benefits of batch normalization to recurrent neural networks .",
        "we report an implementation of a clinical information extraction tool that leverages deep neural network to annotate event spans and their attributes from raw clinical notes and pathology reports .",
        "then we hire temporal ( 1d ) convolutional neural network to learn hidden feature representations .",
        "neural network based approaches for sentence relation modeling automatically generate hidden matching features from raw sentence pairs .",
        "to address this challenge , we propose a new deep neural network architecture that jointly leverage pre - trained word embedding and auxiliary character embedding to learn sentence meanings .",
        "recently recurrent neural networks ( rnn ) has been very successful in handling sequence data .",
        "we present a deep neural network ( dnn ) acoustic model including parametrised and differentiable pooling operators .",
        "on the other hand , word and phrase - based machine translation methods are not designed to cope with orthographic errors , and have recently been outpaced by neural models .",
        "motivated by these issues , we present a neural network - based approach to language correction .",
        "the core component of our method is an encoder - decoder recurrent neural network with an attention mechanism .",
        "recurrent neural network architectures combining with attention mechanism , or neural attention model , have shown promising performance recently for the tasks including speech recognition , image caption generation , visual question answering and machine translation .",
        "in this paper , neural attention model is applied on two sequence classification tasks , dialogue act detection and key term extraction .",
        "the efficiency and differentiability of the model make it especially well - suited for integration with convolutional neural networks , even allowing it to be used in interior , feature - generating layers and stacked multiple times .",
        "given this new evaluation metric , we report more than 100 % improvement across distortion levels over current state of the art recurrent neural network based language models .",
        "in this study we address the problem of training a neuralnetwork for language identification using both labeled and unlabeled speech samples in the form of i - vectors .",
        "we propose a neural network architecture that can also handle out - of - set languages .",
        "inspired by the recent success of methods that employ shape priors to achieve robust 3d reconstructions , we propose a novel recurrent neural network architecture that we call the 3d recurrent reconstruction neural network ( 3d - r2n2 ) .",
        "like previous learned approaches to language generation , our model uses a simple feature - driven architecture ( here a pair of neural \" listener \" and \" speaker \" models ) to ground language in the world .",
        "a way for dealing with this problem is through neuroevolution , a method which trains artificial neural networks using evolutionary algorithms .",
        "we present a model that uses convolutional neural networks to capture semantic correspondence between a mention ' s context and a proposed target entity .",
        "nearly all previous work in neural machine translation ( nmt ) has used quite restricted vocabularies , perhaps with a subsequent method to patch in unknown words .",
        "our character - level recurrent neural networks compute source word representations and recover unknown target words when needed .",
        "our model builds on a deep convolutional neural network ( cnn ) and two separate lstm networks .",
        "in this paper we present an approach to polyphonic sound event detection in real life recordings based on bi - directional long short term memory ( blstm ) recurrent neural networks ( rnns ) .",
        "in this paper , we propose convolutional neural networks for learning an optimal representation of question and answer sentences .",
        "we address these two problems jointly by engaging the low - dimensional semantic representation capabilities of the sequence to sequence neural translation models .",
        "to enable joint multi - task learning for multilingual neural translation of morphologically rich languages we replace the attention mechanism with the sliding - window mechanism and operate the sequence to sequence neural translation model on the character - level rather than on the word - level .",
        "the story segmentation and storyline clustering problem is tackled by examining the low - dimensional vectors produced as a side - product of the neural translation process .",
        "4 % gain when ap - plied to outputs of two nondeterministic amr parsers : a camr + wrapper parser and a novel character - level neural translation amr parser .",
        "for amr parsing task the character - level neural translation attains surprising 7 % gain over the carefully optimized word - level neural translation .",
        "residual learning has recently surfaced as an effective means of constructing very deep neural networks for object recognition .",
        "based on the alternating direction method of multipliers ( admm ) , we formulate the original convex minimization problem as a feed - forward neural network , named \\ textit { deep $ \\ ell _ \\ infty $ encoder } , by introducing the novel bounded linear unit ( blu ) neuron and modeling the lagrange multipliers as network biases .",
        "specifically , we integrate both a neural language model and distributional semantics trained on large text corpora into a recent lstm - based architecture for video description .",
        "recently , neural headline generation models have been proposed to take advantage of well - trained neural networks in learning sentence representations and mapping sequence to sequence .",
        "nevertheless , traditional neural network encoder utilizes maximum likelihood estimation for parameter optimization , which essentially constraints the expected training objective within word level instead of sentence level .",
        "as recurrent neural networks become larger and deeper , training times for single networks are rising into weeks or even months .",
        "different from conventional topic models that largely ignore the sequential order of words or their topic coherence , slrtm gives full characterization to them by using a recurrent neural networks ( rnn ) based framework .",
        "the encoder - decoder framework for neural machine translation ( nmt ) has been shown effective in large data scenarios , but is much less effective for low - resource languages .",
        "we compare a family of irt - based proficiency estimation methods with a recently proposed approach using recurrent neural networks ( rnns ) on two publicly available and one proprietary data set , evaluating each model according to how well a student ' s future response is predicted given previous responses .",
        "the success of deep neural networks is mostly due their ability to learn meaningful features from the data .",
        "features learned in the hidden layers of deep neural networks trained in computer vision tasks have been shown to be similar to mid - level vision features .",
        "here we assume that such interface for ai emerges from an adequate neural - symbolic integration .",
        "for the train of such neural networks we changed the levenderg - marquardt algorithm , restricting the knowledge dissemination in the network structure using soft crystallization .",
        "this procedure reduces neural network plasticity without drastically damaging the learning performance , allowing the emergence of symbolic patterns .",
        "this makes the descriptive power of produced neural networks similar to the descriptive power of { \\ l } ukasiewicz logic language , reducing the information lost on translation between symbolic and connection",
        "we compare these systems with recent recurrent neural net models that directly operate on raw tokens to predict sentences , finding the latter to be roughly comparable to the former in terms of predicting missing events in documents .",
        "we instead propose to use recurrent neural networks ( rnns ) to learn latent , global representations of entity clusters directly from their mentions .",
        "we trained binarized neural networks ( bnns ) on the high resolution imagenet lsvrc - 2102 dataset classification task and achieved a good performance .",
        "rather than training the network node connections and weights via backpropagation in traditional recurrent neural networks , reservoirs instead have fixed connections and weights among the ` hidden layer ' nodes , and traditionally only the weights to the output layer of neurons are trained using linear regression .",
        "for that we trained a neural networks using the levenderg - marquardt algorithm , where we restricted the knowledge dissemination in the network structure .",
        "this procedure reduces neural network plasticity without drastically damaging the learning performance , thus making the descriptive power of produced neural networks similar to the descriptive power of { \\ l } ukasiewicz logic language and simplifying the translation between symbolic and connectionist structures .",
        "we introduce a new approach for disfluency detection using a bidirectional long - short term memory neural network ( blstm ) .",
        "the combination of convolutional and recurrent neural networks in these models has proven to outperform the previous state of the art , obtaining more accurate video descriptions .",
        "first , producing richer image representations by combining object and location information from convolutional neural networks and second , introducing bidirectional recurrent neural networks for capturing both forward and backward temporal relationships in the input frames .",
        "in this paper , we describe a novel deep convolutional neural networks ( cnn ) based approach called contextual deep cnn that can jointly exploit spatial and spectral features for hyperspectral image classification .",
        "we discuss relations between residual networks ( resnet ) , recurrent neural networks ( rnns ) and the primate visual cortex .",
        "we introduce a novel type of artificial neural network structure and training procedure that results in networks that are provably , quantitatively more robust to adversarial samples than classical , end - to - end trained classifiers .",
        "specifically , deep recurrent neural networks were used for improving joint positions and velocities of kinect skeleton , and three methods were proposed to integrate the refined positions and velocities for further enhancement .",
        "more specifically , the generation is two - phase : ( 1 ) dp position detection , which is modeled as a sequential labelling task with recurrent neural networks ; and ( 2 ) dp prediction , which employs a multilayer perceptron with rich features .",
        "in this paper , we propose a modification of the popular and efficient multi - dimensional long short - term memory recurrent neural networks ( mdlstm - rnns ) to enable end - to - end processing of handwritten paragraphs .",
        "in the proposed model , a neural network performs a kind of implicit line segmentation by computing attention weights on the image representation .",
        "we train a number of neural networks to play games bowling , breakout and seaquest using information stored in the memory of a video game console atari 2600 .",
        "we consider four models of neural networks which differ in size and architecture : two networks which use only information contained in the ram and two mixed networks which use both information in the ram and information from the screen .",
        "we experiment shrinking deep learning with recall ( sdlr ) using deep neural network ( dnn ) , deep belief network ( dbn ) and convolution neural network ( cnn ) on 4 data sets .",
        "the iterations of many sparse estimation algorithms are comprised of a fixed linear filter cascaded with a thresholding nonlinearity , which collectively resemble a typical neural network layer .",
        "we illustrate this general approach with an application to dialogue where we integrate a neural chat model , good at conversational aspects , with a neural question - answering model , good at retrieving precise information from a knowledge - base , and show how the integration combines the strengths of the independent components .",
        "the purported \" black box \" nature of neural networks is a barrier to adoption in applications where interpretability is essential .",
        "here we present deeplift ( learning important features ) , an efficient and effective method for computing importance scores in a neural network .",
        "with the growing importance of large network models and enormous training datasets , gpus have become increasingly necessary to train neural networks .",
        "the recent advances in deep neural networks have led to effective vision - based reinforcement learning methods that have been employed to obtain human - level controllers in atari 2600 games from pixel data .",
        "using convolutional deep neural networks with q - learning and experience replay , for both scenarios , we were able to train competent bots , which exhibit human - like behaviors .",
        "in this paper , we propose a neural recovery machine ( nrm ) to model and recover dps in chinese , so that to avoid the non - trivial feature engineering process .",
        "an asynchronous and momentum variant of the easgd method is applied to train deep convolutional neural networks for image classification on the cifar and imagenet datasets .",
        "we present neural autoregressive distribution estimation ( nade ) models , which are neu - ral network architectures applied to the problem of unsupervised distribution and density esitmation .",
        "the recent breakthrough made by alphago , which incorporates convolutional neural networks with bandit algorithms in mcts , also highlights the necessity of bandit algorithms in mcts .",
        "we then suggest two frameworks for solving multiple - instance learning , one based on neural networks , and the second on support vector machines .",
        "while the recent successes of many computer vision related tasks are due to the adoption of convolutional neural networks ( cnns ) , visual emotion analysis has not achieved the same level of success .",
        "the implemented framework supports major deep learning architectures such as multilayer perceptron networks ( mlp ) , convolutional neural networks ( cnn ) and recurrent neural networks ( rnn ) .",
        "taking inspiration from the image classification domain we propose a deep convolutional neural network architecture , must - cnn , to predict protein properties .",
        "in this paper , we enhance the attention - based neural machine translation by adding an explicit coverage embedding model to alleviate issues of repeating and dropping translations in nmt .",
        "in order to capture rich language phenomena , neural machine translation models have to use a large vocabulary size , which requires high computing time and large memory usage .",
        "experimental results on the large - scale english - to - french task show that our method achieves better translation performance by 1 bleu point over the large vocabulary neural machine translation system of jean et al .",
        "this cognitive model is based on multiple time - scale recurrent neural networks ( mtrnn ) .",
        "a novel recurrent neural network called recurrent neural network with parametric bias units ( rnnpb ) runs in three modes , constructing a two - level emotion regulated learning model , was further applied to testify this theory in two different cases .",
        "by introducing perturbations to image descriptions extracted from a deep convolutional neural network , we change their precision and number of dimensions , measuring how it affects the final score .",
        "we introduce polyglot language models , recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted .",
        "we demonstrate these results computationally with a multilayer feedforward neural network .",
        "we present a new convolutional neural network ( cnn ) model for text classification that jointly exploits labels on documents and their component sentences .",
        "we investigate the use of hierarchical phrase - based smt lattices in end - to - end neural machine translation ( nmt ) .",
        "in this paper we present deeplearningkit - an open source framework that supports using pretrained deep learning models ( convolutional neural networks ) for ios , os x and tvos .",
        "we explore the application of neural translation models to the ape problem and achieve good results by treating different models as components in a log - linear model , allowing for multiple inputs ( the mt - output and the source ) that are decoded to the same target language ( post - edited translations ) .",
        "we explore methods of decode - time integration of attention - based neural translation models with phrase - based statistical machine translation .",
        "for english - russian , the phrase - based system cannot surpass state - of - the - art stand - alone neural models .",
        "for the russian - english task , our submission achieves the top bleu result , outperforming the best pure - neural system by 1 .",
        "deep neural networks are typically represented by a much larger number of parameters than shallow models , making them prohibitive for small footprint devices .",
        "recent research shows that there is considerable redundancy in the parameter space of deep neural networks .",
        "in this paper , we propose a method to compress deep neural networks by using the fisher information metric , which we estimate through a stochastic optimization method that keeps track of second - order information in the network .",
        "we evaluate our method on a classification task with a convolutional neural network trained on the mnist data set .",
        "in this paper , a deep neural network is proposed to incorporate background knowledge for conversation modeling .",
        "we propose a framework for learning convolutional neural networks for arbitrary graphs .",
        "in this paper , we present a hybrid architecture of convolutional neural networks ( cnn ) and stacked autoencoders ( sae ) to learn a sequence of actions that nonlinearly transforms an input shape or distribution into a target shape or distribution with the same support .",
        "recently , there is rising interest in modelling the interactions of two sentences with deep neural networks .",
        "self - organizing map ( som ) is a neural network model which is used to obtain a topology - preserving mapping from the ( usually high dimensional ) input / feature space to an output / map space of fewer dimensions ( usually two or three in order to facilitate visualization ) .",
        "despite recent breakthroughs in the applications of deep neural networks , one setting that presents a persistent challenge is that of \" one - shot learning . \"",
        "architectures with augmented memory capacities , such as neural turing machines ( ntms ) , offer the ability to quickly encode and retrieve new information , and hence can potentially obviate the downsides of conventional models .",
        "here , we demonstrate the ability of a memory - augmented neural network to rapidly assimilate new data , and leverage this data to make accurate predictions after only a few samples .",
        "in an effort to model this kind of generative process , we propose a neural network - based generative architecture , with latent stochastic variables that span a variable number of time steps .",
        "we apply the proposed model to the task of dialogue response generation and compare it with recent neural network architectures .",
        "the model is then evaluated in both uni - and multi - modality settings on two different classification tasks with off - the - shelf convolutional neural network ( cnn ) features which generate state - of - the - art results with extremely compact representations .",
        "as a result , we obtain a new type of convolutional neural network with the following properties : ( i ) at each layer , learning filters is equivalent to optimizing a linear subspace in a reproducing kernel hilbert space ( rkhs ) , where we project data , ( ii ) the network may be learned with supervision or without , ( iii ) the model comes with a natural regularization function ( the norm in the rkhs ) .",
        "56 % , by a neural encoder - decoder model ) while being trained on the same data .",
        "convolutional neural networks ( cnn ) have achieved major breakthroughs in recent years .",
        "deep neural networks can capture complex non - linear features ; however this ability comes at the cost of high computational and memory requirements .",
        "many hardware accelerators for deep neural networks have been proposed recently .",
        "this suggests that in addition to describing neural networks in terms of width and depth , there is a third dimension : multiplicity , the size of the implicit ensemble .",
        "we propose a new method for training computationally efficient and compact convolutional neural networks ( cnns ) using a novel sparse connection structure that resembles a tree root .",
        "as the complexity of deep neural networks ( dnns ) trend to grow to absorb the increasing sizes of data , memory and energy consumption has been receiving more and more attentions for industrial applications , especially on mobile devices .",
        "there are families of neural networks that can learn to compute any function , provided sufficient training data .",
        "through a neural implementation of the dual stack machine that underlies forth , programmers can write program sketches with slots that can be filled with learnable behaviour .",
        "as the program interpreter is end - to - end differentiable , we can optimize this behaviour directly through gradient descent techniques on user specified objectives , and also integrate the program into any larger neural computation graph .",
        "in addition , we introduce neural program optimisations based on symbolic computation and parallel branching that lead to significant speed improvements .",
        "by embracing deep neural networks , we are able to demonstrate end - to - end learning of protocols in complex environments inspired by communication riddles and multi - agent computer vision problems with partial observability .",
        "however , the size of the networks becomes increasingly large scale due to the demands of the practical applications , which poses significant challenge to construct a high performance implementations of deep learning neural networks .",
        "at the core of chor - rnn is a deep recurrent neural network trained on raw motion capture data and that can generate new dance sequences for a solo dancer .",
        "recent progress on many imaging and vision tasks has been driven by the use of deep feed - forward neural networks , which are trained by propagating gradients of a loss defined on the final output , back through the network up to the first layer that operates directly on the image .",
        "for an expected loss function of a deep nonlinear neural network , we prove the following statements under the independence assumption adopted from recent work : 1 ) the function is non - convex and non - concave , 2 ) every local minimum is a global minimum , 3 ) every critical point that is not a global minimum is a saddle point , and 4 ) the property of saddle points differs for shallow networks ( with three layers ) and deeper networks ( with more than three layers ) .",
        "moreover , we prove that the same four statements hold for deep linear neural networks with any depth , any widths and no unrealistic assumptions .",
        "instead of being passively exposed to large amounts of natural text , our learners ( implemented as feed - forward neural networks ) engage in cooperative referential games starting from a tabula rasa setup , and thus develop their own language from the need to communicate in order to succeed at the game .",
        "we show that this procedure can be used to train state estimators that use complex input , such as raw camera images , which must be processed using expressive nonlinear function approximators such as convolutional neural networks .",
        "our model can be viewed as a type of recurrent neural network , and the connection to probabilistic filtering allows us to design a network architecture that is particularly well suited for state estimation .",
        "we investigate the parameter - space geometry of recurrent neural networks ( rnns ) , and develop an adaptation of path - sgd optimization method , attuned to this geometry , that can learn plain rnns with relu activations .",
        "despite having high accuracy , neural nets have been shown to be susceptible to adversarial examples , where a small perturbation to an input can cause it to become mislabeled .",
        "we propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program .",
        "we show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the mnist and cifar - 10 datasets .",
        "finally , we show that our techniques can be used to additionally improve neural net robustness both according to the metrics that we propose , but also according to previously proposed metrics .",
        "this paper investigates two different neural architectures for the task of relation classification : convolutional neural networks and recurrent neural networks .",
        "we present a new context representation for convolutional neural networks for relation classification ( extended middle context ) .",
        "furthermore , we propose connectionist bi - directional recurrent neural networks and introduce ranking loss for their optimization .",
        "finally , we show that combining convolutional and recurrent neural networks using a simple voting scheme is accurate enough to improve results .",
        "our neural models achieve state - of - the - art results on the semeval 2010 relation classification task .",
        "this paper introduces a novel model for semantic role labeling that makes use of neural sequence modeling techniques .",
        "how can we efficiently propagate uncertainty in a latent state representation with recurrent neural networks ?",
        "this paper introduces stochastic recurrent neural networks which glue a deterministic recurrent neural network and a state space model together to form a stochastic and sequential neural generative model .",
        "by retaining both the nonlinear recursive structure of a recurrent neural network and averaging over the uncertainty in a latent path , like a state space model , we improve the state of the art results on the blizzard and timit speech modeling data sets by a large margin , while achieving comparable performances to competing methods on polyphonic music modeling .",
        "this gaussian process operates on a continuous space dialogue representation generated in an unsupervised fashion using a recurrent neural network encoder - decoder .",
        "we propose deep structured energy based models ( dsebms ) , where the energy function is the output of a deterministic deep neural network with structure .",
        "in this paper we explore a simple neural model , called commnn , that uses continuous communication for fully cooperative tasks .",
        "we present a new framework of applying deep neural networks ( dnn ) to devise a universal discrete denoiser .",
        "we experimentally show that our resulting algorithm , dubbed as neural dude , significantly outperforms the previous state - of - the - art in several applications with a systematic rule of choosing the hyperparameter , which is an attractive feature in practice .",
        "models of neural machine translation are often from a discriminative family of encoder - decoders that learn a conditional distribution of a target sentence given a source sentence .",
        "in this paper , we propose a variational model to learn this conditional distribution for neural machine translation : a variational encoder - decoder model that can be trained end - to - end .",
        "in order to perform an efficient posterior inference , we build a neural posterior approximator that is conditioned only on the source side .",
        "experiments on nist chinese - english translation tasks show that the proposed variational neural machine translation achieves significant improvements over both state - of - the - art statistical and neural machine translation baselines .",
        "based on the learned phrase representations , we further use a bilinear neural model , trained via a max - margin method , to measure bilingual semantic similarity .",
        "this paper proposes an adaptive neural - compilation framework to address the problem of efficient program learning .",
        "first steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made - - - for the continuous - time case - - - in mallat , 2012 , and wiatowski and b \\ \" olcskei , 2015 .",
        "this paper considers the discrete case , introduces new convolutional neural network architectures , and proposes a mathematical framework for their analysis .",
        "the core algorithms of our system are based on multi - dimensional recurrent neural networks ( mdrnn ) and connectionist temporal classification ( ctc ) .",
        "it has been proven that transfer learning provides an easy way to achieve state - of - the - art accuracies on several vision tasks by training a simple classifier on top of features obtained from pre - trained neural networks .",
        "the goal of this work is to generate better features for transfer learning from multiple publicly available pre - trained neural networks .",
        "to this end , we propose a novel architecture called stacked neural networks which leverages the fast training time of transfer learning while simultaneously being much more accurate .",
        "unlike feature - based svm and sequential neural models such as lstm , this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect .",
        "such importance degree and text representation are calculated with multiple computational layers , each of which is a neural attention model over an external memory .",
        "we explored various comparative methods , namely phrase - based systems and attentional recurrent neural networks models trained using monomodal or multimodal data .",
        "this paper presents research in progress investigating the viability and adaptation of reinforcement learning using deep neural network based function approximation for the task of radio control and signal detection in the wireless domain .",
        "deep neural networks ( dnns ) have demonstrated state - of - the - art results on many pattern recognition tasks , especially vision classification problems .",
        "one path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect .",
        "the activation function of deep neural networks ( dnns ) has undergone many changes during the last decades .",
        "while convolutional neural networks have gained impressive success recently in solving structured prediction problems such as semantic segmentation , it remains a challenge to differentiate individual object instances in the scene .",
        "techniques that combine large graphical models with low - level vision have been proposed to address this problem ; however , we propose an end - to - end recurrent neural network ( rnn ) architecture with an attention mechanism to model a human - like counting process , and produce detailed instance segmentations .",
        "this paper proposes cf - nade , a neural autoregressive architecture for collaborative filtering ( cf ) tasks , which is inspired by the restricted boltzmann machine ( rbm ) based cf model and the neural autoregressive distribution estimator ( nade ) .",
        "in this paper , we present a convolutional neural network framework for predominant instrument recognition in real - world polyphonic music .",
        "in addition , we conducted extensive experiments on several important factors that affect the performance , including analysis window size , identification threshold , and activation functions for neural networks to find the optimal set of parameters .",
        "using a dataset of 10k audio excerpts from 11 instruments for evaluation , we found that convolutional neural networks are more robust than conventional methods that exploit spectral features and source separation with support vector machines .",
        "road pixels are identified by training a multi - scale convolutional neural network on a large number of full - scene - labeled night - time road images including adverse weather conditions .",
        "in this paper we focus on evaluating and improving the correctness of attention in neural image captioning models .",
        "we propose a practical implementation , using variational inference in bayesian neural networks which efficiently handles continuous state and action spaces .",
        "non - linear extensions based on kernels and ( deep ) neural networks are derived , achieving better performance than the linear ones .",
        "while for some specific benchmarks , neural techniques seem to match if not outperform human judgement , challenges are still open for detecting arbitrary concepts in arbitrary videos .",
        "in this paper , we propose a system that combines neural techniques , a large scale visual concepts ontology , and an active learning loop , to provide on the fly model learning of arbitrary concepts .",
        "in addition , our model reasons about the question and consequently the image via the co - attention mechanism in a hierarchical fashion via a novel 1 - dimensional convolution neural networks ( cnn ) model .",
        "in this paper , we address these limitations by using two different yet complementary neural network models , namely a neural network global lexicon model and a neural network joint model .",
        "these neural networks can generalize better by using continuous space representation of words and learn non - linear mappings .",
        "we present a content - based automatic music tagging algorithm using fully convolutional neural networks ( fcns ) .",
        "our system does not rely on handwritten rules or engineered features ; instead , we train deep neural networks on a large conversational dataset .",
        "currently two major paradigms for language modeling exist : count - based n - gram models , which have advantages of scalability and test - time speed , and neural lms , which often achieve superior modeling performance .",
        "this formulation allows us to create novel hybrid models that combine the desirable features of count - based and neural lms , and experiments demonstrate the advantages of these approaches .",
        "in recent year , parallel implementations have been used to speed up the training of deep neural networks ( dnn ) .",
        "we propose a new way of modeling this task with neural encoder - decoder models .",
        "generative neural samplers are probabilistic models that implement sampling using feedforward neural networks : they take a random input vector and produce a sample from a probability distribution defined by the network weights .",
        "the generative - adversarial training method allows to train such models through the use of an auxiliary discriminative neural network .",
        "we show that any f - divergence can be used for training generative neural samplers .",
        "we introduce the multiresolution recurrent neural network , which extends the sequence - to - sequence framework to model natural language generation as two parallel discrete stochastic processes : a sequence of high - level coarse tokens , and a sequence of natural language tokens .",
        "such procedure allows training the multiresolution recurrent neural network by maximizing the exact joint log - likelihood over both sequences .",
        "we tested 14 very different classification algorithms ( random forest , gradient boosting machines , svm - linear , polynomial , and rbf - 1 - hidden - layer neural nets , extreme learning machines , k - nearest neighbors and a bagging of knn , naive bayes , learning vector quantization , elastic net logistic regression , sparse linear discriminant analysis , and a boosting of linear classifiers ) on 115 real life binary datasets .",
        "meantime , as the neural network - based ( nn - based ) methods develop , nn - based kb - qa has already achieved impressive results .",
        "hence , we present a neural attention - based model to represent the questions dynamically according to the different focuses of various candidate answer aspects .",
        "we extend the synthetic data approach to natural language by developing a neural generative model for such data .",
        "we propose a simple duality between this dense associative memory and neural networks commonly used in deep learning .",
        "on the deep learning side of the duality , this family corresponds to feedforward neural networks with one hidden layer and various activation functions , which transmit the activities of the visible neurons to the hidden layer .",
        "the proposed duality makes it possible to apply energy - based intuition from associative memory to analyze computational properties of neural networks with unusual activation functions - the higher rectified polynomials which until now have not been used for training neural networks .",
        "convolutional neural networks ( cnns ) have become the state - of - the - art in supervised learning vision tasks .",
        "in this paper , to mimic the human sentence composition process using a neural network approach , we propose to incorporate different categories of linguistic features into distributed representation of words in order to learn simultaneously the writing style representations based on unlabeled texts for authorship analysis .",
        "the main component of the model is a recurrent neural network ( an lstm ) , which maps from raw dialog history directly to a distribution over system actions .",
        "our model which we call dense ( as shorthand for dependency neural selection ) employs bidirectional recurrent neural networks for the head selection task .",
        "in this paper we propose a neural conversation model for conducting dialogues .",
        "experimental results indicate that the model outperforms previously proposed neural conversation architectures , and that using specificity in the objective function significantly improves performances for both generation and retrieval .",
        "we present a neural network based coreference system that produces high - dimensional vector representations for pairs of coreference clusters .",
        "in this work , we investigate several neural network architectures for fine - grained entity type classification .",
        "particularly , we consider extensions to a recently proposed attentive neural architecture and make three key contributions .",
        "previous work on attentive neural architectures do not consider hand - crafted features , we combine learnt and hand - crafted features and observe that they complement each other .",
        "in this paper , we show that by feeding the weights of a deep neural network ( dnn ) during training into a deep q - network ( dqn ) as its states , this dqn can learn policies to accelerate the training of that dnn .",
        "recent neural models of dialogue generation offer great promise for generating responses for conversational agents , but tend to be shortsighted , predicting utterances one at a time while ignoring their influence on future outcomes .",
        "this work marks a first step towards learning a neural conversational model based on the long - term success of dialogues .",
        "we introduce a new attention mechanism which uses multiplicative interactions between the query embedding and intermediate states of a recurrent neural network reader .",
        "in recent years deep neural networks have achieved great success in sentiment classification for english , thanks in part to the availability of copious annotated resources .",
        "we introduce a recurrent neural network language model ( rnn - lm ) with long short - term memory ( lstm ) units that utilizes both character - level and word - level inputs .",
        "in order to capture some of these advantages in machine perception , we ask two questions : whether deep neural networks can learn universal image representations , useful not only for a single task but for all of them , and how the solutions to the different tasks can be integrated in this framework .",
        "the dominant approach for many nlp tasks are recurrent neural networks , in particular lstms , and convolutional neural networks .",
        "in this paper , we propose phrasenet , a neural machine translator with a phrase memory which stores phrase pairs in symbolic form , mined from corpus or specified by human experts .",
        "the phrasenet not only approaches one step towards incorporating external knowledge into neural machine translation , but also makes an effort to extend the word - by - word generation mechanism of recurrent neural network .",
        "45 bleu improvement over the generic neural machine translator .",
        "we propose a simple neural architecture for natural language inference .",
        "we firstly design policy - based brokers and identify then a learning broker based on artificial neural networks .",
        "recent results show that deep neural networks achieve excellent performance even when , during training , weights are quantized and projected to a binary representation .",
        "previous neural models require parses , surface features , or a small label set to work well .",
        "here , we propose neural network models that are based on feedforward and long - short term memory architecture without any surface features .",
        "our models present the first neural chinese discourse parser in the style of chinese discourse treebank , showing that our results hold cross - linguistically .",
        "we propose cfo , a conditional focused neural - network - based approach to answering factoid questions with knowledge bases .",
        "powered by deep recurrent neural networks and neural embeddings , our proposed cfo achieves an accuracy of 75 .",
        "we propose to enhance the rnn decoder in a neural machine translator ( nmt ) with external memory , as a natural but powerful extension to the state in the decoding rnn .",
        "neural machine translation ( nmt ) often makes mistakes in translating low - frequency content words that are essential to understanding the meaning of the sentence .",
        "we investigate the potential of attention - based neural machine translation in simultaneous translation .",
        "we introduce a novel decoding algorithm , called simultaneous greedy decoding , that allows an existing neural machine translation model to begin translating before a full source sentence is received .",
        "this paper presents a first step toward building a full simultaneous translation system based on neural machine translation .",
        "we introduce a novel playlist generation algorithm that focuses on the quality of transitions using a recurrent neural network ( rnn ) .",
        "we propose a novel neural attention architecture to tackle machine comprehension tasks , such as answering cloze - style queries with respect to a document .",
        "the epireader is an end - to - end neural model comprising two components : the first component proposes a small set of candidate answers after comparing a question to its supporting text , and the second component formulates hypotheses using the proposed candidates and the question , then reranks the hypotheses based on their estimated concordance with the supporting text .",
        "we present experiments demonstrating that the epireader sets a new state - of - the - art on the cnn and children ' s book test machine comprehension benchmarks , outperforming previous neural models by a significant margin .",
        "despite the success of convolutional neural networks , selecting the optimal architecture for a given task remains an open problem .",
        "in this paper we study different types of recurrent neural networks ( rnn ) for sequence labeling tasks .",
        "disco nets allow us to efficiently sample from a posterior distribution parametrised by a neural network .",
        "we empirically show that ( i ) by modeling uncertainty on the output value , disco nets outperform equivalent non - probabilistic predictive networks and ( ii ) disco nets accurately model the uncertainty of the output , outperforming existing probabilistic models based on deep neural networks .",
        "neural machine translation has become a major alternative to widely used phrase - based statistical machine translation .",
        "we notice however that much of research on neural machine translation has focused on european languages despite its language agnostic nature .",
        "in this paper , we apply neural machine translation to the task of arabic translation ( ar & lt ; - & gt ; en ) and compare it against a standard phrase - based translation system .",
        "we run extensive comparison using various configurations in preprocessing arabic script and show that the phrase - based and neural translation systems perform comparably to each other and that proper preprocessing of arabic script has a similar effect on both of the systems .",
        "we however observe that the neural machine translation significantly outperform the phrase - based system on an out - of - domain test set , making it attractive for real - world deployment .",
        "a unified neural network framework is proposed to enable the system to first learn by supervision from a set of dialogue data and then continuously improve its behaviour via reinforcement learning , all using gradient - based algorithms on one single model .",
        "we propose an attention - based neural network model that is able to absorb information from multiple text units to construct informative , concise , and fluent summaries .",
        "( 2015 ) seek to solve this problem by creating over a million training examples by pairing cnn and daily mail news articles with their summarized bullet points , and show that a neural network can then be trained to give good performance on this task .",
        "we participated in the wmt 2016 shared news translation task by building neural translation systems for four language pairs , each trained in both directions : english & lt ; - & gt ; czech , english & lt ; - & gt ; german , english & lt ; - & gt ; romanian and english & lt ; - & gt ; russian .",
        "neural machine translation has recently achieved impressive results , while using little in the way of external linguistic information .",
        "in this paper we show that the strong learning capability of neural mt models does not make linguistic features redundant ; they can be easily incorporated to provide further improvements in performance .",
        "we add morphological features , part - of - speech tags , and syntactic dependency labels as input features to english & lt ; - & gt ; german neural machine translation systems .",
        "seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local , next - word distributions .",
        "recurrent neural networks such as the gru and lstm found wide adoption in natural language processing and achieve state - of - the - art results for many tasks .",
        "various systems using word overlap , neural embeddings and neural compositional models are evaluated on two datasets of learner writing .",
        "convolutional neural networks ( cnns ) with convolutional and pooling operations along the frequency axis have been proposed to attain invariance to frequency shifts of features .",
        "our design features several innovations including : a robust and smartphone - orientation - independent walking cycle extraction block , a novel feature extractor based on convolutional neural networks , a one - class support vector machine to classify walking cycles , and the coherent integration of these into a multi - stage authentication system .",
        "to the best of our knowledge , our system is the first exploiting convolutional neural networks as universal feature extractors for gait recognition , and using classification results from subsequent walking cycles into a multi - stage decision making framework .",
        "in this work we study various model architectures and different ways to represent and aggregate the source information in an end - to - end neural dialogue system framework .",
        "in fact selection , we match the subject entity in fact with the entity mention in question by a character - level convolutional neural network ( char - cnn ) , and match the predicate in fact with the question by a word - level cnn ( word - cnn ) .",
        "we propose a novel approach to reduce memory consumption of the backpropagation through time ( bptt ) algorithm when training recurrent neural networks ( rnns ) .",
        "modeling crisp logical regularities is crucial in semantic parsing , making it difficult for neural models with no task - specific prior knowledge to achieve good results .",
        "we present a new approach to natural language generation using recurrent neural networks in an encoder - decoder framework .",
        "here we compare the performances of four systems on datasets covering 16 languages , two of these systems being feature - based ( memms and crfs ) and two of them being neural - based ( bi - lstms ) .",
        "for morphologically rich languages ) , whereas neural - based results are higher on datasets with less lexical variability ( e .",
        "this shows that , under certain conditions , feature - based approaches enriched with morphosyntactic lexicons are competitive with respect to neural methods .",
        "we propose a novel neural belief tracking ( nbt ) framework which aims to overcome these problems by building on recent advances in semantic representation learning .",
        "we employed a recurrent neural network initialized with features learned via distant supervision on two large unlabeled datasets .",
        "we present an effective approach to generating color descriptions using recurrent neural networks and a fourier - transformed color representation .",
        "recent advances in building end - to - end neural architectures have been highly successful in solving such tasks .",
        "we derive am - rnns , a recurrent associative memory ( am ) which augments generic recurrent neural networks ( rnn ) .",
        "in this paper , we propose a framework for training multiple neural networks simultaneously .",
        "the parameters from all models are regularised by the tensor trace norm , so that one neural network is encouraged to reuse others ' parameters if possible - - this is the main motivation behind multi - task learning .",
        "in this work , we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories .",
        "in this paper , we propose a novel finetuning algorithm for the recently introduced multi - way , mulitlingual neural machine translate that enables zero - resource machine translation .",
        "when used together with novel many - to - one translation strategies , we empirically show that this finetuning algorithm allows the multi - way , multilingual model to translate a zero - resource language pair ( 1 ) as well as a single - pair neural translation model trained with up to 1m direct parallel sentences of the same language pair and ( 2 ) better than pivot - based translation strategy , while keeping only one additional copy of attention - related parameters .",
        "deep neural networks have dramatically advanced the state of the art for many areas of machine learning .",
        "neural machine translation ( nmt ) aims at solving machine translation ( mt ) problems with purely neural networks and exhibits promising results in recent years .",
        "we propose a new active learning ( al ) method for text classification based on convolutional neural networks ( cnns ) .",
        "neural models capitalize on word embeddings as features , tuning these to the task at hand .",
        "we argue that al strategies for neural text classification should focus on selecting instances that most affect the embedding space ( i .",
        "in contrast to most modern neural systems of translation , which discard the identity for rare words , in this paper we propose several architectures for learning word representations from character and morpheme level word decompositions .",
        "large - scale supervised classification algorithms , especially those based on deep convolutional neural networks ( dcnns ) , require vast amounts of training data to achieve state - of - the - art performance .",
        "in an attempt to make our results more interpretable , and inspired by recent advances in visualizing neural networks , we introduce a novel method for identifying the regions of the text that the model has found more discriminative .",
        "in this paper , we propose a novel neural framework which thoroughly eliminates context windows and can utilize complete segmentation history .",
        "our model employs a gated combination neural network over characters to produce distributed representations of word candidates , which are then given to a long short - term memory ( lstm ) language scoring model .",
        "when evaluating the performances of several different neural network architectures in a parallel computing environment .",
        "we show how real logic can be implemented in deep tensor neural networks with the use of google ' s tensorflow primitives .",
        "deep neural networks have recently been shown to lack robustness against adversarially crafted inputs .",
        "these inputs are derived from regular inputs by minor yet carefully selected perturbations that deceive the neural network into desired misclassifications .",
        "we study the effectiveness of neural sequence models for premise selection in automated theorem proving , one of the main bottlenecks in the formalization of mathematics .",
        "we demonstrate this on a number of tasks , including simple convex problems , training neural networks , and styling images with neural art .",
        "given a specification of a convolutional neural network , we study how to minimize the time to train this model on a cluster of commodity cpus and gpus .",
        "we use long short - term memories ( lstm ) to induce distributed representations of each argument , and then combine these representations with surface features in a neural network .",
        "the architecture of the neural network is determined by bayesian hyperparameter search .",
        "deep neural networks ( dnn ) have shown promise in a wide range of machine learning tasks , but for behavioral signal processing ( bsp ) tasks their application has been constrained due to limited quantity of data .",
        "in this work we study variance in the results of neural network training on a wide variety of configurations in automatic speech recognition .",
        "we present query - regression network ( qrn ) , a variant of recurrent neural network ( rnn ) that is suitable for end - to - end machine comprehension .",
        "while end - to - end neural machine translation ( nmt ) has made remarkable progress recently , nmt systems only rely on parallel corpora for parameter estimation .",
        "specifically , we first devise a joint visual modelling approach to encode video data by combining a forward lstm pass , a backward lstm pass , together with visual features from convolutional neural networks ( cnns ) .",
        "we present the siamese continuous bag of words ( siamese cbow ) model , a neural network for efficient estimation of high - quality sentence embeddings .",
        "the underlying neural network learns word embeddings by predicting , from a sentence representation , its surrounding sentences .",
        "we present a novel deep recurrent neural network architecture that learns to build implicit plans in an end - to - end manner by purely interacting with an environment in reinforcement learning setting .",
        "deep neural networks ( dnn ) have been successful in en - hancing noisy speech signals .",
        "in the proposed unified hybrid architecture , features from a convolution neural network ( cnn ) that processes the visual cues and features from a fully connected dnn that processes the audio signal are integrated using a bidirectional long short - term memory ( bilstm ) network .",
        "in this work we explore this idea in the context of neural encoder decoder architectures , albeit on a smaller scale and without mt as the end goal .",
        "to address this issue , we explore new and powerful generative models for three popular deep visualization tasks using untrained , random weight convolutional neural networks .",
        "to our knowledge this is the first demonstration of image representations using untrained deep neural networks .",
        "our goal is to be able to build a generative model from a deep neural network architecture to try to create music that has both harmony and melody and is passable as music composed by humans .",
        "in particular , there has been a lot of work based off of recurrent neural networks combined with restricted boltzmann machines ( rnn - rbm ) and other similar recurrent energy based models .",
        "our approach , however , is to perform end - to - end learning and generation with deep neural nets alone .",
        "motivated by the complementary nature of syntactical machine translation and neural machine translation ( nmt ) , we exploit the synergies of hiero and nmt in different combination schemes .",
        "starting out with a simple neural lattice rescoring approach , we show that the hiero lattices are often too narrow for nmt ensembles .",
        "experimental results show that the proposed method which is based on semi - supervised training of a deep neural network largely outperforms phoneme based continuous speech recognition on the timit dataset .",
        "while this does not seem like a challenging task , many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35 % - 65 % on benchmark sets .",
        "based on this assumption of the structure , our simple yet effective approach trains two recurrent neural networks to outperform state of the art by significant margins - - - relative improvement reaches 16 % for webquestions , and surpasses 38 % for simplequestions .",
        "infinite - - layer networks ( iln ) have recently been proposed as an architecture that mimics neural networks while enjoying some of the advantages of kernel methods .",
        "we study the expressivity of deep neural networks with random weights .",
        "the latter , a notion defined in this paper , is further studied using properties of hyperplane arrangements , which also help precisely characterize the effect of the neural network on the input space .",
        "these results also suggest that the remaining depth of a neural network is an important determinant of expressivity , supported by experiments on mnist and cifar - 10 .",
        "we combine riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic , deep neural networks with random weights .",
        "over the last years convolutional neural networks have achieved almost human performance in recognizing concrete classes ( i .",
        "the concept tree - symbolic neural network relation is also extended further .",
        "for each model , we investigate four implementations : a \" standard \" n - gram language model and three discriminatively trained \" neural \" language models that generate embeddings for semantic frames .",
        "we further trained a phrase - based smt system using state - of - the - art features and components such as operation sequence model , class - based language model , sparse features , neural network joint model , genre - based hierarchically - interpolated language model , unsupervised transliteration mining , phrase - table merging , and hypothesis combination .",
        "we experiment with various aggregation functions , including neural network attention models .",
        "recent progress in neural learning demonstrated that machines can do well in regularized tasks , e .",
        "in this paper , we demonstrate that a simple neural model can imitate human in some tasks of art generation .",
        "our method is based on an attention - based recurrent neural network , which accepts a set of keywords as the theme and generates poems by looking at each keyword during the generation .",
        "in conventional deep neural network based speech synthesis , the input text features are repeated for the entire duration of phoneme for mapping text and speech parameters .",
        "using recurrent neural network based auto - encoder , we show that it is indeed possible to map units of varying duration to a single vector .",
        "we then use this acoustic representation at unit - level to synthesize speech using deep neural network based statistical parametric speech synthesis technique .",
        "recently , bidirectional recurrent neural network ( brnn ) has been widely used for question answering ( qa ) tasks with promising performance .",
        "we propose a new training method for a feedforward neural network having the activation functions with the geometric contraction property .",
        "acoustic models based on long short - term memory recurrent neural networks ( lstm - rnns ) were applied to statistical parametric speech synthesis ( spss ) and showed significant improvements in naturalness and latency over those based on hidden markov models ( hmms ) .",
        "fisher information and natural gradient provided deep insights and powerful tools to artificial neural networks .",
        "this concept is important because the geometry structure is much simplified and it can be easily applied to guide the learning of neural networks .",
        "we propose dorefa - net , a method to train convolutional neural networks that have low bitwidth weights and activations using low bitwidth parameter gradients .",
        "moreover , as bit convolutions can be efficiently implemented on cpu , fpga , asic and gpu , dorefatnet opens the way to accelerate training of low bitwidth neural network on these hardware .",
        "designing and implementing efficient , provably correct parallel neural network processing is challenging .",
        "however , the diversity and large - scale data size have posed a significant challenge to construct a flexible and high - performance implementation of deep learning neural networks .",
        "compared to state - of - the - art models such as neural tensor network and holographic embeddings , our approach based on complex embeddings is arguably simpler , as it only uses the hermitian dot product , the complex counterpart of the standard dot product between real vectors .",
        "recently , neural network approaches for parsing have largely automated the combination of individual features , but still rely on ( often a larger number of ) atomic features created from human linguistic intuition , and potentially omitting important global context .",
        "however , as high - capacity supervised neural networks trained with a large amount of labels have achieved remarkable success in many computer vision tasks , the availability of large - scale labeled images reduced the significance of unsupervised learning .",
        "inspired by the recent trend toward revisiting the importance of unsupervised learning , we investigate joint supervised and unsupervised learning in a large - scale setting by augmenting existing neural networks with decoding pathways for reconstruction .",
        "we introduce a general and simple structural design called multiplicative integration ( mi ) to improve recurrent neural networks ( rnns ) .",
        "this paper investigates neural character - based morphological tagging for languages with complex morphology and large tag sets .",
        "we systematically explore a variety of neural architectures ( dnn , cnn , cnnhighway , lstm , blstm ) to obtain character - based word vectors combined with bidirectional lstms to model across - word context in an end - to - end setting .",
        "increasing the model capacity by adding depth , for example , and carefully optimizing the neural networks can lead to substantial improvements , and the differences in accuracy ( but not training time ) become much smaller or even negligible .",
        "both the accordion annealing and the pem methods are used during training of a recurrent neural network which is then evaluated on three databases .",
        "we present a comprehensive study of deep bidirectional long short - term memory ( lstm ) recurrent neural network ( rnn ) based acoustic models for automatic speech recognition ( asr ) .",
        "recently , the rapid development of word embedding and neural networks has brought new inspiration to various nlp and ir tasks .",
        "in this paper , we describe a staged hybrid model combining recurrent convolutional neural networks ( rcnn ) with highway layers .",
        "the highway network module is incorporated in the middle takes the output of the bi - directional recurrent neural network ( bi - rnn ) module in the first stage and provides the convolutional neural network ( cnn ) module in the last stage with the input .",
        "the experiment shows that our model outperforms common neural network models ( cnn , rnn , bi - rnn ) on a sentiment analysis task .",
        "word embeddings and convolutional neural networks ( cnn ) have attracted extensive attention in various classification tasks for twitter , e .",
        "in this paper , we introduce a model that employs information retrieval by utilizing convolutional deep structured semantic neural network - based features in the ranker to present human - like responses in ongoing conversation with a user .",
        "stability evaluation of a weight - update system of higher - order neural units ( honus ) with polynomial aggregation of neural inputs ( also known as classes of polynomial neural networks ) for adaptation of both feedforward and recurrent honus by a gradient descent method is introduced .",
        "assuring stability of the weight - update system ( at every single adaptation step ) naturally results in adaptation stability of the whole neural architecture that adapts to target data .",
        "as an aside , the used approach highlights the fact that the weight optimization of honu is a linear problem , so the proposed approach can be generally extended to any neural architecture that is linear in its adaptable parameters .",
        "with this in mind , we argue that embedding kbs within deep neural architectures supporting documentquery matching would give rise to fine - grained latent representations of both words and their semantic relations .",
        "in this paper , we review the main approaches of neural - based document ranking as well as those approaches for latent representation of entities and relations via kbs .",
        "we then propose some avenues to incorporate kbs in deep neural approaches for document ranking .",
        "unlike previous works that optimized mrfs using iterative algorithm , we solve mrf by proposing a convolutional neural network ( cnn ) , namely deep parsing network ( dpn ) , which enables deterministic end - to - end computation in a single forward pass .",
        "we propose text2vis , a neural network that generates a visual representation , in the visual feature space of the fc6 - fc7 layers of imagenet , from a short descriptive text .",
        "we propose a novel approach based on deep neural networks for modeling the dynamics of robot ' s interactions directly from images , by jointly estimating forward and inverse models of dynamics .",
        "recurrent neural networks , and in particular long short - term memory networks ( lstms ) , are a remarkably effective tool for sequence modeling that learn a dense black - box hidden representation of their sequential input .",
        "in this work , we present lstmvis a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics .",
        "neural sequence to sequence learning recently became a very promising paradigm in machine translation , achieving competitive results with statistical phrase - based systems .",
        "in this system description paper , we attempt to utilize several recently published methods used for neural sequential learning in order to build systems for wmt 2016 shared tasks of automatic post - editing and multimodal machine translation .",
        "deep neural networks ( dnn ) are capable of learning ideal representations of data during the training process , removing the need for independently extracting features .",
        "in the last decades , few attempts where done to handle that objective with neural networks , but recently an architecture based on autoencoders proved to be a promising approach .",
        "in this paper we propose to use a fully deep neural network ( dnn ) framework to handle the multi - label classification task in a regression way .",
        "inspired by natural language processing ( nlp ) techniques , we propose a novel neural network ( nn ) based next - song recommender , cnn - rec , in this paper .",
        "vanishing ( and exploding ) gradients effect is a common problem for recurrent neural networks with nonlinear activation functions which use backpropagation method for calculation of derivatives .",
        "deep feedforward neural networks with many hidden layers also suffer from this effect .",
        "we investigate the usage of convolutional neural networks ( cnns ) for the slot filling task in spoken language understanding .",
        "our proposed cnn architecture outperforms even the previously best ensembling recurrent neural network model and achieves state - of - the - art results with an f1 - score of 95 .",
        "here we propose a power - efficient approach for real - time inference , in which deep neural networks ( dnns ) are implemented through low - power analog circuits .",
        "we apply our evaluation methodology to the comparison of a count vector model and several neural network models and demonstrate important properties of these models .",
        "neural machine translation ( nmt ) offers a novel alternative formulation of translation that is potentially simpler than statistical approaches .",
        ", 2015 ) that have proven successful for reducing the size of neural models in other domains to the problem of nmt .",
        "in this application , we explored various recurrent neural network frameworks and show that they significantly outperformed the crf models .",
        "we describe an implementation of this framework using a combination of restricted boltzmann machines and feedforward neural networks .",
        "in the realm of neural networks , the invention of connectionist temporal classification ( ctc ) made it possible to train recurrent neural networks on unsegmented sequences with great success .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "recurrent neural networks ( rnns ) were recently proposed for the session - based recommendation task .",
        "gradient descent training techniques are remarkably successful in training analog - valued artificial neural networks ( anns ) .",
        "we propose the gaussian error linear unit ( gelu ) , a high - performing neural network activation function .",
        "the supervised learning of the discriminative convolutional neural network ( convnet ) is powered by back - propagation on the parameters .",
        "this paper discusses models for dialogue state tracking using recurrent neural networks ( rnn ) .",
        "we introduce a neural network model that , given a definite description and a set of objects represented by natural images , points to the intended object if the expression has a unique referent , or indicates a failure , if it does not .",
        "in our simulations , we train a vector - space model on either an english or a chinese corpus and then feed the resulting representations to a feed - forward neural network .",
        "the task of the neural network was to find a mapping between the word representations and the novel words .",
        "neural machine translation ( nmt ) , like many other deep learning domains , typically suffers from over - parameterization , resulting in large storage sizes .",
        "our main objective is to exploit the power of convolution neural network ( cnn ) to learn features automatically and thus reduce the dependency on manual feature engineering .",
        "our results indicate that convolution neural network can be a good model for relation exaction in clinical text without being dependent on expert ' s knowledge on defining quality features .",
        "in particular , we propose various end - to - end recurrent neural network ( rnn ) models for the tasks of disease name recognition and their classification into four pre - defined categories .",
        "we also utilize convolution neural network ( cnn ) in cascade of rnn to get character - based embedded features and employ it with word - embedded features in our model .",
        "convolutional neural networks ( cnns ) have greatly improved state - of - the - art performances in a number of fields , notably computer vision and natural language processing .",
        "we present a simple neural network for word alignment that builds source and target word window representations to compute alignment scores for sentence pairs .",
        "in this paper , we extend neural turing machine ( ntm ) into a dynamic neural turing machine ( d - ntm ) by introducing a trainable memory addressing scheme .",
        "this paper introduces a data - driven user simulator based on an encoder - decoder recurrent neural network .",
        "a catastrophic forgetting problem makes deep neural networks forget the previously learned information , when learning data collected in new environments , such as by different sensors or in different light conditions .",
        "finally , we show our less - forgetting learning method is also helpful to improve the performance of deep neural networks in terms of recognition rates .",
        "recently neural network based models have been proposed which do not require handcrafted features but still require annotated corpora .",
        "in this paper , we propose a neural network based model which allows sharing the decoder as well as word and character level parameters between two languages thereby allowing a resource fortunate language to aid a resource deprived language .",
        "however , from gaussian mixture models hmms ( gmm - hmm ) to deep neural network hmms ( dnn - hmm ) , the underlying markovian chain of state - of - the - art models did not changed much .",
        "we propose a simple domain adaptation method for neural networks in a supervised setting .",
        "recently , recurrent neural networks have been shown to be successful on a variety of nlp tasks such as caption generation ; however , the existing domain adaptation techniques are limited to ( 1 ) tune the model parameters by the target dataset after the training by the source dataset , or ( 2 ) design the network to have dual output , one for the source domain and the other for the target domain .",
        "reformulating the idea of the domain adaptation technique proposed by daume ( 2007 ) , we propose a simple domain adaptation method , which can be applied to neural networks trained with a cross - entropy loss .",
        "we first observe a potential weakness of continuous vector representations of symbols in neural machine translation .",
        "this has the consequence that the encoder and decoder recurrent networks in neural machine translation need to spend substantial amount of their capacity in disambiguating source and target words based on the context which is defined by a source sentence .",
        "the experiments on en - fr and en - de reveal that the proposed approaches of contextualization and symbolization improves the translation quality of neural machine translation systems significantly .",
        "we present a new theoretical framework for analyzing and learning artificial neural networks .",
        "we introduce the first global recursive neural parsing model with optimality guarantees during decoding .",
        "we demonstrate that charagram embeddings outperform more complex architectures based on character - level recurrent and convolutional neural networks , achieving new state - of - the - art performance on several similarity tasks .",
        "however , recurrent neural networks with such ' deep ' transition functions remain difficult to train , even when using long short - term memory networks .",
        "over the past few months , we have seen much progress that utilizing neural network approach to solve cloze - style questions .",
        "unlike the previous works , our neural network model requires less pre - defined hyper - parameters and uses an elegant architecture for modeling .",
        "guided policy search algorithms can be used to optimize complex nonlinear policies , such as deep neural networks , without directly computing policy gradients in the high - dimensional parameter space .",
        "a major challenge in the training of recurrent neural networks is the so - called vanishing or exploding gradient problem .",
        "in this paper , we present the first experiments using neural network models for the task of error detection in learner writing .",
        "we present an approach to training neural networks to generate sequences using actor - critic methods from reinforcement learning ( rl ) .",
        "in this paper , we improve the attention or alignment accuracy of neural machine translation by utilizing the alignments of training sentence pairs .",
        "our experiments on large - scale chinese - to - english task show that our model improves both translation and alignment qualities significantly over the large - vocabulary neural machine translation system , and even beats a state - of - the - art traditional syntax - based system .",
        "we propose a novel unsupervised algorithm based on sequence prediction models such as markov chains and recurrent neural network .",
        "in this work we experimented with various crf based structured learning models with recurrent neural networks .",
        "as examples , we studied neural data with real - valued observations , count data from a market basket analysis , and ratings data from a movie recommendation system .",
        "on all three applications - neural activity of zebrafish , users ' shopping behavior , and movie ratings - we found exponential family embedding models to be more effective than other types of dimension",
        "inspired by the findings from the cmabrigde uinervtisy effect , we propose a word recognition model based on a semi - character level recursive neural network ( scrnn ) .",
        "in contrast to prior work , the proposed neural model does not utilize domain - specific crafting , learning to translate directly from a parallel corpus .",
        "to fully explore the potential of neural models , we propose a methodology for collecting a large corpus of regular expression , natural language pairs .",
        "the task contains a rich variety of challenging classification and extraction sub - tasks , making it well - suited for end - to - end models such as deep neural networks ( dnns ) .",
        "high demand for computation resources severely hinders deployment of large - scale deep neural networks ( dnn ) in resource constrained devices .",
        "such groundings are easily achieved for recurrent neural language model architectures , which can be further conditioned on incomplete background knowledge bases .",
        "recent studies show that the 1 - nearest neighbor with dynamic time warping ( 1nn - dtw ) and the long short term memory ( lstm ) neural network can achieve a better performance than other machine learning algorithms .",
        "two common methods include representations based on averaging word vectors , and representations based on the hidden states of recurrent neural networks such as lstms .",
        "the ability of deep convolutional neural networks ( cnn ) to learn discriminative spectro - temporal patterns makes them well suited to environmental sound classification .",
        "this study has two primary contributions : first , we propose a deep convolutional neural network architecture for environmental sound classification .",
        "unsupervised neural networks , such as restricted boltzmann machines ( rbms ) and deep belief networks ( dbns ) , are powerful tools for feature selection and pattern recognition tasks .",
        "we demonstrate that overfitting occurs in such models just as in deep feedforward neural networks , and discuss possible regularization methods to reduce overfitting .",
        "our aims are to develop new machine learning approaches based on neural networks and graphical models , and to understand the capabilities of machine learning techniques relative to traditional alternatives , such as those based on constraint solving from the programming languages community .",
        "a recurrent neural network that has been trained to separately model the language of several documents by unknown authors is used to measure similarity between the documents .",
        "within the field of statistical machine translation ( smt ) , the neural approach ( nmt ) has recently emerged as the first technology able to challenge the long - standing dominance of phrase - based approaches ( pbmt ) .",
        "to understand in what respects nmt provides better translation quality than pbmt , we perform a detailed analysis of neural versus phrase - based smt outputs , leveraging high quality post - edits performed by professional translators on the iwslt data .",
        "for the first time , our analysis provides useful insights on what linguistic phenomena are best modeled by neural models - - such as the reordering of verbs - - while pointing out other aspects that remain to be improved .",
        "in the field of language modelling , traditional n - gram techniques and modern recurrent neural network ( rnn ) approaches have been applied to algorithmically find structure in language and predict the next word given the previous words in the sentence or paragraph as input .",
        "the different types of features are integrated in a neural network that uses a novel architecture to learn latent modes of discussion structure that perform as well as deep neural networks but are more interpretable .",
        "the optimization of deep neural networks can be more challenging than traditional convex optimization problems due to the highly non - convex nature of the loss function , e .",
        "in this paper , we attack the problem of optimization of highly non - convex neural networks by starting with a smoothed - - or \\ textit { mollified } - - objective function that gradually has a more non - convex energy landscape during the training .",
        "we show improvements on various difficult optimization tasks and establish a relationship with recent works on continuation methods for neural networks and mollifiers .",
        "in order to cope with a wide range of reverberations in real - world situations , we present novel approaches for acoustic modeling including an ensemble of deep neural networks ( dnns ) and an ensemble of jointly trained dnns .",
        "we follow the recent success of an integrated neural method for hypernymy detection ( shwartz et al .",
        "we confirm the effectiveness of our method using two benchmark tasks with neural networks as function approximation .",
        "training directed neural networks typically requires forward - propagating data through a computation graph , followed by backpropagating error signal , to produce weight updates .",
        "we realise decoupled neural interfaces .",
        "we show results for feed - forward models , where every layer is trained asynchronously , recurrent neural networks ( rnns ) where predicting one ' s future gradient extends the time over which the rnn can effectively model , and also a hierarchical rnn system with ticking at different timescales .",
        "these methods first convert the ascii text to a phonetic script , and then learn a deep neural network to synthesize speech from that .",
        "recently , a multi - level fuzzy min max neural network ( mlf ) was proposed , which improves the classification accuracy by handling an overlapped region ( area of confusion ) with the help of a tree structure .",
        "the sequence to sequence architecture is widely used in the response generation and neural machine translation to model the potential relationship between two sentences .",
        "in this paper , we propose a novel approach that models both skipping and reading , using an unsupervised architecture that combines a neural attention with autoencoding , trained on raw text using reinforcement learning .",
        "most existing works have to suffer the tradeoff between the two by either picking complex black box models such as recurrent neural networks ( rnn ) or relying on less accurate traditional models with better interpretation such as logistic regression .",
        "retain is a two - level neural attention model that can find influential past visits and significant clinical variables within those visits ( e .",
        "recurrent neural nets are widely used for predicting temporal data .",
        "in neural machine translation ( nmt ) , generation of a target word depends on both source and target contexts .",
        "we propose local binary convolution ( lbc ) , an efficient alternative to convolutional layers in standard convolutional neural networks ( cnn ) .",
        "empirically , cnns with lbc layers , called local binary convolutional neural networks ( lb",
        "we further propose an attention - based multi - hop recurrent neural network ( amrnn ) architecture for this task , achieving encouraging results in the initial tests .",
        "the generator is based on recurrent neural networks and the sequence - to - sequence approach .",
        "we benchmark the running performance of these tools with three popular types of neural networks on two cpu platforms and three gpu platforms .",
        "we show that collaborative filtering can be viewed as a sequence prediction problem , and that given this interpretation , recurrent neural networks offer very competitive approach .",
        "recurrent neural networks have recently been used for learning to describe images using natural language .",
        "recent approaches usually leverage neural networks based on structure features such as syntactic or dependency features to solve this problem .",
        "therefore , this paper proposes a bi - directional long - short - term - memory recurrent - neural - network ( bi - lstm - rnn ) model based on low - cost sequence features to address relation classification .",
        "an attention - based multi - hop recurrent neural network ( amrnn ) architecture was also proposed for this task , which considered only the sequential relationship within the speech utterances .",
        "motivated to tackle the problems causing the rd phenomenon , we propose the pomdp - rec framework , which is a neural - optimized partially observable markov decision process algorithm for recommender systems .",
        "we propose an end - to - end neural architecture for the task .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "the signer - independent setting is much more challenging , but with neural network adaptation we achieve up to 17 % letter error rates .",
        "convolutional neural networks ( cnns ) are extensively used in image and video recognition , natural language processing and other machine learning applications .",
        "in this paper a high speed neural network classifier based on extreme learning machines for multi - label classification problem is proposed and dis - cussed .",
        "there are no real - time online neural network based multi - label classifier available in the literature .",
        "we perform experiments and show that the derived bounds provide very accurate estimates when applied to various state - of - the - art deep neural networks and datasets .",
        "deep neural networks have shown striking progress and obtained state - of - the - art results in many ai research fields in the recent years .",
        "in generation , we convert a formula into natural language using a sequence - to - sequence recurrent neural network .",
        "whenever a new class ( non - native to the knowledge learnt thus far ) is encountered , the neural network structure gets remodeled automatically by facilitating new neurons and interconnections , and the parameters are calculated in such a way that it retains the knowledge learnt thus far .",
        "in this paper , a high - speed online neural network classifier based on extreme learning machines for multi - label classification is proposed .",
        "experiments on speech recognition and machine translation for neural sequence to sequence models show notable improvements over a maximum likelihood baseline by using edit distance augmented maximum likelihood .",
        "the computation and storage requirements for deep neural networks ( dnns ) are usually high .",
        "in this paper , we propose ternary neural networks ( tnns ) in order to make deep learning more resource - efficient .",
        "during training , a ternary neural network inherently prunes the smaller weights by setting them to zero .",
        "recent works using artificial neural networks based on word distributed representation greatly boost the performance of various natural language learning tasks , especially question answering .",
        "in this paper , we propose to straightforwardly model sentences by means of character sequences , and then utilize convolutional neural networks to integrate character embedding learning together with point - wise answer selection training .",
        "with the rise of big data sets , the popularity of kernel methods declined and neural networks took over again .",
        "however , such symbolic operations break the differentiability of the system and prevent end - to - end training of neural dialogue agents .",
        "we describe the class of convexified convolutional neural networks ( ccnns ) , which capture the parameter sharing of convolutional neural networks in a convex manner .",
        "for learning two - layer convolutional neural networks , we prove that the generalization error obtained by a convexified cnn converges to that of the best possible cnn .",
        "empirically , ccnns achieve performance competitive with cnns trained by backpropagation , svms , fully - connected neural networks , stacked denoising auto - encoders , and other baseline methods .",
        "attention - based encoder - decoder neural network models have recently shown promising results in machine translation and speech recognition .",
        "in this work , we propose an attention - based neural network model for joint intent detection and slot filling , both of which are critical steps for many speech understanding and dialog systems .",
        "predictive coding ( pdc ) has recently attracted attention in the neuroscience and computing community as a candidate unifying paradigm for neuronal studies and artificial neural network implementations particularly targeted at unsupervised learning systems .",
        "the mismatch negativity ( mmn ) has also recently been studied in relation to pc and found to be a useful ingredient in neural predictive coding systems .",
        "however , most neural systems still do not account for large number of synapses even though this has been shown by a few machine learning researchers as an effective and very important component of any neural system if such a system is to behave properly .",
        "our major point here is that pdc systems with the mmn effect in addition to a large number of synapses can greatly improve any neural learning system ' s performance and ability to make decisions in the machine world .",
        "in this paper , we describe a recurrent neural network ( rnn ) model that jointly performs intent detection , slot filling , and language modeling .",
        "the neural network model keeps updating the intent estimation as word in the transcribed utterance arrives and uses it as contextual features in the joint model .",
        "learning both hierarchical and temporal representation has been among the long - standing challenges of recurrent neural networks .",
        "multiscale recurrent neural networks have been considered as a promising approach to resolve this issue , yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence .",
        "in this paper , we propose a novel multiscale approach , called the hierarchical multiscale recurrent neural networks , which can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism .",
        "our approach effectively captures the multimodal semantics of queries and videos using state - of - the - art deep neural networks and creates a summary that is both semantically coherent and visually attractive .",
        "computation is classically studied in terms of automata , formal languages and algorithms ; yet , the relation between neural dynamics and symbolic representations and operations is still unclear in traditional eliminative connectionism .",
        "therefore , we suggest a unique perspective on this central issue , to which we would like to refer as to transparent connectionism , by proposing accounts of how symbolic computation can be implemented in neural substrates .",
        "finally , we present a mapping between nonlinear dynamical automata and recurrent artificial neural networks .",
        "in this work , the goal is to predict the score of food reviews on a scale of 1 to 5 with two recurrent neural networks that are carefully tuned .",
        "for a more robust and accurate approach , we propose the light weight convolutional neural networks , an end to end system , for estimating human body orientation .",
        "through theoretical analysis , we reveal an inherent connection between this model and recurrent neural networks , and thereon derive an approximated feed - forward network that couples multiple rnns along opposite directions .",
        "this formulation combines the expressive power of deep neural networks and the cyclic dependency structure of mrf in a unified model , bringing the modeling capability to a new level .",
        "in this work we introduce a convolutional neural network ( cnn ) that jointly handles low - , mid - , and high - level vision tasks in a unified architecture that is trained end - to - end .",
        "to bring learning models into this new paradigm , a novel elaboration of standard architectures called the competitive overcomplete output layer ( cool ) neural network is introduced .",
        "experiments demonstrate the effectiveness of cool by applying it to fooling , separable concept learning , one - class neural networks , and standard classification benchmarks .",
        "our approach is based on a deep neural network architecture that ingests curated article information such as tags and images , and is trained to predict sales for a large set of frequent customers .",
        "we also explain how neural networks fit into our framework , although the current implementation does not scale to provide guarantees for real - world neural networks .",
        "we use a convolutional neural network to determine sentiment and participate in all subtasks , i .",
        "we use a convolutional neural network ( cnn ) for both aspect extraction and aspect - based sentiment analysis .",
        "recently recurrent neural networks ( rnn ) obtained strong results on nlu due to their superior ability of preserving sequential information over time .",
        "we describe a novel approach to stride length estimation that uses deep convolutional neural networks to map stride - specific inertial sensor data to the resulting stride length .",
        "to overcome this , we present a method to translate the abstract information provided by wearable sensors to context - related expert features based on deep convolutional neural networks .",
        "a generic and scalable reinforcement learning scheme for artificial neural networks is presented , providing a general purpose learning machine .",
        "we present a dependency parser implemented as a single deep neural network that reads orthographic representations of words and directly generates dependencies and their labels .",
        "this paper introduces wavenet , a deep neural network for generating raw audio waveforms .",
        "we describe microsoft ' s conversational speech recognition system , in which we combine recent developments in neural - network - based acoustic and language modeling to advance the state of the art on the switchboard recognition task .",
        "inspired by machine learning ensemble techniques , the system uses a range of convolutional and recurrent neural networks .",
        "since deep neural networks are powerful models that have achieved excellent performance over many difficult tasks , in this paper , we propose to use the long short - term memory ( lstm ) encoder - decoder model for sentence level ts , which makes minimal assumptions about word sequence .",
        "to accurately capture the fine grained nonlinear coevolution of these features , we propose a recurrent coevolutionary feature embedding process model , which combines recurrent neural network ( rnn ) with a multidimensional point process model .",
        "recurrent neural network ( rnn ) based character - level language models ( clms ) are extremely useful for modeling unseen words by nature .",
        "convolutional neural networks ( cnns ) were recently shown to provide state - of - the - art results for object category viewpoint estimation .",
        "the attention mechanism is an important part of the neural machine translation ( nmt ) where it was reported to produce richer source representation compared to fixed - length encoding sequence - to - sequence models .",
        "the attention mechanisim is appealing for neural machine translation , since it is able to dynam - ically encode a source sentence by generating a alignment between a target word and source words .",
        "we introduce a convolutional recurrent neural network ( crnn ) for music tagging .",
        "crnns take advantage of convolutional neural networks ( cnns ) for local feature extraction and recurrent neural networks for temporal summarisation of the extracted features .",
        "in this paper a character - based encoder - decoder model has been proposed that consists of two recurrent neural networks .",
        "the encoder is a bidirectional recurrent neural network that encodes a sequence of symbols into a fixed - length vector representation , and the decoder generates the target sequence using an attention - based recurrent neural network .",
        "we propose an approximate strategy to efficiently train neural network based language models over very large vocabularies .",
        "many success stories involving deep neural networks are instances of supervised learning , where available labels power gradient - based learning methods .",
        "we present a new approach for neural machine translation ( nmt ) using the morphological and grammatical decomposition of the words ( factors ) in the output side of the neural network .",
        "the model employs a convolutional network for text and layout recognition in tandem with an attention - based neural machine translation system .",
        "many research works have successfully extended algorithms such as evolutionary algorithms , reinforcement agents and neural networks using \" opposition - based learning \" ( obl ) .",
        "in this paper , we introduce an approach to learn type - ii opposites from the given inputs and their outputs using the artificial neural networks ( anns ) .",
        "then we propose a select - additive learning ( sal ) procedure that improves the generalizability of trained discriminative neural networks .",
        "we make a step towards a general learning - based solution that can be adapted to specific situations and present a metric based on a convolutional neural network .",
        "deep reinforcement learning ( drl ) brings the power of deep neural networks to bear on the generic task of trial - and - error learning , and its effectiveness has been convincingly demonstrated on tasks such as atari video games and the game of go .",
        "in this paper , we propose an end - to - end reinforcement learning architecture comprising a neural back end and a symbolic front end with the potential to overcome each of these shortcomings .",
        "inspired by the recent success of deep reinforcement learning , we present neural - based models that jointly learn a policy and the behavior of opponents .",
        "we introduce a new approach to supervising neural networks by specifying constraints that should hold over the output space , rather than direct examples of input - output pairs .",
        "we are able to train a convolutional neural network to detect and track objects without any labeled examples .",
        "we instead propose to build graphs over the scene objects and over the question words , and we describe a deep neural network that exploits the structure in these representations .",
        "recently , recurrent neural networks ( rnn ) based methods have been successfully applied in several sequential modeling tasks .",
        "in this paper , we propose a novel model , named context - aware recurrent neural networks ( ca - rnn ) .",
        "this paper advances the design of ctc - based all - neural ( or end - to - end ) speech recognizers .",
        "with the availability of large annotated data , neural network models have recently advanced the field significantly .",
        "deep neural networks have achieved remarkable results across many language processing tasks , however these methods are highly sensitive to noise and adversarial attacks .",
        "empirical evaluation over a range of sentiment datasets with a convolutional neural network shows that , compared to a baseline model and the dropout method , our method achieves superior performance over noisy inputs and out - of - domain data .",
        "this paper presents an overview of political event data , including methods and ontologies , and a set of experiments to determine the applicability of deep neural networks to the extraction of political events from news text .",
        "a convolutional recurrent neural network is trained to predict depth from monocular video input , which , along with the current video image and the camera trajectory , can then be used to compute the next frame .",
        "to mimic the repeated reading strategy , we propose the neural networks with multi - level attention ( nnma ) , combining the attention mechanism and external memories to gradually fix the attention on some specific words helpful to judging the discourse relations .",
        "neural machine translation ( nmt ) becomes a new state - of - the - art and achieves promising translation results using a simple encoder - decoder neural network .",
        "this neural network is trained once on the parallel corpus and the fixed network is used to translate all the test sentences .",
        "convolutional neural networks ( cnns ) have demonstrated superior capability for extracting information from raw signals in computer vision .",
        "deep neural networks are learning models with a very high capacity and therefore prone to over - fitting .",
        "softtarget regularization proved to be an effective tool in various neural network architectures .",
        "we investigate the ' digital synaptic neural substrate ' ( dsns ) computational creativity approach further with respect to the size and quality of images that can be used to seed the process .",
        "more specifically , for each image of an entity , we construct image - based representations via a neural image encoder , and these representations with respect to multiple image instances are then integrated via an attention - based method .",
        "we introduce a method to train quantized neural networks ( qnns ) - - - neural networks with extremely low precision ( e .",
        "quantized recurrent neural networks were tested over the penn treebank dataset , and achieved comparable accuracy as their 32 - bit counterparts using only 4 - bits .",
        "given each reference sentence of an entity , we first utilize recurrent neural network with pooling or long short - term memory network to encode the semantic information of the sentence with respect to the entity .",
        "specifically , we propose using fully convolutional neural networks , which consist of lesser number of parameters than fully connected networks .",
        "this paper presents the input convex neural network architecture .",
        "these are scalar - valued ( potentially deep ) neural networks with constraints on the network parameters such that the output of the network is a convex function of ( some of ) the inputs .",
        "we show that many existing neural network architectures can be made input - convex with only minor modification , and develop specialized optimization algorithms tailored to this setting .",
        "new output neurons corresponding to new labels are added and the neural network connections and parameters are automatically restructured as if the label has been introduced from the beginning .",
        "neural network based models have achieved impressive results on various specific tasks .",
        "more specifically , we augment neural model with an external memory , which is shared by several tasks .",
        "we use dependency parsing and lstm recurrent neural network to predict a set of sound concepts for a given acoustic scene .",
        "we present the first reinforcement - learning model to self - improve its reward - modulated training implemented through a continuously improving \" intuition \" neural network .",
        "an agent was trained how to play the arcade video game pong with two reward - based alternatives , one where the paddle was placed randomly during training , and a second where the paddle was simultaneously trained on three additional neural networks such that it could develop a sense of \" certainty \" as to how probable its own predicted paddle position will be to return the ball .",
        "if the agent was less than 95 % certain to return the ball , the policy used an intuition neural network to place the paddle .",
        "through this , we found that the reinforcement learning model that uses an intuition neural network for placing the paddle during reward training quickly overtakes the simple architecture in its ability to outplay the near - perfect opponent , additionally outscoring that opponent by an increasingly wide margin after additional epochs of training .",
        "we propose a neural network approach to price eu call options that significantly outperforms some existing pricing models and comes with guarantees that its predictions are economically reasonable .",
        "to achieve this , we introduce a class of gated neural networks that automatically learn to divide - and - conquer the problem space for robust and accurate pricing .",
        "to address this issue , we build inference chains between two target entities via intermediate entities , and propose a path - based neural relation extraction model to encode the relational semantics from both direct sentences and inference chains .",
        "we developed a character - level neural network for this task .",
        "for this reason , this paper investigates the effectiveness of contemporary recurrent neural architectures - the elman and jordan networks and the bidirectional lstm with crf decoding - at performing dnr straight from the text .",
        "in this work , we compare standard phrase - based and neural systems on arabic - hebrew translation .",
        "we experiment with tokenization by external tools and sub - word modeling by character - level neural models , and show that both methods lead to improved translation performance , with a small advantage to the neural models .",
        "learning based on networks of real neurons , and by extension biologically inspired models of neural networks , has yet to find general learning rules leading to widespread applications .",
        "in this paper , we argue for the existence of a principle allowing to steer the dynamics of a biologically inspired neural network .",
        "we show that lsa has a higher explanatory power than existing hypotheses about the response of biological neural networks to external simulation , and can be used as a learning rule for an embodied application : learning of wall avoidance by a simulated robot .",
        "the surge in popularity of artificial neural networks is mostly directed to disembodied models of neurons with biologically irrelevant dynamics : to the authors ' knowledge , this is the first work demonstrating sensory - motor",
        "in this paper we examine learning methods combining the random neural network , a biologically inspired neural network and the extreme learning machine that achieve state of the art classification performance while requiring much shorter training time .",
        "the random neural network is a integrate and fire computational model of a neural network whose mathematical structure permits the efficient analysis of large ensembles of neurons .",
        "neural machine translation ( nmt ) heavily relies on word level modelling to learn semantic representations of input sentences .",
        "to handle these issues , we propose word - lattice based recurrent neural network ( rnn ) encoders for nmt , which generalize the standard rnn to word lattice topology .",
        "implementing an accurate and fast activation function with low cost is a crucial aspect to the implementation of deep neural networks ( dnns ) on fpgas .",
        "recent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies .",
        "we introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "the multi - signer setting is much more challenging , but with neural network adaptation we achieve up to 83 % letter accuracies in this setting .",
        "we propose a highly structured neural network architecture for semantic segmentation of images that combines i ) a haar wavelet - based tree - like convolutional neural network ( cnn ) , ii ) a random layer realizing a radial basis function kernel approximation , and iii ) a linear classifier .",
        "these vectors are incorporated into a neural structured prediction model , which captures structural constraints that are inherent in the entity linking task .",
        "in an extremely low - resource scenario , our model performs significantly better than both a neural model and a strong baseline .",
        "neural machine translation ( nmt ) is an end - to - end learning approach for automated translation , with the potential to overcome many of the weaknesses of conventional phrase - based translation systems .",
        "in this work , we present gnmt , google ' s neural machine translation system , which attempts to address many of these issues .",
        "this paper proposes new nonnegative ( shallow and multi - layer ) autoencoders by combining the model of spiking random neural network ( rnn ) , the network architecture in the deep - learning area and the training technique in the nonnegative matrix factorization ( nmf ) area .",
        "we introduce an online neural sequence to sequence model that learns to alternate between encoding and decoding segments of the input as it is read .",
        "our results show that neural network - based models underperform when the data is small , and that the most reliable model over data of varying sizes and frequency ranges is the inverted factorized model .",
        "with the fast development of deep learning , people have started to train very big neural networks using massive data .",
        "based on the database and another two free data resources ( thchs30 and the cmu dictionary ) , a speech recognition ( asr ) baseline was constructed with the deep neural network - hidden markov model ( dnn - hmm ) hybrid system .",
        "experimental results show that the proposed method delivers substantial performance improvement over the baseline system , especially when a deep neural network ( dnn ) is used as the decision maker , and the dnn input involves some statistical features derived from the cohort scores .",
        "the model is based on a multi - task recurrent neural network where the output of one task is fed as the input of the other , leading to a collaborative learning framework that can improve both language and speaker recognition by borrowing information from each other .",
        "in this abstract we present an investigation in learning genomic representations with neural networks to predict patient survival in cancer .",
        "in this paper we instead apply reinforcement learning to directly optimize a neural mention - ranking model for coreference evaluation metrics .",
        "we present a neural network architecture to predict a point in color space from the sequence of characters in the color ' s name .",
        "recurrent neural networks ( rnns ) have shown clear superiority in sequence modeling , particularly the ones with gated units , such as long short - term memory ( lstm ) and gated recurrent unit ( gru ) .",
        "in this work , we present the first results for neuralizing an unsupervised hidden markov model .",
        "we introduce a novel tracking system based on similarity mapping by enhanced siamese neural network ( esnn ) , which accounts for both appearance and geometric information , and is trainable end - to - end .",
        "recurrent neural networks have achieved state - of - the - art results for many problems in nlp and two most popular rnn architectures are tail model and pooling model .",
        "inspired by the recently presented deeptracking approach [ ondruska , 2016 ] , we employ a recurrent neural network ( rnn ) to capture the temporal evolution of the state of the environment , and propose to use spatial transformer modules to exploit estimates of the egomotion of the vehicle .",
        "we experiment several cross - lingual annotation projection methods using recurrent neural networks ( rnn ) models .",
        "for this , we develop a novel contextual generative adversarial network based on recurrent neural networks ( context - rnn - gans ) , where both the generator and the discriminator modules are based on contextual history ( modeled as rnns ) and the adversarial discriminator guides the generator to produce realistic images for the particular time step in the image sequence .",
        "in the proposed approach , we segment and label multiple views of a scene with a fully convolutional neural network , and then fit pre - scanned 3d object models to the resulting segmentation to get the 6d object pose .",
        "training a deep neural network for segmentation typically requires a large amount of training data .",
        "the system drastically improves learning in a range of deep neural networks on various data - sets in comparison to non - cpn neural networks .",
        "neural encoder - decoder models have shown great success in many sequence generation tasks .",
        "in this paper , we propose methods for controlling the output sequence length for neural encoder - decoder models : two decoding - based methods and two learning - based methods .",
        "we introduce a unified algorithm to efficiently learn a broad class of linear and non - linear state space models , including variants where the emission and transition distributions are modeled by deep neural networks .",
        "our learning algorithm simultaneously learns a compiled inference network and the generative model , leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution .",
        "recent work on improving the efficiency of neural translation models adopted a similar strategy by restricting the output vocabulary to a subset of likely candidates given the source .",
        "this brings the time to decode with a state of the art neural translation system to just over 140 msec per sentence on a single cpu core for english - german .",
        "more specifically , we employ the framework of the residual neural networks to model the temporal closeness , period , and trend properties of the crowd traffic , respectively .",
        "st - resnet learns to dynamically aggregate the output of the three residual neural networks based on data , assigning different weights to different branches and regions .",
        "in this work , we propose very deep convolutional neural networks ( cnns ) that directly use time - domain waveforms as inputs .",
        "we propose a neural machine translation ( nmt ) framework for simultaneous translation in which an agent learns to make decisions on when to translate from the interaction with a pre - trained nmt environment .",
        "the model and the neural architecture reflect the time , space and color structure of video tensors and encode it as a four - dimensional dependency chain .",
        "in this paper , a neural network based real - time speech recognition ( sr ) system is developed using an fpga for very low - power operation .",
        "the implemented system employs two recurrent neural networks ( rnns ) ; one is a speech - to - character rnn for acoustic modeling ( am ) and the other is for character - level language modeling ( lm ) .",
        "by applying deep recurrent neural networks we learn to discriminate between several application layer traffic types on top of a constant envelope modulation without using an expert demodulation algorithm .",
        "in this paper , we develop a chinese event extraction system that uses word embedding vectors to represent language , and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering .",
        "in this paper , we propose to use deep neural network ( dnn ) to address two types of information needs of response organizations : 1 ) identifying informative tweets and 2 ) classifying them into topical classes .",
        "in this tutorial , we build a neural - based approach to answer questions about images .",
        "in this paper we provide the largest published comparison of translation quality for phrase - based smt and neural machine translation across 30 translation directions .",
        "in the second part of the paper we investigate aspects of translation speed , introducing amunmt , our efficient neural machine translation decoder .",
        "we demonstrate that current neural machine translation could already be used for in - production systems when comparing words - per - second ratios .",
        "we study how approximation errors of neural networks with relu activation functions depend on the depth of the network .",
        "deep learning is a branch of artificial intelligence employing deep neural network architectures that has significantly advanced the state - of - the - art in computer vision , speech recognition , natural language processing and other domains .",
        "and then we investigate the advancement of multi - view representation learning that ranges from shallow methods including multi - modal topic learning , multi - view sparse coding , and multi - view latent space markov networks , to deep methods including multi - modal restricted boltzmann machines , multi - modal autoencoders , and multi - modal recurrent neural networks .",
        "sample complexity and safety are major challenges when learning policies with reinforcement learning for real - world tasks - - especially when the policies are represented using rich function approximators like deep neural networks .",
        "as another improvement , it uses deep neural networks for joint - speaker identification and gain estimation which makes these two steps easier than before producing competitive results for these steps .",
        "we introduce a neural network model that marries together ideas from two prominent strands of research on domain adaptation through representation learning : structural correspondence learning ( scl , ( blitzer et al .",
        ", 2006 ) ) and autoencoder neural networks .",
        "particularly , our model is a three - layer neural network that learns to encode the nonpivot features of an input example into a low - dimensional representation , so that the existence of pivot features ( features that are prominent in both domains and convey useful information for the nlp task ) in the example can be decoded from that representation .",
        "learning - based exploration methods , including convolutional neural networks , provide excellent strategies without human - designed logic for the feature extraction .",
        "on this study , we perform the ability of 1d convolutional neural network ( 1dcnn ) to construct classification model that can distinguish the eeg and eog stroke data from eeg and eog control data .",
        "the word denoising embeddings are obtained by strengthening salient information and weakening noise in the original word embeddings , based on a deep feed - forward neural network filter .",
        "however , implementation strategy of metaheuristic for accuracy improvement on convolution neural networks ( cnn ) , a famous deep learning method , is still rarely investigated .",
        "deep neural networks have proven to be quite effective in a wide variety of machine learning tasks , ranging from improved speech recognition systems to advancing the development of autonomous vehicles .",
        "these samples are constructed by manipulating real examples from the training data distribution in order to \" fool \" the original neural model , resulting in misclassification ( with high confidence ) of previously correctly classified samples .",
        "addressing this weakness is of utmost importance if deep neural architectures are to be applied to critical applications , such as those in the domain of cybersecurity .",
        "in this paper , we present an analysis of this fundamental flaw lurking in all neural architectures to uncover limitations of previously proposed defense mechanisms .",
        "more importantly , we present a unifying framework for protecting deep neural models using a non - invertible data transformation - - developing two adversary - resilient architectures utilizing both linear and nonlinear dimensionality reduction .",
        ", hidden - state crf ( hcrf ) and latent - dynamic crf ( ldcrf ) ; and conditional neural fields ( cnf ) and its variant ( ldcnf ) .",
        "using state of the art convolutional neural networks , we provide impressive baseline performances at scene classification .",
        "garnett , editors , advances in neural information processing systems 28 , pages 2116 - - 2124 .",
        "parallel implementations of stochastic gradient descent ( sgd ) have received significant research attention , thanks to excellent scalability properties of this algorithm , and to its efficiency in the context of training deep neural networks .",
        "in this paper , we present a simple and efficient method for training deep neural networks in a semi - supervised setting where only a small portion of training data is labeled .",
        "in this paper , we proposed the adaptive convolutional elm method ( acnnelm ) as enhancement of convolutional neural network ( cnn ) with a hybrid extreme learning machine ( elm ) model plus adaptive capability .",
        "we propose a technique for making convolutional neural network ( cnn ) - based models more transparent by visualizing the regions of input that are \" important \" for predictions from these models - or visual explanations .",
        "neural sequence models are widely used to model time - series data in many fields .",
        "we describe recurrent neural networks ( rnns ) , which have attracted great attention on sequential tasks , such as handwriting recognition , speech recognition and image to text .",
        "however , compared to general feedforward neural networks , rnns have feedback loops , which makes it a little hard to understand the backpropagation step .",
        "we present an interpretable neural network approach to predicting and understanding politeness in natural language requests .",
        "our models are based on simple convolutional neural networks directly on raw text , avoiding any manual identification of complex sentiment or syntactic features , while performing better than such feature - based models from previous work .",
        "further , this analysis reveals multiple novel , high - scoring politeness strategies which , when added back as new features , reduce the accuracy gap between the original featurized system and the neural model , thus providing a clear quantitative interpretation of the success of these neural networks .",
        "for this purpose , we explore the vgg - 16 and k - cnn convolutional neural networks to extract visual features from the image .",
        "we describe an attentive encoder that combines tree - structured recursive neural networks and sequential recurrent neural networks for modelling sentence pairs .",
        "we introduce a neural machine translation ( nmt ) model that maps a source character sequence to a target character sequence without any segmentation .",
        "in this paper , we propose a novel neural approach for paraphrase generation .",
        "towards this goal , we leverage the power of recurrent neural networks and multimodal information present in the interaction , and propose a predictive model to recognize social norm violation .",
        "we then \" translate \" this information into a natural language instruction using a neural sequence - to - sequence model that learns to generate free - form instructions from natural language corpora .",
        "long short - term memory ( lstm ) recurrent neural networks ( rnns ) have been shown to give state - of - the - art performance on many speech recognition tasks , as they are able to provide the learned dynamically changing contextual window of all sequence history .",
        "on the other hand , the convolutional neural networks ( cnns ) have brought significant improvements to deep feed - forward neural networks ( ffnns ) , as they are able to better reduce spectral variation in the input signal .",
        "in this paper , a network architecture called as convolutional recurrent neural network ( crnn ) is proposed by combining the cnn and lstm rnn .",
        "recently , attempts have been made to remove gaussian mixture models ( gmm ) from the training process of deep neural network - based hidden markov models ( hmm / dnn ) .",
        "we present a model of visually - grounded language learning based on stacked gated recurrent neural networks which learns to predict visual features given an image description in the form of a sequence of phonemes .",
        "we present deep variational canonical correlation analysis ( vcca ) , a deep multi - view learning model that extends the latent variable model interpretation of linear cca ~ \\ citep { bachjordan05a } to nonlinear observation models parameterized by deep neural networks ( dnns ) .",
        "our approach uses a novel convolutional neural network ( cnn ) architecture , that only needs volume - level labels to be trained to automatically asses whether an oct volume is healthy or contains amd .",
        "in this work we implement a training of a language model ( lm ) , using recurrent neural network ( rnn ) and glove word embeddings , introduced by pennigton et al .",
        "we develop several strong baselines , relying on logistic regression and state - of - the - art recurrent neural networks .",
        "we propose a neural - network based model for coordination boundary prediction .",
        "neural networks are among the state - of - the - art techniques for language modeling .",
        "existing neural language models typically map discrete words to distributed , dense vector representations .",
        "in this paper , we propose to compress neural language models by sparse word representations .",
        "the proposed architecture uses a convolutional neural network for the sentence representation and a long - short term memory network for the context representation .",
        "recently there has been much interest in understanding why deep neural networks are preferred to shallow networks .",
        "first , we consider univariate functions on a bounded interval and require a neural network to achieve an approximation error of $ \\ varepsilon $ uniformly over the interval .",
        "our results are derived for neural networks which use a combination of rectifier linear units ( relus ) and binary step units",
        "we propose low - rank bilinear neural networks using hadamard product ( element - wise multiplication ) , commonly implemented in many scientific computing frameworks .",
        "a feed - forward neural network based methodology is adopted in this paper .",
        "the multi - layer perceptron ( mlp ) neural network model was trained using matlab .",
        "2953 m has been achieved with a 12 - 12 - 2 neural network structure .",
        "to recover the ` clustering - friendly ' latent representations and to better cluster the data , we propose a joint dr and k - means clustering approach in which dr is accomplished via learning a deep neural network ( dnn ) .",
        "the motivation is to keep the advantages of jointly optimizing the two tasks , while exploiting the deep neural network ' s ability to approximate any nonlinear function .",
        "in this paper , we propose a novel approach for word level quality estimation using recurrent neural network language model ( rnn - lm ) architecture .",
        "recently , neural networks have achieved great success on sentiment classification due to their ability to alleviate feature engineering .",
        "to address this problem , we present a cached long short - term memory neural networks ( clstm ) to capture the overall semantic information in long texts .",
        "conventional attention - based neural machine translation ( nmt ) conducts dynamic alignment in generating the target sentence .",
        "and neural machine translator with our interactive attention can outperform the open source attention - based nmt system groundhog by 4 .",
        "neural machine translation ( nmt ) is a new approach to machine translation that has made great progress in recent years .",
        "recently , the development of neural machine translation ( nmt ) has significantly improved the translation quality of automatic machine translation .",
        "the key to our system ' s performance is the systematic use of convolutional and lstm neural networks , combined with a novel spatial smoothing method and lattice - free mmi acoustic training .",
        "the proposed methods are evaluated on the application of training a deep neural network to perform image classification .",
        "since the first online demonstration of neural machine translation ( nmt ) by lisa , nmt development has recently moved from laboratory to production systems as demonstrated by several entities announcing roll - out of nmt engines to replace their existing technologies .",
        "conventional deep neural networks ( dnn ) for speech acoustic modeling rely on gaussian mixture models ( gmm ) and hidden markov model ( hmm ) to obtain binary class labels as the targets for dnn training .",
        "morden state - of - the - art speech recognition systems usually employ neural networks for acoustic modeling .",
        "however , compared to the conventional gaussian mixture models , deep neural network ( dnn ) based acoustic models usually have much larger number of model parameters , making it challenging for their applications in resource constrained platforms such as mobile devices .",
        "in this paper , we study the application of the recently proposed highway deep neural network ( hdnn ) for training small - footprint acoustic models .",
        "hdnn is a type of depth - gated feedforward neural network , which introduces two type of gate functions to facilitate the information flow through different layers .",
        "until recently , research on artificial neural networks was largely restricted to systems with only two types of variable : neural activities that represent the current or recent input and weights that learn to capture regularities among inputs , outputs and payoffs .",
        "synapses have dynamics at many different time - scales and this suggests that artificial neural networks might benefit from variables that change slower than activities but much faster than the standard weights .",
        "these \" fast weights \" can be used to store temporary memories of the recent past and they provide a neurally plausible way of implementing the type of attention to the past that has recently proved very helpful in sequence - to - sequence models .",
        "by using fast weights we can avoid the need to store copies of neural activity patterns .",
        "this paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into convolutional neural networks .",
        "in this paper , we investigate how grounded and conditional extensions to standard neural language models can bring improvements in the tasks of word prediction and completion .",
        "though this is not normally a problem for a neural network designed for a specific task , such a bound is undesirable for a system that continually learns over an open range of domains .",
        "an enfn distinctive feature is its computational simplicity compared to other artificial neural networks and neuro - fuzzy systems .",
        "a new architecture and learning algorithms for the multidimensional hybrid cascade neural network with neuron pool optimization in each cascade are proposed in this paper .",
        "the developed system combines reinforcement learning with a neural network for learning to predict the possible outcomes of its actions .",
        "this year , the nara institute of science and technology ( naist ) / carnegie mellon university ( cmu ) submission to the japanese - english translation track of the 2016 workshop on asian translation was based on attentional neural machine translation ( nmt ) models .",
        "most existing neural machine translation models use groups of characters or whole words as their unit of input and output .",
        "we parameterize our model as a convolutional neural network that predicts discrete substitutions to an existing translation based on an attention mechanism over both the source sentence as well as the current translation output .",
        "we experiment with various models including a neural generative model as well as a semantic graph matching one .",
        "experiments on synthetic data and deep neural networks validate our theory , demonstrating the effectiveness and scalability of sg - mcmc with stale gradients .",
        "we ask whether neural networks can learn to use secret keys to protect information from other neural networks .",
        "thus , a system may consist of neural networks named alice and bob , and we aim to limit what a third neural network named eve learns from eavesdropping on the communication between alice and bob .",
        "we do not prescribe specific cryptographic algorithms to these neural networks ; instead , we train end - to - end , adversarially .",
        "we demonstrate that the neural networks can learn how to perform forms of encryption and decryption , and also how to apply these operations selectively in order to meet confidentiality goals .",
        "we quantify a source of ineffectual computations when processing the multiplications of the convolutional layers in deep neural networks ( dnns ) and propose pragmatic ( pra ) , an architecture that exploits it improving performance and energy efficiency .",
        "generative approaches , typically based on recurrent neural networks ( rnns ) , can synthesize new replies , but they suffer from the problem of generating short , meaningless utterances .",
        "in our approach , the retrieved candidate , in addition to the original query , is fed to an rnn - based reply generator , so that the neural model is aware of more information .",
        "these models have broad applications in image registration , and they are a fundamental aspect of novel machine vision or deep learning algorithms , such as convolutional neural networks ( cnn ) , which perform shift and scale invariant functions followed by classification .",
        "deconvolutional networks fully exploit the advantage the powerful expressiveness of deep neural networks in the manner of unsupervised learning .",
        "neural machine translation ( nmt ) has become the new state - of - the - art in several language pairs .",
        "we propose a novel method of regularization for recurrent neural networks called suprisal - driven zoneout .",
        "we analyze the performance of encoder - decoder neural models and compare them with well - known established methods .",
        "we explore the suitability of a deep neural network architecture for this task , particularly a deep bi - lstm network applied on a character level .",
        "we propose a neural architecture that is composed of two modules trained jointly : a recurrent neural network ( rnn ) module and a structured prediction model .",
        "recently , distributed representation of sentences learned by neural models from unlabeled data has been shown to outperform the traditional bag - of - words representation .",
        "a general purpose image segmentation approach is used , including two feature learning algorithms ; multi - scale multi - layered perceptrons ( mlp ) and convolutional neural networks ( cnn ) .",
        "in the second part we implement a convolutional neural network trained on top of pre - trained word vectors .",
        "we view the lambada task as a reading comprehension problem and apply off - the - shelf comprehension models based on neural networks .",
        "we analyze 100 instances , finding that neural network readers perform well in cases that involve selecting a name from the context based on dialogue or discourse cues but struggle when coreference resolution or external knowledge is needed .",
        "distributed representation learned with neural networks has recently shown to be effective in modeling natural languages at fine granularities such as words , phrases , and even sentences .",
        "this paper aims to enhance neural network models for such a purpose .",
        "in this paper , we propose neural models to train computers not just to pay attention to specific regions and content of input documents with attention models , but also distract them to traverse between different content of a document so as to better grasp the overall meaning for summarization .",
        "in this paper , we employ knowledge - based approaches that also exploit recent advances in neural word / concept embeddings to improve over the state - of - the - art in biomedical wsd using the msh wsd dataset as the test set .",
        "several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years .",
        "attention has improved image classification , image captioning , speech recognition , generative models , and learning algorithmic tasks , but it had probably the largest impact on neural machine translation .",
        "in this work , we develop models based on a pre - trained convolutional neural network for extracting sentiment , emotion and personality features for sarcasm detection .",
        "while convolutional neural networks can categorize scenes well , they also learn an intermediate representation not aligned across modalities , which is undesirable for cross - modal transfer applications .",
        "we present methods to regularize cross - modal convolutional neural networks so that they have a shared representation that is agnostic of the modality .",
        "neural networks augmented with external memory have the ability to learn algorithmic solutions to complex tasks .",
        "as well , we show how our approach can be adapted for models that maintain temporal associations between memories , as with the recently introduced differentiable neural computer .",
        "in second part the article describes a research carried out with the data collected from quench detection system by means of using an lstm recurrent neural network .",
        "the optimization problem behind neural networks is highly non - convex .",
        "in contrast we show under quite weak assumptions on the data that a particular class of feedforward neural networks can be trained globally optimal with a linear convergence rate with our nonlinear spectral method .",
        "recurrent neural networks ( rnns ) have become the state - of - the - art choice for extracting patterns from temporal sequences .",
        "this paper demonstrates that neural sequence - to - sequence models obtain state of the art or close to state of the art results on existing datasets .",
        "a biological neural network is constituted by numerous subnetworks and modules with different functionalities .",
        "for an artificial neural network , the relationship between a network and its subnetworks is also important and useful for both theoretical and algorithmic research , i .",
        "in this paper we explore the relationship between an elm neural network and its subnetworks .",
        "to the best of our knowledge , we are the first to prove a theorem that shows an elm neural network can be scattered into subnetworks and its optimal solution can be constructed recursively by the optimal solutions of these subnetworks .",
        "based on the theorem we also present two algorithms to train a large elm neural network efficiently : one is a parallel network training algorithm and the other is an incremental network training algorithm .",
        "the learning capability of a neural network improves with increasing depth at higher computational costs .",
        "we propose feature map and kernel level pruning for reducing the computational complexity of a deep convolutional neural network .",
        "building large models with parameter sharing accounts for most of the success of deep convolutional neural networks ( cnns ) .",
        "in this paper , we propose doubly convolutional neural networks ( dcnns ) , which significantly improve the performance of cnns by further exploring this idea .",
        "in this paper we describe an end to end neural model for named entity recognition ner ) which is based on bi - directional rnn - lstm ' s .",
        "we provide a depth - based separation result for feed - forward relu neural networks , showing that a wide family of non - linear , twice - differentiable functions on $ [ 0 , 1 ] ^ d $ , which can be approximated to accuracy $ \\ epsilon $ by relu networks of depth and width $ \\ mathcal { o } ( \\ text { poly } ( \\ log ( 1 / \\ epsilon ) ) ) $ , cannot be approximated to similar accuracy by constant - depth relu networks , unless their width is at least $ \\ omega ( 1 / \\ epsilon ) $ .",
        "in this paper , we propose a novel two - stage poetry generating method which first plans the sub - topics of the poem according to the user ' s writing intent , and then generates each line of the poem sequentially , using a modified recurrent neural network encoder - decoder framework .",
        "recurrent neural networks ( rnns ) have achieved state - of - the - art performances in many natural language processing tasks , such as language modeling and machine translation .",
        "we show that the ctc word models work very well as an end - to - end all - neural speech recognition model without the use of traditional context - dependent sub - word phone units that require a pronunciation lexicon , and without any language model removing the need to decode .",
        "this paper proposes dynamic chunk reader ( dcr ) , an end - to - end neural reading comprehension ( rc ) model that is able to extract and rank a set of answer candidates from a given document to answer questions .",
        "dcr is able to predict answers of variable lengths , whereas previous neural rc models primarily focused on predicting single tokens or entities .",
        "dcr encodes a document and an input question with recurrent neural networks , and then applies a word - by - word attention mechanism to acquire question - aware representations for the document , followed by the generation of chunk representations and a ranking module to propose the top - ranked chunk as the answer .",
        "we present a novel neural network algorithm , the tensor switching ( ts ) network , which generalizes the rectified linear unit ( relu ) nonlinearity to tensor - valued hidden units .",
        "we present a neural architecture for sequence processing .",
        "the bytenet is a stack of two dilated convolutional neural networks , one to encode the source sequence and one to decode the target sequence , where the target network unfolds dynamically to generate variable length outputs .",
        "the bytenet decoder attains state - of - the - art performance on character - level language modelling and outperforms the previous best results obtained with recurrent neural networks .",
        "the bytenet also achieves a performance on raw character - level machine translation that approaches that of the best neural translation models that run in quadratic time .",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "recent neural program induction approaches have attempted to address this problem , but are typically limited to differentiable memory , and consequently cannot scale beyond small synthetic tasks .",
        "in this work , we propose the manager - programmer - computer framework , which integrates neural networks with non - differentiable memory to support abstract , scalable and precise operations through a friendly neural computer interface .",
        "specifically , we introduce a neural symbolic machine , which contains a sequence - to - sequence neural \" programmer \" , and a non - differentiable \" computer \" that is a lisp interpreter with code assist .",
        "recurrent neural networks are powerful models for processing sequential data , but they are generally plagued by vanishing and exploding gradient problems .",
        "unitary recurrent neural networks ( urnns ) , which use unitary recurrence matrices , have recently been proposed as a means to avoid these issues .",
        "we propose a convolutional recurrent neural network , with winner - take - all dropout for high dimensional unsupervised feature learning in multi - dimensional time series .",
        "our contributions can be summarized as a scalable reinterpretation of the deep predictive coding networks trained end - to - end with backpropagation through time , an extension of the previously proposed winner - take - all autoencoders to sequences in time , and a new technique for initializing and regularizing convolutional - recurrent neural networks .",
        "we propose a framework for detecting action patterns from motion sequences and modeling the sensory - motor relationship of animals , using a generative recurrent neural network .",
        "we develop a multi - level sentiment - enriched word embedding learning method , which uses parallel asymmetric neural network to model n - gram , word level sentiment and tweet level sentiment in learning process .",
        "owing to these variations , the pedestrian data is distributed as highly - curved manifolds in the feature space , despite the current convolutional neural networks ( cnn ) ' s capability of feature extraction .",
        "deep models like deep neural networks , on the other hand , cannot be directly applied for the high - dimensional input because of the huge feature space .",
        "in this paper , we propose a product - based neural networks ( pnn ) with an embedding layer to learn a distributed representation of the categorical data , a product layer to capture interactive patterns between inter - field categories , and further fully connected layers to explore high - order feature interactions .",
        "while neural machine translation ( nmt ) is making good progress in the past two years , tens of millions of bilingual sentence pairs are needed for its training .",
        "this paper proposes a novel distributed vector representation of a document : a simple recurrent - neural - network language model ( rnn - lm ) or a long short - term memory rnn language model ( lstm - lm ) is first created from all documents in a task ; some of the lm parameters are then adapted by each document , and the adapted parameters are vectorized to represent the document .",
        "we introduce a powerful recurrent neural network based method for novelty detection to the application of detecting radio anomalies .",
        "specifically , we apply additive base kernels to subsets of output features from deep neural architectures , and jointly learn the parameters of the base kernels and deep network through a gaussian process marginal likelihood objective .",
        "neural networks ( nn ) have achieved state - of - the - art performance in various applications .",
        "one effective way to alleviate this problem is to exploit the bayesian approach by using bayesian neural networks ( bnn ) .",
        "to address these problems , we propose a class of probabilistic neural networks , dubbed natural - parameter networks ( npn ) , as a novel and lightweight bayesian treatment of nn .",
        "we propose novel methods of solving two tasks using convolutional neural networks , firstly the task of generating hdr map of a static scene using differently exposed ldr images of the scene captured using conventional cameras and secondly the task of finding an optimal tone mapping operator that would give a better score on the tmqi metric compared to the existing methods .",
        "we describe a framework for extracting common - sense knowledge for corpora , which is then used to construct a dataset for this ordinal entailment task , which we then use to train and evaluate a sequence to sequence neural network model .",
        "despite their advantages in terms of computational resources , latency , and power consumption , event - based implementations of neural networks have not been able to achieve the same performance figures as their equivalent state - of - the - art deep network models .",
        "the neural gpu is a recent model that can learn algorithms such as multi - digit binary addition and binary multiplication in a way that generalizes to inputs of arbitrary length .",
        "we show that there are two simple ways of improving the performance of the neural gpu : by carefully designing a curriculum , and by increasing model size .",
        "the latter requires careful memory management , as a naive implementation of the neural gpu is memory intensive .",
        "we find that these techniques to increase the set of algorithmic problems that can be solved by the neural gpu : we have been able to learn to perform all the arithmetic operations ( and generalize to arbitrarily long numbers ) when the arguments are given in the decimal representation ( which , surprisingly , has not been possible before ) .",
        "we have also been able to train the neural gpu to evaluate long arithmetic expressions with multiple operands that require respecting the precedence order of the operands , although these have succeeded only in their binary representation , and not with 100 \\ % accuracy .",
        "afterwards , a simple feedforward neural network is used to reject or predict entity label for each individual fragment .",
        "here , we are attempting to bridge this gap by mining the collective knowledge contained in recent deep learning research to discover underlying principles for designing neural network architectures .",
        "many models such as svm , random forest , and deep neural nets have been proposed and achieved great success .",
        "experimental results show that the neural network - based parsers perform significantly better than the traditional parsers .",
        "inspired by this work we present binary paragraph vectors , simple neural networks that learn short binary codes for fast information retrieval .",
        "the discrete traffic state encoding is used as input to a deep convolutional neural network , trained using q - learning with experience replay .",
        "our agent was compared against a one hidden layer neural network traffic signal control agent and reduces average cumulative delay by 82 % , average queue length by 66 % and average travel time by 20 % .",
        "latent representation learned from multi - layered neural networks via hierarchical feature abstraction enables recent success of deep learning .",
        "we designed a neural network model based on the assumption that good base representation can be attained by maximizing the total correlation between the input , latent , and output variables .",
        "the success of long short - term memory ( lstm ) neural networks in language processing is typically attributed to their ability to capture long - distance statistical regularities .",
        "recent work on program induction has proposed neural architectures , based on abstractions like stacks , turing machines , and interpreters , that operate on abstract computational machines or on execution traces .",
        "combining abstract , symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning .",
        "as a step in this direction , we propose a new architecture , called neural equivalence networks , for the problem of learning continuous semantic representations of mathematical and logical expressions .",
        "the challenge is that semantic representations must be computed in a syntax - directed manner , because semantics is compositional , but at the same time , small changes in syntax can lead to very large changes in semantics , which can be difficult for continuous neural architectures .",
        "recently deep neural networks have received considerable attention due to their ability to extract and represent high - level abstractions in data sets .",
        "deep neural networks such as fully - connected and convolutional neural networks have shown excellent performance on a wide range of recognition and classification tasks .",
        "the power / energy consumption of neural networks is dominated by memory accesses , the majority of which occur in fully - connected networks .",
        "in fact , they contain most of the deep neural network parameters .",
        "the proposed architecture can save up to 90 % of memory compared to the conventional implementations of fully - connected neural networks .",
        "for our model , we also present a new kind of recurrent neural network inspired by residual networks that decouples memory from computation allowing to model complex environments that do not require lots of memory .",
        "we present a supervised sequence to sequence transduction model with a hard attention mechanism which combines the more traditional statistical alignment methods with the power of recurrent neural networks .",
        "we evaluate the model on the task of morphological inflection generation and show that it provides state of the art results in various setups compared to the previous neural and non - neural approaches .",
        "we specifically apply this idea to modify adam , a popular algorithm for training deep neural networks .",
        "recurrent neural networks are a powerful tool for modeling sequential data , but the dependence of each timestep ' s computation on the previous timestep ' s output limits parallelism and makes rnns unwieldy for very long sequences .",
        "we introduce quasi - recurrent neural networks ( qrnns ) , an approach to neural sequence modeling that alternates convolutional layers , which apply in parallel across timesteps , and a minimalist recurrent pooling function that applies in parallel across channels .",
        "experiments on language modeling , sentiment classification , and character - level neural machine translation demonstrate these advantages and underline the viability of qrnns as a basic building block for a variety of sequence tasks .",
        "neural networks are powerful and flexible models that work well for many difficult learning tasks in image , speech and natural language understanding .",
        "despite their success , neural networks are still hard to design .",
        "in this paper , we use a recurrent network to generate the model descriptions of neural networks and train this rnn with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set .",
        "deep neural network models , though very powerful and highly successful , are computationally expensive in terms of space and time .",
        "neural network is one of the techniques which are widely used for diagnosis in medical field .",
        "in this article efficiency of nine algorithms , which are basis of neural network learning in diagnosing cardiovascular diseases , will be assessed .",
        "in this paper we present a technique to train neural network models on small amounts of data .",
        "current methods for training neural networks on small amounts of rich data typically rely on strategies such as fine - tuning a pre - trained neural network or the use of domain - specific hand - engineered features .",
        "while deep learning parsing approaches have proven very successful at finding the structure of sentences , most neural dependency parsers use neural networks only for feature extraction , and then use those features in traditional parsing algorithms .",
        "in contrast , this paper builds off recent work using general - purpose neural network components , training an attention mechanism over an lstm to attend to the head of the phrase .",
        "in this paper , we present a general \" compare - aggregate \" framework that performs word - level matching followed by aggregation using convolutional neural networks .",
        "we find that some simple comparison functions based on element - wise operations can work better than standard neural network and neural tensor network .",
        "while most successful neural approaches to this problem rely on recurrent neural networks ( rnns ) , training rnns over long documents can be prohibitively slow .",
        "recent years have seen the proposal of a number of neural architectures for the problem of program induction .",
        "while achieving impressive results , these approaches have a number of important limitations : ( a ) they are computationally expensive and hard to train , ( b ) a model has to be trained for each task ( program ) separately , and ( c ) it is hard to interpret or verify the correctness of the learnt mapping ( as it is defined by a neural network ) .",
        "our method is based on two novel neural modules .",
        "the second module , the recursive - reverse - recursive neural network ( r3nn ) , given the continuous representation of",
        "we devise a novel neural network architecture for this task which we train end - to - end .",
        "although end - to - end neural machine translation ( nmt ) has achieved remarkable progress in the past two years , it suffers from a major drawback : translations generated by nmt systems often lack of adequacy .",
        "in this work , we propose a novel framework called ac - blstm for modeling setences and documents , which combines the asymmetric convolution neural network ( acnn ) with the bidirectional long short - term memory network ( blstm ) .",
        "moreover , since our regularization is directly performed on the weights , it is especially suitable for fully convolutional neural networks , where the weight space is constant compared to the feature map space .",
        "in recent years , deep neural networks ( dnns ) based methods have achieved remarkable performance in a wide range of tasks and have been among the most powerful and widely used techniques in computer vision , speech recognition and natural language processing .",
        "the approach is to train a neural network to predict properties of the program that generated the outputs from the inputs .",
        "we use the neural network ' s predictions to augment search techniques from the programming languages community , including enumerative search and an smt - based solver .",
        "empirically , we show that our approach leads to an order of magnitude speedup over the strong non - augmented baselines and a recurrent neural network approach , and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites .",
        "artificial neural networks have gone through a recent rise in popularity , achieving state - of - the - art results in various fields , including image classification , speech recognition , and automated control .",
        "in our work , machine learning is leveraged by training an artificial neural network to predict the performance",
        "at present , designing convolutional neural network ( cnn ) architectures requires both human expertise and labor .",
        "we present a novel layerwise optimization algorithm for the learning objective of a large class of convolutional neural networks ( cnns ) .",
        "recent works on neural architectures have demonstrated the utility of attention mechanisms for a wide variety of tasks .",
        "the prevalent approach to neural machine translation relies on bi - directional lstms to encode the source sentence .",
        "the key technical tool is the neural taylor approximation - - a straightforward application of taylor expansions to neural networks - - and the associated taylor loss .",
        "experiments on a range of optimizers , layers , and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization .",
        "in this work , we present dependency sensitive convolutional neural networks ( dscnn ) as a general - purpose classification system for both sentences and documents .",
        "compared with existing recursive neural models with tree structures , dscnn does not rely on parsers and expensive phrase labeling , and thus is not restricted to sentence - level tasks .",
        "recently , spiking neural networks ( snns ) have been attracting a great deal of attention , notably owning to their power efficiency , which can potentially allow us to implement a low - power deep learning engine suitable for real - time / mobile applications .",
        "consequently , most of the previous studies employ a workaround technique , which first trains a conventional weighted - sum deep neural network and then maps the learning weights to the snn under training , instead of training snn parameters directly .",
        "in this paper we present new discriminative embedding models based on recurrent neural networks ( rnns ) .",
        "we formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models .",
        "in this work we propose an end - to - end neural approach based on the recently proposed set to sequence mapping framework to address the sentence ordering problem .",
        "we used the latest deep neural network algorithms which provide a leap in performance over the traditional gmm approach , and apply data augmentation methods to improve robustness to noise and speaker variation .",
        "an intriguing property of deep neural networks is the existence of adversarial examples , which can transfer among different architectures .",
        "these transferable adversarial examples may severely hinder deep neural network - based applications .",
        "recent work has demonstrated the effectiveness of employing explicit external memory structures in conjunction with deep neural models for algorithmic learning ( graves et al .",
        "in this work , we propose an alternative model , lie - access memory , that is explicitly designed for the neural setting .",
        "to experiment with this approach , we implement several simplified lie - access neural turing machine ( lantm ) with different lie groups .",
        "in this work , we propose a training algorithm for an audio - visual automatic speech recognition ( av - asr ) system using deep recurrent neural network ( rnn ) .",
        "deep neural networks ( dnns ) have come to outperform humans in visual classifications tasks .",
        "to sidestep the curse of dimensionality , we propose an algorithm that leverages a neural network to approximate the minimum time - to - reach function to synthesize controls .",
        "we show that our neural network generates near optimal controls which are guaranteed to successfully drive the system to a target state .",
        "unlike many previous neural network reachability formulations , our approximation is conservative and hence any trajectories we generate will be strictly feasible .",
        "convolutional neural networks excel in image recognition tasks , but this comes at the cost of high computational and memory complexity .",
        "recent advances in language technology have given rise to unsupervised neural models for learning representations of words as well as bigger textual units .",
        "this survey is meant as an introduction to the use of neural models for semantic matching .",
        "we detail the required background and terminology , a taxonomy grouping the rapidly growing body of work in the area , and then survey work on neural models for semantic matching in the context of three tasks : query suggestion , ad retrieval , and document retrieval .",
        "our model is a hierarchical recurrent neural network , where the layers and the structure of the hierarchy encode our prior knowledge about how pop music is composed .",
        "we additionally show two applications of our framework : neural dancing and karaoke , as well as neural story singing .",
        "despite their massive size , successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance .",
        "three consonant voicing classifiers were developed : ( 1 ) manually selected acoustic features anchored at a phonetic landmark , ( 2 ) mfccs ( either averaged across the segment or anchored at the landmark ) , and ( 3 ) acoustic features computed using a convolutional neural network ( cnn ) .",
        "the entity linking ( el ) system consists of two modules : a rule based candidate generation and a neural networks probability ranking model .",
        "most neural network models for document classification on social media focus on text infor - mation to the neglect of other information on these platforms .",
        "in this paper , we classify post stance on social media channels and develop utcnn , a neural network model that incorporates user tastes , topic tastes , and user comments on posts .",
        "moreover , our work compares two different strategies to extract features from a convolutional neural network for each region proposal : a first one that computes new feature maps for each region proposal , and a second one that computes the feature maps for the whole image to later generate crops for each region proposal .",
        "we present a learning to learn approach for training recurrent neural networks to perform black - box global optimization .",
        "in the meta - learning phase we use a large set of smooth target functions to learn a recurrent neural network ( rnn ) optimizer , which is either a long - short term memory network or a differentiable neural computer .",
        "though a variety of neural network models have been proposed very recently , however , previous models either depend on expensive phrase - level annotation , whose performance drops substantially when trained with only sentence - level annotation ; or do not fully employ linguistic resources ( e .",
        "we compare the performance of using audio spectrum in the log scale and using polyphonic sound sequences from raw audio samples to train the neural network and to classify speech as either english or spanish .",
        "to achieve this , we use the novel approach of using a convolutional recurrent neural network using long short term memory ( lstm ) or a gated recurrent unit ( gru ) for forward propagation of the neural network .",
        "our hypothesis is that the performance of using polyphonic sound sequence as features and both lstm and gru as the gating mechanisms for the neural network outperform the traditional mfcc features using a unidirectional deep neural network .",
        "the collision prediction model is represented by a deep convolutional neural network that directly processes raw image inputs .",
        "in this paper , we take a first step towards bridging this gap , by developing flavors of competitive hebbian learning which produce sparse , distributed neural codes using online adaptation with minimal tuning .",
        "we present summarunner , a recurrent neural network ( rnn ) based sequence model for extractive summarization of documents and show that it achieves performance better than or comparable to state - of - the - art .",
        "conditional random field ( crf ) and recurrent neural models have achieved success in structured prediction .",
        "more recently , there is a marriage of crf and recurrent neural models , so that we can gain from both non - linear dense features and globally normalized crf objective .",
        "these recurrent neural crf models mainly focus on encode node features in crf undirected graphs .",
        "in this work , we introduce a new recurrent neural crf model , which learns non - linear edge features , and thus makes non - linear features encoded completely .",
        "we compare our model with different neural models in well - known structured prediction tasks .",
        "with massive unlabeled text and quite limited labelled corpus , we propose a semi - supervised learning model based on b - lstm neural network .",
        "we present two novel and contrasting recurrent neural network ( rnn ) based architectures for extractive summarization of documents .",
        "a shared component of many powerful generative models is a decoder network , a parametric deep neural net that defines a generative distribution .",
        "this article provides an interesting exploration of character - level convolutional neural network solving chinese corpus text classification problem .",
        "we constructed a large - scale chinese language dataset , and the result shows that character - level convolutional neural network works better on chinese corpus than its corresponding pinyin format dataset .",
        "this is the first time that character - level convolutional neural network applied to text classification problem .",
        "recent work has begun exploring neural acoustic word embeddings - - fixed - dimensional vector representations of arbitrary - length speech segments corresponding to words .",
        "we propose an approach to build a neural machine translation system with no supervised resources ( i .",
        "we propose a simple , elegant solution to use a single neural machine translation ( nmt ) model to translate between multiple languages .",
        "training time on large datasets for deep neural networks is the principal workflow bottleneck in a number of important applications of deep learning , such as object classification and detection in automatic driver assistance systems ( adas ) .",
        "to minimize training time , the training of a deep neural network must be scaled beyond a single machine to as many machines as possible by distributing the optimization method used for training .",
        "to this end , we propose a knowledge enhanced hybrid neural network ( kehnn ) .",
        "the three channels are processed by a convolutional neural network to generate high level features for matching , and the features are synthesized as a matching score by a multilayer perceptron .",
        "in this work we use the recent advances in representation learning to propose a neural architecture for the problem of natural language inference .",
        "the model uses variants of long short term memory ( lstm ) , attention mechanism and composable neural networks , to carry out the task .",
        "in this paper , we present our first attempts in building a multilingual neural machine translation framework under a unified approach .",
        "the nonlinearity of the model is revealed by its connection to rectified linear unit ( relu ) neural networks .",
        "we further extend the model to deep structures and show that deep models can be used for unsupervised pre - training of rectifier neural networks .",
        "neural machine translation systems typically rely on the size of parallel corpora .",
        "in this paper , we propose an end - to - end neural approach to address the sentence ordering problem , which uses the pointer network ( ptr - net ) to alleviate the error propagation problem and utilize the whole contextual information .",
        "in this paper , we propose an approach to pos tag code - mixed social media text using recurrent neural network language model ( rnn - lm ) architecture .",
        "nevertheless , the neural network has its advantages : it uses only tactile and proprioceptive feedback but no visual feedback about the object ( i .",
        "various deep neural architectures underperform human baselines on these tasks , suggesting that comics contains fundamental challenges for both vision and language .",
        ", max pooling ) in convolutional neural networks ( cnns ) serve the dual purpose of providing increasingly abstract representations as well as yielding computational savings in subsequent convolutional layers .",
        "our method for transforming deep artificial neural networks into spiking networks is scalable and works with a wide range of neural nonlinearities .",
        "we achieve these results by softening the neural response function , such that its derivative remains bounded , and by training the network with noise to provide robustness against the variability introduced by spikes .",
        "in the context of deep neural networks , this idea is often realized by hand - designed network architectures with layers that are shared across tasks and branches that encode task - specific features .",
        "in this work , we present a shared variable neural network model called proje that fills - in missing information in a knowledge graph by learning joint embeddings of the knowledge graph ' s entities and edges , and through subtle , but important , changes to the standard loss function .",
        "inspired by such capability , we propose deluge networks ( delugenets ) , a novel class of neural networks facilitating massive cross - layer information inflows from preceding layers to succeeding layers .",
        "we then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow .",
        "the current trend in object detection and localization is to learn predictions with high capacity deep neural networks trained on a very large amount of annotated data and using a high amount of processing power .",
        "in this work , we propose a new neural model which directly predicts bounding box coordinates .",
        "recurrent neural network grammars ( rnng ) are a recently proposed probabilistic generative modeling family for natural language .",
        "researchers have recently started investigating deep neural networks for dialogue applications .",
        "in support of this goal , we review recently proposed models based on generative encoder - decoder neural network architectures , and show that these models have better ability to incorporate long - term dialogue history , to model uncertainty and ambiguity in dialogue , and to generate responses with high - level compositional structure .",
        "a novel data representation method of convolutional neural net - work ( cnn ) is proposed in this paper to represent data of different modalities .",
        "the complexity of deep neural network algorithms for hardware implementation can be lowered either by scaling the number of units or reducing the word - length of weights .",
        "for this study , the performances of fully - connected deep neural networks ( fcdnns ) and convolutional neural networks ( cnns ) are evaluated while changing the network complexity and the word - length of weights .",
        "7x ( on gpu / cpu ) relative to a state - of - the - art convolutional neural network , at competitive accuracy .",
        "neural network based models are a very powerful tool for creating word embeddings , the objective of these models is to group similar words together .",
        "neural language models are able to learn word representations which have been used to capture semantic shifts across time and geography .",
        "we will train a neural language model on texts from a diverse set of disciplines philosophy , religion , fiction etc .",
        "deep neural network architectures with external memory components allow the model to perform inference and capture long term dependencies , by storing information explicitly .",
        "the difficulty in analyzing lstm - like recurrent neural networks lies in the complex structure of the recurrent unit , which induces highly complex nonlinear dynamics .",
        "recently published methods enable training of bitwise neural networks which allow reduced representation of down to a single bit per weight .",
        "we present a method that exploits ensemble decisions based on multiple stochastically sampled network models to increase performance figures of bitwise neural networks in terms of classification accuracy at inference .",
        "our work contributes to efficient embedded bitwise neural networks .",
        "we develop a model that decomposes both images and paragraphs into their constituent parts , detecting semantic regions in images and using a hierarchical recurrent neural network to reason about language .",
        "recurrent neural network ( rnn ) is one of the most popular architectures used in natural language processsing ( nlp ) tasks because its recurrent structure is very suitable to process variable - length text .",
        "adaptive stochastic gradient methods such as adagrad have gained popularity in particular for training deep neural networks .",
        "on the task of training convolutional neural networks as well as recurrent neural networks , radagrad achieves faster convergence than diagonal adagrad .",
        "deep neural networks with lots of parameters are typically used for large - scale computer vision tasks such as image classification .",
        "in this work , we train and build neural networks which implicitly use sparse computations .",
        "we experimentally validate our method on both small and large networks and achieve state - of - the - art compression results for sparse neural network models .",
        "in addition , we highlight a direct link of the proposed non - local models to convolutional neural networks .",
        "deep neural networks often require good regularizers to generalize well .",
        "another member of this family selects the width of neural network layers .",
        "we describe a new rl learning framework called bi - pomdp , and a new learning model called budgeted option neural network ( bonn ) able to discover options based on a budgeted learning objective .",
        "convolutional neural networks ( cnns ) exhibit remarkable performance in various machine learning tasks .",
        "performance of end - to - end automatic speech recognition ( asr ) systems can significantly be improved by the increasing large speech corpus and deeper neural network .",
        "given the arising problem of training speed and recent success of deep convolutional neural network in asr , we build a novel deep recurrent convolutional network for acoustic modeling and apply deep residual learning framework to it , our experiments show that it has not only faster convergence speed but better recognition accuracy over traditional deep convolutional recurrent network .",
        "deep convolutional neural networks have become a widespread tool to address high - level computer vision tasks very successfully .",
        "we are the first to propose such a formulation : training a neural network to rank points in a transformation - invariant manner .",
        "we propose a multigrid extension of convolutional neural networks ( cnns ) .",
        "we propose incorporating this idea of tunable sensitivity for hard examples in neural network learning , using a new generalization of the cross - entropy gradient step , which can be used in place of the gradient in any gradient - based training method .",
        "we therefore conclude that tunable sensitivity can be helpful for neural network learning .",
        "a new model for video captioning is developed , using a deep three - dimensional convolutional neural network ( c3d ) as an encoder for videos and a recurrent neural network ( rnn ) as a decoder for captions .",
        "the word - to - vector representation is used , and convolutional neural networks are employed as sentence encoders , mapping an input sentence into a fixed - length vector .",
        "this representation is decoded using long short - term memory recurrent neural networks , considering several tasks , such as reconstructing the input sentence , or predicting the future sentence .",
        "a significant number of neural architectures for this task ( neural readers ) have recently been developed and evaluated on large cloze - style datasets .",
        "in an independent contribution , we show that the addition of linguistics features to the input to existing neural readers significantly boosts performance yielding the best results to date on the who - did - what datasets .",
        "recurrent neural networks ( rnns ) have shown promising performance for language modeling .",
        "more specifically , we apply random walk based learning method with recurrent neural network to match the similarities between askers question and historical questions proposed by other users .",
        "this paper introduces a neural language model with a sparse pointer network aimed at capturing very long - range dependencies .",
        "on this corpus , we found standard neural language models to perform well at suggesting local phenomena , but struggle to refer to identifiers that are introduced many tokens in the past .",
        "by augmenting a neural language model with a pointer network specialized in referring to predefined classes of identifiers , we obtain a much lower perplexity and a 5 percentage points increase in accuracy for code suggestion compared to an lstm baseline .",
        "based on these datasets , we propose and compare several recurrent neural networks ( rnns ) based multimodal ( text and image ) models .",
        "although attention - based neural machine translation have achieved great success , attention - mechanism cannot capture the entire meaning of the source sentence because the attention mechanism generates a target word depending heavily on the relevant parts of the source sentence .",
        "the report of earlier studies has introduced a latent variable to capture the entire meaning of sentence and achieved improvement on attention - based neural machine translation .",
        "as described herein , we propose a neural machine translation model that introduces a continuous latent variable containing an underlying semantic extracted from texts and images .",
        "in this paper , we propose a simple , fast decoding algorithm that fosters diversity in neural generation .",
        "we propose a neural network framework for high - dimensional conditional density estimation .",
        "recurrent neural networks ( rnns ) have achieved great success in language modeling .",
        "dpn is a deep neural network that consists of two important layers : template projection layer and dense aggregate layer .",
        "we approach the problem of learning synthetic driving using generative neural networks .",
        "in this work , we propose to utilize unlabeled data to train neural network based grammatical error detection models .",
        "we introduce an attention - based neural network to capture long - distance dependencies that influence the word being detected .",
        "we define a likelihood for a set distribution and learn its parameters using a deep neural network .",
        "we use reinforcement learning to learn tree - structured neural networks for computing representations of natural language sentences .",
        "in this work , we employ a recurrent neural network ( rnn ) to predict real estate price using the state - of - the - art visual features .",
        "convolutional neural networks achieve good performance on this task , while being computationally efficient .",
        "here we study greedy algorithms for unsupervised learning of dictionaries of shift - invariant atoms and propose a new method where each atom is selected with the same probability on average , which corresponds to the homeostatic regulation of a recurrent convolutional neural network .",
        "this generalisation has two mathematically equivalent views in multi - linear algebra and gated neural networks respectively .",
        "moreover , by exploiting the semantic descriptor , it provides neural networks the capability of zero - shot learning ( zsl ) , where a classifier is generated for an unseen class without any training data ; as well as zero - shot domain adaptation ( zsda ) , where a model is generated for an unseen domain without any training data .",
        "we propose a single neural network architecture for two tasks : on - line keyword spotting and voice activity detection .",
        "we develop novel inference algorithms for an end - to - end recurrent neural network trained with the connectionist temporal classification loss function which allow our model to achieve high accuracy on both keyword spotting and voice activity detection without retraining .",
        "we describe a neural attention model with a learnable retinal sampling lattice .",
        "the computational mechanisms by which nonlinear recurrent neural networks ( rnns ) achieve their goals remains an open question .",
        "we concatenate this layer with a convolutional neural network ( cnn ) model .",
        "we train input specific state - of - the - art deep neural networks for each input source , show the potential of forging them together into a multi - modal architecture and train a novel policy network that learns to choose between them .",
        "an associative memory is a framework of content - addressable memory that stores a collection of message vectors ( or a dataset ) over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version .",
        "designing an associative memory requires addressing two main tasks : 1 ) learning phase : given a dataset , learn a concise representation of the dataset in the form of a graphical model ( or a neural network ) , 2 ) recall phase : given a noisy version of a message vector from the dataset , output the correct message vector via a neurally feasible algorithm over the network learnt during the learning phase .",
        "this paper studies the problem of designing a class of neural associative memories which learns a network representation for a large dataset that ensures correction against a large number of adversarial errors during the recall phase .",
        "we measure human performance on the dataset and compare it to several strong neural models .",
        "we proposed two novel approaches which encode the contexts into a continuous semantic representation and then decode the semantic representation into text sequences with recurrent neural networks .",
        "generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks .",
        "reducing bit - widths of weights , activations , and gradients of a neural network can shrink its storage size and memory usage , and also allow for faster training and inference by exploiting bitwise operations .",
        "sequence modeling with neural networks has lead to powerful models of symbolic music data .",
        "recurrent neural networks ( rnns ) have been successfully used in many applications .",
        "fully convolutional neural networks give accurate , per - pixel prediction for input images and have applications like semantic segmentation .",
        "we propose a method to train bit fully convolution network ( bfcn ) , a fully convolutional neural network that has low bit - width weights and activations .",
        "our model takes graphs as input , performs object - and relation - centric reasoning in a way that is analogous to a simulation , and is implemented using deep neural networks .",
        "recent literature has pointed out that machine learning classifiers , including deep neural networks ( dnn ) , are vulnerable to adversarial samples that are maliciously created inputs that force a machine learning classifier to produce wrong output labels .",
        "we present the neural physics engine ( npe ) , an object - based neural network architecture for learning predictive models of intuitive physics .",
        "our approach draws on the strengths of both symbolic and neural approaches : like a symbolic physics engine , the npe is endowed with generic notions of objects and their interactions , but as a neural network it can also be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds .",
        "recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables , such as variational autoencoders .",
        "we present several definition model architectures based on recurrent neural networks , and experiment with the models over multiple data sets .",
        "in this work , we present how convolutional neural networks can be used to directly classify pre - segmented breast masses in mammograms as benign or malignant , using a combination of transfer learning , careful pre - processing and data augmentation to overcome limited training data .",
        "to address this limitation , we leverage a fast neural model to extract lookahead features .",
        "in this paper , we propose a new neural network to estimate distributed word representations using a lexicon and a corpus .",
        "the proposed neural network can be trained using negative sampling , which maximizing the log probabilities of target words given the context words , by distinguishing the target words from random noises .",
        "we compare the proposed neural network",
        "in order to handle the patients ' historical information as sequential data , we apply the so - called encoder - decoder - framework which is based on recurrent neural networks ( rnn ) as encoders and a tensor factorization model as a decoder , a combination which is novel in machine learning .",
        "this paper presents a systematic evaluation of neural network ( nn ) for classification of real - world data .",
        "we present probabilistic neural programs , a framework for program induction that permits flexible specification of both a computational model and inference algorithm while simultaneously enabling the use of deep neural networks .",
        "probabilistic neural programs combine a computation graph for specifying a neural network with an operator for weighted nondeterministic choice .",
        "thus , a program describes both a collection of decisions as well as the neural network architecture used to make each one .",
        "we evaluate our approach on a challenging diagram question answering task where probabilistic neural programs correctly execute nearly twice as many programs as a baseline model .",
        "multiple extensions of recurrent neural networks ( rnns ) have been proposed recently to address the difficulty of storing information over long time periods .",
        "in this paper , we experiment with the capacity of neural turing machines ( ntms ) to deal with these long - term dependencies on well - balanced strings of parentheses .",
        "the significant computational costs of deploying neural networks in large - scale or resource constrained environments , such as data centers and mobile devices , has spurred interest in model compression , which can achieve a reduction in both arithmetic operations and storage memory .",
        "several techniques have been proposed for reducing or compressing the parameters for feed - forward and convolutional neural networks , but less is understood about the effect of parameter compression on recurrent neural networks ( rnn ) .",
        "to address the issues , we propose an end - to - end deep recurrent neural network with limited contextual dialogue memory by jointly training nlu and sap on dstc4 multi - domain human - human dialogues .",
        "deep neural networks are widely used in machine learning applications .",
        "however , the deployment of large neural networks models can be difficult to deploy on mobile devices with limited power budgets .",
        "to solve this problem , we propose trained ternary quantization ( ttq ) , a method that can reduce the precision of weights in neural networks to ternary values .",
        "this paper presents some techniques using fuzzy logic and neural networks to improve the accuracy of the use case points method .",
        "as a proof of concept for the proposed scheme , we designed a system consisting of deep convolutional neural networks , and applied it to successfully learn a computerized agent capable of autonomous highway steering over the",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "recent neural program induction approaches have attempted to address this problem , but are typically limited to differentiable memory , and consequently cannot scale beyond small synthetic tasks .",
        "in this work , we propose the manager - programmer - computer framework , which integrates neural networks with non - differentiable memory to support abstract , scalable and precise operations through a friendly neural computer interface .",
        "specifically , we introduce a neural symbolic machine , which contains a sequence - to - sequence neural \" programmer \" , and a non - differentiable \" computer \" that is a lisp interpreter with code assist .",
        "network quantization is one of network compression techniques employed to reduce the redundancy of deep neural networks .",
        "it compresses the size of the storage for a large number of network parameters in a neural network by quantizing them and encoding the quantized values into binary codewords of smaller sizes .",
        "to this end , we analyze the quantitative relation of quantization errors to the loss function of a neural network and identify that the hessian - weighted distortion measure is locally the right objective function that we need to optimize for minimizing the loss due to quantization .",
        "the vectors are then accumulated in a chronological order through a recurrent neural network ( rnn ) which models the relationships among the utterances .",
        "we introduce condensed memory neural networks ( c - memnns ) , a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory .",
        "we demonstrate that max - sum inference in the drmm yields an algorithm that exactly reproduces the operations in deep convolutional neural networks ( dcns ) , providing a first principles derivation .",
        "cross - entropy loss together with softmax is arguably one of the most common used supervision components in convolutional neural networks ( cnns ) .",
        "building neural networks to query a knowledge base ( a table ) with natural language is an emerging research topic in nlp .",
        "the neural enquirer typically necessitates multiple steps of execution because of the compositionality of queries .",
        "in summary , the coupled neural enquirer takes advantages of both distributed and symbolic exec",
        "like a neural turing machine or differentiable neural computer ( graves et al .",
        "we propose an extension to neural network language models to adapt their prediction to the recent history .",
        "we also draw a link between the use of external memory in neural network and cache models used with count based language models .",
        "we present a method for implementing an efficient unitary neural network ( eunn ) whose computational complexity is merely $ \\ mathcal { o } ( 1 ) $ per parameter and has full tunability , from spanning part of unitary space to all of it .",
        "we apply the eunn in recurrent neural networks , and test its performance on the standard copying task and the mnist digit recognition benchmark , finding that it significantly outperforms a non - unitary rnn , an lstm network , an exclusively partial space urnn and a projective urnn with comparable parameter numbers .",
        "we introduce an exceptionally simple gated recurrent neural network ( rnn ) that achieves performance comparable to well - known gated architectures , such as lstms and grus , on the word - level language modeling task .",
        "parsing accuracy using efficient greedy transition systems has improved dramatically in recent years thanks to neural networks .",
        "despite striking results in dependency parsing , however , neural models have not surpassed state - of - the - art approaches in constituency parsing .",
        "research has shown that convolutional neural networks contain significant redundancy , and high classification accuracy can be obtained even when weights and activations are reduced from floating point to binary values .",
        "by utilizing a novel set of optimizations that enable efficient mapping of binarized neural networks to hardware , we implement fully connected , convolutional and pooling layers , with per - layer compute resources being tailored to user - provided throughput requirements .",
        "in this work , to leverage class ties , we propose to make joint relation extraction with a unified model that integrates convolutional neural network with a general pairwise ranking framework , in which two novel ranking loss functions are introduced .",
        "we show that our model , which profits from combining memory - less modules , namely autoregressive multilayer perceptrons , and stateful recurrent neural networks in a hierarchical structure is able to capture underlying sources of variations in the temporal sequences over very long time spans , on three datasets of different nature .",
        "the pre - dominant approach to language modeling to date is based on recurrent neural networks .",
        "the predictron yielded significantly more accurate predictions than conventional deep neural network architectures .",
        "this work provides the first neural network - based approach to argumentation mining , focusing on the two tasks of extracting links between argument components , and classifying types of argument components .",
        "the above limitations can be overcome by using deep cases and neural network .",
        "hence we propose a modified qas in which we create a deep artificial neural network with associative memory from text documents .",
        "we present an end - to - end graph - based neural network dependency parser that can be trained to reproduce matrices of edge scores , which can be directly projected across word alignments .",
        "we introduce a tree - structured attention neural network for sentences and small phrases and apply it to the problem of sentiment classification .",
        "neural machine translation ( nmt ) is a new approach for machine translation ( mt ) , and due to its success , it has absorbed the attention of many researchers in the field .",
        "we present a natural representation of to reinforcement learning ( rl ) problems using recurrent convolutional neural networks ( rcnns ) , to better exploit this inherent structure .",
        "more specifically , we employ the residual neural network framework to model the temporal closeness , period , and trend properties of crowd traffic .",
        "st - resnet learns to dynamically aggregate the output of the three residual neural networks based on data , assigning different weights to different branches and regions .",
        "we introduce a simple and accurate neural model for dependency - based semantic role labeling .",
        "we describe an open - source toolkit for neural machine translation ( nmt ) .",
        "in this work , we propose a novel decoding approach for neural machine translation ( nmt ) based on continuous optimisation .",
        "our approach is general and can be applied to other sequence - to - sequence neural models as well .",
        "we aim to shed light on the strengths and weaknesses of the newly introduced neural machine translation paradigm .",
        "to that end , we conduct a multifaceted evaluation in which we compare outputs produced by state - of - the - art neural machine translation and phrase - based machine translation systems for 9 language directions across a number of dimensions .",
        "we find out that translations produced by neural machine translation systems are considerably different , more fluent and more accurate in terms of word order compared to those produced by phrase - based systems .",
        "neural machine translation systems are also more accurate at producing inflected forms , but they perform poorly when translating very long sentences .",
        "in this paper , we present a novel neural network model antsynnet that exploits lexico - syntactic patterns from syntactic parse trees .",
        "currently successful methods for video description are based on encoder - decoder sentence generation using recur - rent neural networks ( rnns ) .",
        "we feed the word vectors into a simple neural network with a long short - term memory ( lstm ) architecture .",
        "without any attempts to extract manually crafted features and considering that our medical dataset is too small to be fed into neural network , we obtained promising results .",
        "neural conversation models - - purely data - driven systems trained end - to - end on dialogue corpora - - have shown great promise recently , yet they often produce short and generic responses .",
        "in this paper , a novel architecture for a deep recurrent neural network , residual lstm is introduced .",
        "in this paper , we propose an efficient transfer leaning methods for training a personalized language model using a recurrent neural network with long short - term memory architecture .",
        "therefore , we would like to omit it and use deep neural networks that learn from simple features .",
        "credit assignment in traditional recurrent neural networks usually involves back - propagating through a long chain of tied weight matrices .",
        "we built both phrase - based and neural machine translation models , in an effort to probe whether the newly emerged nmt framework surpasses the traditional phrase - based systems in arabic - english language pairs .",
        "we trained a very strong phrase - based system including , a big language model , the operation sequence model , neural network joint model and class - based models along with different domain adaptation techniques such as mml filtering , mixture modeling and using fine tuning over nnjm model .",
        "however , a neural mt system , trained by stacking data from different genres through fine - tuning , and applying ensemble over 8 models , beat our very strong phrase - based system by a significant 2 bleu points margin in arabic - & gt ; english direction .",
        "this paper examines bypassing such an explicit representation by depending on a latent neural embedding of state and learning selective attention to dialogue history together with copying to incorporate relevant prior context .",
        "we complement recent work by showing the effectiveness of simple sequence - to - sequence neural architectures with a copy mechanism .",
        "most of the current deep neural network ( dnn ) based methods consider these tasks as a sequence labeling problem , in which a word , rather than a chunk , is treated as the basic unit for labeling .",
        "in this paper , we propose an alternative approach by investigating the use of dnn for sequence chunking , and propose three neural models so that each chunk can be treated as a complete unit for labeling .",
        "experimental results show that the proposed neural sequence chunking models can achieve start - of - the - art performance on both the text chunking and slot filling tasks .",
        "we design recurrent neural network ( rnn ) based contextual language models that specially track the interactions between speakers in a dialog .",
        "end - to - end ( e2e ) systems have achieved competitive results compared to conventional hybrid hidden markov model ( hmm ) - deep neural network based automatic speech recognition ( asr ) systems .",
        "the first sub - system is a recurrent neural network ( rnn ) - based acoustic auto - encoder trained to reconstruct the audio through a finite - dimensional representation .",
        "the second sub - system is a character - level rnn language model using embeddings learned from a convolutional neural network .",
        "since the acoustic and text query embeddings occupy different representation spaces , they are input to a third feed - forward neural network that predicts whether the query occurs in the acoustic utterance or not .",
        "how much can pruning algorithms teach us about the fundamentals of learning representations in neural networks ?",
        "neural network model compression has become a topic of great interest in recent years , and many different techniques have been proposed to address this problem .",
        "at the same time , the decision of what to prune and when to prune necessarily forces us to confront our assumptions about how neural networks actually learn to represent patterns in data .",
        "in this work we set out to test several long - held hypotheses about neural network learning representations and numerical approaches to pruning .",
        "recently , convolutional neural networks ( cnn ) , have shown success in this task .",
        "the proposed model , named deep cooperative neural networks ( deepconn ) , consists of two parallel neural networks coupled in the last layers .",
        "for the latter claim , two paradigmatic examples are presented : logic programming with kleene semantics for modelling reasoning from information in a discourse , to an interpretation of the state of affairs of the intended model , and a neural - symbolic implementation of input / output logic for dealing with uncertainty in dynamic normative contexts .",
        "introduction to deep neural networks and their history .",
        "this work aims to investigate the use of deep neural network to detect commercial hobby drones in real - life environments by analyzing their sound data .",
        ", a gaussian mixture model ( gmm ) , convolutional neural network ( cnn ) , and recurrent neural network ( rnn ) , for drone sound detection .",
        "we address a problem of optimization on product of embedded submanifolds of convolution kernels ( pems ) in convolutional neural networks ( cnns ) .",
        "to address this problem , we propose a multichannel convolutional neural networks ( cnn ) architecture , in which we treat english and chinese language as different input channels of one single cnn model .",
        "we introduce multi - modal , attention - based neural machine translation ( nmt ) models which incorporate visual features into different parts of both the encoder and the decoder .",
        "we utilise global image features extracted using a pre - trained convolutional neural network and incorporate them ( i ) as words in the source sentence , ( ii ) to initialise the encoder hidden state , and ( iii ) as additional data to initialise the decoder hidden state .",
        "to the best of our knowledge , it is the first time a purely neural model significantly improves over a pbsmt model on all metrics evaluated on this data set .",
        "we systematically explore regularizing neural networks by penalizing low entropy output distributions .",
        "we introduce a general strategy for improving neural sequence generation by incorporating knowledge about the future .",
        "in this study , an artificial neural network ( ann ) approach is utilized to perform a parametric study on the process of extraction of lubricants from heavy petroleum cuts .",
        "a feed - forward multi - layer perceptron neural network was successfully applied to capture the relationship between inputs and output parameters .",
        "in this paper , we propose a graph - based recursive neural network framework for collective vertex classification .",
        "in this framework , we generate hidden representations from both attributes of vertices and representations of neighbouring vertices via recursive neural networks .",
        "under this framework , we explore two types of recursive neural units , naive recursive neural unit and long short - term memory unit .",
        "we propose a neural network based approach for learning topics from text and image datasets .",
        "furthermore , since the approach utilizes neural networks , it can be implemented on gpu with ease , and hence it is very scalable .",
        "we train and compare several deep neural network models on the traces of existing atp proofs of mizar statements and use them to select processed clauses during proof search .",
        "using a few proof guidance strategies that leverage deep neural networks , we have found first - order proofs of 7 .",
        "an analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with ai techniques including artificial neural networks ( ann ) , ensembling and reinforcement learning ( rl ) to evolve control strategies for ucavs .",
        "in this work , we study the effect of discretization on the performance of linear classifiers optimizing three distinct discriminative objective functions - - - logistic regression ( optimizing negative log - likelihood ) , support vector classifiers ( optimizing hinge loss ) and a zero - hidden layer artificial neural network ( optimizing mean - square - error",
        "convolutional neural networks ( cnns ) has shown a great success in many areas including complex image classification tasks .",
        "in this paper , we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural - network - based statistical machine - learning techniques .",
        "chatbot ) , machine translation , text sequence prediction , neural architecture design , personalized web services , healthcare , finance , and music generation .",
        "an artificial visual system was built based on a fully recurrent neural network set within a reinforcement learning protocol , and learned to attend to regions of interest while solving a classification task .",
        "the application of deep neural networks for ranking in search engines may obviate the need for the extensive feature engineering common to current learning - to - rank methods .",
        "however , we show that combining simple relevance matching features like bm25 with existing deep neural net models often substantially improves the accuracy of these models , indicating that they do not capture essential local relevance matching signals .",
        "we describe a novel deep recurrent neural net - based model that we call match - tensor .",
        "machine learning models , such as neural networks , decision trees , random forests and gradient boosting machines accept a feature vector and provide a prediction .",
        "proposed approach uses deep recurrent neural network trained on a sequence of acoustic features calculated over small speech intervals .",
        "automatic phoneme recognition for bengali language using multilayer neural network is reviewed .",
        "usefulness of multilayer neural network over single layer neural network is discussed .",
        "experiments using deep neural network models trained on social media data show that the combination of visual and textual context can enhance the quality of generated conversational turns .",
        "in human evaluation , a gap between human performance and that of both neural and retrieval architectures suggests that igc presents an interesting challenge for vision and language research .",
        "recently neural network models using latent features has shown to be perform similar or better than the other existing models using handcrafted features .",
        "the neural network characteristic of these systems provides appropriate tool for automatically adjusting the membership functions .",
        "for artificial general intelligence ( agi ) it would be efficient if multiple users trained the same giant neural network , permitting parameter reuse , without catastrophic forgetting .",
        "it is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re - use for new tasks .",
        "during learning , a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation .",
        "the recent success of deep convolutional neural networks on image classification and recognition tasks has led to new applications in very diversifying contexts .",
        "one of these is medical imaging where scarcity and imbalance of training data has hindered rapid development of neural network related applications .",
        "we show how neural network based rl enables the control of discretized pdes whose parameters are unknown , random , and time - varying .",
        "subsequently , high dimensional non - linear function approximators like neural networks have been used to learn policies from scratch .",
        "convolutional neural network ( cnn ) models have achieved tremendous success in many visual detection and recognition tasks .",
        "recurrent neural network ( rnn ) models , on the other hand , are often used to process text and voice data due to their ability to learn intrinsic representations of sequential and temporal data .",
        "here , we propose a novel neural network tracking model that is capable of integrating information over time and tracking a selected target in video .",
        "we compare our model with an existing neural - network based tracking method and show that the proposed tracking approach works well in various scenarios by performing rigorous validation experiments on artificial video sequences",
        "we show that dsfs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks ( dnns ) .",
        "skip connections made the training of very deep neural networks possible and have become an indispendable component in a variety of neural architectures .",
        "here , we present an explanation for the benefits of skip connections in training very deep neural networks .",
        "it is well known that it is challenging to train deep neural networks and recurrent neural networks for tasks that exhibit long term dependencies .",
        "traditionally , first - order models such as hidden markov models were used for this task , with recent works suggesting to apply recurrent neural networks instead .",
        "we have developed and trained a convolutional neural network to automatically and simultaneously segment optic disc , fovea and blood vessels .",
        "the image is first decomposed into regions using selective search and these regions are classified as containing textual and / or graphical information using a convolutional neural network .",
        "this set is finally passed to a second convolutional neural network to classify the graphemes , based on a standard corpus .",
        "multiple pcgml methods are covered , including neural networks , long short - term memory ( lstm ) networks , autoencoders , and deep convolutional networks ; markov models , $ n $ - grams , and multi - dimensional markov chains ; clustering",
        "this is the right time to revitalize the area of interpreting how symbols are represented inside neural networks .",
        "attention networks have proven to be an effective approach for embedding categorical inference within a deep neural network .",
        "we experiment with two different classes of structured attention networks : a linear - chain conditional random field and a graph - based parsing model , and describe how these models can be practically implemented as neural network layers .",
        "experiments show that this approach is effective for incorporating structural biases , and structured attention networks outperform baseline attention models on a variety of synthetic and real tasks : tree transduction , neural machine translation , question answering , and natural language inference .",
        "the problem of quantizing the activations of a deep neural network is considered .",
        "we evaluate our embeddings on an image - sentence ranking ( isr ) , a semantic textual similarity ( sts ) , and a neural machine translation ( nmt ) task .",
        "neural machine translation ( nmt ) models are able to partially learn syntactic information from sequential lexical information .",
        "our predictive model is based on bootstrapped neural networks using dropout , allowing it to process raw sensory inputs from high - bandwidth sensors such as cameras .",
        "we introduce a multi - modal neural machine translation model in which a doubly - attentive decoder naturally incorporates spatial visual features obtained using pre - trained convolutional neural networks , bridging the gap between image description and translation .",
        "to solve multi - class problem we map pre - trained category - specific lhm classifiers to a multi - class neural network and adjust the weights with very fast tuning .",
        "a characteristic of opinion recommendation is the reliance of multiple data sources for multi - task joint learning , which is the strength of neural models .",
        "we use a single neural network to model users and products , capturing their correlation and generating customised product representations using a deep memory network , from which customised ratings and reviews are constructed jointly .",
        "in this paper we propose to exploit the automatic quality estimation ( qe ) of asr hypotheses to perform the unsupervised adaptation of a deep neural network modeling acoustic probabilities .",
        "the backbone of our system is a deep convolutional neural network that is not only computationally inexpensive , but also provides state - of - the - art results on several competitive benchmarks .",
        "in this work , we run experiments with different kinds of teacher net - works to enhance the translation performance of a student neural machine translation ( nmt ) network .",
        "the basic concept in neural machine translation ( nmt ) is to train a large neural network that maximizes the translation performance on a given parallel corpus .",
        "our approach uses a recursive neural network and a newly proposed attention mechanism to compute a representation of the text that focuses on salient content , from the perspective of both rst and the task .",
        "deep neural networks ( dnn ) have revolutionized the field of natural language processing ( nlp ) .",
        "convolutional neural network ( cnn ) and recurrent neural network ( rnn ) , the two main types of dnn architectures , are widely explored to handle various nlp tasks .",
        "neural network models are capable of generating extremely natural sounding conversational interactions .",
        "this paper presents a novel , fully data - driven , and knowledge - grounded neural conversation model aimed at producing more contentful responses without slot filling .",
        "this paper proposes an alternative to bi - lstms for this purpose : iterated dilated convolutional neural networks ( id - cnns ) , which have better capacity than traditional cnns for large context and structured prediction .",
        "this paper presents a novel neural machine translation model which jointly learns translation and source - side latent graph representations of sentences .",
        "unlike existing pipelined approaches using syntactic parsers , our end - to - end model learns a latent graph parser as part of the encoder of an attention - based neural machine translation model , so the parser is optimized according to the translation objective .",
        "two perspective , cmac as a neural network and cmac as a table look - up technique are presented .",
        "in this work we propose a novel model based on artificial neural networks to answer questions with multiple answers by exploiting multiple facts retrieved from a knowledge base .",
        "recent research in neural machine translation has largely focused on two aspects ; neural network architectures and end - to - end learning algorithms .",
        "in this paper , we solely focus on the problem of decoding given a trained neural machine translation model .",
        "more specifically , we design an actor that observes and manipulates the hidden state of the neural machine translation decoder and propose to train it using a variant of deterministic policy gradient .",
        "traditional optical - flow - based solutions often fail where flow estimation is challenging , while newer neural - network - based methods that hallucinate pixel values directly often produce blurry results .",
        "a fundamental advantage of neural models for nlp is their ability to learn representations from scratch .",
        "prior work on weight sharing in neural networks has considered it largely as a means of model compression .",
        "in contrast , we treat weight sharing as a flexible mechanism for incorporating prior knowledge into neural models .",
        "focusing on using lexical cues for humor recognition , we systematically compare a newly emerging text classification method based on convolutional neural networks ( cnns ) with a well - established conventional method using linguistic knowledge .",
        "specifically , we propose two variants of the deep conflation model , based on long - short - term memory ( lstm ) recurrent neural network ( rnn ) and convolutional neural network ( cnn ) , respectively .",
        "in recent years , machine learning techniques based on neural networks for mobile computing become increasingly popular .",
        "classical multi - layer neural networks require matrix multiplications at each stage .",
        "in this paper , we propose a new energy efficient neural network with the universal approximation property over space of lebesgue integrable functions .",
        "this network , called , additive neural network , is very suitable for mobile computing .",
        "the neural structure is based on a novel vector product definition , called ef - operator , that permits a multiplier - free implementation .",
        "the proposed additive neural network successfully solves the xor problem .",
        "the experiments on mnist dataset show that the classification performances of the proposed additive neural networks are very similar to the corresponding multi - layer perceptron and convolutional neural networks ( lenet )",
        "however , because different subjects have different neural responses to even the same stimulus , it is very difficult to build a generic erp classifier whose parameters fit all subjects .",
        "in this paper , we enhance the traditional confusion network system combination approach with an additional model trained by a neural network .",
        "we train a local system voting model by a neural network which is based on the words themselves and the combinatorial occurrences of the different system outputs .",
        "this paper presents incremental network quantization ( inq ) , a novel method , targeting to efficiently convert any pre - trained full - precision convolutional neural network ( cnn ) model into a low - precision version whose weights are constrained to be either powers of two or zero .",
        "in recent years , neural networks have enjoyed a renaissance as function approximators in reinforcement learning .",
        "two decades after teasauro ' s td - gammon achieved near top - level human performance in backgammon , the deep reinforcement learning algorithm dqn ( combining q - learning with a deep neural network , experience replay , and a separate target network ) achieved human - level performance in many atari 2600 games .",
        "first , based on the expected energy restricted boltzmann machine ( ee - rbm ) , we propose two activation functions for neural network function approximation in reinforcement learning : the sigmoid - weighted linear ( sil ) unit and its derivative function ( sild1 ) .",
        "several machine learning algorithms ( naive bayes , support vector machine and logistic regression ) alongside deep and convolutional neural networks were utilized in our experiments of sentiment analysis on our health dataset .",
        "end - to - end learning of recurrent neural networks ( rnns ) is an attractive solution for dialog systems ; however , current techniques are data - intensive and require thousands of dialogs to learn simple behaviors .",
        "in this paper we propose two neural embedding models in order to learn continuous concept vectors .",
        "in this work , we propose to train a deep neural network by distributed optimization over a graph .",
        "recently , machine learning methods have provided a broad spectrum of original and efficient algorithms based on deep neural networks ( dnn ) to automatically predict an outcome with respect to a sequence of inputs .",
        "recurrent hidden cells allow these dnn - based models to manage long - term dependencies such as recurrent neural networks ( rnn ) and long short - term memory ( lstm ) .",
        "there has been relatively little attention to incorporating linguistic prior to neural machine translation .",
        "in this paper , we propose a hybrid model , called nmt + rg , that learns to parse and translate by combining the recurrent neural network grammar into the attention - based neural machine translation .",
        "our approach encourages the neural machine translation model to incorporate linguistic prior during training , and lets it translate on its own afterward .",
        "in this paper we explore whether or not deep neural architectures can learn to classify boolean satisfiability ( sat ) .",
        "then , we define a graph representation for boolean formulas in conjunctive normal form , and train neural classifiers over general graph structures called graph neural networks , or gnns , to recognize features of satisfiability .",
        "in a weakly - supervised setting , that is , without problem specific feature engineering , graph neural networks can learn features of satisfiability .",
        "in this paper , we developed a deep neural network ( dnn ) that learns to solve simultaneously the three tasks of the cqa challenge proposed by the semeval - 2016 task 3 , i .",
        "the results on the official challenge test set show that our approach produces higher accuracy and faster convergence rates than the individual neural networks .",
        "in order to improve the reliability of speaker verification systems , we develop a new filter bank based cepstral feature , deep neural network filter bank cepstral coefficients ( dnn - fbcc ) , to distinguish between natural and spoofed speech .",
        "the deep neural network filter bank is automatically generated by training a filter bank neural network ( fbnn ) using natural and synthetic speech .",
        "we introduce a neural architecture for navigation in novel environments .",
        "cmp constructs a top - down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step .",
        "the backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive , but also provide state - of - the - art results on several competitive benchmarks .",
        "the goal of this work is to better understand the nature of neural networks through the examination of these new empirical results .",
        "recent works have been shown effective in using neural networks for chinese word segmentation .",
        "finally , given that insufficient data puts forward higher requirements for feature extraction , we propose a novel neural network which improves feature learning .",
        "besides , we explore an asynchronous parallel method on neural word segmentation to speed up training .",
        "in this paper , we present a novel reordering approach utilizing a neural network and dependency - based embeddings to predict whether the translations of two source words linked by a dependency relation should remain in the same order or should be swapped in the translated sentence .",
        "neural language models predict the next token using a latent representation of the immediate token history .",
        "recently , various methods for augmenting neural language models with an attention mechanism over a differentiable memory have been proposed .",
        "however , conventional attention mechanisms used in memory - augmented neural language models produce a single output vector per time step .",
        "in this paper , we propose a neural language model with a key - value attention mechanism that outputs separate representations for the key and value of a differentiable memory , as well as for encoding the next - word distribution .",
        "this model outperforms existing memory - augmented neural language models on two corpora .",
        "this led to the unexpected main finding that a much simpler model based only on the concatenation of recent output representations from previous time steps is on par with more sophisticated memory - augmented neural language models .",
        "this article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input .",
        "making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black - box classifiers in application areas such as medicine .",
        "while truncated back - propagation through time ( bptt ) is the most popular approach to training recurrent neural networks ( rnns ) , it suffers from being inherently sequential ( making parallelization difficult ) and from truncating gradient flow between distant time - steps .",
        "deep neural networks ( dnns ) have set state of the art results in many machine learning and nlp tasks .",
        "neural attention models have achieved great success in different nlp tasks .",
        "we show that our methods achieve significant improvement over a baseline neural atten - tion model and our results are also compet - itive against state - of - the - art systems that do not use extra linguistic resources .",
        "in this work , we introduce relation networks ( rns ) - a general purpose neural network architecture for object - relation reasoning .",
        "in humans , these two processes underlie fairly different cognitive and neural mechanisms .",
        "our model is a recurrent neural network ( rnn ) with long short - term memory ( lstm ) cells that labels clauses .",
        "recently , neural - network based methods have been proposed for learning this representation from large corpora .",
        "this paper focuses on the development of randomized approaches for building deep neural networks .",
        "deep neural networks are currently among the most commonly used classifiers .",
        "this paper presents a method to automatically segment liver and lesions in ct and mri abdomen images using cascaded fully convolutional neural networks ( cfcns ) enabling the segmentation of a large - scale medical trial or quantitative image analysis .",
        "neural networks have been successfully applied to this problem , and in this paper , we propose an attention - based deep neural network which better incorporates different embeddings of the queries and search results with an attention - based mechanism .",
        "the embeddings are trained with convolutional neural networks or the word2vec model .",
        "in this paper , we propose a novel and elegant solution to \" multi - source neural machine translation \" ( msnmt ) which only relies on preprocessing a n - way multilingual corpus without modifying the neural machine translation ( nmt ) architecture or training procedure .",
        "neural networks are able to process tasks like image recognition ( better than humans ) but in memory aspects are still limited ( by attention mechanism , size ) .",
        "recurrent neural network ( rnn ) and it ' s modified version lstm are able to solve small memory contexts , but as context becomes larger than a threshold , it is difficult to use them .",
        "still , it poses many challenges like , how to train neural networks for discrete memory representation , how to describe long term dependencies in sequential data etc .",
        "most prominent neural architectures for such tasks are memory networks : inference components combined with long term memory and neural turing machines : neural networks using external memory resources .",
        "preliminary results of above neural architectures on simple algorithms ( sorting , copying ) and question answering ( based on story , dialogs ) application are comparable with the state of the art .",
        "we train a recurrent neural network sequence - to - sequence model with attention to select facts and generate textual summaries .",
        "convolutional neural networks ( cnn ) are able to extract higher level features that are invariant to local spectral and temporal variations .",
        "recurrent neural networks ( rnns ) are powerful in learning the longer term temporal context in the audio signals .",
        "we combine these two approaches in a convolutional recurrent neural network ( crnn ) and apply it on a polyphonic sound event detection task .",
        "our architecture is inspired by previously proposed neural - network - based belief - tracking systems .",
        "in this paper , we train a recognition model by optimizing an interpolation between the scrf and ctc losses , where the same recurrent neural network ( rnn ) encoder used for feature extraction for both outputs .",
        "fpga - based hardware accelerators for convolutional neural networks ( cnns ) have obtained great attentions due to their higher energy efficiency than gpus .",
        "finally , we also research new dropout prediction architectures based on deep , fully - connected , feed - forward neural networks and find that ( 4 ) networks with as many as 5 hidden layers can",
        "we present a recurrent neural network based action - value function , and demonstrate its ability to learn how and when to request labels .",
        "advances in natural language processing tasks have gained momentum in recent years due to the increasingly popular neural network methods .",
        "second , paraphrases of logical forms and questions are embedded in a jointly learned vector space using word and character convolutional neural networks .",
        "a neural scoring function is further used to rank and retrieve the most probable logical form ( interpretation ) of a question .",
        "7 % , thus slightly surpassing both the engineered feature scoring baseline , as well as the neural programmer model of [ neelakantan et",
        "we present an encoder - - decoder style neural network to produce a derived form character - by - character , based on its corresponding character - level representation of the base form and the context .",
        "we propose an approach that gives a neural network - - based conversational agent this ability .",
        "we propose a neural network model that jointly learns entity mentions and their context representation to eliminate use of hand crafted features .",
        "we propose a novel progressive learning model which augments the progressive neural network with gated recurrent adapters .",
        "recent studies have shown that deep neural networks ( dnn ) are vulnerable to adversarial samples : maliciously - perturbed samples crafted to yield incorrect model outputs .",
        "reinforcement learning improves accuracy of both labeled and unlabeled dependencies of the stanford neural dependency parser , a high performance greedy parser , while maintaining its efficiency .",
        "deep neural nets have caused a revolution in many classification tasks .",
        "we present a neural network architecture for identifying the type of safety events which is the first step in understanding these narratives .",
        "our proposed model is based on a soft neural attention model to improve the effectiveness of encoding long sequences .",
        "the back - propagation ( bp ) algorithm has been considered the de facto method for training deep neural networks .",
        "in this work , we propose a more biologically plausible paradigm of neural architecture according to biological findings .",
        "our experimental results show that our neural model outperforms two baselines as well as humans solving the same task , suggesting that computational models are able to better capture the underlying semantics of emojis .",
        "a recurrent neural network model of phonological pattern learning is proposed .",
        "the model is a relatively simple neural network with one recurrent layer , and displays biases in learning that mimic observed biases in human learning .",
        "in non - recurrent models , capturing these biases requires the use of alpha features or some other representation of repeated features , but with a recurrent neural network , these elaborations are not necessary .",
        "the probability of a segmented sequence is calculated as the product of the probabilities of all its segments , where each segment is modeled using existing tools such as recurrent neural networks .",
        "recently , there was a paradigm shift towards using word embeddings and deep neural networks , where the use of surface features is very limited .",
        "in this paper , we show that a simple svm model with surface features outperforms more complex neural models for detecting anaphoric mentions .",
        "deep neural network ( dnn ) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene .",
        "in this paper , we propose to use a convolutional neural network ( cnn ) to extract robust features from mel - filter banks ( mfbs ) , spectrograms or even raw waveforms for audio tagging .",
        "gated recurrent unit ( gru ) based recurrent neural networks ( rnns ) are then cascaded to model the long - term temporal structure of the audio signal .",
        "especially , convolutional neural networks ( cnns ) have been revisited in asr recently .",
        "experimental results show that our proposed single system rcnn - ctc can achieve the lowest word error rate ( wer ) on wsj and tencent chat data sets , compared to several widely used neural network systems in asr .",
        "we present deep voice , a production - quality text - to - speech system constructed entirely from deep neural networks .",
        "deep voice lays the groundwork for truly end - to - end neural speech synthesis .",
        "for the segmentation model , we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification ( ctc ) loss .",
        "by using a neural network for each component , our system is simpler and more flexible than traditional text - to - speech systems , where each component requires laborious feature engineering and extensive domain expertise .",
        "we describe a rationalization technique that uses neural machine translation to translate internal state - action representations of the autonomous agent into natural language .",
        "modern parallel computing systems provide the capability to reduce the required training time of deep neural networks .",
        "in this paper , we present our parallelization scheme for training convolutional neural networks ( cnn ) named controlled hogwild with arbitrary order of synchronization ( chaos ) .",
        "we consider a neural net with one hidden layer and a convolutional structure with no overlap and a relu activation function .",
        "to the best of our knowledge , this is the first global optimality guarantee of gradient descent on a convolutional neural network with relu activations .",
        "on the theoretical side , we use results from statistical physics to carry out critical point calculations in feed - forward / fully connected networks , while on the experimental side we set out to find traces of criticality in deep neural networks .",
        "fixed - point optimization of deep neural networks plays an important role in hardware based design and low - power implementations .",
        "many deep neural networks show fairly good performance even with 2 - or 3 - bit precision when quantized weights are fine - tuned by retraining .",
        "the experiments are conducted for feed - forward deep neural networks ( ffdnns ) , convolutional neural networks ( cnns ) , and recurrent neural networks ( rnns ) .",
        "we introduce deepnat , a 3d deep convolutional neural network for the automatic segmentation of neuroanatomy in t1 - weighted magnetic resonance images .",
        "multi - task learning ( mtl ) in deep neural networks for nlp has recently received increasing interest due to some compelling benefits , including its potential to efficiently regularize models and to reduce the need for labeled data .",
        "this architecture , called the neural map , uses a spatially structured 2d memory image to learn to store arbitrary information about the environment over long time lags .",
        "we demonstrate empirically that the neural map surpasses previous drl memories on a set of challenging 2d and 3d maze environments and show that it is capable of generalizing to environments that were not seen during training .",
        "here we describe a neural controller system which learns how to sequentially compose the these primitive differentiable operations to solve reasoning tasks , and in particular , to perform knowledge base completion .",
        "in this paper , we propose an asymmetric tri - training method for unsupervised domain adaptation , where we assign pseudo - labels to unlabeled samples and train neural networks as if they are true labels .",
        "however , it is difficult to create a large dataset to train the ability of deep neural network models ( dnns ) .",
        "in this paper we propose the expose neural network , which uses a deep learning approach we have developed to take generic , raw short character strings as input ( a common case for security inputs , which include artifacts like potentially malicious urls , file paths , named pipes , named mutexes , and registry keys ) , and learns to simultaneously extract features and classify using character - level embeddings and convolutional neural network .",
        "in this paper , we propose a novel method to enrich the representation provided to the output layer of feedforward neural networks in the form of an auto - clustering output layer ( acol ) which enables the network to naturally create sub - clusters under the provided main class la - bels .",
        "in addition , a novel regularization term is introduced which allows acol to encourage the neural network to reveal its own explicit clustering objective .",
        "to address the first challenge , we present the scaffolding network , an attention - based neural network agent that can reason over a dynamic memory .",
        "deep neural networks require a large amount of labeled training data during supervised learning .",
        "recently low displacement rank ( ldr ) matrices , or so - called structured matrices , have been proposed to compress large - scale neural networks .",
        "empirical results have shown that neural networks with weight matrices of ldr matrices , referred as ldr neural networks , can achieve significant reduction in space and computational complexity while retaining high accuracy .",
        "first , we prove the universal approximation property of ldr neural networks with a mild condition on the displacement operators .",
        "we then show that the error bounds of ldr neural networks are as efficient as general neural networks with both single - layer and multiple - layer structure .",
        "finally , we propose back - propagation based training algorithm for general ldr neural networks .",
        "in contrast , we investigate the effectiveness of a single neural network for end - to - end long - term prediction of mechanical phenomena .",
        "we evaluate on two tasks : one supervised learning task , using a neural network to recognise users ' current activity from accelerometer traces ; and one unsupervised learning task , identifying topics in a large set of documents .",
        "sophisticated gated recurrent neural network architectures like lstms and grus have been shown to be highly effective in a myriad of applications .",
        "we also benchmark a set of simple baseline machine learning models suited for the tasks ( including logistic regression , convolutional neural networks and recurrent neural networks ) .",
        "in one particularly standout example , we show that the method is capable of learning to play sudoku given just input and output games , with no a priori information about the rules of the game ; this task is virtually impossible for other neural network architectures that we have experimented with , and highlights the representation capabilities of our approach .",
        "when training neural networks , the use of synthetic gradients ( sg ) allows layers or modules to be trained without update locking - without waiting for a true error gradient to be backpropagated - resulting in decoupled neural interfaces ( dnis ) .",
        "this unlocked ability of being able to update parts of a neural network asynchronously and with only local information was demonstrated to work empirically in jaderberg et al ( 2016 ) .",
        "we show that the incorporation of sgs does not affect the representational strength of the learning system for a neural network , and prove the convergence of the learning system for linear and deep linear models .",
        "the learned vector is then incorporated into neural attention models , which allows learning the mapping of syntactic structures between question and context pairs .",
        "we introduce a new metric called neural net distance for which generalization does occur .",
        "we suggest analyzing neural networks through the prism of space constraints .",
        "in this paper we describe how we use mixing complexity to obtain new results on what can and cannot be learned using neural networks .",
        "in this work we propose the first wii approach based upon deep convolutional neural networks ( cnns ) .",
        "in deep learning the ubiquitous architecture used for this task is the siamese neural network which maps each entity to a representation through a learnable function and expresses similarity through the distances among the entities in the representation space .",
        "we develop a novel neural model called attentive recurrent comparators ( arcs ) that dynamically compares two entities and test the model extensively on the omniglot dataset .",
        "in the challenging task of one - shot learning on the same dataset , an arc based model achieves the first super - human performance for a neural method with an error rate of 1 .",
        "in our experiments with deep neural networks , we obtained better performance compared to the popular stochastic gradient algorithms .",
        "despite their great success , there is still no com - prehensive theoretical understanding of learning with deep neural networks ( dnns ) or their in - ner organization .",
        "deep neural networks have been successfully applied in applications with a large amount of labeled data .",
        "however , there are major drawbacks of the neural networks that are related to rapid generalization with small data and continual learning of new concepts without forgetting .",
        "we propose a new neural generative model which combines variational auto - encoders and holistic attribute discriminators for effective imposition of semantic structures .",
        "the efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks .",
        "this paper presents an end - to - end learning framework for task - completion neural dialogue systems , which leverages supervised and reinforcement learning with various deep - learning models .",
        "as training data rapid growth , large - scale parallel training with multi - gpus cluster is widely applied in the neural network model learning currently .",
        "we present a new approach that applies exponential moving average method in large - scale parallel training of neural network model .",
        "fully - connected feed - forward neural networks ( dnns ) and deep unidirectional long short - term memory ( lstm ) recurrent neural networks ( rnns ) are successfully trained with proposed method for large vocabulary continuous speech recognition on shenma voice search data in mandarin .",
        ", robotics control , sequential prediction ) with deep neural network models .",
        "using both feedforward and recurrent neural network predictors , we present stochastic gradient procedures on a sequential prediction task , dependency - parsing from raw image data , as well as on various high dimensional robotics control problems .",
        "neural networks have proven effective at solving difficult problems but designing their architectures can be challenging , even for image classification problems alone .",
        "on the other hand , it is comparatively easy to build discriminative models on top of complex states such as images using standard deep neural networks .",
        "we present a new distributed representation in deep neural nets wherein the information is represented in native form as a matrix .",
        "this differs from current neural architectures that rely on vector representations .",
        "deep convolutional neural networks ( cnn ) have shown their good performances in many computer vision tasks .",
        "we frame the problem in the context of unsupervised domain adaptation and apply an adversarial framework to train a deep neural network with the additional objective to align features across domains .",
        "in this work , we build a generic architecture of convolutional neural networks to discover empirical properties of neural networks .",
        "recently , the end - to - end approach that learns hierarchical representations from raw data using deep convolutional neural networks has been successfully explored in the image , text and speech domains .",
        "to this end , we propose sample - level deep convolutional neural networks which learn representations from very small grains of waveforms ( e .",
        "considering this issue , we propose a convolutional neural networks ( cnn ) - based architecture that embraces multi - level and multi - scaled features .",
        "deep neural network is difficult to train and this predicament becomes worse as the depth increases .",
        "equipped with these two ingredients , we propose several novel optimization solutions that can be utilized for training a specific - structured ( repetitively triple modules of conv - bnrelu ) extremely deep convolutional neural network ( cnn ) without any shortcuts / identity mappings from scratch .",
        "we reinterpret multiplicative noise in neural networks as auxiliary random variables that augment the approximate posterior in a variational setting for bayesian neural networks .",
        "in experiments we show that with this new approximation we can significantly improve upon classical mean field for bayesian neural networks on both predictive accuracy as well as predictive uncertainty .",
        "we propose neural episodic control : a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them .",
        "in this work , we propose a novel metric learning method to evaluate distance between graphs that leverages the power of convolutional neural networks , while exploiting concepts from spectral graph theory to allow these operations on irregular graphs .",
        "although little is known , the author ' s group has propounded this framework for around 20 years and already has shown a variety of functions that emerge in a neural network ( nn ) through rl .",
        "data noising is an effective technique for regularizing neural network models .",
        "in this paper , we derive a connection between input noising in neural network language models and smoothing in $ n $ - gram models .",
        "training recurrent neural networks to model long term dependencies is difficult .",
        "we introduce a model that encodes such graphs as explicit memory in recurrent neural networks , and use it to model coreference relations in text .",
        "the performance of these trained policies are competitive with state of the art results , obtained with more elaborate parameterizations such as fully connected neural networks .",
        "deep neural networks coupled with fast simulation and improved computation have led to recent successes in the field of reinforcement learning ( rl ) .",
        "we represent the policy as a mixture of actor - critic neural network , which consists of n control policies and the corresponding value functions .",
        "taking advantage of specialised models such as bayesian convolutional neural networks , we demonstrate our active learning techniques with image data , obtaining a significant improvement on existing active learning approaches .",
        "we prove new upper and lower bounds on the vc - dimension of deep neural networks with the relu activation function .",
        "this paper develops a general framework for learning interpretable data representation via long short - term memory ( lstm ) recurrent neural networks over hierarchal graph structures .",
        "deep convolutional neural network ( cnn ) inference requires significant amount of memory and computation , which limits its deployment on embedded devices .",
        "despite recent advances , memory - augmented deep neural networks are still limited when it comes to life - long and one - shot learning , especially in remembering rare events .",
        "we demonstrate that this approach leads to state - of - the - art performance on a few - shot image classification benchmark , produces good results on few - shot regression , and accelerates fine - tuning for policy gradient reinforcement learning with neural network policies .",
        "training deep neural networks is a highly nontrivial task , involving carefully selecting appropriate training algorithms , scheduling step sizes and tuning other hyperparameters .",
        "in stark contrast , biological neural networks continually adapt to changing domains , and solve a diversity of tasks simultaneously .",
        "in this study , we take a first step toward bringing this biological complexity into artificial neural networks .",
        "on linear models and convolutional neural networks , we demonstrate that influence functions are useful for many different purposes : to understand model behavior , debug models and detect dataset errors , and even identify and exploit vulnerabilities to adversarial training - set attacks .",
        "the field of speech recognition is in the midst of a paradigm shift : end - to - end neural networks are challenging the dominance of hidden markov models as a core technology .",
        "we propose a version of graph convolutional networks ( gcns ) , a recent class of multilayer neural networks operating on graphs , suited to modeling syntactic dependency graphs .",
        "this paper proposes a new route for applying the generative adversarial nets ( gans ) to nlp tasks ( taking the neural machine translation as an instance ) and the widespread perspective that gans can ' t work well in the nlp area turns out to be unreasonable .",
        "we propose an approach wherein the outputs of multiple neural network classifiers are combined using a supervised machine learning model .",
        "in this paper , we propose a deep neural networks ( dnn ) based pbe model called neural programming by example ( npbe ) , which can learn from input - output strings and induce programs that solve the string manipulation problems .",
        "our npbe model has four neural network based components : a string encoder , an input - output analyzer , a program generator , and a symbol selector .",
        "deep learning with convolutional neural networks ( deep convnets ) has revolutionized computer vision through end - to - end learning , i .",
        "in this paper we show how the performance of tweet clustering can be improved by leveraging character - based neural networks .",
        "this paper presents a study of employing ranking svm and convolutional neural network for two missions : legal information retrieval and question answering in the competition on legal information extraction / entailment .",
        "for the legal question answering task , additional statistical features from information retrieval task integrated into convolutional neural network contribute to higher accuracy .",
        "current deep learning approaches have been very successful using convolutional neural networks ( cnn ) trained on large graphical processing units ( gpu ) - based computers .",
        "towards achieving them , we study convolutional recurrent neural networks ( crnns ) .",
        "this paper describes a neural - network model which performed competitively ( top 6 ) at the semeval 2017 cross - lingual semantic textual similarity ( sts ) task .",
        "our system employs an attention - based recurrent neural network model that optimizes the sentence similarity .",
        "first , we propose a convolutional neural network architecture for geometric matching .",
        "in this paper , we demonstrate that such data can be automatically extracted by deep neural networks ( aka deep learning ) , which is a cutting - edge type of artificial intelligence .",
        "in particular , we use the existing human - labeled images from the snapshot serengeti dataset to train deep convolutional neural networks for identifying 48 species in 3 .",
        "we train neural networks that automatically identify animals with over 92 % accuracy .",
        "in this paper we aim at filling this gap by comparing four popular parallel training algorithms in speech recognition , namely asynchronous stochastic gradient descent ( asgd ) , blockwise model - update filtering ( bmuf ) , bulk synchronous parallel ( bsp ) and elastic averaging stochastic gradient descent ( easgd ) , on 1000 - hour librispeech corpora using feed - forward deep neural networks ( dnns ) and convolutional , long short - term memory , dnns ( cldnns ) .",
        "taking advantage of the recent success of unsupervised learning in deep neural networks , we propose an end - to - end learning framework that is able to extract more robust multi - modal representations across domains .",
        "in this paper , we introduce two different convolutional neural network architectures for whole slide image segmentation to accurately identify the tissue sections .",
        "we propose and systematically evaluate three strategies for training dynamically - routed artificial neural networks : graphs of learned transformations through which different input signals may take different paths .",
        "this is achieved using recurrent neural networks ( rnns ) by forcing separated frames belonging to the same speaker to be aligned to the same output layer during training .",
        "recent papers have shown that neural networks obtain state - of - the - art performance on several different sequence tagging tasks .",
        "in this paper we explore the problem of transfer learning for neural sequence taggers , where a source task with plentiful annotations ( e .",
        "this makes it difficult to directly train a deep neural network for semantic segmentation , because it will be prone to overfitting .",
        "to cope with this , deep learning models typically use convolutional neural networks pre - trained on large - scale image classification datasets , which are then fine - tuned for semantic segmentation .",
        "in this paper , we developed two deep neural networks for semantic segmentation of multispectral remote sensing imagery .",
        "in this paper , we introduce recurrent collective classification ( rcc ) , a variant of ica analogous to recurrent neural network prediction .",
        "in the past few years , performance in image caption generation has seen significant improvement through the adoption of recurrent neural networks ( rnn ) .",
        "in machine learning and neuroscience , certain computational structures and algorithms are known to yield disentangled representations without us understanding why , the most striking examples being perhaps convolutional neural networks and the ventral stream of the visual cortex in humans and primates .",
        "for the step placement task , we combine recurrent and convolutional neural networks to ingest spectrograms of low - level audio features to predict steps , conditioned on chart difficulty .",
        "on these features , we apply five models : gaussian mixture model ( gmm ) , deep neural network ( dnn ) , recurrent neural network ( rnn ) , convolutional deep neural net - work ( cnn ) and i - vector .",
        "to our knowledge , this is the first successful transfer of a deep neural network trained only on simulated rgb images ( without pre - training on real images ) to the real world for the purpose of robotic control .",
        "we started with simple machine learning methods to estimate basic prediction performance and moved further by applying advanced methods based on shallow and deep neural networks .",
        "lstnet uses the convolution neural network ( cnn ) to extract short - term local dependency patterns among variables , and the recurrent neural network ( rnn ) to discover long - term patterns and trends .",
        "in this paper , we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task - oriented neural dialogue system in a reinforcement learning based setting .",
        "here the fact that multiple smiles represent the same molecule is explored as a technique for data augmentation of a molecular qsar dataset modeled by a long short term memory ( lstm ) cell based neural network .",
        "recurrent neural networks ( rnns ) , especially long short - term memory ( lstm ) rnns , are effective network for sequential task like speech recognition .",
        "this paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2d and 3d face alignment datasets .",
        "( c ) following that , we train a neural network for 3d face alignment and evaluate it on the newly introduced ls3d - w .",
        "large - scale deep convolutional neural networks ( cnns ) are widely used in machine learning applications .",
        "recently , two competing approaches for automatic program learning have received significant attention : ( 1 ) neural program synthesis , where a neural network is conditioned on input / output ( i / o ) examples and learns to generate a program , and ( 2 ) neural program induction , where a neural network generates new outputs directly using a latent program representation .",
        "moreover , using automatic phoneme - like tokenizations , we demonstrate that a convolutional neural network based framework for learning spoken document representations provides competitive performance compared to a standard bag - of - words representation , as evidenced by comprehensive topic id evaluations on both single - label and multi - label classification tasks .",
        "in this paper we analyze the gate activation signals inside the gated recurrent neural networks , and find the temporal structure of such signals is highly correlated with the phoneme boundaries .",
        "we develop an autoregressive convolutional neural network that learns to iteratively generate multiple frames .",
        "in this paper , we formulate the task as a matching problem of utterances before and after a certain decision point ; we propose a hierarchical recurrent neural network ( rnn ) with static sentence - level attention .",
        "experimental results show that neural networks consistently achieve better performance than feature - based approaches , and that our attention - based model significantly outperforms non - attention neural networks .",
        "we report the results of our classification - based machine translation model , built upon the framework of a recurrent neural network using gated recurrent units .",
        "the compositional kernels we use are inspired by the structure of convolutional neural networks and kernels .",
        "to address both concerns , we propose a novel architecture based on a network of deep neural networks , where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them .",
        "feedforward neural network ( fnn ) - based language models estimate the probability of the next word based on the history of the last n words , whereas recurrent neural networks ( rnn ) perform the same task based only on the last word and some context information that cycles in the network .",
        "extensive experiments conducted on the penn treebank ( ptb ) and the large text compression benchmark ( ltcb ) corpus showed a significant reduction of the perplexity when compared to state - of - the - art feedforward as well as recurrent neural network architectures .",
        "in state - of - the - art neural machine translation , an attention mechanism is used during decoding to enhance the translation .",
        "we propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the visual7w dataset .",
        "we start with lstm - encoding of input questions and answers ; build on this with context generation by lstm - encodings of neural image and question representations and attention over images ; and evaluate the diversity and predictive power of our models and the ensemble thereof .",
        "concretely , we use an image - to - words multi - label visual classifier to tag images with soft textual labels , and then train a neural network to map from the speech to these soft targets .",
        "deep convolutional neural networks are generally regarded as robust function approximators .",
        "here we explore the robustness of convolutional neural networks to perturbations to the internal weights and architecture of the network itself .",
        "to address this concern , a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network .",
        "catastrophic forgetting is a problem which refers to losing the information of the first task after training from the second task in continual learning of neural networks .",
        "to resolve this problem , we propose the incremental moment matching ( imm ) , which uses the bayesian neural network framework .",
        "imm assumes that the posterior distribution of parameters of neural networks is approximated with gaussian distribution and incrementally matches the moment of the posteriors , which are trained for the first and second task , respectively .",
        "to tackle the above problems , in this paper , we utilize the rich framework of ( temporal ) point processes to model event data and timely update its intensity function by the synergic twin recurrent neural networks ( rnns ) .",
        "furthermore , to enhance the interpretability of the model , the attention mechanism for the neural point process is introduced .",
        "large - scale deep neural networks ( dnn ) have been successfully used in a number of tasks from image recognition to natural language processing .",
        "with different information content ) such that the neural net can better learn using less bits .",
        "we model inference as a neural network and incorporate beacon placement as a differentiable neural layer .",
        "encouraged by the success of machine learning , and in particular convolutional neural networks , we propose to learn a matching function which directly maps multiple image patches to a scalar similarity score .",
        "learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling .",
        "the delta recurrent neural network ( delta - rnn ) framework is a simple and high - performing design that unifies previously proposed gated neural models .",
        "for retrieval we introduce a hand - crafted model and a neural model for ranking relevant articles .",
        "when a neural language model is used for caption generation , the image information can be fed to the neural network either by directly incorporating it in a recurrent neural network - - conditioning the language model by injecting image features - - or in a layer following the recurrent neural network - - conditioning the language model by merging the image features .",
        "furthermore , this suggests that recurrent neural networks should not be viewed as actually generating text , but only as encoding it for prediction in a subsequent layer .",
        "we survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition .",
        "especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real - life har application .",
        "multiple different approaches of generating adversarial examples have been proposed to attack deep neural networks .",
        "we efficiently train feed - forward neural networks in a self - supervised manner to generate adversarial examples against a target network or set of networks .",
        "the model , which is trained in a weakly supervised fashion , measures the similarity between customer questions and agent answers using a dual encoder network , a siamese - like neural network architecture .",
        "technically , we follow the current best practice and implement a convolutional neural network ( cnn ) , which is trained to carry out the end - to - end mapping from an entire rgb image to the corresponding hyperspectral image of",
        "artificial neural networks ( anns ) are trained to map damage fingerprints to damage characteristic parameters .",
        "frequency response function data after being reduced in size using pca is fed to individual neural networks to localize and predict the severity of damage on the structure .",
        "we analyze the performance of both baseline and state - of - the - art vqa models , including multi - modal compact bilinear pooling ( mcb ) , neural module networks , and recurrent answering units .",
        "in this paper , we propose a real time collective anomaly detection model based on neural network learning and feature operating .",
        "normally a long short term memory recurrent neural network ( lstm rnn ) is trained only on normal data and it is capable of predicting several time steps ahead of an input .",
        "we demonstrate superior results by a system which combines recurrent neural networks with convolutional neural networks in a voting approach .",
        "the gated - recurrent - unit - based neural networks are particularly well - suited to distinguish actions based on long - term information from optical tracking data ; the 3d - cnns focus more on detailed , recent information from video data .",
        "in this model , a preliminary trained convolutional neural network is essentially integrated with the adversarial framework , which can drive the generated textures to possess given perceptual attributes .",
        "one of them , the item response theory , is a well established method , while the other two , bayesian and neural networks , are new in the area of educational testing .",
        "they are based on the item response theory , bayesian networks , and neural networks .",
        "we propose two methods , which are based on recurrent neural networks , to learn the similarity function .",
        "previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima .",
        "however , the practical observation is that , at least for the most successful deep convolutional neural networks ( dcnns ) for visual processing , practitioners can always increase the network size to fit the training data ( an extreme example would be [ 1 ] ) .",
        "in visual recognition tasks , convolutional neural networks ( cnns ) have been successful to learn generalized feature extractors with shared parameters over the spatial domain .",
        "within hadid , a top - down hierarchical classification is applied , in which we use deep neural networks ( dnns ) method to build a local classifier for every parent node into the hierarchy dialect structure .",
        "in this paper , we study the use of recurrent neural networks ( rnns ) for modeling and forecasting time series .",
        "the proposed approach builds sentence representations using learned embeddings based on neural network .",
        "the results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance .",
        "we present a model of pragmatic referring expression interpretation in a grounded communication task ( identifying colors from descriptions ) that draws upon predictions from two recurrent neural network classifiers , a speaker and a listener , unified by a recursive pragmatic reasoning framework .",
        "an hybrid of a hidden markov model ( hmm ) and a deep neural network ( dnn ) is considered .",
        "biological neural networks are systems of extraordinary computational capabilities shaped by evolution , development , and lifetime learning .",
        "inspired by such intricate natural phenomena , evolved plastic artificial neural networks ( epanns ) use simulated evolution in - silico to breed plastic neural networks , artificial systems composed of sensors , outputs , and plastic components that change in response to sensory - output experiences in an environment .",
        "current scientific and technological advances in artificial neural networks are now setting the conditions for radically new approaches and results .",
        "in particular , the limitations of hand - designed structures and algorithms currently used in most deep neural networks could be overcome by more flexible and innovative solutions .",
        "though neural networks have seen success in computer vision and natural language processing , they have not been as useful in stock market trading .",
        "to demonstrate the applicability of a neural network in stock trading , we made a single - layer neural network that recommends buying or selling shares of a stock by comparing the highest high of 10 consecutive days with that of the next 10 days , a process repeated for the stock ' s year - long historical data .",
        "a chi - squared analysis found that the neural network can accurately and appropriately decide whether to buy or sell shares for a given stock , showing that a neural network can make simple decisions about the stock market .",
        "deep neural perception and control networks are likely to be a key component of self - driving vehicles .",
        "in this paper , we present midinet , a deep convolutional neural network ( cnn ) based generative adversarial network ( gan ) that is intended to provide a general , highly adaptive network structure for symbolic - domain music generation .",
        "while recent neural encoder - decoder models have shown great promise in modeling open - domain conversations , they often generate dull and generic responses .",
        "we return to an idea by langford and caruana ( 2001 ) , who used pac - bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two - layer two - hidden - unit neural networks via a sensitivity analysis .",
        "by optimizing the pac - bayes bound directly , we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples .",
        "our approach combines a search component based on bigram hashing and tf - idf matching with a multi - layer recurrent neural network model trained to detect answers in wikipedia paragraphs .",
        "we present a novel cross - lingual transfer method for paradigm completion , the task of mapping a lemma to its inflected forms , using a neural encoder - decoder model , the state of the art for the monolingual task .",
        "ensembles of neural networks are known to be much more robust and accurate than individual networks .",
        "in this paper , we propose a method to obtain the seemingly contradictory goal of ensembling multiple neural networks at no additional training cost .",
        "we achieve this goal by training a single neural network , converging to several local minima along its optimization path and saving the model parameters .",
        "we propose a feature imitation framework in which an implicit relation network is driven to learn from another neural network with access to connectives , and thus encouraged to extract similarly salient features for accurate classification .",
        "recent works have proved that synthetic parallel data generated by existing translation models can be an effective solution to various neural machine translation ( nmt ) issues .",
        "recurrent neural network ( rnn ) with long - short - term memory ( lstm ) only treats sentence as sequence data and can not utilize higher level syntactic information .",
        "to overcome this , we explore several auxiliary tasks , including semantic super - sense tagging and identification of multi - word expressions , and cast the task as a multi - task learning problem with deep recurrent neural networks .",
        "the input to a neural sequence - to - sequence model is often determined by an up - stream system , e .",
        "we showcase this method for two challenging applications : image compression and neural network compression .",
        "increasing the capacity of recurrent neural networks ( rnn ) usually involves augmenting the size of the hidden layer , resulting in a significant increase of computational cost .",
        "an alternative is the recurrent neural tensor network ( rntn ) , which increases capacity by employing distinct hidden layer weights for each vocabulary word .",
        "in this paper , we introduce restricted recurrent neural tensor networks ( r - rntn ) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words .",
        "recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence - to - sequence problems .",
        "more specifically , our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company .",
        "deep neural networks ( dnns ) have advanced the state - of - the - art in a variety of machine learning tasks and are deployed in increasing numbers of products and services .",
        "in this work , we propose dynamic variable effort deep neural networks ( dyvedeep ) to reduce the computational requirements of dnns during inference .",
        "although deep neural networks ( dnns ) have achieved great success in many computer vision tasks , recent studies have shown they are vulnerable to adversarial examples .",
        "luckily , several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature .",
        "in this paper , we reformulate existing models into a single common framework we call message passing neural networks ( mpnns ) and explore additional novel variations within this framework .",
        "regarding integration , we note that the most impactful recent contributions have been made possible through the integration of recent machine learning methods ( based in particular on deep learning and recurrent neural networks ) with more traditional ones ( e .",
        "it contains practical advice for those interested in testing the use of deep neural networks on applications that are novel for deep learning .",
        "in this paper , we propose two machine learning methods for automatic measurement of pre - aspiration duration : feedforward neural network , which works at the frame level ; and structured prediction model , which relies on manually designed feature functions , and works at the segment level .",
        "the generative model can use neural networks to handle both discrete and continuous latent variables to exploit various features of data .",
        "informed by previous work in semantic parsing , in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge .",
        "in this work , we propose to apply the neural encoder - decoder model to generate meaningful and diverse questions from natural language sentences .",
        "we conduct a preliminary study on neural question generation from text with the squad dataset , and the experiment results show that our method can produce fluent and diverse questions .",
        "is a powerful type of neural network that can capture long range dependencies and nonlinear dynamics .",
        "in this paper we present a novel application of software defined radio ( sdr ) based on lstm recurrent neural networks to decode audio signal from its noisy frequency demodulated version .",
        "an ensemble combining our neural semantic parser with an existing , traditional parser , yields a small gain in performance .",
        "we explored three different deep learning approaches : a character - level convolutional neural network ( cnn ) , a stacked learner with an mlp meta - classifier , and an attention based bi - lstm .",
        "however , we erroneously trained 2 out of 3 neural nets ( the stacker and the cnn ) on only roughly 15 % of the full data , namely , the original development set .",
        "for example , a recent model , deepconn , uses neural nets to learn one latent representation for the text of all reviews written by a target user , and a second latent representation for the text of all reviews for a target item , and then combines these latent representations to obtain state - of - the - art performance on recommendation tasks .",
        "based on the two - step framework , we implement a novel constrained neural generation model to simplify sentences given simplified words .",
        "the method exploits the temporal structure of a speech signal and more specifically , it trains deep neural networks ( dnns ) to discriminate temporal events obtained by uniformly segmenting the signal without using any label information , in contrast to conventional dnn based bn feature extraction methods that train dnns using labeled data to discriminate speakers or passphrases or phones or a combination of them .",
        "this paper explores the use of pyramid vector quantization ( pvq ) to reduce the computational cost for a variety of neural networks ( nns ) while , at the same time , compressing the weights that describe them .",
        "the purported \" black box \" ' nature of neural networks is a barrier to adoption in applications where interpretability is essential .",
        "here we present deeplift ( deep learning important features ) , a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input .",
        "we introduce an approach to implicit semantic role labeling ( isrl ) based on a recurrent neural semantic frame model that learns probability distributions over sequences of explicit semantic frame arguments .",
        "the theory of random vector functional link network ( rvfln ) has provided a breakthrough in the design of neural networks ( nns ) since it conveys solid theoretical justification of randomized learning .",
        "together with the proper choice of graph coarsening , we explore constructing deep neural networks for graph classification .",
        "to efficiently pre - train a large span of skills , we use stochastic neural networks combined with an information - theoretic regularizer .",
        "this complementarity is exploited in a new convolutional neural network ( cnn ) framework , which proposes the use of semantics as constraints for recognition .",
        "for computer vision applications , prior works have shown the efficacy of reducing the numeric precision of model parameters ( network weights ) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters .",
        "it has been believed that stochastic feedforward neural networks ( sfnns ) have several advantages beyond deterministic deep neural networks ( dnns ) : they have more expressive power allowing multi - modal mappings and regularize better due to their stochastic nature .",
        "ensembling is a well - known technique in neural machine translation ( nmt ) .",
        "instead of a single neural net , multiple neural nets with the same topology are trained separately , and the decoder generates predictions by averaging over the individual models .",
        "first , we show that the ensemble can be unfolded into a single large neural network which imitates the output of the ensemble system .",
        "as the first step to model emotional state of a person , we build sentiment analysis models with existing deep neural network algorithms and compare the models with psychological measurements to enlighten the relationship .",
        "the result shows that although cnn performed the best among other deep neural network algorithms ( lstm , gru ) , its results are not related to the psychological state .",
        "neural machine translation ( mt ) models obtain state - of - the - art performance while maintaining a simple , end - to - end architecture .",
        "in this work , we analyze the representations learned by neural mt models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part - of - speech and morphological tagging tasks .",
        "our data - driven , quantitative evaluation sheds light on important aspects in the neural mt system and its ability to capture word structure .",
        "although neural networks are well suited for sequential transfer learning tasks , the catastrophic forgetting problem hinders proper integration of prior knowledge .",
        "surprisingly , we find that first distilling a human made rule based sentiment engine into a recurrent neural network and then integrating the knowledge with the target task data leads to a substantial gain in generalization performance .",
        "we also discuss first submissions to the benchmark that use deep convolutional neural networks ( cnns ) as a work horse , which already show remarkable performance improvements over state - of - the - art .",
        "recent advances in deep neural networks have substantially improved the performance of this task .",
        "in order to adopt deep learning for ad - hoc information retrieval , it is essential to establish suitable representations of query - document pairs and to design neural architectures that are able to digest such representations .",
        "existing methods of neural word embeddings , including sngs , are multi - pass algorithms and thus cannot perform incremental model update .",
        "we propose a simple yet effective text - based user geolocation model based on a neural network with one hidden layer , which achieves state of the art performance over three twitter benchmark geolocation datasets , in addition to producing word and phrase embeddings in the hidden layer that we show to be useful for detecting dialectal terms .",
        "convolutional neural networks - cnns - on single images ) while only very few studies exist involving temporal deep learning approaches ( i .",
        "e recurrent neural networks - rnns ) to deal with remote sensing time series .",
        "in this letter we evaluate the ability of recurrent neural networks , in particular the long - short term memory ( lstm ) model , to perform land cover classification considering multi - temporal spatial data derived from a time series of satellite images .",
        "the obtained results show that recurrent neural networks are competitive compared to state - of - the - art classifiers , and may outperform classical approaches in presence of low represented and / or highly mixed classes .",
        "in this study we determined neural network weights and biases by imperialist competitive algorithm ( ica ) in order to train network for predicting earthquake intensity in richter .",
        "the studied neural network has two hidden layer : its first layer has 16 neurons and the second layer has 24 neurons .",
        "in this work , we propose class - enhanced attentive response ( clear ) : an approach to visualize and understand the decisions made by deep neural networks ( dnns ) given a specific input .",
        "in this paper , we use the framework of neural machine translation to learn joint sentence representations across different languages .",
        "extracting per - frame features using convolutional neural networks for real - time processing of video data is currently mainly performed on powerful gpu - accelerated workstations and compute clusters .",
        "we then present a novel neural synthesis algorithm to search for programs in the dsl that are consistent with a given set of examples .",
        "the search algorithm uses recently introduced neural architectures to encode input - output examples and to model the program search in the dsl .",
        "in this paper , we present an entity - drivenrecursive deep modelfor the chinese discourse coherence evaluation based on current english discourse coherenceneural network model .",
        "specifically , to overcome the shortage of identifying the entity ( nouns ) overlap across sentences in the currentmodel , our combined modelsuccessfully investigatesthe entities information into the recursive neural network freamework .",
        "in this paper , we propose a cross - sentence context - aware approach and investigate the influence of historical contextual information on the performance of neural machine translation ( nmt ) .",
        "neural sequence - to - sequence models have provided a viable new approach for abstractive text summarization ( meaning they are not restricted to simply selecting and rearranging passages from the original text ) .",
        "while neural approaches can achieve ( almost ) human - like accuracy for certain tasks and conditions , they often are sensitive to small changes in the input such as non - canonical input ( e .",
        "moreover , we empirically evaluate the robustness of different models ( convolutional neural networks , recurrent neural networks , non - neural models ) , different basic units ( characters , byte pair encoding units ) , and different nlp tasks ( morphological tagging , machine translation ) .",
        "we show that by modifying the training objective of a competitive neural coreference system , we obtain a substantial gain in performance .",
        "this paper proposes a new data - driven approach for modeling detailed splashes for liquid simulations with neural networks .",
        "we use neural networks to model the regression of splash formation using a classifier together with a velocity modification term .",
        "neural machine translation ( nmt ) , a new approach to machine translation , has achieved promising results comparable to those of traditional approaches such as statistical machine translation ( smt ) .",
        "neural machine translation ( nmt ) , a new approach to machine translation , has achieved promising results comparable to those of traditional approaches such as statistical machine translation ( smt ) .",
        ", 2016 ) results in accurate performance on this task , while being far simpler than many competing neural architectures .",
        "in this approach image reconstruction is performed with a deep convolutional neural network ( cnn ) , whose weights are adjusted prior to the actual image reconstruction based on a set of training data .",
        "the agent uses a deep recurrent neural network for function approximation .",
        "we present a simple and effective approach to incorporating syntactic structure into neural attention - based encoder - decoder models for machine translation .",
        "we rely on graph - convolutional networks ( gcns ) , a recent class of neural networks developed for modeling graph - structured data .",
        ", on top of bidirectional rnns or convolutional neural networks ) .",
        "we present a simple method to incorporate syntactic information about the target language in a neural machine translation system by translating into linearized , lexicalized constituency trees .",
        "in this paper , we model this effect by creating embeddings for characters based on their visual characteristics , creating an image for the character and running it through a convolutional neural network to produce a visual character embedding .",
        "the purpose of this study is to investigate whether pseudorehearsal can increase performance of an actor - critic agent with neural - network based policy selection and function approximation in a pole balancing task and compare different pseudorehearsal approaches .",
        "we propose a novel deep learning model for joint document - level entity disambiguation , which leverages learned neural representations .",
        "key components are entity embeddings , a neural attention mechanism over local context windows , and a differentiable joint inference stage for disambiguation .",
        "neural networks are function approximators that have achieved state - of - the - art accuracy in numerous machine learning tasks .",
        "in this paper , we explore the idea of learning weight evolution pattern from a simple network for accelerating training of novel neural networks .",
        "we use a neural network to learn the training pattern from mnist classification and utilize it to accelerate training of neural networks used for cifar - 10 and imagenet classification .",
        "the results indicate a general trend in the weight evolution during training of neural networks .",
        "adversarial attack has cast a shadow on the massive success of deep neural networks .",
        "despite being almost visually identical to the clean data , the adversarial images can fool deep neural networks into wrong predictions with very high confidence .",
        "this paper proposes two monte carlo techniques for these \" likelihood - free \" models , one of which can use likelihood estimates from neural networks to accelerate inference .",
        "our experiment with a neural machine translation on 4 gpus achieved a 22 % speed boost without impacting bleu score .",
        "recurrent neural networks ( rnn ) are widely used to solve a variety of problems and as the quantity of data and the amount of available compute have increased , so have model sizes .",
        "at the end of training , the parameters of the network are sparse while accuracy is still close to the original dense neural network .",
        "to learn from the resulting rhetoric structure , we propose a tensor - based , tree - structured deep neural network ( named rst - lstm ) in order to process the complete discourse tree .",
        "convolutional neural networks provide visual features that perform remarkably well in many computer vision applications .",
        "such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets , where it outperforms the sophisticated neural network models , including skip - thought vectors , by 15 % on average .",
        "we study the performance of faulty implementations of certain deep neural networks based on pessimistic and optimistic models of the effect of hardware faults .",
        "end - to - end neural machine translation has overtaken statistical machine translation in terms of translation quality for some language pairs , specially those with a large amount of parallel data available .",
        "beside this palpable improvement , neural networks embrace several new properties .",
        "in this paper , we propose a novel mer method by using deep convolutional neural network ( cnn ) on the music spectrograms that contains both the original time and frequency domain information .",
        "we propose a novel convolutional neural network to classify the complex time series data and determine if it corresponds to a breathing activity , followed by a random forest estimator to determine breathing rate .",
        "neural network models have shown their promising opportunities for multi - task learning , which focus on learning the shared layers to extract the common and task - invariant features .",
        "recent studies have shown that embedding textual relations using deep neural networks greatly helps relation extraction .",
        "this paper presents a deep attention model on the basis of recurrent neural networks ( rnn ) to learn \\ textit { selectively } temporal hidden representations of sequential posts for identifying rumors .",
        "we discover two problems , small micro variance and large macro variance , of pre - trained word embeddings that hurdle their direct use in neural networks , and propose standardization techniques as a remedy .",
        "this work is the first to overcome this limitation by interpreting the correlation filter learner , which has a closed - form solution , as a differentiable layer in a deep neural network .",
        "during the development stage , a deep neural network ( dnn ) that will be used to extract j - vector , is initialized and trained with the speech frames as input and the actual side information of the utterance as flat output block - wise one - hot labels .",
        "we investigate neural techniques for end - to - end computational argumentation mining .",
        "in this paper , we propose a hierarchical recurrent neural network enhanced by residual learning that detects kb relations given an input question .",
        "we compare treatment policies from fitted q - iteration with extremely randomized trees and with feedforward neural networks , and demonstrate that the policies learnt show promise in recommending weaning protocols with improved outcomes , in terms of minimizing rates of reintubation and regulating physiological stability .",
        "neural machine translation ( nmt ) becomes a new approach to machine translation and generates much more fluent results compared to statistical machine translation ( smt ) .",
        "we advance this framework by lifting linear bandit learning to neural sequence - to - sequence learning problems using attention - based recurrent neural networks .",
        "we present an evaluation on a neural machine translation task that shows improvements of up to 5 .",
        "modeling attention in neural multi - source sequence - to - sequence learning remains a relatively unexplored area , despite its usefulness in tasks that incorporate multiple source languages or modalities .",
        "empirically , neural networks that attempt to learn programs from data have exhibited poor generalizability .",
        "in order to address these issues , we propose augmenting neural architectures with a key abstraction : recursion .",
        "as an application , we implement recursion in the neural programmer - interpreter framework on four tasks : grade - school addition , bubble sort , topological sort , and quicksort .",
        "recursion divides the problem into smaller pieces and drastically reduces the domain of each neural network component , making it tractable to prove guarantees about the overall system ' s behavior .",
        "our experience suggests that in order for neural architectures to robustly learn program semantics , it is necessary to incorporate a concept like recursion .",
        "we are using deep convolutional neural networks to represent complex features .",
        "there has been a lot of research in this direction but the problem of integrating state - of - the - art neural language models with affective information remains an area ripe for exploration .",
        "we present a deep neural architecture that parses sentences into three semantic dependency graph formalisms .",
        "recurrent neural networks are showing much promise in many sub - areas of natural language processing , ranging from document classification to machine translation to automatic question answering .",
        "in this paper , we propose a new method for calculating the output layer in neural machine translation systems .",
        "neural models with minimal feature engineering have achieved competitive performance against traditional methods for the task of chinese word segmentation .",
        "however , both training and working procedures of the current neural models are computationally inefficient .",
        "this paper presents a greedy neural word segmenter with balanced word and character embedding inputs to alleviate the existing drawbacks .",
        "our segmenter is truly end - to - end , capable of performing segmentation much faster and even more accurate than state - of - the - art neural models on chinese benchmark datasets .",
        "in this paper , we propose an efficient vehicle trajectory prediction framework based on recurrent neural network .",
        "our approach is data - driven and simple to use in that it learns complex behavior of the vehicles from the massive amount of trajectory data through deep neural network model .",
        "the proposed trajectory prediction method employs the recurrent neural network called long short - term memory ( lstm ) to analyze the temporal behavior and predict the future coordinate of the surrounding vehicles .",
        "recurrent neural network ( rnn ) are being extensively used over feed - forward neural networks ( ffnn ) because of their inherent capability to capture temporal relationships that exist in the sequential data such as speech .",
        "the sentence encoder and decoder are built with recurrent neural networks .",
        "we propose a neural encoder - decoder transition - based parser which is the first full - coverage semantic graph parser for minimal recursion semantics ( mrs ) .",
        "to model both structured knowledge and unstructured language , we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses .",
        "automatic and human evaluations show that our model is both more effective at achieving the goal and more human - like than baseline neural and rule - based models .",
        "we demonstrate the feasibility and flexibility of lexically constrained decoding by conducting experiments on neural interactive - predictive translation , as well as domain adaptation for neural machine translation .",
        "for automatically parsing a spoken utterance , we introduce a model that integrates transcribed text and acoustic - prosodic features using a convolutional neural network over energy and pitch trajectories coupled with an attention - based recurrent neural network that accepts text and word - based prosodic features .",
        "we use neural word embeddings to discover words that are morphologically derived from each other and thereby that are semantically similar .",
        "we use letter successor variety counts obtained from tries that are built by neural word embeddings .",
        "our results show that using different information sources such as neural word embeddings and letter successor variety as prior information improves morphological segmentation in a bayesian model .",
        "neural machine translation represents an exciting leap forward in translation quality .",
        "to exemplify this approach , we present an english - french challenge set , and use it to analyze phrase - based and neural systems .",
        "the resulting analysis provides not only a more fine - grained picture of the strengths of neural systems , but also insight into which linguistic phenomena remain out of reach .",
        "briefly , in a reasoning system , a deep feedforward neural network is used to guide rewriting processes after learning from algebraic reasoning examples produced by humans .",
        "to enable the neural network to recognise patterns of algebraic expressions with non - deterministic sizes , reduced partial trees are used to represent the expressions .",
        "experimental results reveal that the algebraic reasoning examples can be accurately learnt only if the feedforward neural network has enough hidden layers .",
        "in this paper , we propose an approach to joint pos tagging and dependency parsing using transition - based neural networks .",
        "three neural network based classifiers are designed to resolve shift / reduce , tagging , and labeling conflicts .",
        "we study unsupervised learning by developing introspective generative modeling ( igm ) that attains a generator using progressively learned deep convolutional neural networks .",
        "in order to represent the complexity of the full space of inputs , we use aligned deformations from optical flow solves , and we leverage the power of generative neural networks to synthesize additional deformations for refinement .",
        "as part of a complete software stack for autonomous driving , nvidia has created a neural - network - based system , known as pilotnet , which outputs steering angles given images of the road ahead .",
        "we apply our learning algorithm to a new neural semantic parser and show significant gains over existing state - of - the - art results on a recent context - dependent semantic parsing task .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "we present a neural language model that incorporates document context in the form of a topic model - like architecture , thus providing a succinct representation of the broader document context outside of the current sentence .",
        "while the optimization problem behind deep neural networks is highly non - convex , it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points .",
        "in recent years , deep learning based on artificial neural network ( ann ) has achieved great success in pattern recognition .",
        "however , there is no clear understanding of such neural computational models .",
        "the class - pathway of a class is obtained by connecting the activated neural nodes in each layer from input to output , where activation value of neural node ( node - value ) is defined by the weights of each layer in a trained ann - classifier .",
        "at last , from the neural encodes view , we define the importance of each neural node through the class - pathways , which is helpful to optimize the structure of a classifier .",
        "the machine learned features from fully convolutional neural network ( fcn ) and hand - designed texton fea - tures are used to classify the mri image voxels .",
        "in machine learning , the use of an artificial neural network is the mainstream approach .",
        "here we investigate the possibility of replacing the inner product with a quadratic function of the input vector , thereby upgrading the 1st order neuron to the 2nd order neuron , empowering individual neurons , and facilitating the optimization of neural networks .",
        "we introduce a neural semantic parser which is interpretable and scalable .",
        "neural machine translation ( nmt ) heavily relies on an attention network to produce a context vector for each target word prediction .",
        "to discover hidden representations for the smiles strings , we use convolutional neural networks ( cnns ) .",
        "among the suitable models for the framework , splice junction classification using deep recurrent neural networks ( rnns ) is most appropriate for performing dna steganalysis .",
        "this paper aims to catalyze the discussions about text feature extraction techniques using neural network architectures .",
        "the research questions discussed in the paper focus on the state - of - the - art neural network techniques that have proven to be useful tools for language processing , language generation , text classification and other computational linguistics tasks .",
        "in recent years , deep neural networks have been used with great success in determining emotional states .",
        "to this purpose , we utilize a convolutional neural network ( cnn ) to extract features from the speech , while for the visual modality a deep residual network ( resnet ) of 50 layers .",
        "to achieve this , we adapt neural sequence models to map utterances directly to sql with its full expressivity , bypassing any intermediate meaning representations .",
        "we use reinforcement learning in a contextual bandit setting to train a neural network agent .",
        "in this study , we propose a 3d convolutional neural network ( cnn ) based nodule characterization strategy .",
        "we introduce parseval networks , a form of deep neural networks in which the lipschitz constant of linear , convolutional and aggregation layers is constrained to be smaller than 1 .",
        "parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation .",
        "a proper initialization of the weights in a neural network is critical to its convergence .",
        "first , i derive a general weight initialization strategy for any neural network using activation functions differentiable at 0 .",
        "recent advances in combining deep neural network architectures with reinforcement learning techniques have shown promising potential results in solving complex control problems with high dimensional state and action spaces .",
        "neural word segmentation research has benefited from large - scale raw texts by leveraging them for pretraining character and word embeddings .",
        "we investigate the effectiveness of a range of external training sources for neural word segmentation by building a modular segmentation model , pretraining the most important submodule using rich external sources .",
        "neural conversational models require substantial amounts of dialogue data for their parameter estimation and are therefore usually learned on large corpora such as chat forums or movie subtitles .",
        "in this paper , we propose a deep multi - view convolutional neural network to classify glitches automatically .",
        "the suggested classifier is a multi - view deep neural network that exploits four different views for classification .",
        "pre - trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for nlp tasks .",
        "here , we introduce a neural machine for top - down generation of tree structures that aims to infer such tree structures without the specified leaf nodes .",
        "deep learning refers to a set of machine learning techniques that utilize neural networks with many hidden layers for tasks , such as image classification , speech recognition , language understanding .",
        "\\ gpus and clouds ) for implementing , training and deploying deep neural networks .",
        "we particularly focus on convolutional neural networks and computer vision use cases , such as the visual inspection process in manufacturing plants and the analysis of social media data .",
        "to train neural networks , curated and labeled datasets are essential .",
        "in this paper , we discuss a twin neural network for learning from large datasets that are unbalanced , while optimizing the feature map at the same time .",
        "our results clearly demonstrate the generalization ability and scalability obtained by the twin neural network on large unbalanced datasets .",
        "recent advances in gpu hardware have enabled neural networks to achieve significant gains over the previous best models , these models still fail to leverage gpus ' capability for massive parallelism due to their requirement of sequential processing of the sentence .",
        "in response , we propose dilated iterated graph convolutional neural networks ( dig - cnns ) for graph - based dependency parsing , a graph convolutional architecture that allows for efficient end - to - end gpu parsing .",
        "in experiments on the english penn treebank benchmark , we show that dig - cnns perform on par with some of the best neural network parsers .",
        "we propose a novel neural network model for joint training from both sources of data based on cross - lingual word embeddings , and show substantial empirical improvements over baseline techniques .",
        "the quality of a neural machine translation system depends substantially on the availability of sizable parallel corpora .",
        "two methods are studied : an end to end , deep neural network that directly uses audio waveforms as input versus a pipelined approach that performs asr ( automatic speech recognition ) on the question , followed by text - based visual question answering .",
        "this paper proposes a new residual convolutional neural network ( cnn ) architecture for single image depth estimation .",
        "learning a better representation with neural networks is a challenging problem , which was tackled extensively from different prospectives in the past few years .",
        "we evaluate them on two most common types of models , recurrent neural networks and convolutional neural networks , showing that the approach we propose consistently improves the quality of kmeans clustering in terms of adjusted mutual information score and outperforms previously proposed methods .",
        "we quantify relevance by measuring the distance between frames and queries in a common textual - visual semantic embedding space induced by a neural network .",
        "we have designed a novel , hybrid convolutional neural network to integrate meta - data with text .",
        "feed - forward neural networks using n - gram embedding features encode messages into vectors which are optimized to give message - response pairs a high dot - product value .",
        "using an implementation based on deep neural networks , we demonstrate that phantom sampling dramatically avoids catastrophic forgetting .",
        "we apply these strategies to competitive multi - class incremental learning of deep neural networks .",
        "while end - to - end neural machine translation ( nmt ) has made remarkable progress recently , it still suffers from the data scarcity problem for low - resource language pairs and domains .",
        "in the experiment , we show that a neural network trained using stair captions can generate more natural and better japanese captions , compared to those generated using english - japanese machine translation after generating english captions .",
        "deep neural networks ( dnns ) have provably enhanced the state - of - the - art neural machine translation ( nmt ) with their capability in modeling complex functions and capturing complex linguistic structures .",
        "even though a linguistics - free sequence to sequence model in neural machine translation ( nmt ) has certain capability of implicitly learning syntactic information of source sentences , this paper shows that source syntax can be explicitly incorporated into nmt effectively to provide further improvements .",
        "the deployment of artificial neural networks ( anns ) in safety - critical applications poses a number of new verification and certification challenges .",
        "we view intersection handling as a deep reinforcement learning problem , which approximates the state action q function as a deep neural network .",
        "we present an approach for the verification of feed - forward neural networks in which all nodes have a piece - wise linear activation function .",
        "recurrent neural network ( rnn ) has been widely applied for sequence modeling .",
        "we propose a simple technique called parallel cells ( pcs ) to enhance the learning ability of recurrent neural network ( rnn ) .",
        "in typical neural machine translation ~ ( nmt ) , the decoder generates a sentence word by word , packing all linguistic granularities in the same time - scale of rnn .",
        "recently , artificial neural networks , so called deep - learning approaches , have been proposed to address this challenge .",
        "popular deep learning frameworks require users to fine - tune their memory usage so that the training data of a deep neural network ( dnn ) fits within the gpu physical memory .",
        "here , we focus on efficient decoding , with a goal of achieving accuracy close the state - of - the - art in neural machine translation ( nmt ) , while achieving cpu decoding speed / throughput close to that of a phrasal decoder .",
        "we propose a recurrent neural model that generates natural - language questions from documents , conditioned on answers .",
        "this paper presents senti17 system which uses ten convolutional neural networks ( convnet ) to assign a sentiment label to a tweet .",
        "to tackle these problems , in this work , we formulate acbd as a sequence labeling problem and propose a variety of recurrent neural network ( rnn ) based methods , which do not use domain specific or handcrafted features beyond the relative position of the sentence in the document .",
        "this technique enables neural networks to learn from old and successful resolution processes and to use learnt experiences to guide new resolution processes .",
        "it includes a prolog library of deep feedforward neural networks and some essential functions of resolution .",
        "in the sldr - dl framework , users can define logical rules in the form of definite clauses and teach neural networks to use the rules in reasoning processes .",
        "in this paper we propose a neural network model with a novel sequential attention layer that extends soft attention by assigning weights to words in an input sequence in a way that takes into account not just how well that word matches a query , but how well surrounding words match .",
        "we present deep speaker , a neural speaker embedding system that maps utterances to a hypersphere where speaker similarity is measured by cosine similarity .",
        "we describe a neural network model that jointly learns distributed representations of texts and knowledge base ( kb ) entities .",
        "in this paper , we proposed a scene text erasing method to properly hide the information via an inpainting convolutional neural network ( cnn ) model .",
        "recently , several end - to - end neural models have been proposed for machine comprehension tasks .",
        "the prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks .",
        "we introduce an architecture based entirely on convolutional neural networks .",
        "it shows how to process the source data , train a neural network to learn the high - dimensional embeddings for individual languages and expands the framework for testing their quality beyond the english language .",
        "deep neural models , particularly the lstm - rnn model , have shown great potential in language identification ( lid ) .",
        "however , the phonetic information has been largely overlooked by most of existing neural lid methods , although this information has been used in the conventional phonetic lid systems with a great success .",
        "we present a phonetic temporal neural model for lid , which is an lstm - rnn lid system but accepts phonetic features produced by a phone - discriminative dnn as the input , rather than raw acoustic features .",
        "our experiments conducted on the babel database and the ap16 - olr database demonstrate that the temporal phonetic neural approach is very effective , and significantly outperforms existing acoustic neural models .",
        "pure acoustic neural models , particularly the lstm - rnn model , have shown great potential in language identification ( lid ) .",
        "however , the phonetic information has been largely overlooked by most of existing neural lid models , although this information has been used in the conventional phonetic lid systems with a great success .",
        "we present a phone - aware neural lid architecture , which is a deep lstm - rnn lid system but accepts output from an rnn - based asr system .",
        "inspired by the deep learning approaches in natural language processing , we propose a recurrent neural network model with multiple attention layers for ddi classification .",
        "in this paper , we explore novel approaches for modeling dialogue context in a re - current neural network ( rnn ) based lan - guage understanding system .",
        "we also present two baseline algorithms : a feature - based classifier and a state - of - the - art neural network , that performs well on squad reading comprehension .",
        "both the program generator and the execution engine are implemented by neural networks , and are trained using a combination of backpropagation and reinforce .",
        "recently deep neural networks ( dnns ) have been used to learn speaker features .",
        "however , the quality of the learned features is not sufficiently good , so a complex back - end model , either neural or probabilistic , has to be used to address the residual uncertainty when applied to speaker verification , just as with raw features .",
        "this paper presents a convolutional time - delay deep neural network structure ( ct - dnn ) for speaker feature learning .",
        "it has been shown that chinese poems can be successfully generated by sequence - to - sequence neural models , particularly with the attention mechanism .",
        "a potential problem of this approach , however , is that neural models can only learn abstract rules , while poem generation is a highly creative process that involves not only rules but also innovations for which pure statistical models are not appropriate in principle .",
        "this work proposes a memory - augmented neural model for chinese poem generation , where the neural model and the augmented memory work together to balance the requirements of linguistic accordance and aesthetic innovation , leading to innovative generations that are still rule - compliant .",
        "in this work , we present a minimal neural model for constituency parsing based on independent scoring of labels and spans .",
        "this paper demonstrates end - to - end neural network architectures for vietnamese named entity recognition .",
        "our best model is the combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which achieves an f1 score of 88 .",
        "given an existing trained neural network , it is often desirable to be able to add new capabilities without hindering performance of already learned tasks .",
        "our experiments show that the proposed method can achieve competitive results , comparable to neural embedding learning techniques , however , with only a fraction of the computational complexity of these methods .",
        "bridging this gap , we develop a method to predict human impressions of faces in 40 subjective social dimensions , using deep representations from state - of - the - art neural networks .",
        "we introduce a neural network model with intra - attention and a new training method .",
        "we achieve this by utilizing improved neural architectures for streaming inference , solving optimization issues , and employing strategies that increase audio and label modelling versatility .",
        "after that , the encoded image is fed to convolutional neural network ( cnn ) for automatic feature extraction and learning , reducing the expert ' s intervention .",
        "word - embedding or obtaining vector representation of words from a large corpora of free texts using neural network methods have been shown to give significant performance for several natural language processing tasks .",
        "in recent years , the deep neural network has enjoyed a great success in large - scale image and video recognitions .",
        "in this paper , we propose and experiment using deep convolutional neural network to imitate how human brain processes hierarchical structures in the auditory signals , such as music , speech , etc .",
        "in this paper , we compare established methods like bayes , rocchio , knn , svm , and logistic regression as well as recent methods like learning to rank and neural networks to the multi - label document classification problem .",
        "the best method on title data is a modern variant of neural networks .",
        "for one dataset , a stacking of logistic regression and decision trees performs slightly better than neural networks .",
        "neural task - oriented dialogue systems often struggle to smoothly interface with a knowledge base .",
        "in this work , we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded , multi - domain discourse through a novel key - value retrieval mechanism .",
        "our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule - based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics .",
        "expectation for the emergence of higher functions is getting larger in the framework of end - to - end reinforcement learning using a recurrent neural network .",
        "over the past two decades , the feedforward neural network ( fnn ) optimization has been a key interest among the researchers and practitioners of multiple disciplines .",
        "this article also tries to connect various research directions emerged out of the fnn optimization practices , such as evolving neural network ( nn ) , cooperative coevolution nn , complex - valued nn , deep learning , extreme learning machine , quantum n",
        "we treat the relation inference tasks as a machine learning problem and tackle it with neural networks .",
        "we propose a new neural network module , contrast association unit ( cau ) , which explicitly models the relations between two sets of input variables .",
        "experiments show that neural networks with caus are more effective in learning five fundamental image transformations than conventional neural networks .",
        "long short - term memory ( lstm ) is a specific recurrent neural network ( rnn ) architecture that is well - suited to learn from experience to classify , process and predict time series with time lags of unknown size .",
        "we train naive long short - term memory ( lstm ) recurrent neural networks ( rnns ) on six formal languages drawn from the strictly local ( sl ) and strictly piecewise ( sp ) classes .",
        "we present a novel neural network model that learns pos tagging and graph - based dependency parsing jointly .",
        "our extensive experiments , on 19 languages from the universal dependencies project , show that our model outperforms the state - of - the - art neural network - based stack - propagation model for joint pos tagging and transition - based dependency parsing , resulting in a new state of the art .",
        "frame stacking is broadly applied in end - to - end neural network training like connectionist temporal classification ( ctc ) , and it leads to more accurate models and faster decoding .",
        "however , it is not well - suited to conventional neural network based on context - dependent state acoustic model , if the decoder is unchanged .",
        "long short - term memory ( lstm ) recurrent neural networks ( rnns ) using it achieve almost linear training speedup and reduces relative 41 \\ % real time factor ( rtf ) .",
        "we present a semi - supervised way of training a character - based encoder - decoder recurrent neural network for morphological reinflection , the task of generating one inflected word form from another .",
        "the approach comprises data cleaning , normalization , capping , time - based compression , and finally classification with a recurrent neural network .",
        "we investigate dependency parsing of singlish by constructing a dependency treebank under the universal dependencies scheme , and then training a neural network model by integrating english syntactic knowledge into a state - of - the - art parser trained on the singlish treebank .",
        "to the best of our knowledge , we are the first to use neural stacking to improve cross - lingual dependency parsing on low - resource languages .",
        "in this work , we propose a novel two - stream 3d convolutional neural network ( cnn ) architecture by introducing the discriminative code layer and the corresponding discriminative code loss function .",
        "we conduct an elaborate analysis of different fusion schemes ( weighted average , single and double - layer neural nets ) applied to different 3d cnn outputs .",
        "in this work we present our results on learning strategies in atari games using a convolutional neural network , the math kernel library and tensorflow 0 .",
        "recently , deep convolutional neural network ( dcnn ) achieved increasingly remarkable success and rapidly developed in the field of natural image recognition .",
        "while the sparse coding principle can successfully model information processing in sensory neural systems , it remains unclear how learning can be accomplished under neural architectural constraints .",
        "we describe a neural network with spiking neurons that can address the aforementioned fundamental challenge and solve the l1 - minimizing dictionary learning problem , representing the first model able to do so .",
        "there are many applications scenarios for which the computational performance and memory footprint of the prediction phase of deep neural networks ( dnns ) needs to be optimized .",
        "binary neural networks ( bdnns ) have been shown to be an effective way of achieving this objective .",
        "in this paper , we show how convolutional neural networks ( cnns ) can be implemented using binary representations .",
        "we experimentally show that espresso is significantly faster than existing implementations of optimized binary neural networks ( $ \\ approx $ 2 orders of magnitude )",
        "recent research has shown that one can train a neural network with binary weights and activations at train time by augmenting the weights with a high - precision continuous latent variable that accumulates small changes from stochastic gradient descent .",
        "our main result is that the neural networks with binary weights and activations trained using the method of courbariaux , hubara et al .",
        "our theory serves as a foundation for understanding not only bnns but a variety of methods that seek to compress traditional neural networks .",
        "furthermore , a better understanding of multilayer binary neural networks serves as a starting point for generalizing bnns to other neural network architectures such as recurrent neural networks .",
        "deep neural networks ( dnns ) are presently the state - of - the - art for image classification tasks .",
        "as such , the design of a general defense strategy against a wide range of attacks for neural networks becomes a challenging problem .",
        "adjacency of the examples is inferred using the predictions of a neural network model which is first initialized by a supervised pretraining .",
        "ultimately , the proposed framework provides an effective and scalable graph - based solution which is natural to the operational mechanism of deep neural networks .",
        "a different parametrization of the hyperplanes is used in the neural net algorithm .",
        "the experimental results of pso - p on ib are compared to results of closed - form control policies derived from the model - based recurrent control neural network ( rcnn ) and the model - free neural fitted q - iteration ( nfq ) .",
        "neural networks are known to be vulnerable to adversarial examples : inputs that are close to valid inputs but classified incorrectly .",
        "in this paper , we extend an attention - based neural machine translation ( nmt ) model by allowing it to access an entire training set of parallel sentence pairs even after training .",
        "we address the problem of reconstructing sparse signals from noisy and compressive measurements using a feed - forward deep neural network ( dnn ) with an architecture motivated by the iterative shrinkage - thresholding algorithm ( ista ) .",
        "adversarial neural networks solve many important problems in data science , but are notoriously difficult to train .",
        "this model employs multi - layer recurrent neural networks as an encoder and a decoder .",
        "we propose a novel neural network structure called crossnets , which considers architectures on directed acyclic graphs .",
        "how to develop slim and accurate deep neural networks has become crucial for real - world applications , especially for those employed in embedded systems .",
        "in this paper , we propose a new layer - wise pruning method for deep neural networks .",
        "while previous contributions to feature extraction propose embeddings based on a single layer of the network , in this paper we propose a full - network embedding which successfully integrates convolutional and fully connected features , coming from all layers of a deep convolutional neural network .",
        "deep neural networks have been shown to succeed at a range of natural language tasks such as machine translation and text summarization .",
        "as first solutions , we design a set of deep neural models that learn to represent the context of each variable location and variable usage in a data flow - sensitive way .",
        "experiments show significant speed gains for various deep neural networks .",
        "batch normalization ( bn ) is very effective in accelerating the convergence of a neural network training phase that it has become a common practice .",
        "with the evolution of neural network based methods , automatic speech recognition ( asr ) field has been advanced to a level where building an application with speech interface is a reality .",
        "this paper highlights the significance of including memory structures in neural networks when the latter are used to learn perception - action loops for autonomous robot navigation .",
        "this work is a first thorough study of memory structures for deep - neural - network - based robot navigation , and offers novel tools to train such networks from supervision and quantify their ability to generalize to unseen scenarios .",
        "we analyze the separation and generalization abilities of feedforward , long short - term memory , and differentiable neural computer networks .",
        "recurrent neural network ( rnn ) are a popular choice for modeling temporal and sequential tasks and achieve many state - of - the - art performance on various complex problems .",
        "recently , sequence - to - sequence model by using encoder - decoder neural network has gained popularity for automatic speech recognition ( asr ) .",
        "these works mainly focused on the detection algorithms which use features with fixed dimension , while some researchers have begun to use recurrent neural networks ( rnn ) to detect malware based on sequential api features .",
        "in this paper , we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input , namely the indicators , that act as the hints to suggest logical outcomes .",
        "we used the mnist data to demonstrate the design and use of these indicators in a convolutional neural network .",
        "we trained a series of such hybrid neural networks with variations of the indicators .",
        "our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models .",
        "we propose to use a hierarchical semantic representation of the objects , coming from a convolutional neural network , to solve this ambiguity .",
        "our idea is to mark parts as \" matching \" if their features are close to each other at all the levels of convolutional feature hierarchy ( neural paths ) .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "we introduce an architecture in which internal representations , learned by end - to - end optimization in a deep neural network performing a textual question - answering task , can be interpreted using basic concepts from linguistic theory .",
        "planning new policies is performed by tree search , while a deep neural network generalises those plans .",
        "in contrast , standard deep reinforcement learning algorithms rely on a neural network not only to generalise plans , but to discover them too .",
        "recurrent neural networks architectures excel at processing sequences by modelling dependencies over different timescales .",
        "in particular , we compare both long short - term memory networks ( lstm ) and convolutional neural networks ( cnn ) for prediction of five intervention tasks : invasive ventilation , non - invasive ventilation , vasopressors , colloid boluses , and crystalloid boluses .",
        "selective classification techniques ( also known as reject option ) have not yet been considered in the context of deep neural networks ( dnns ) .",
        "in this paper we propose a method to construct a selective classifier given a trained neural network .",
        "in our evaluation , we use our algorithm to interpret random forests and neural nets trained on several datasets from the uci machine learning repository , as well as control policies learned for three classical reinforcement learning problems .",
        "a major challenge in designing neural network ( nn ) systems is to determine the best structure and parameters for the network given the data for the machine learning problem at hand .",
        "recent advances in generative sequential modeling have suggested to combine recurrent neural networks with state space models ( e .",
        "inheriting these advantages of stochastic neural sequential models , we propose a structured and stochastic sequential neural network , which models both the long - term dependencies via recurrent neural networks and the uncertainty in the segmentation and labels via discrete random variables .",
        "neural networks , with their distributed representations , are challenging these methods .",
        "we introduce a technique for augmenting neural text - to - speech ( tts ) with lowdimensional trainable speaker embeddings to generate different voices from a single model .",
        "as a starting point , we show improvements over the two state - ofthe - art approaches for single - speaker neural tts : deep voice 1 and tacotron .",
        "we improve tacotron by introducing a post - processing neural vocoder , and demonstrate a significant audio quality improvement .",
        "we show that a single neural tts system can learn hundreds of unique voices from less than half an hour of data per speaker , while achieving high audio quality synthesis and preserving the speaker identities almost perfectly .",
        "in this paper , we model the background by a recurrent neural network ( rnn ) with its units aligned with time series indexes while the history effect is modeled by another rnn whose units are aligned with asynchronous events to capture the long - range dynamics .",
        "we instantiate our framework using neural networks , and build a concrete model , dauto .",
        "the approach uses recurrent neural networks as its building blocks .",
        "the design of neural architectures for structured objects is typically guided by experimental insights rather than a formal process .",
        "in this work , we appeal to kernels over combinatorial structures , such as sequences and graphs , to derive appropriate neural operations .",
        "we introduce a class of deep recurrent neural operations and formally characterize their associated kernel spaces .",
        "similar to traditional neural operations , these reference objects are parameterized and directly optimized in end - to - end training .",
        "we empirically evaluate the proposed class of neural architectures on standard applications such as language modeling and molecular graph regression , achieving state - of - the - art or competitive results across these applications .",
        "we report results for learning the cdprs with a deep neural network and using them to solve two tasks with deep reinforcement learning .",
        "this paper proposes a simple neural model for rte problem .",
        "we introduce a neural network that represents sentences by composing their words according to induced binary parse trees .",
        "in this paper an image classification model based on convolutional neural network is applied to quantitative light - induced fluorescence images .",
        "the deep neural network outperforms other state of the art shallow classification models in predicting labels derived from three different dental plaque assessment scores .",
        "drawing inspiration from recent efforts to empower neural networks with a structural bias , we propose a model that can encode a document while automatically inducing rich structural dependencies .",
        "specifically , we embed a differentiable non - projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases .",
        "recurrent neural networks have achieved remarkable success at generating sequences with complex structures , thanks to advances that include richer embeddings of input and cures for vanishing gradients .",
        "an approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated asr confidence measures .",
        "it also shown that combining an slu approach based on conditional random fields with a neural encoder / decoder attention based architecture , it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy .",
        "in this paper we propose a method that takes the advantage of recurrent neural network ( rnn ) to extract higher level features present across the sentence .",
        "we explore several methods to detect and explain crisis using a combination of neural and non - neural techniques .",
        "in recent years , stochastic gradient descent ( sgd ) based techniques has become the standard tools for training neural networks .",
        "however , formal theoretical understanding of why sgd can train neural networks in practice is largely missing .",
        "we evaluate the character - level translation method for neural semantic parsing on a large corpus of sentences annotated with abstract meaning representations ( amrs ) .",
        "neural networks ( nn ) are constructed to parameterize a stochastic policy that directly maps sensory data collected by the robot to its velocity outputs , while respecting a set of social norms .",
        "we investigate the possibility of using deep residual convolutional neural network with spectrograms as an input features in the text - dependent speaker verification task .",
        "our work addresses two important issues with recurrent neural networks : ( 1 ) they are over - parameterized , and ( 2 ) the recurrence matrix is ill - conditioned .",
        "we show that a recently proposed neural dependency parser can be improved by joint training on multiple languages from the same family .",
        "the parser is implemented as a deep neural network whose only input is orthographic representations of words .",
        "in this paper , we propose a latent intention dialogue model ( lidm ) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference .",
        "to this end , we introduce a new model for statistical relational learning that is built upon deep recursive neural networks , and give experimental evidence that it can easily compete with , or even outperform , existing logic - based reasoners on the task of ontology reasoning .",
        "we show that a modular neural network ( mnn ) can combine various speech enhancement modules , each of which is a deep neural network ( dnn ) specialized on a particular enhancement job .",
        "deep learning tends to emphasize on sentence level semantics when learning a representation with models like recurrent neural network or recursive neural network , however from the success of tf - idf representation , it seems a bag - of - words type of representation has its strength .",
        "we apply the model on characters and our results show that our model is better than all the other character - based and word - based convolutional neural network models by \\ cite { zhang15 } across seven different datasets with only 1 \\ % of their parameters .",
        "deep neural networks trained on large supervised datasets have led to impressive results in recent years .",
        "in this paper , we investigate the behavior of deep neural networks on training sets with massively noisy labels .",
        "we propose a new linguistic stegosystem based on a long short - term memory ( lstm ) neural network .",
        "we present a transition - based dependency parser that uses a convolutional neural network to compose word representations from characters .",
        "in the neural network domain , methods for hyperparameter optimization and meta - modeling are computationally expensive due to the need to train a large number of neural network configurations .",
        "in this paper , we show that a simple regression model , based on support vector machines , can predict the final performance of partially trained neural network configurations using features based on network architectures , hyperparameters , and time - series validation performance data .",
        "we use this regression model to develop an early stopping strategy for neural network configurations .",
        "most of the previous studies focus on discriminative neural networks which unnecessarily require a separation of input / output variables .",
        "recent development of generative neural networks such as restricted boltzmann machines ( rbms ) has shown a capability of learning semantic abstractions directly from data , posing a promise for general symbolic learning and reasoning .",
        "we introduce neural networks for end - to - end differentiable theorem proving that operate on dense vector representations of symbols .",
        "these neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in prolog .",
        "by using gradient descent , the resulting neural network can be trained to infer facts from a given incomplete knowledge base .",
        "we demonstrate that this architecture outperforms complex , a state - of - the - art neural link prediction model , on four benchmark knowledge bases while at the same time inducing interpretable function - free first - order logic rules .",
        "we developed a hierarchical architecture based on neural networks that is simple to train .",
        "stochastic gradient descent ( sgd ) , which updates the model parameters by adding a local gradient times a learning rate at each step , is widely used in model training of machine learning algorithms such as neural networks .",
        "we propose an algorithm to automatically learn learning rates using neural network based actor - critic methods from deep reinforcement learning ( rl ) .",
        "in the past few years , attention mechanisms have become an indispensable component of end - to - end neural machine translation models .",
        "learning neural network architectures is a way to discover new highly predictive models .",
        "for instance , our approach is able to solve the following task : find the best neural network architecture ( in a very large set of possible architectures ) able to predict well in less than 100 milliseconds on my mobile phone .",
        "deep neural network ( dnn ) are currently of great inter - est in research and application .",
        "this paper presents a new approach to nlg by using recurrent neural networks ( rnn ) , in which a gating mechanism is applied before rnn computation .",
        "this paper presents a recurrent neural network based encoder - decoder architecture , in which an lstm - based decoder is introduced to select , aggregate semantic elements produced by an attention mechanism over the input elements , and to produce the required utterances .",
        "this paper presents alternative neural approaches to topic modelling by providing parameterisable distributions over topics which permit training by backpropagation in the framework of neural variational inference .",
        "experimental results on the mxm song lyrics , 20newsgroups and reuters news datasets demonstrate the effectiveness and efficiency of these neural topic models .",
        "in this paper , we explore the use of tensor contractions as neural network layers and investigate several ways to apply them to activation tensors .",
        "specifically , we propose the tensor contraction layer ( tcl ) , the first attempt to incorporate tensor contractions as end - to - end trainable neural network layers .",
        "in this paper , we present nmtpy , a flexible python toolkit based on theano for training neural machine translation and other neural sequence - to - sequence architectures .",
        "a deep convolutional neural network approach is developed to model the voxel - wise spatio - temporal tumor progression .",
        "stripes is a deep neural network ( dnn ) accelerator that uses bit - serial computation to offer performance that is proportional to the fixed - point precision of the activation values .",
        "for instance , non - parametric artificial neural networks .",
        "in this paper , we describe the \" pixelgan autoencoder \" , a generative autoencoder in which the generative path is a convolutional autoregressive neural network on pixels ( pixelcnn ) that is conditioned on a latent code , and the recognition path uses a generative adversarial network ( gan ) to impose a prior distribution on the latent code .",
        "deep neural networks are able to solve tasks across a variety of domains and modalities of data .",
        "in this work , we present a general method for visualizing an arbitrary neural network ' s inner mechanisms and their power and limitations .",
        "we demonstrate the effectiveness of our framework on a variety of deep neural network architectures in domains from computer vision , natural language processing , and reinforcement learning .",
        "in this work , we conduct extensive experiments using an attentive convolutional neural network with multi - view learning objective function .",
        "we overview dataflow matrix machines as a turing complete generalization of recurrent neural networks and as a programming platform .",
        "we describe vector space of finite prefix trees with numerical leaves which allows us to combine expressive power of dataflow matrix machines with simplicity of traditional recurrent neural networks .",
        "exploiting the great expressive power of deep neural network architectures , relies on the ability to train them .",
        "training a deep convolutional neural network ( cnn ) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence .",
        "this paper demonstrates the potential of convolutional neural networks ( cnn ) for detecting and classifying prosodic events on words , specifically pitch accents and phrase boundary tones , from frame - based acoustic features .",
        "unlike traditional singleton neural network , our model incorporates character - aware convolutional neural network ( char - cnn ) with character - aware recurrent neural network ( char - rnn ) to form a convolutional recurrent neural network ( crnn ) .",
        "a recently explored solution space lies in compressing ( approximating or simplifying ) deep neural networks in some manner before use on the device .",
        "first , unlike current solutions geared for compressing specific types of neural networks , deepiot presents a unified approach that compresses all commonly used deep learning structures for sensing applications , including fully - connected , convolutional , and recurrent neural networks , as well as their combinations .",
        "second , unlike solutions that either sparsify weight matrices or assume linear structure within weight matrices , deepiot compresses neural network structures into smaller dense matrices by finding the minimum number of non - redundant hidden elements , such as filters and dimensions required by each layer , while keeping the performance of sensing applications the same .",
        "we propose a novel method to learn a neural program operating a domain - specific non - differentiable machine , and demonstrate that this method can be applied to learn programs that are significantly more complex than the ones synthesized before : programming language parsers from input - output pairs without knowing the underlying grammar .",
        "the main challenge is to train the neural program without supervision on execution traces .",
        "to tackle it , we propose : ( 1 ) ll machines and neural programs operating them to effectively regularize the space of the learned programs ; and ( 2 ) a two - phase reinforcement learning - based search technique to train the model .",
        "this is the first successful demonstration of applying reinforcement learning to train a neural program operating a non - differentiable machine that can fully generalize to test sets on a non - trivial task .",
        "to date , recurrent neural networks that learn language models at character , word , or sentence levels have had little success generating coherent stories .",
        "while other works in the field rely on the use of a hand - written rule set or specialized features , we made use of artificial neural networks .",
        "training gans for text generation has proven to be more difficult , because of the non - differentiable nature of generating text with recurrent neural networks .",
        "in this work , we show that recurrent neural networks can be trained to generate text with gans from scratch by employing curriculum learning , slowly increasing the length of the generated text , and by training the rnn simultaneously to generate sequences of different lengths .",
        "relational reasoning is a central component of generally intelligent behavior , but has proven difficult for neural networks to learn .",
        "we present a novel training framework for neural sequence models , particularly for grounded dialog generation .",
        "across a variety of domains , a recurring problem with mle trained generative neural dialog models ( g ) is that they tend to produce ' safe ' and generic responses ( \" i don ' t know \" , \" i can ' t tell \" ) .",
        "in particular , the first two models employ a one - class svm algorithm and a recurrent neural network based deep learning model , respectively .",
        "we present a general - purpose tagger based on convolutional neural networks ( cnn ) , used for both composing word vectors and encoding context information .",
        "in the last few years , recurrent neural networks ( rnns ) have proved effective on several nlp tasks .",
        "we propose a web - based visualization tool , \\ textit { adversarial - playground } , to demonstrate the efficacy of common adversarial methods against a deep neural network ( dnn ) model , built on top of the tensorflow library .",
        "in this paper , we demonstrated that the speaker factor is also a short - time spectral pattern and can be largely identified with just a few frames using a simple deep neural network ( dnn ) .",
        "to assess whether unsupervised deep learning is appropriate , we first pose a smaller question : can unsupervised neural networks apply linguistic rules productively , using them in novel situations ?",
        "we use neural machine translation to generate sentential paraphrases via back - translation of bilingual sentence pairs .",
        "in the process , we explore how neural machine translation output differs from human - written sentences , finding clear differences in length , the amount of repetition , and the use of rare words .",
        "symbolic has been long considered as a language of human intelligence while neural networks have advantages of robust computation and dealing with noisy data .",
        "the integration of neural - symbolic can offer better learning and reasoning while providing a means for interpretability through the representation of symbolic knowledge .",
        "although previous works focus intensively on supervised feedforward neural networks , little has been done for the unsupervised counterparts .",
        "in this paper we show how to integrate symbolic knowledge into unsupervised neural networks .",
        "we implement a qg model based on sequence - to - sequence learning , and a qa model based on recurrent neural network .",
        "this paper studies the detection of bird calls in audio segments using stacked convolutional and recurrent neural networks .",
        "ladder networks are a notable new concept in the field of semi - supervised learning by showing state - of - the - art results in image recognition tasks while being compatible with many existing neural architectures .",
        "we present the recurrent ladder network , a novel modification of the ladder network , for semi - supervised learning of recurrent neural networks which we evaluate with a phoneme recognition task on the timit corpus .",
        "in order to adopt such models for artificial intelligence , researchers have handcrafted the relevant states , and then used neural networks to learn the state transitions using simulation runs as training data .",
        "in this work , we investigate if neural networks can implicitly learn physical states of real - world mechanical processes only based on visual data , and thus enable long - term physical extrapolation .",
        "we develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates .",
        "we extend the convolutional recurrent neural network to handle more than one type of these multichannel features by learning from each of them separately in the initial stages .",
        "we propose a method based on convolutional ( cnn ) and recurrent neural networks ( rnn ) , having significantly fewer parameters compared with the state - of - the - art method for the same task .",
        "in this paper , we propose the use of spatial and harmonic features in combination with long short term memory ( lstm ) recurrent neural network ( rnn ) for automatic sound event detection ( sed ) task .",
        "despite the promising power of deep neural networks ( dnn ) , how to alleviate overfitting during training has been a research topic of interest .",
        "deep neural networks ( dnn ) have been successfully applied for music classification including music tagging .",
        "in this article , we investigate specific aspects of neural networks to deepen our understanding of their properties .",
        "in this paper , we introduce a generalized value iteration network ( gvin ) , which is an end - to - end neural network planning module .",
        "we propose a deep dynamic neural network model built on a dynamic vision network , a motor generation network , and a higher - level network .",
        "to remedy this , we present a ranking based approach , and implement both carefully designed features and neural network architectures to measure the relevance between a query and the content of a table .",
        "we introduce a semantic relevance based neural model to encourage high semantic similarity between texts and summaries .",
        "despite the recent success of neural networks in tasks involving natural language understanding ( nlu ) there has only been limited progress in some of the fundamental challenges of nlu , such as the disambiguation of the meaning and function of words in context .",
        "deep learning thrives with large neural networks and large datasets .",
        "to achieve state - of - the - art results on challenges in vision , convolutional neural networks learn stationary filters that take advantage of the underlying image structure .",
        "the encoder is a deep convolutional neural network ( cnn ) based on the vgg network .",
        "we explore simple , efficient token embedding models based on standard neural network architectures .",
        "the iterations of many first - order algorithms , when applied to minimizing common regularized regression functions , often resemble neural network layers with pre - specified weights .",
        "deep convolutional neural networks are being actively investigated in a wide range of speech and audio processing applications including speech recognition , audio event detection and computational paralinguistics , owing to their ability to reduce factors of variations , such as speaker and environment information in signals , for speech recognition .",
        "however , studies have suggested to favor a certain type of convolutional operations when building a deep convolutional neural network for speech applications although there has been promising results using different types of convolutional operations .",
        "since affective behavioral information has been shown to reflect temporally varying of mental state and convolutional operation are applied locally in time , all deep neural networks share a deep recurrent sub - network architecture for further temporal modeling .",
        "finally we show that all of our deep neural networks provide state - of - the",
        "we present an end - to - end system for musical key estimation , based on a convolutional neural network .",
        "a novel method for learning optimal , orthonormal wavelet bases for representing 1 - and 2d signals , based on parallels between the wavelet transform and fully connected artificial neural networks , is described .",
        "in this work , we study how depthwise separable convolutions can be applied to neural machine translation .",
        "in this paper , we consider regression problems with one - hidden - layer neural networks ( 1nns ) .",
        "neural machine translation has meant a revolution of the field .",
        "post - editing offers a unique opportunity for improving neural machine translation systems , using online learning techniques and treating the post - edited translations as new , fresh training data .",
        "this paper aims at one - shot learning of deep neural nets , where a highly parallel setting is considered to address the algorithm calibration problem - selecting the best neural architecture and learning hyper - parameter values depending on the dataset at hand .",
        "we focus on progressive neural networks and compare these networks to the conventional deep learning method of pre - training and fine - tuning .",
        "progressive neural networks provide a way to transfer knowledge and avoid the forgetting effect present when pre - training neural networks on different tasks .",
        "neural networks and rational functions efficiently approximate each other .",
        "we show that multi - layer neural networks can learn almost - optimal auctions for settings for which there are analytical solutions , such as myerson ' s auction for a single item , manelli and vincent ' s mechanism for a single bidder with additive preferences over two items , or yao ' s auction for two additive bidders with binary support distributions and multiple items , even if no prior knowledge about the form of optimal auctions is encoded in the network and the only feedback during training is revenue and regret .",
        "popular independent ensembles ( ie ) relying on naive averaging / voting scheme have been of typical choice for most applications involving deep neural networks , but they do not consider advanced collaboration among ensemble models .",
        "in this paper , we propose new ensemble methods specialized for deep neural networks , called confident multiple choice learning ( cmcl ) : it is a variant of multiple choice learning ( mcl ) via addressing its overconfidence issue .",
        "our system is based on an attentional sequence - to - sequence neural network model using long short - term memory ( lstm ) cells , with joint training of morphological inflection and the inverse transformation , i .",
        "neural network models outperform traditional approaches in domains where large datasets exist , such as squad ( ca .",
        "in this work , we adapt a neural qa system trained on a large open - domain dataset ( squad , source ) to a biomedical dataset ( bioasq , target ) by employing various transfer learning techniques .",
        "the dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder - decoder configuration .",
        "we study the representation and encoding of phonemes in a recurrent neural network model of grounded speech .",
        "we consider an approach to query - by - example search that embeds both the query and database segments according to a neural model , followed by nearest - neighbor search to find the matching segments .",
        "we find that our embeddings , based on recurrent neural networks trained to optimize word discrimination , achieve substantial improvements in performance and run - time efficiency over the previous approaches .",
        "neural machine translation ( nmt ) models usually use large target vocabulary sizes to capture most of the words in the target language .",
        "we explore six challenges for neural machine translation : domain mismatch , amount of training data , rare words , long sentences , word alignment , and beam search .",
        "while going deeper has been witnessed to improve the performance of convolutional neural networks ( cnn ) , going smaller for cnn has received increasing attention recently due to its attractiveness for mobile / embedded applications .",
        "to address these difficulties , we propose bloom embeddings , a compression technique that can be applied to the input and output of neural network models dealing with sparse high - dimensional binary - coded instances .",
        "the first part is a novel deep alternative neural network ( dann ) used to generate candidates of next move .",
        "compared with existing deep convolutional neural network ( dcnn ) , dann inserts recurrent layer after each convolutional layer and stacks them in an alternative manner .",
        "this reduction has several advantages : we can ( 1 ) learn relation - extraction models by extending recent neural reading - comprehension techniques , ( 2 ) build very large training sets for those models by combining relation - specific crowd - sourced questions with distant supervision , and even ( 3 ) do zero - shot learning by extracting new relation types that are only specified at test - time , for which we have no labeled training examples .",
        "in this work , we explore multiple neural architectures adapted for the task of automatic post - editing of machine translation output .",
        "we focus on neural end - to - end models that combine both inputs $ mt $ and $ src $ in a single neural architecture , modeling $ \\ { mt , src \\ } \\ rightarrow pe $ directly .",
        "recurrent neural networks have recently been shown to perform very well in session - based settings .",
        "recent advances in convolutional neural networks ( cnn ) allow us to shift our focus to learning entities and relations from images , as they build robust models that require little or no pre - processing of the images .",
        "convolutional neural networks ( cnns ) have shown great success in computer vision , approaching human - level performance when trained for specific tasks via application - specific loss functions .",
        "the recent adaptation of deep neural network - based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks .",
        "we compare three approaches to statistical machine translation ( pure phrase - based , factored phrase - based and neural ) by performing a fine - grained manual evaluation via error annotation of the systems ' outputs .",
        "inter - annotator agreement is high for such a task , and results show that the best performing system ( neural ) reduces the errors produced by the worst system ( phrase - based ) by 54 % .",
        "we propose several neural models arranged in a two - stage framework to tackle question generation from documents .",
        "first , we estimate the probability of \" interesting \" answers in a document using a neural model trained on a question - answering corpus .",
        "empirically , our neural key phrase detection models significantly outperform an entity - tagging baseline system .",
        "we discover that modern neural networks , unlike those from a decade ago , are poorly calibrated .",
        "our analysis and experiments not only offer insights into neural network learning , but also provide a simple and straightforward recipe for practical settings : on most datasets , temperature scaling - - a single - parameter variant of platt scaling - - is surprisingly effective at calibrating predictions .",
        "we offer a generalized point of view on the backpropagation algorithm , currently the most common technique to train neural networks via stochastic gradient descent and variants thereof .",
        "in a systematic quantitative analysis , we compare to related approaches on a supervised visual learning task ( cifar - 10 ) for fully connected as well as convolutional neural networks and for an unsupervised autoencoder ( usps dataset ) .",
        "we use a wrist - mounted sensor to acquire depth images in front of the gripper and train a convolutional neural network that directly learns the value function for grasp pose candidates .",
        "ongoing research has proposed several methods to defend neural networks against adversarial examples , many of which researchers have shown to be ineffective .",
        "we build the answer extraction model with state - of - the - art neural networks for reading comprehension , and the answer generation model with sequence - to - sequence neural networks .",
        "at the heart of deep learning we aim to use neural networks as function approximators - training them to produce outputs from inputs in emulation of a ground truth function or data creation process .",
        "in many cases we only have access to input - output pairs from the ground truth , however it is becoming more common to have access to derivatives of the target output with respect to the input - for example when the ground truth function is itself a neural network such as in network compression or distillation .",
        "this paper introduces sobolev training for neural networks , which is a method for incorporating these target derivatives in addition the to target values while training .",
        "by optimising neural networks to not only approximate the function ' s outputs but also the function ' s derivatives we encode additional information about the target function within the parameters of the neural network .",
        "the state - of - the - art solutions to the vocabulary mismatch in information retrieval ( ir ) mainly aim at leveraging either the relational semantics provided by external resources or the distributional semantics , recently investigated by deep neural approaches .",
        "guided by the intuition that the relational semantics might improve the effectiveness of deep neural approaches , we propose the deep semantic resource inference model ( dsrim ) that relies on : 1 ) a representation of raw - data that models the relational semantics of text by jointly considering objects and relations expressed in a knowledge resource , and 2 ) an end - to - end neural architecture that learns the query - document relevance by leveraging the distributional and relational semantics of documents and queries .",
        "the experimental evaluation carried out on two trec datasets from trec terabyte and trec cds tracks relying respectively on wordnet and mesh resources , indicates that our model outperforms state - of - the - art semantic and deep neural ir models .",
        "deep neural networks are known to be difficult to train due to the instability of back - propagation .",
        "the past few years have witnessed a growth in size and computational requirements for training and inference with neural networks .",
        "importantly , the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions .",
        "our main result is that on inception - v3 for imagenet classification , and on rnn lstm , for language modeling and neural machine translation , our model finds non - trivial device placements that outperform hand - crafted heuristics and traditional algorithmic methods .",
        ", convolutional neural networks ) offer a promising solution .",
        "to deal with delayed reward , we propose a new neural architecture in the meta controller that learns when to update the subtask , which makes learning more efficient .",
        "this work presents a novel approach to jointly tackling automatic post - editing ( ape ) and word - level quality estimation ( qe ) using ensembles of specialized neural machine translation ( nmt ) systems .",
        "we show that it outperforms a strong baseline on three character - level decoder neural machine translation on wmt ' 15 corpus .",
        "in our experiments , we expose qualitative differences in gradient - based optimization of deep neural networks ( dnns ) on noise vs .",
        "adaptive gradient methods have become recently very popular , in particular as they have been shown to be useful in the training of deep neural networks .",
        "in this paper we have analyzed rmsprop , originally proposed for the training of deep neural networks , in the context of online convex optimization and show $ \\ sqrt { t } $ - type regret bounds .",
        "finally , we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or stochastic gradient descent in the optimization of strongly convex functions as well as in training of deep neural networks .",
        "we propose a simple yet effective technique for neural network learning .",
        "convolution is a critical component in modern deep neural networks , thus several algorithms for convolution have been developed .",
        "we instead propose a hierarchical policy class that automatically reasons about both long - term and short - term goals , which we instantiate as a hierarchical neural network .",
        "we present a method for training a convolutional neural network such that it takes in an input image and produces a full graph .",
        "deep neural networks ( dnns ) have advanced performance on a wide range of complex tasks , rapidly outpacing our understanding of the nature of their solutions .",
        "inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task .",
        "specifically , safetynets develops and implements a specialized interactive proof ( ip ) protocol for verifiable execution of a class of deep neural networks , i .",
        "our empirical results on three - and four - layer deep neural networks demonstrate the run - time costs of safetynets for both the client and server are low .",
        "safetynets detects any incorrect computations of the neural network by the untrusted server with high probability , while achieving state - of - the - art accuracy on the mnist digit recognition ( 99 .",
        "we propose a novel deep neural networks ( dnn ) based model , canonical correlated autoencoder ( c2ae ) , for solving this task .",
        "in state - of - the - art neural machine translation ( nmt ) , an attention mechanism is used during decoding to enhance the translation .",
        "we propose character - level neural sequence - to - sequence ( s2s ) methods for the task of portmanteau generation that are end - to - end - trainable , language independent , and do not explicitly use additional phonetic information .",
        "while natural languages are compositional , how state - of - the - art neural models achieve compositionality is still unclear .",
        "further developing upon recent work on neural machine translation , we propose a new hybrid neural model with nested attention layers for gec .",
        "experiments show that the new model can effectively correct errors of both types by incorporating word and character - level information , and that the model significantly outperforms previous neural models for gec as measured on the standard conll - 14 benchmark dataset .",
        "recent work has proposed several generative neural models for constituency parsing that achieve state - of - the - art results .",
        "this paper proposes a novel deep reinforcement learning ( rl ) architecture , called value prediction network ( vpn ) , which integrates model - free and model - based rl methods into a single neural network .",
        "the prnet first projects the drifted data to a feature space , and uses a powerful deep convolutional neural network to recover the estimated drift - free measurements .",
        "we also provide helpful insights for designing deep neural networks for sensor calibration .",
        "existing algorithms even though are accurate but they do not focus on utilizing the parameters of neural network efficiently .",
        "in this paper , we propose a novel deep neural network architecture which allows it to learn without any significant increase in number of parameters .",
        "both bottom - up and top - down strategies have been used for neural transition - based constituent parsing .",
        "this paper proposes a hierarchical attentional neural translation model which focuses on enhancing source - side hierarchical representations by covering both local and global semantic information using a bidirectional tree - based encoder .",
        "empirical results reveal that the proposed model significantly outperforms sequence - to - sequence attention - based and tree - based neural translation models in english - chinese translation tasks .",
        "most neural machine translation ( nmt ) models are based on the sequential encoder - decoder framework , which makes no use of syntactic information .",
        "in this paper , we show that a neural language model such as word2vec only necessitates minor modifications to its standard architecture to learn new terms from tiny data , using background knowledge from a previously learnt semantic space .",
        "sgnmt provides a generic interface to neural and symbolic scoring modules ( predictors ) with left - to - right semantic such as translation models like nmt , language models , translation lattices , $ n $ - best lists or other kinds of scores and constraints .",
        "we present a newly collected police fatality corpus , which we release publicly , and present a model to solve this problem that uses em - based distant supervision with logistic regression and convolutional neural network classifiers .",
        "we present a novel neural model hypervec to learn hierarchical embeddings for hypernymy detection and directionality .",
        "the context word sequence , together with a parts - of - speech tag sequence and a dependency relation sequence that are generated corresponding to the word sequence , are then provided as input to bidirectional recurrent neural network ( lstm ) models .",
        "the neural nets learn compositional syntactic and semantic representations of contexts surrounding the two events and predict the temporal relation between them .",
        "evaluation of the proposed approach on timebank corpus shows that sequential modeling is capable of accurately recognizing temporal relations between events , which outperforms a neural net model using various discrete features as input that imitates previous feature based models .",
        "yet , current neural machine translation training focuses on expensive human - generated reference translations .",
        "we describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback .",
        ", 2016 ) with the attention - based neural encoder - decoder architecture ( luong et al .",
        "we introduce globally normalized convolutional neural networks for joint entity classification and relation extraction .",
        "recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records .",
        "in particular , we introduce a new , large - scale corpus of data records paired with descriptive documents , propose a series of extractive evaluation methods for analyzing performance , and obtain baseline results using current neural generation methods .",
        "moreover , even templated baselines exceed the performance of these neural models on some metrics , though copy - and reconstruction - based extensions lead to noticeable improvements .",
        "our results suggest that neural representations are capable of spontaneously developing a \" syntax \" with functional analogues to qualitative properties of natural language .",
        "to ensure good interpretability and appropriate lexical usage we combine symbolic and neural representations , using a neural reasoning algorithm trained on commonsense causal tuples to predict the next cause step .",
        "deep residual learning ( resnet ) is a new method for training very deep neural networks using identity map - ping for shortcut connections .",
        "in this paper , we design a novel convolutional neural network ( cnn ) with residual learning , and investigate its impacts on the task of distantly supervised noisy relation extraction .",
        "generative neural models have recently achieved state - of - the - art results for constituency parsing .",
        "we describe an alternative to the conventional action - level beam search used for discriminative neural models that enables us to decode directly in these generative models .",
        "we argue that relevant law articles play an important role in this task , and therefore propose an attention - based neural network method to jointly model the charge prediction task and the relevant article extraction task in a unified framework .",
        "one central mystery of neural nlp is what neural models \" know \" about their subject matter .",
        "when a neural machine translation system learns to translate from one language to another , does it learn the syntax or semantics of the languages ?",
        "exploiting the existence of parallel texts in more than a thousand languages , we build a massive many - to - one neural machine translation ( nmt ) system from 1017 languages into english , and use this to predict information missing from typological databases .",
        "we investigate techniques for supervised domain adaptation for neural machine translation where an existing model trained on a large out - of - domain dataset is adapted to a small in - domain dataset .",
        "we apply these techniques , alone and in combination , to neural machine translation , obtaining improvements on iwslt datasets for english - & gt ; german and english - & gt ; russian .",
        "we show that small and shallow feed - forward neural networks can achieve near state - of - the - art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models .",
        "motivated by resource - constrained environments like mobile phones , we showcase simple techniques for obtaining such small neural network models , and investigate different tradeoffs when deciding how to allocate a small memory budget .",
        "with the recent increase in popularity of neural machine translation ( nmt ) , we explore in this paper to what extent and how nmt can also benefit from data selection .",
        "we experimented with l - dmv , a lexicalized version of dependency model with valence and l - ndmv , our lexicalized extension of the neural dependency model with valence .",
        "in the encoder - decoder architecture for neural machine translation ( nmt ) , the hidden states of the recurrent structures in the encoder and decoder carry the crucial information about the sentence .",
        "however , it is difficult to integrate them into current neural machine translation ( nmt ) which reads and generates sentences word by word .",
        "neural machine translation ( nmt ) has achieved notable success in recent times , however it is also widely recognized that this approach has limitations with handling infrequent words and word pairs .",
        "this paper presents a novel memory - augmented nmt ( m - nmt ) architecture , which stores knowledge about how words ( usually infrequently encountered ones ) should be translated in a memory and then utilizes them to assist the neural model .",
        "for this task , we make use of the visual storytelling dataset and a model composed of three hierarchically - attentive recurrent neural nets ( rnns ) to : encode the album photos , select representative ( summary ) photos , and compose the story .",
        "in this paper , we introduce a hybrid search for attention - based neural machine translation ( nmt ) .",
        "we propose a dynamic ranking paradigm , named as dnn - mab , that is composed of a pairwise deep neural network ( dnn ) $ \\ mathit { pre } $ - ranker connecting a revised multi - armed bandit ( mab ) dynamic $ \\ mathit { post } $ - ranker .",
        "we show how the robot can successfully perform a tight clearance peg - in - hole task through training a recurrent neural network with reinforcement learning .",
        "the neural network learns to take the optimal action by observing the robot sensors to estimate the system state .",
        "here we present a novel routing methodology that employs both hierarchical and mesh routing strategies and combines heterogeneous memory structures for minimizing both memory requirements and latency , while maximizing programming flexibility to support a wide range of event - based neural network architectures , through parameter configuration .",
        "finally , we demonstrate the use of the neuromorphic processor with a convolutional neural network for the real - time classification of visual symbols being flashed",
        "this paper introduces a corpus for text - based emotion detection on multiparty dialogue as well as deep neural models that outperform the existing approaches for document classification .",
        "we then suggest four types of sequence - based convolutional neural network models with attention that leverage the sequence information encapsulated in dialogue .",
        "we propose a method for embedding two - dimensional locations in a continuous vector space using a neural network - based model incorporating mixtures of gaussian distributions , presenting two model variants for text - based geolocation and lexical dialectology .",
        "character - based neural lms provide a straight forward solution for open vocabulary speech recognition and all - neural models , and can be decoded with beam search .",
        "neural networks are capable of learning rich , nonlinear feature representations shown to be beneficial in many predictive tasks .",
        "first , a biometric is applied to a neural network to create a feature vector .",
        "this neural network alone can be used for one - to - one matching ( authentication ) ,",
        "existing works based on deep neural network ( dnn ) mostly construct one common space for different modalities to find the latent alignments between them , which lose their exclusive modality - specific characteristics .",
        "we give initial baseline results for neural networks trained from this data to predict game outcomes and player actions .",
        "in particular , it considers the neural binding structure of an earlier paper .",
        "it is suggested that the simplest of linking between a tree and ensemble can explain neural binding and variable signal strengths .",
        "in this paper , we propose a novel multi - task neural network approach for both encoding and prediction of non - discrete attribute information in a relational setting .",
        "specifically , we train a neural network for triplet prediction along with a separate network for attribute value regression .",
        "compared to a hybrid of convolutional neural network and long - short - term - memory ( cnn - lstm ) , our proposed 3d cnns simultaneously extract short - term and long - term spectral features with a moderate number of parameters .",
        "inspired by convolutional neural networks , we propose a new mechanism to store relevant context in different memory slots to model context information .",
        "recent applications of neural language models have led to an increased interest in the automatic generation of natural language .",
        "however impressive , the evaluation of neurally generated text has so far remained rather informal and anecdotal .",
        "here , we present an attempt at the systematic assessment of one aspect of the quality of neurally generated text .",
        "we focus on a specific aspect of neural language generation : its ability to reproduce authorial writing styles .",
        "using established models for authorship attribution , we empirically assess the stylistic qualities of neurally generated text .",
        "in comparison to conventional language models , neural models generate fuzzier text that is relatively harder to attribute correctly .",
        "nevertheless , our results also suggest that neurally generated text offers more valuable perspectives for the augmentation of training data .",
        "convolutional neural network provides an end - to - end solution to train many computer vision tasks and has gained great successes .",
        "recently , bidirectional recurrent network language models ( bi - rnnlms ) have been shown to outperform standard , unidirectional , recurrent neural network language models ( uni - rnnlms ) on a range of speech recognition tasks .",
        "in this paper these issues are addressed by proposing a novel neural network structure , succeeding word rnnlms ( su - rnnlms ) .",
        "an efficient algorithm for recurrent neural network training is presented .",
        "an example is given for the online handwriting recognition task using an lstm recurrent neural network .",
        "neural machine translation ( nmt ) approaches have improved the state of the art in many machine translation settings over the last couple of years , but they require large amounts of training data to produce sensible output .",
        "we describe the 2017 version of microsoft ' s conversational speech recognition system , in which we update our 2016 system with recent developments in neural - network - based acoustic and language modeling to further advance the state of the art on the switchboard speech recognition task .",
        "we cast the problem as sequence tagging and introduce semi - supervised methods to a neural tagging model , which builds on recent advances in named entity recognition .",
        "in this series of notes , we try to model neural networks as as discretizations of continuous flows on the space of data , which can be called flow model .",
        "however , with the advent of neural machine translation ( nmt ) systems , which can theoretically take into account global sentential context , one may hypothesize that this problem has been alleviated .",
        "the deployment of deep convolutional neural networks ( cnns ) in many real world applications is largely hindered by their high computational cost .",
        "while hierarchy and partial observability are usually tackled separately , for instance by combining recurrent neural networks and options , we show that addressing both problems simultaneously is simpler and more efficient in many cases .",
        "our experiments show that oois allow agents to learn optimal policies in challenging pomdps , outperforming an human - provided policy in our robotic experiment , while learning much faster than a recurrent neural network over options .",
        "in this paper we show that outsourced training introduces new security risks : an adversary can create a maliciously trained network ( a backdoored neural network , or a \\ emph { badnet } ) that has state - of - the - art performance on the user ' s training and validation samples , but behaves badly on specific attacker - chosen inputs .",
        "we address the problem of anytime prediction in neural networks .",
        "recurrent neural networks ( rnns ) continue to show outstanding performance in sequence modeling tasks .",
        "the performance of neural network ( nn ) - based language models is steadily improving due to the emergence of new architectures , which are able to learn different natural language characteristics .",
        "extensive experiments conducted on the penn treebank ( ptb ) and the large text compression benchmark ( ltcb ) corpus showed a significant reduction of the perplexity when compared to state - of - the - art feedforward as well as recurrent neural network architectures .",
        "during the last years , convolutional neural networks ( cnns ) have achieved state - of - the - art performance in image classification .",
        "the techniques from the literature that are presented herein have great performances , however , instead of the machine learning techniques employed in these works , we propose to use deep learning techniques such as long - short term memory ( lstm ) recurrent neural network ( rnn ) , and show the improved performance .",
        "deep neural networks are generally trained using iterative gradient updates .",
        "this paper demonstrates neural network - based toolkit namely nnvlp for essential vietnamese language processing tasks including part - of - speech ( pos ) tagging , chunking , named entity recognition ( ner ) .",
        "our toolkit is a combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which outperforms previously published toolkits on these three tasks .",
        "an exhaustive study on neural network language modeling ( nnlm ) is performed in this paper .",
        "different architectures of basic neural network language models are described and examined .",
        "a number of different improvements over basic neural network language models , including importance sampling , word classes , caching and bidirectional recurrent neural network ( birnn ) , are studied separately , and the advantages and disadvantages of every technique are evaluated .",
        "then , the limits of neural network language modeling are explored from the aspects of model architecture and knowledge representation .",
        "part of the statistical information from a word sequence will loss when it is processed word by word in a certain order , and the mechanism of training neural network by updating weight matrixes and vectors imposes severe restrictions on any significant enhancement of nnlm .",
        "for knowledge representation , the knowledge represented by neural network language models is the approximate probabilistic distribution of word sequences from a certain training data set rather than the knowledge of a language itself or the information conveyed by word sequences in a natural language .",
        "finally , some directions for improving neural network language modeling further is discussed .",
        "neural network models have recently received heated research attention in the natural language processing community .",
        "compared with traditional models with discrete features , neural models have two main advantages .",
        "second , deep neural networks can be used to automatically combine input features , and including non - local features that capture semantic patterns that cannot be expressed using discrete indicator features .",
        "as a result , neural network models have achieved competitive accuracies compared with the best discrete models for a range of nlp tasks .",
        "for such domains , we propose to use deep neural networks in learning for planning , based on learning a reactive policy that imitates execution traces produced by a planner .",
        "to model changing customer and store environments , our recommendation method employs a pair of neural networks : to overcome the cold start problem , a feedforward network generates article embeddings in \" fashion space , \" which serve as input to a recurrent neural network that predicts a style vector in this space for each client , based on their past purchase sequence .",
        "we describe a recurrent neural network model that can capture long range context and compare it to a baseline logistic regression model corresponding to the current cloudscan production system .",
        "the recurrent neural network and baseline model achieve 0 .",
        "for the harder task of unseen invoice layouts , the recurrent neural network model outperforms the baseline with 0 .",
        "we design a siamese convolutional neural network architecture and feed it with title pairs of items , which are either compatible or incompatible .",
        "recent advances in deep neural networks ( dnns ) have led to the development of dnn - driven autonomous cars that , using sensors like camera , lidar , etc .",
        "the performance tests for the de facto standard mnist data set were carried out on h2o framework for deep learning algorithms designed for cpu and gpu platforms for single - threaded and multithreaded modes of operation also , we present the results of testing neural networks architectures on h2o platform for various activation functions , stopping metrics , and other parameters of machine learning algorithm .",
        "compared to current poisoning strategies , our approach is able to target a wider class of learning algorithms , trained with gradient - based procedures , including neural networks and deep learning architectures .",
        "in this paper , we explore alternative ways to train a neural machine translation system in a multi - domain scenario .",
        "a study to compare the reliability and efficiency of artificial neural network and support vector machine in detecting nontor traffic in unb - cic tor network traffic dataset is presented in this paper .",
        "a hybrid artificial neural network proved a better classifier than svm in detecting nontor traffic in unb - cic tor network traffic dataset .",
        "we also propose a new initialization method that uses the pre - trained weights from a feed - forward neural network to initialize our lstm - based model .",
        "specifically , we train convolutional neural networks to predict population in the usa at a $ 0 .",
        "the generation of complex derived word forms has been an overlooked problem in nlp ; we fill this gap by applying neural sequence - to - sequence models to the task .",
        "state - of - the - art neural models , adapted from the inflection task , are able to learn a range of derivation patterns , and outperform a non - neural baseline by 16 .",
        "in the work presented here , we explore a transfer learning scheme , whereby we train character - level recurrent neural taggers to predict morphological taggings for high - resource languages and low - resource languages together .",
        "the usefulness of this concept is illustrated over a number of applied areas , including generalized regression and classification ( support tensor machines , canonical correlation analysis , higher order partial least squares ) , generalized eigenvalue decomposition , riemannian optimization , and in the optimization of deep neural networks .",
        "the attention model has become a standard component in neural machine translation ( nmt ) and it guides translation process by selectively focusing on parts of the source sentence when predicting each target word .",
        "however , we find that the generation of a target word does not only depend on the source sentence , but also rely heavily on the previous generated target words , especially the distant words which are difficult to model by using recurrent neural networks .",
        "in this paper , we adapt neural machine translation ( nmt ) to automatically \" translate \" diffs into commit messages .",
        "we present a simple method to improve neural translation of a low - resource language pair using parallel data from a related , also low - resource one .",
        "in recent years researchers have achieved considerable success applying neural network methods to question answering ( qa ) .",
        "being inspired by the success of convolutional neural networks in computer vision , we use them to incorporate the spatio - structural patterns of chinese glyphs as rendered in raw pixels .",
        "we evaluate state - of - the - art deep convolutional neural network ( cnns ) on this novel dataset with its different spectral bands .",
        "we propose seq2sql , a deep neural network for translating natural language questions to corresponding sql queries .",
        "in recent studies , researchers use neural language models and encoder - decoder frameworks for table - to - text generation .",
        "however , these neural network - based approaches do not model the order of contents during text generation .",
        "in order to achieve a robust adi system , we explored both siamese neural network models to learn similarity and dissimilarities among arabic dialects , as well as i - vector post - processing to adapt domain mismatches .",
        "we present a neural transition - based parser for spinal trees , a dependency representation of constituent trees .",
        "there is an increasing interest on accelerating neural networks for real - time applications .",
        "this is done using multilayer perceptron neural network which can be adaptively trained to showcase the true nature of the compatibility index .",
        "also , a recurrent neural network in which a word is represented as a sum of embeddings of its patterns is on",
        "specifically , we utilize a convolutional neural network ( cnn ) as a quasi - projection operator within a least squares minimization procedure .",
        "we explore three language - independent alternatives to morphological segmentation using : i ) data - driven sub - word units , ii ) characters as a unit of learning , and iii ) word embeddings learned using a character cnn ( convolution neural network ) .",
        "in our analysis , we show that a neural machine translation system is sensitive to the ratio of source and target tokens , and a ratio close to 1 or greater , gives optimal performance .",
        "we combine a generative model parameterized by deep neural networks with non - linear embedding technique .",
        "we propose a methodology for designing dependable artificial neural networks ( ann ) by extending the concepts of understandability , correctness , and validity that are crucial ingredients in existing certification standards .",
        "in this paper , we use the optimal ratio mask as the training target of the deep neural network ( dnn ) for speech separation .",
        "we explain how the prototype automatic chess problem composer , chesthetica , successfully composed a rare and interesting chess problem using the new digital synaptic neural substrate ( dsns ) computational creativity approach .",
        "embed - rul utilizes a sequence - to - sequence model based on recurrent neural networks ( rnns ) to generate embeddings for multivariate time series subsequences .",
        "recent work on reinforcement learning and other gradient estimators for latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence , all without exposure to ground - truth parse trees at training time .",
        "for computer vision applications , prior works have shown the efficacy of reducing numeric precision of model parameters ( network weights ) in deep neural networks .",
        "in this context , exploiting deep neural network ( dnn ) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for hmm based decoding .",
        "we propose \\ emph { neural word salience } ( nws ) scores , unlike heuristics , are learnt from a corpus .",
        "we consider paragraph - level linguistic features to unveil the satire by incorporating neural network and attention mechanism .",
        "this study addresses the problem of identifying the meaning of unknown words or entities in a discourse with respect to the word embedding approaches used in neural language models .",
        "we proposed a method for on - the - fly construction and exploitation of word embeddings in both the input and output layers of a neural model by tracking contexts .",
        "deep neural networks are state of the art methods for many learning tasks due to their ability to extract increasingly better features at each network layer .",
        "even though sequence - to - sequence neural machine translation ( nmt ) model have achieved state - of - art performance in the recent fewer years , but it is widely concerned that the recurrent neural network ( rnn ) units are very hard to capture the long - distance state information , which means rnn can hardly find the feature with long term dependency as the sequence becomes longer .",
        "similarly , convolutional neural network ( cnn ) is introduced into nmt for speeding recently , however , cnn focus on capturing the local feature of the sequence ; to relieve this issue , we incorporate a relation network into the standard encoder - decoder framework to enhance information - propogation in neural network , ensuring that the information of the source sentence can flow into the decoder adequately .",
        "in this work , we present a neural framework for supporting and studying users in both types of communities .",
        "we introduce such a model for the task of machine translation , pairing a recurrent neural network grammar encoder with a novel attentional rnng decoder and applying policy gradient reinforcement learning to induce unsupervised tree structures on both the source and target .",
        "deep neural networks ( dnn ) have been successfully applied for music classification tasks including music tagging .",
        "in this paper , we investigate the effect of audio preprocessing on music tagging with neural networks .",
        "we further study the invariances in neural networks , suggest complexity measures and optimization algorithms that have similar invariances to those in neural networks and evaluate them on a number of learning tasks .",
        "due to the challenges , we train and translate the terminological expressions in the medial and financial domain with statistical as well as with neural machine translation methods .",
        "nevertheless , through the specific and unique terminological expressions , subword segmentation within nmt does not outperform a word based neural translation model .",
        "the patch extracted around this object is subsequently fed through an off - the - shelf deep convolutional neural network to obtain a high level feature representation , which is then combined with traditional surface electromyography in the classification stage .",
        "long - short term memory recurrent neural networks ( lstm - rnn ) is applied as the basic uni - modality model to capture long time dependencies .",
        "we study embedded binarized neural networks ( ebnns ) with the aim of allowing current binarized neural networks ( bnns ) in the literature to perform feedforward inference efficiently on small embedded devices .",
        "to accomplish this , ebnn reorders the computation of inference while preserving the original bnn structure , and uses just a single floating - point temporary for the entire neural network .",
        "we present a novel method to embed discourse features in a convolutional neural network text classifier , which achieves a state - of - the - art result by a substantial margin .",
        "when convolutional neural networks are used to tackle learning problems based on time series , e .",
        ", audio data , raw one - dimensional data are commonly pre - processed to obtain spectrogram or mel - spectrogram coefficients , which are then used as input to the actual neural network .",
        "an extensive set of experiments shows that the proposed deep neural networks are able to answer the visual - relational queries efficiently and accurately .",
        "we propose a neural embedding algorithm called network vector , which learns distributed representations of nodes and the entire networks simultaneously .",
        "the expressive power of neural networks is important for understanding deep learning .",
        "in this paper , we study how width affects the expressiveness of neural networks .",
        "several recent works demonstrate the benefits of depth by proving the depth - efficiency of neural networks .",
        "kernel methods have recently attracted resurgent interest , matching the performance of deep neural networks in tasks such as speech recognition .",
        "after initial pre - processing phase on data , packets are fed to deep packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic .",
        "recurrent neural networks scale poorly due to the intrinsic difficulty in parallelizing their state computations .",
        "we show how vector representations maintaining semantic characteristics of the original data can be obtained from a given graph using neural encoding architectures and considering the topological properties of the graph .",
        "existing neural approaches make use of expensive bi - directional attention mechanisms or score all possible answer spans , limiting scalability .",
        "we present joint end - to - end neural network architectures that combine long short - term memory ( lstm ) and a latent topic model to simultaneously train a classifier for mortality prediction and learn latent topics indicative of mortality from textual clinical notes .",
        "however , we achieve limited success with our method for interpreting topics from the trained models by looking at the neural network weights .",
        "we simulate multiple environments in parallel , and group them to perform the neural network computation on a batch rather than individual observations .",
        "although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices , they overlooked the reliability of mobile computing models .",
        "we propose simple and flexible training and decoding methods for influencing output style and topic in neural encoder - decoder based language generation .",
        "we decompose the neural generation process into empirically easier sub - problems : a faithfulness model and a decoding method based on selective - sampling .",
        "our system builds upon a state - of - the - art fully convolutional artificial neural network ( fcn ) as well as an active user model for training .",
        "vulnerability of state - of - the - art deep neural networks to adversarial attacks has been attracting a lot of attention recently .",
        "in this work , a computational intelligence ( ci ) technique named flexible neural tree ( fnt ) was developed to predict die filling performance of pharmaceutical granules and to identify significant die filling process variables .",
        "fnt resembles feedforward neural network , which creates a tree - like structure by using genetic programming .",
        "while some remarkable progress has been made in neural machine translation ( nmt ) research , there have not been many reports on its development and evaluation in practice .",
        "for visual features we used the hog ( histogram of gradients ) features , fisher encodings of sift ( scale - invariant feature transform ) features based on gaussian mixture model ( gmm ) and some pretrained convolutional neural network layers as features ; all these extracted for each video clip .",
        "then we trained fully connected neural network regression model on the dataset for all these different modalities .",
        "classification is done on fused as well as independent features using support vector machine ( svm ) and neural networks .",
        "recently , deep neural networks ( dnns ) have been demonstrated to achieve superior object detection performance compared to other approaches , with yolov2 ( an improved you only look once model ) being one of the state - of - the - art in dnn - based object detection methods in terms of both speed and accuracy .",
        "our approach explores sequence - to - sequence learning using a bidirectional multi - layer recurrent neural network .",
        "to overcome such performance limitations , we propose a novel machine learning algorithm , namely boosted subspace probabilistic neural network ( bspnn ) , which integrates an adaptive boosting technique and a semi parametric neural network to obtain good tradeoff between accuracy and generality .",
        "artificial neural network ( ann ) s has widely been used for recognition of optically scanned character , which partially emulates human thinking in the domain of the artificial intelligence .",
        "recursive neural networks are non - linear adaptive models that are able to learn deep structured information .",
        "in this paper , we propose a model of boolean neural network that incorporates these strategies by recurring to global optimization strategies during the learning session .",
        "the model characterizes as well the passage from an unstructured / chaotic attractor neural network typical of data - driven processes to a faster one , forward - only and representative of schema - driven processes .",
        "in this paper , a new content - based method for the purpose of file type detection and file type clustering is proposed that is based on the pca and neural networks .",
        "basic symbols are recognized by neural classifier .",
        "we report recent research on computing with biology - based neural network models by means of physics - based opto - electronic hardware .",
        "the difficulty of the arabic handwriting recognition is that , the accuracy of the character recognition which affects on the accuracy of the word recognition , in additional there is also two or three from for each character , the suggested solution by using artificial neural network can solve the problem and overcome the difficulty of arabic handwriting recognition .",
        "we show that the learning sample complexity of a sigmoidal neural network constructed by sontag ( 1992 ) required to achieve a given misclassification error under a fixed purely atomic distribution can grow arbitrarily fast : for any prescribed rate of growth there is an input distribution having this rate as the sample complexity , and the bound is asymptotically tight .",
        "we propose to use a model called growing neural gas to learn by imitation the topology of the environment .",
        "improvements for the growing neural gas to give more information to the character ' s model are given in the conclusion .",
        "we propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including : part - of - speech tagging , chunking , named entity recognition , and semantic role labeling .",
        "regularization is a well studied problem in the context of neural networks .",
        "we demonstrate the power of complexification through the neuroevolution of augmenting topologies ( neat ) method , which evolves increasingly complex neural network architectures .",
        "nowadays , computer scientists have shown the interest in the study of social insect ' s behaviour in neural networks area for solving different combinatorial and statistical problems .",
        "standard problem solver architectures of personal computers or neural networks tend to generalize by solving numerous tasks outside the self - invented training set ; powerplay ' s ongoing search for novelty keeps fighting to extend beyond the generalization abilities of its present solver .",
        "the proposed semi - supervised method is a model by means of a feed - forward neural network trained by a back propagation algorithm ( multi - layer perceptron ) in order to predict the category of an unknown customer ( potential customers ) .",
        "this paper presents a lcs where each traditional rule is represented by a spiking neural network , a type of network with dynamic internal state .",
        "the cg is considerably depends on initial weights of connections of artificial neural network ( ann ) , so , a metaheuristic algorithm , the so - called modified cuckoo search is applied in order to select the optimal weights .",
        "unlike neural networks , however , these circuits take \" concepts \" or \" percepts \" as inputs and outputs .",
        "we classify digits of real - world house numbers using convolutional neural networks ( convnets ) .",
        "convnets are hierarchical feature learning neural networks whose structure is biologically inspired .",
        "a number of representation schemes have been presented for use within learning classifier systems , ranging from binary encodings to neural networks .",
        "a number of representation schemes have been presented for use within learning classifier systems , ranging from binary encodings to neural networks , and more recently dynamical genetic programming ( dgp ) .",
        "computational analysis of time - course data with an underlying causal structure is needed in a variety of domains , including neural spike trains , stock price movements , and gene expression levels .",
        "this paper deals with the distributed processing in the search for an optimum classification model using evolutionary product unit neural networks .",
        "in order to get the best classification models we use evolutionary algorithms to train and design neural networks , which require a very time consuming computation .",
        "this paper demonstrates the nature of handwritten characters , conversion of handwritten data into electronic data , and the neural network approach to make machine capable of recognizing hand written characters .",
        "this paper demonstrates the use of neural networks for developing a system that can recognize hand - written english alphabets .",
        "in this system , each english alphabet is represented by binary values that are used as input to a simple feature extraction system , whose output is fed to our neural network system .",
        "this paper proposes a method to derive an accurate and optimized schedule for rejuvenation of a web server ( apache ) by using radial basis function ( rbf ) based feed forward neural network , a variant of artificial neural networks ( ann ) .",
        "aging indicators are obtained through experimental setup involving apache web server and clients , which acts as input to the neural network model .",
        "we then continue with the clustering technique that is used to group the similar things together and discuss the machine learning technique called self - organizing maps [ 6 ] or som , which is a data visualization technique that reduces the dimensions of data through the use of self - organizing neural networks .",
        "these methods include various artificial neural network ( ann ) models ( primarily supervised in nature ) , genetic algorithm ( ga ) based techniques , intensity histogram based methods etc .",
        "we introduce a probabilistic model based on distribution estimators conditioned on a recurrent neural network that is able to discover temporal dependencies in high - dimensional sequences .",
        "in spite of their superior performance , neural probabilistic language models ( nplms ) remain far less widely used than n - gram models due to their notoriously long training times , which are measured in weeks even for moderately - sized datasets .",
        "we demonstrate that inhomogeneous markets of agents with isoelastic utilities outperform state of the art aggregate classifiers such as random forests , as well as single classifiers ( neural networks , decision trees ) on a number of machine learning benchmarks , and show that isoelastic combination methods are generally better than their logarithmic counterparts .",
        "we show in experiments that cp turns out to work well in practice , giving very accurate estimates of the hessian of neural networks , for example , with a relatively small amount of work .",
        "the proposed methodology can be applied to a large class of learning problems including the learning of sparse priors in compressed sensing or identification of linear - nonlinear cascade models in dynamical systems and neural spiking processes .",
        "training recurrent neural networks is more troublesome than feedforward ones because of the vanishing and exploding gradient problems detailed in bengio et al .",
        "in this paper , we present new features and efficiency improvements to theano , and benchmarks demonstrating theano ' s performance relative to torch7 , a recently introduced machine learning library , and to rnnlm , a c + + library targeted at recurrent neural networks .",
        "in this paper , first we present a new explanation for the relation between logical circuits and artificial neural networks , logical circuits and fuzzy logic , and artificial neural networks and fuzzy inference systems .",
        "proposed research work uses anfis ( artificial neural network fuzzy inference system ) for image classification and then compares the results with fcm ( fuzzy c means ) and k - nn ( k - nearest neighbor ) .",
        "after a more than decade - long period of relatively little research activity in the area of recurrent neural networks , several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions towards more efficient training of recurrent networks .",
        "rc models are neural networks which a recurrent part ( the reservoir ) that does not participate in the learning process , and the rest of the system where no recurrence ( no neural circuit ) occurs .",
        "some success was also observed with another recently proposed neural network designed using queueing theory , the random neural network ( randnn ) .",
        "artificial neural networks have emerged as an important tool for classification and have been widely used to classify a non - linear separable pattern .",
        "the most popular artificial neural networks model is a multilayer perceptron ( mlp ) as it is able to perform classification task with significant success .",
        "however due to the complexity of mlp structure and also problems such as local minima trapping , over fitting and weight interference have made neural network training difficult .",
        "this paper presents the ability of functional link neural network ( flnn ) to overcome the complexity structure of mlp by using single layer architecture and propose an artificial bee colony ( abc ) optimization for training the flnn .",
        "in this paper , we present a new neural network architecture designed to embed multi - relational graphs into a flexible continuous vector space in which the original data is kept and enhanced .",
        "this article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting .",
        "past research suggest diminishing returns when increasing the size of neural networks .",
        "recent studies have shown that deep neural networks ( dnns ) perform significantly better than shallow networks and gaussian mixture models ( gmms ) on large vocabulary speech recognition tasks .",
        "a neural probabilistic language model ( nplm ) provide an idea to achieve the better perplexity than n - gram language model and their smoothed language models .",
        "we introduce a neural tensor network ( ntn ) model which predicts new relationship entries that can be added to the database .",
        "a key characteristic of work on deep learning and neural networks in general is that it relies on representations of the input that support generalization , robust inference , domain adaptation and other desirable functionalities .",
        "in this paper , we propose an alternative method that is more efficient than prior work and produces representations that have a property we call focality - - a property we hypothesize to be important for neural network representations .",
        "several recent results in machine learning have established formal connections between autoencoders - - - artificial neural network models that attempt to reproduce their inputs - - - and other coding models like sparse coding and k - means .",
        "the quality of these representations is measured in a word similarity task , and the results are compared to the previously best performing techniques based on different types of neural networks .",
        "besides the paper suggests the structure of neural elements , i .",
        "recently , artificial neural networks ( anns ) have found extensive applications in many practical forecasting problems .",
        "in this paper a stochastic version of the algorithm is adapted to probabilistic neural networks describing the associative dependency of variables .",
        "autoencoder is a special kind of neural network based on reconstruction .",
        "we introduce persistent contextual neural networks ( pcnns ) as a probabilistic model for learning symbolic data sequences , aimed at discovering complex algorithmic dependencies in the sequence .",
        "pcnns are similar to recurrent neural networks but feature an architecture inspired by finite automata and a modified time evolution to better model memory effects .",
        "mel frequency cepstral coefficient ( mfcc ) is used as feature extraction method and generalized regression neural network is used as recognizer .",
        "neural network improves the accuracy .",
        "this paper shows how long short - term memory recurrent neural networks can be used to generate complex sequences with long - range structure , simply by predicting one data point at a time .",
        "experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these \" deep and wide multiscale recursive \" ( dawmr ) networks lead to new levels of image labeling performance .",
        "the neural autoregressive distribution estimator ( nade ) and its real - valued version rnade are competitive density models of multidimensional data across a variety of domains .",
        "our generative model is an $ n $ node multilayer neural net that has degree at most $ n ^ { \\ gamma } $ for some $ \\ gamma & lt ; 1 $ and each edge has a random edge weight in $ [ - 1 , 1 ] $ .",
        "the fusion of the images is performed by feed - forward neural network trained on a set of known examples .",
        "the projection is performed by a multi - layer neural network whose weights are learned on parallel training data .",
        "recurrent neural networks ( rnn ) have recently achieved the best performance in off - line handwriting text recognition .",
        "convolutional neural network models have recently been shown to achieve excellent performance on challenging recognition benchmarks .",
        "to address this , we introduce a novel type of recursive neural network that is convolutional in nature .",
        "we show performance of several well - known types of language models , with the best results achieved with a recurrent neural network based language model .",
        "instead , we build micro neural networks with more complex structures to handle the variance of the local receptive fields .",
        "we instantiate the micro neural network with a nonlinear multiple layer structure which is a potent function approximator .",
        "the deep nin is thus implemented as stacking of multiple sliding micro neural networks .",
        "experimental results on nonlinear dimensionality reduction show that the proposed method can learn abstract representations on both large - scale and small - scale problems , and meanwhile is much faster than deep neural networks on large - scale problems .",
        "scalability properties of deep neural networks raise key research questions , particularly as the problems considered become larger and more challenging .",
        "for sparse neural networks , this can result in considerable speed gains .",
        "experimental results using the mnist and svhn data sets with a fully - connected deep neural network demonstrate the performance robustness of the proposed scheme with respect to the error introduced by the conditional computation process .",
        "finally we train a convolutional neural network to discriminate between these surrogate classes .",
        "in this work , we propose to utilize a single - layer neural networks approach in large - scale multi - label text classification tasks with recently proposed learning techniques .",
        "we carried out experiments on six textual datasets with varying characteristics and size , and show that a simple neural networks model equipped with recent advanced techniques for neural networks components such as activation layer , optimization , and generalization algorithms performs as well as or even outperforms the previous state - of - the - art approaches on large - scale datasets with diverse characteristics .",
        "word embeddings resulting from neural language models have been shown to be successful for a large variety of nlp tasks .",
        "the model is a convolutional neural network , trained with a variant of q - learning , whose input is raw pixels and whose output is a value function estimating future rewards .",
        "in this work we evaluate different approaches to parallelize computation of convolutional neural networks across several gpus within the same server .",
        "standard techniques from the neural networks literature are used to learn the tensors , which are tested on a selectional preference - style task with a simple 2 - dimensional sentence space .",
        "currently , deep neural networks are the state of the art on problems such as speech recognition and computer vision .",
        "moreover , the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model .",
        "our success in training shallow neural nets to mimic deeper models suggests that there probably exist better algorithms for training shallow feed - forward nets than those currently available .",
        "the ability to train large - scale neural networks has resulted in state - of - the - art performance in many areas of computer vision .",
        "we show using gpu a - sgd it is possible to speed up training of large convolutional neural networks useful for computer vision .",
        "recursive neural network models and their accompanying vector representations for words have seen success in an array of increasingly semantically sophisticated tasks , but almost nothing is known about their ability to accurately capture the aspects of linguistic meaning that are necessary for interpretation or reasoning .",
        "deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks .",
        "convolutional neural networks are extremely efficient architectures in image and audio recognition tasks , thanks to their ability to exploit the local translational invariance of signal classes over their domain .",
        "a new initialization method for hidden parameters in a neural network is proposed .",
        "derived from the integral representation of the neural network , a nonparametric probability distribution of hidden parameters is introduced .",
        "in this paper we have developed an ann ( artificial neural network ) based automated coin recognition system for the recognition of indian coins of denomination rs .",
        "then , the extracted features are passed as input to a trained neural network .",
        "we investigate the use of deep neural networks for the novel task of class generic object detection .",
        "we show that neural networks originally designed for image recognition can be trained to detect objects within images , regardless of their class , including objects for which no bounding box labels have been provided .",
        "in this paper , we will assess the customer credit through a combined classification using artificial neural networks , genetics algorithm and bayesian probabilities simultaneously , and the results obtained from three methods mentioned above would be used to achieve an appropriate and final result .",
        "this paper proposes a revised hybrid model built upon empirical mode decomposition ( emd ) based on the feed - forward neural network ( fnn ) modeling framework incorporating the slope - based method ( sbm ) , which is capable of capturing the complex dynamic of crude oil prices .",
        "reservoir computing ( rc ) is a novel approach to time series prediction using recurrent neural networks .",
        "we marry ideas from deep neural networks and approximate bayesian inference to derive a generalised class of deep , directed generative models , endowed with a new algorithm for scalable inference and learning .",
        "we encode our model for text analysis and game playing in a multi - layer neural network , representing linguistic decisions via latent variables in the hidden layers , and game action quality via the output layer .",
        "meanwhile , in recent years , deep neural networks ( dnns ) have shown state - of - the - art performance on various asr tasks .",
        "using these recipes , we can build up multiple systems including dnn hybrid systems , convolutional neural network ( cnn ) systems and bottleneck feature systems .",
        ", quadratic classifier , k - nearest neighbor algorithm , support vector machine , and artificial neural networks .",
        "hierarchical bayesian networks and neural networks with stochastic hidden units are commonly perceived as two separate types of models .",
        "since the 1950s , different computational techniques related to artificial intelligence have been used for algorithmic composition , including grammatical representations , probabilistic methods , neural networks , symbolic rule - based systems , constraint programming and evolutionary algorithms .",
        "to learn these representations we introduce nested dropout , a procedure for stochastically removing coherent nested sets of hidden units in a neural network .",
        "we study the complexity of functions computable by deep feedforward neural networks with piece - wise linear activations in terms of the number of regions of linearity that they have .",
        "this note investigates the complexity of such compositional maps and contributes new theoretical results regarding the advantage of depth for neural networks with piece - wise linear activation functions .",
        "in this paper , we propose a simple but effective coupled neural network , called deeply coupled autoencoder networks ( dcan ) , which seeks to build two deep neural networks , coupled with each other in every corresponding layers .",
        "recurrent neural networks ( rnns ) have the ability , in theory , to cope with these temporal dependencies by virtue of the short - term memory implemented by their recurrent ( feedback ) connections .",
        "we also provide an application of our methods to a classification task using neural networks and to online bayesian matrix factorization .",
        "we propose a statistical learning model for classifying cognitive processes based on distributed patterns of neural activation in the brain , acquired via functional magnetic resonance imaging ( fmri ) .",
        "in this study , linguistic hedges neural - fuzzy classifier with selected features ( lhnfcsf ) is presented for diagnosis of thyroid diseases .",
        "we describe a convolutional architecture dubbed the dynamic convolutional neural network ( dcnn ) that we adopt for the semantic modelling of sentences .",
        "inspired by these observations , we introduce a novel framework based on recurrent neural networks ( rnn ) .",
        "we present a method for training a deep neural network containing sinusoidal activation functions to fit to time - series data .",
        "we provide a method for automatically detecting change in language across time through a chronologically trained neural language model .",
        "here we argue , based on results from statistical physics , random matrix theory , and neural network theory , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep neural network training , and provide preliminary numerical evidence for its superior performance .",
        "latest results indicate that features learned via convolutional neural networks outperform previous descriptors on classification tasks by a large margin .",
        "in this paper we compare features from various layers of convolutional neural nets to standard sift descriptors .",
        "surprisingly , convolutional neural networks clearly outperform sift on descriptor matching .",
        "the system is based on neural network and simulates the process of visual interpretation from remote sensing images and hence increases the efficiency of image analysis .",
        "in addition to the user survey we check the learnability of the evolved games using an artificial neural network based controller .",
        "in this paper , we propose a novel neural network model called rnn encoder - - decoder that consists of two recurrent neural networks ( rnn ) .",
        "the first of these is a simple n - gram model , the other being a recursive neural - network .",
        "supervised recursive neural network models ( rnns ) for sentence meaning have been successful in an array of sophisticated language tasks , but it remains an open question whether they can learn compositional semantic grammars that support logical deduction .",
        "we address this question directly by for the first time evaluating whether each of two classes of neural model - - - plain rnns and recursive neural tensor networks ( rntns ) - - - can correctly learn relationships such as entailment and contradiction between pairs of sentences , where we have generated controlled data sets of sentences from a logical grammar .",
        "experiments on various benchmark tasks - - - word similarity ranking , analogies , sentence completion , and sentiment analysis - - - demonstrate that the method outperforms or is competitive with state - of - the - art neural network representations .",
        "we propose several simple approaches to training deep neural networks on data with noisy labels .",
        "here we argue , based on results from statistical physics , random matrix theory , neural network theory , and empirical evidence , that a deeper and more profound difficulty originates from the proliferation of saddle points , not local minima , especially in high dimensional problems of practical interest .",
        "we apply this algorithm to deep or recurrent neural network training , and provide numerical evidence for its superior optimization performance .",
        "these random views are then used to train a deep convolutional neural network ( cnn ) classifier .",
        "deep convolutional neural networks have recently proven extremely competitive in challenging image recognition tasks .",
        "this paper proposes the epitomic convolution as a new building block for deep neural networks .",
        "an epitomic convolution layer replaces a pair of consecutive convolution and max - pooling layers found in standard deep convolutional neural networks .",
        "our experiments on imagenet indicate improved recognition performance compared to standard convolutional neural networks of similar architecture .",
        "in this paper , we address this goal with a new type of convolutional neural network ( cnn ) whose invariance is encoded by a reproducing kernel .",
        "unlike traditional approaches where neural networks are learned either to represent data or for solving a classification task , our network learns to approximate the kernel feature map on training data .",
        "second , we bridge a gap between the neural network literature and kernels , which are natural tools to model invariance .",
        "we propose an heterogeneous multi - task learning framework for human pose estimation from monocular image with deep convolutional neural network .",
        "we evaluate the following machine learning techniques for green energy ( wind , solar ) prediction : bayesian inference , neural networks , support vector machines , clustering techniques ( pca ) .",
        "applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels .",
        "we present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution .",
        "like convolutional neural networks , the proposed model has a degree of translation invariance built - in , but the amount of computation it performs can be controlled independently of the input image size .",
        "we evaluate our model on several image classification tasks , where it significantly outperforms a convolutional neural network baseline on cluttered images , and on a dynamic visual control problem , where it learns to track a simple object without an explicit training signal for doing so .",
        "current methods for training convolutional neural networks depend on large amounts of labeled samples for supervised training .",
        "in this paper we present an approach for training a convolutional neural network using only unlabeled data .",
        "it uses a deep layered architecture , parts of which are borrowed from recent work on neural network learning , and parts of which incorporate computations that are specific to image deconvolution .",
        "moreover , we show that advanced neural networks and deep learning methods can be compressed as privileged information .",
        "self - organising maps ( som ) are artificial neural networks used in pattern recognition tasks .",
        "traditional convolutional neural networks ( cnn ) are stationary and feedforward .",
        "dropout training , originally designed for deep neural networks , has been successful on high - dimensional single - layer natural language tasks .",
        "the general perception is that kernel methods are not scalable , and neural nets are the methods of choice for nonlinear learning problems .",
        "our approach can readily scale kernel methods up to the regimes which are dominated by neural",
        "the framework is a bsd - licensed c + + library with python and matlab bindings for training and deploying general - purpose convolutional neural networks and other deep models efficiently on commodity architectures .",
        "we report on a series of experiments with convolutional neural networks ( cnn ) trained on top of pre - trained word vectors for sentence - level classification tasks .",
        "we provide a comparative study between neural word representations and traditional vector spaces based on co - occurrence counts , in a number of compositional tasks .",
        "in the more constrained tasks , co - occurrence vectors are competitive , although choice of compositional method is important ; on the larger - scale tasks , they are outperformed by neural word embeddings , which show robust , stable performance across the tasks .",
        "deep neural networks ( dnns ) are powerful models that have achieved excellent performance on difficult learning tasks .",
        "to evaluate whether deep learning is beneficial for program analysis , we feed the representations to deep neural networks , and achieve higher accuracy in the program classification task than \" shallow \" methods , such as logistic regression and the support vector machine .",
        ", has been shown a promising learning algorithm for single - hidden layer feedforward neural networks ( slfns ) .",
        "another popular approach to model the multimodal data is through deep neural networks , such as the deep boltzmann machine ( dbm ) .",
        "recently , a new type of topic model called the document neural autoregressive distribution estimator ( docnade ) was proposed and demonstrated state - of - the - art performance for text document modeling .",
        "deep neural networks have made significant breakthroughs in many fields of artificial intelligence .",
        "in this paper , we propose the tree - based convolutional neural network ( tbcnn ) to model programming languages , which contain rich and explicit tree structural information .",
        "to our best knowledge , this paper is the first to analyze programs with deep neural networks ; we extend the scope of deep learning to the field of programming language processing .",
        "e algorithm is compared against known learning and classification techniques / algorithms such as : the perceptron criterion algorithm , linear support vector machines , the linear fisher discriminant and a simple neural network .",
        "for the comparison with the neural network , the classical xor problem is considered .",
        "this paper presents a new contextual bandit algorithm , neuralbandit , which does not need hypothesis on stationarity of contexts and rewards .",
        "several neural networks are trained to modelize the value of rewards knowing the context .",
        "by means of a preprocessing for word - grouping and time - period related analysis of the common lexicon , we determine a bias reference level for the recurrence frequency of the words within analysed texts , and then train a radial basis neural networks ( rbpnn ) - based classifier to identify the correct author .",
        "neural networks sequentially build high - level features through their successive layers .",
        "we propose here a new neural network model where each layer is associated with a set of candidate mappings .",
        "neural language models learn word representations that capture rich linguistic and conceptual information .",
        "here we investigate the embeddings learned by neural machine translation models .",
        "the findings suggest that , while monolingual models learn information about how concepts are related , neural - translation models better capture their true ontological status .",
        "existing deep convolutional neural network ( cnn ) architectures are trained as n - way classifiers to distinguish between n output classes .",
        "we present a deep layered architecture that generalizes classical convolutional neural networks ( convnets ) .",
        "in this paper , we present a multimodal recurrent neural network ( m - rnn ) model for generating novel sentence descriptions to explain the content of images .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "it is well - known that neural networks are computationally hard to train .",
        "on the other hand , in practice , modern day neural networks are trained efficiently using sgd and a variety of tricks that include different activation functions ( e .",
        "in this paper we revisit the computational complexity of training neural networks from a modern perspective .",
        "we provide both positive and negative results , some of them yield new provably efficient and practical algorithms for training certain types of neural networks .",
        "recently proposed neural network activation functions such as rectified linear , maxout , and local winner - take - all have allowed for faster and more effective training of deep neural architectures on large and complex datasets .",
        "we also show how our insights can be directly useful for efficiently performing retrieval over large datasets using neural networks .",
        "we address this question using two neural network - based models for learning embeddings : plain neural networks and neural tensor networks .",
        "neural machine translation ( nmt ) has recently attracted a lot of attention due to the very high performance achieved by deep neural networks in other domains .",
        "we parametrize this transformation so that computing the determinant of the jacobian and inverse jacobian is trivial , yet we maintain the ability to learn complex non - linear transformations , via a composition of simple building blocks , each based on a deep neural network .",
        "we carried out experiments using the switchboard corpus , with both mel frequency cepstral coefficient features and bottleneck feature derived from a deep neural network .",
        "reductions in word error rate were obtained by using tied plda , compared with the plda mixture model , subspace gaussian mixture models , and deep neural networks .",
        "convolutional neural nets ( convnets ) trained from massive labeled datasets have substantially improved the state - of - the - art in image classification and object detection .",
        "recently convolutional neural networks ( cnns ) have been shown to achieve state - of - the - art performance on various classification tasks .",
        "we use recurrent neural networks ( rnns ) and their variants as music language models ( mlms ) and present a generative architecture for combining these models with predictions from a frame level acoustic classifier .",
        "we also compare different neural network architectures for acoustic modeling .",
        "many deep neural networks trained on natural images exhibit a curious phenomenon in common : on the first layer they learn features similar to gabor filters and color blobs .",
        "in this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results .",
        "our pipeline effectively unifies joint image - text embedding models with multimodal neural language models .",
        "we introduce the structure - content neural language model that disentangles the structure of a sentence to its content , conditioned on representations produced by the encoder .",
        "as an increasing number of researchers would like to experiment with word2vec , i notice that there lacks a material that comprehensively explains the parameter learning process of word2vec in details , thus preventing many people with less neural network experience from understanding how exactly word2vec works .",
        "we propose a new neurally - inspired model that can learn to encode global relationship context of visual events across time and space and to use the contextual information to modulate the analysis by synthesis process in a predictive coding framework .",
        "this paper aims to explore the effect of prior disambiguation on neural network - based compositional models , with the hope that better semantic representations for text compounds can be produced .",
        "we propose learning this mapping using a recurrent neural network .",
        "we train a generative convolutional neural network which is able to generate images of objects given object type , viewpoint , and color .",
        "error backpropagation is an extremely effective algorithm for assigning credit in artificial neural networks .",
        "even though convolutional neural networks ( cnn ) has achieved near - human performance in various computer vision tasks , its ability to tolerate scale variations is limited .",
        "in this paper , we propose a scaleinvariant convolutional neural network ( sicnn ) , a modeldesigned to incorporate multi - scale feature exaction and classification into the network structure .",
        "we study the connection between the highly non - convex loss function of a simple model of the fully - connected feed - forward neural network and the hamiltonian of the spherical spin - glass model under the assumptions of : i ) variable independence , ii ) redundancy in network parametrization , and iii ) uniformity .",
        "these assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from the random matrix theory .",
        "convolutional neural network ( cnn ) is a neural network that can make use of the internal structure of data such as the 2d structure of image data .",
        "when using skip - gram features the models are able to match the state - of - the - art recurrent neural network ( rnn ) lms ; combining the two modeling techniques yields the best known result on the benchmark .",
        "compared to image representation based on low - level local descriptors , deep neural activations of convolutional neural networks ( cnns ) are richer in mid - level representation , but poorer in geometric invariance properties .",
        "neural machine translation , a recently proposed approach to machine translation based purely on neural networks , has shown promising results compared to the existing approaches such as phrase - based statistical machine translation .",
        "despite its recent success , neural machine translation has its limitation in handling a larger vocabulary , as training complexity as well as decoding complexity increase proportionally to the number of target words .",
        "the models trained by the proposed approach are empirically found to outperform the baseline models with a small vocabulary as well as the lstm - based neural machine translation models .",
        "due to imprecision and uncertainties in predicting real world problems , artificial neural network ( ann ) techniques have become increasingly useful for modeling and optimization .",
        "this paper presents an artificial neural network approach for forecasting electric energy consumption .",
        "to overcome these challenges in large scale in synonym extraction , we proposed ( 1 ) a new cost function to accommodate the unbalanced learning problem , and ( 2 ) a feature learning based deep neural network to model the complicated relationships in synonym pairs .",
        "we compare several different approaches based on svms and neural networks , and find out our feature learning based neural network outperforms the methods with hand - assigned features .",
        "the transcription of handwritten text on images is one task in machine learning and one solution to solve it is using multi - dimensional recurrent neural networks ( mdrnn ) with connectionist temporal classification ( ctc ) .",
        "we propose a multimodal deep learning framework that can transfer the knowledge obtained from a single - modal neural network to a network with a different modality .",
        "in this paper we compare different types of recurrent units in recurrent neural networks ( rnns ) .",
        "this paper addresses how a recursive neural network model can automatically leave out useless information and emphasize important evidence , in other words , to perform \" weight tuning \" for higher - level representation acquisition .",
        "we propose two models , weighted neural network ( wnn ) and binary - expectation neural network ( benn ) , which automatically control how much one specific unit contributes to the higher - level representation .",
        "the proposed model can be viewed as incorporating a more powerful compositional function for embedding acquisition in recursive neural networks .",
        "experimental results demonstrate the significant improvement over standard neural models .",
        "in this paper , we train recurrent neural networks with only raw features , and use word embedding to automatically learn meaningful representations .",
        "matconvnet is an implementation of convolutional neural networks ( cnns ) for matlab .",
        "in this paper , we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure .",
        "al , 2012 ) in a deep neural network trains a pseudo - ensemble of child subnetworks generated by randomly masking nodes in the parent network .",
        "we provide a case study in which we transform the recursive neural tensor network of ( socher et .",
        "recent work has shown deep neural networks ( dnns ) to be highly susceptible to well - designed , small perturbations at the input layer , or so - called adversarial examples .",
        "convolutional neural networks ( convnets ) have shown excellent results on many visual classification tasks .",
        "we present flattened convolutional neural networks that are designed for fast feedforward execution .",
        "the redundancy of the parameters , especially weights of the convolutional filters in convolutional neural networks has been extensively studied and different heuristics have been proposed to construct a low rank basis of the filters after training .",
        "deep convolutional neural networks ( cnn ) has become the most promising method for object recognition , repeatedly demonstrating record breaking results for image classification and object detection in recent years .",
        "the convolutional neural networks ( cnns ) have proven to be a powerful tool for discriminative learning .",
        "in this work , we present a novel neural network based architecture for inducing compositional crosslingual word representations .",
        "neural language models learn word representations , or embeddings , that capture rich linguistic and conceptual information .",
        "here we investigate the embeddings learned by neural machine translation models , a recently - developed class of neural language model .",
        "finally , we apply a new method for training neural translation models with very large vocabularies , and show that this vocabulary expansion algorithm results in minimal degradation of embedding quality .",
        "we propose a simple two - step approach for speeding up convolution layers within large convolutional neural networks based on tensor decomposition and discriminative fine - tuning .",
        "we train a large 12 - layer convolutional neural network by supervised learning from a database of human professional games .",
        "we consider learning representations of entities and relations in kbs using the neural - embedding approach .",
        "we show that most existing models , including ntn and transe , can be generalized under a unified learning framework , where entities are low - dimensional vectors learned from a neural network and relations are bilinear and / or linear mapping functions .",
        "convolutional neural networks perform well on object recognition because of a number of recent advances : rectified linear units ( relus ) , data augmentation , dropout , and large labelled datasets .",
        "experiments on a benchmark neural network show that the hot swapping approach leads to consistently better solutions compared to well - known alternatives such as adadelta and stochastic gradient with exhaustive hyperparameter search .",
        "we propose a novel architecture for solving ctr prediction problem by combining artificial neural networks ( ann ) with decision trees .",
        "our method does not require gradient - based training of neural networks , matrix decompositions as with lsa , or convolutions as with beagle .",
        "among these , the restricted boltzmann machine ( rbm ) has been the prototype for some recent advancements in the unsupervised training of deep neural networks .",
        "in this paper , we present a multimodal recurrent neural network ( m - rnn ) model for generating novel image captions .",
        "the model consists of two sub - networks : a deep recurrent neural network for sentences and a deep convolutional network for images .",
        "it is today acknowledged that neural network language models outperform back - off language models in applications like speech recognition or statistical machine translation .",
        "we present efficient techniques to adapt a neural network language model to new data .",
        "an asynchronous variant of the algorithm is applied to train convolutional neural",
        "most modern convolutional neural networks ( cnns ) used for object recognition are built using the same principles : alternating convolution and max - pooling layers followed by a small number of fully connected layers .",
        "to facilitate the process , the proposed approach leverages with densenet , an efficient implementation of multiscale convolutional neural networks ( cnn ) , to extract an informative feature vector for each pixel and uses an svm classifier to accomplish contour detection .",
        "the convolutional neural network ( cnn ) has achieved great success in image classification .",
        "to the best of our knowledge the use of multi - modal deep convolutional neural networks for dynamic real - time lidar - video registration has not been presented .",
        "we trained a deep convolutional neural network ( cnn ) to identify occlusion edges in images and videos with both rgb - d and rgb inputs .",
        "we simulate the training of a set of state of the art neural networks , the maxout networks ( goodfellow et al .",
        "this paper introduces a greedy parser based on neural networks , which leverages a new compositional sub - tree representation .",
        "composition and tagging is achieved over continuous ( word or tag ) representations , and recurrent neural networks .",
        "( 2014 ) on recurrent neural models for attention into less constrained visual environments , beginning with fine - grained categorization on the stanford dogs data set .",
        "deep convolutional neural networks ( dcnns ) have recently shown state of the art performance in high level vision tasks , such as image classification and object detection .",
        "we propose diverse embedding neural network ( denn ) - a novel architecture for neural network language models ( lms ) .",
        "a denn - lm projects the input word history vector onto multiple diverse low - dimensional sub - spaces instead of a single higher - dimensional sub - space as in conventional feed - forward neural network lms .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "recently , convolutional neural networks have been shown to be able to estimate phoneme conditional probabilities in a completely data - driven manner , i .",
        "this paper presents an in - depth investigation on integrating neural language models in translation systems .",
        "scaling neural language models is a difficult task , but crucial for real - world applications .",
        "we show when explicitly normalising neural models is necessary and what optimisation tricks one should use in such scenarios .",
        "we explore the trade - offs between neural models and back - off n - gram models and find that neural models make strong candidates for natural language applications in memory constrained environments , yet still lag behind traditional models in raw translation quality .",
        "we conclude with a set of recommendations one should follow to build a scalable neural language model for mt .",
        "additionally , we hope that ordering parameters may provide additional insights into optimization of deep convolutional neural networks and how the network architecture impacts performance .",
        "in this paper we study the application of convolutional neural networks for jointly detecting objects depicted in still images and estimating their 3d pose .",
        "deep neural networks have been extremely successful at various image , speech , video recognition tasks because of their ability to model deep structures within the data .",
        "based on the observation that the key computation common to most neural network layers is a vector / matrix product , we propose a fast locality - sensitive hashing technique to approximate the actual dot product enabling us to scale up the training and inference to millions of output classes .",
        "in this study , we propose a deep temporal convolutional neural network architecture for brain decoding task in order to reduce dimensionality of feature space along with improved classification performance .",
        "we examine the performance profile of convolutional neural network training on the current generation of nvidia graphics processing units .",
        "recurrent neural network is a powerful model that learns temporal patterns in sequential data .",
        "this is achieved by using a slight structural modification of the simple recurrent neural network architecture .",
        "the proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image .",
        "a process centric view of robust pca ( rpca ) allows its fast approximate implementation based on a special form o a deep neural network with weights shared across all layers .",
        "deep networks have inspired a renaissance in neural network use , and are becoming the default option for difficult tasks on large datasets .",
        "our model learns to embed image representations ( generated from a previously trained convolutional neural network ) into a multimodal space that is common to the images and the phrases that are used to described them .",
        "artificial neural networks are powerful pattern classifiers ; however , they have been surpassed in accuracy by methods such as support vector machines and random forests that are also easier to use and faster to train .",
        "backpropagation , which is used to train artificial neural networks , suffers from the herd effect problem which leads to long training times and limit classification accuracy .",
        "in this paper , we have used recurrent neural networks to capture and model human motion data and generate motions by prediction of the next immediate data point at each time - step .",
        "a particular case of recurrent neural network ( rnn ) was introduced at the beginning of the 2000s under the name of echo state networks ( esns ) .",
        "luckily , a simplified neural network module ( snnm ) has been proposed to directly learn the discriminative dictionaries for avoiding the expensive inference .",
        "our experiments include a logistic regression , hmm , and bayesian neural net .",
        "this paper investigates the scaling properties of recurrent neural network language models ( rnnlms ) .",
        "more interestingly , we have shown the proposed hope models are closely related to neural networks ( nns ) in a sense that each nn hidden layer can be reformulated as a hope model .",
        "models of multilayer perceptrons , support vector machines , and radial basis function neural networks were trained and tested using the mit - bih arrhythmia database .",
        "in this work , we propose a novel recurrent neural network ( rnn ) architecture .",
        "training of large - scale deep neural networks is often constrained by the available computational resources .",
        "we study the effect of limited precision data representation and computation on neural network training .",
        "recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation .",
        "in this paper , we propose a new deep adaptation network ( dan ) architecture , which generalizes deep convolutional neural network to the domain adaptation scenario .",
        "training deep neural networks is complicated by the fact that the distribution of each layer ' s inputs changes during training , as the parameters of the previous layers change .",
        "recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers .",
        "we train our three - layer deep neural network on the yahoo !",
        "these gradients allow us to optimize thousands of hyperparameters , including step - size and momentum schedules , weight initialization distributions , richly parameterized regularization schemes , and neural network architectures .",
        "there has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples .",
        "we introduce a simple modification for autoencoder neural networks that yields powerful generative models .",
        "neural network based technologies have high ability of adaption as well as generalization .",
        "as per our knowledge , very little work has been done in this field using neural network .",
        "this paper evaluates performance of three supervised learning algorithms of artificial neural network by creating classifiers for the complex problem of latest web spam pattern classification .",
        "in this paper , we present a gaussian mixture neural topic model ( gmntm ) which incorporates both the ordering of words and the semantic meaning of sentences into topic modeling .",
        "deep neural networks ( dnn ) are the state of the art on many engineering problems such as computer vision and audition .",
        "we train a purely bilinear model that learns a metric between an image representation ( generated from a previously trained convolutional neural network ) and phrases that are used to described them .",
        "we introduce deep neural programs ( dnp ) , a novel programming paradigm for writing adaptive controllers for cy - ber - physical systems ( cps ) .",
        "dnp replace if and while statements , whose discontinuity is responsible for undecidability in cps analysis , intractability in cps design , and frailness in cps implementation , with their smooth , neural nif and nwhile counterparts .",
        "to the best of our knowledge , dnp are the first approach linking neural networks to programs , in a way that makes explicit the meaning of the network .",
        "inspired by the brain , deep neural networks ( dnn ) are thought to learn abstract representations through their hierarchical architecture .",
        "finally , the kalman filter updates can be seen as a linear recurrent neural network .",
        "we demonstrate that using the parameters of our model to initialize a non - linear recurrent neural network language model reduces its training time by a day and yields lower perplexity .",
        "in this paper , we explore joint optimization of masking functions and deep recurrent neural networks for monaural source separation tasks , including the monaural speech separation task , monaural singing voice separation task , and speech denoising task .",
        "the joint optimization of the deep recurrent neural networks with an extra masking layer enforces a reconstruction constraint .",
        "moreover , we explore a discriminative training criterion for the neural networks to further enhance the separation performance .",
        ", with approximate rather than exact posteriors , implemented by neural dynamics .",
        "here , we train a deep neural network to re - synthesize its inputs at its output layer for a given class of data .",
        "this paper introduces the deep recurrent attentive writer ( draw ) neural network architecture for image generation .",
        "here , we propose a novel model called temporal embedding - enhanced convolutional neural network ( tenet ) to learn repeatedly - occurring - yet - hidden structural elements in periodical time - series , called abstract snippets , for predicting future changes .",
        "our model uses convolutional neural networks and embeds a time - series with its potential neighbors in the temporal domain for aligning it to the dominant patterns in the dataset .",
        "in recent years multilayer perceptrons ( mlps ) with many hid - den layers deep neural network ( dnn ) has performed sur - prisingly well in many speech tasks , i .",
        "for these tasks , the policies are neural networks with tens of thousands of parameters , mapping from observations to actions .",
        "further to improve the accuracy of classification a hybrid neurosvm model was developed using svm and feed - forward artificial neural network ( ann ) .",
        "a scheme is derived for learning connectivity in spiking neural networks .",
        "this learning scheme is demonstrated using a layered feedforward spiking neural network trained self - supervised on a prediction and classification task for moving mnist images collected using a dynamic vision sensor .",
        "this paper develops a model that addresses sentence embedding using recurrent neural networks ( rnn ) with long short term memory ( lstm ) cells .",
        "this paper presents a new state - of - the - art for document image classification and retrieval , using features learned by deep convolutional neural networks ( cnns ) .",
        "in object and scene analysis , deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations .",
        "in this paper , we propose a new approach which uses deep neural network to learn features automatically from data .",
        "a long short - term memory ( lstm ) network is a type of recurrent neural network architecture which has recently obtained strong results on a variety of sequence modeling tasks .",
        "in this paper , we propose a non - linear modeling for the quality of translation hypotheses based on neural networks , which allows more complex interaction between features .",
        "recursive neural models , which use syntactic parse trees to recursively generate representations bottom - up from parse children , are a popular new architecture , promising to capture structural properties like the scope of negation or long - distance semantic dependencies .",
        "in this paper we benchmark recursive neural models against sequential recurrent neural models , which are structured solely on word sequences .",
        "our results offer insights on the design of neural architectures for representation learning .",
        "we apply a sequential model - based optimization technique and show that our method makes standard linear models competitive with more sophisticated , expensive state - of - the - art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems .",
        "we then refine this alignment using a state - of - the - art visual food detector , based on a deep convolutional neural network .",
        "among these are a convolutional neural network , focusing on capturing visual information in detected faces , a deep belief net focusing on the representation of the audio stream , a k - means based \" bag - of - mouths \" model , which extracts visual features around the mouth region and a relational autoencoder , which addresses spatio - temporal aspects of videos .",
        "deep neural networks have recently achieved state of the art performance thanks to new training algorithms for rapid parameter estimation and new regularization methods to reduce overfitting .",
        "for convolutional neural networks , our method relies on iterative split / merge clustering of convolutional kernels interleaved by stochastic gradient descent .",
        "the recently proposed neural network joint model ( nnjm ) ( devlin et al .",
        "this representation , together with target language words , are fed to a deep neural network ( dnn ) to form a stronger nnjm .",
        "we present a bayesian approach to adapting parameters of a well - trained context - dependent deep - neural - network hid - den markov models ( cd - dnn - hmms ) to improve automatic speech recognition performance .",
        "an artificial neural network ( self - organizing map ) is fitted to train on more than a million data points to predict \" good investments \" given testing stocks from 2013 and after .",
        "convolutional neural networks with many layers have recently been shown to achieve excellent results on many high - level tasks such as image classification , object detection and more recently also semantic segmentation .",
        "we propose a novel method for translation selection in statistical machine translation , in which a convolutional neural network is employed to judge the similarity between a phrase pair in two languages .",
        "we propose neural responding machine ( nrm ) , a neural network - based response generator for short - text conversation .",
        "nrm takes the general encoder - decoder framework : it formalizes the generation of response as a decoding process based on the latent representation of the input text , while both encoding and decoding are realized with recurrent neural networks ( rnn ) .",
        "deep neural networks ( dnns ) are analyzed via the theoretical framework of the information bottleneck ( ib ) principle .",
        "we are proposing an extension of the recursive neural network that makes use of a variant of the long short - term memory architecture .",
        "experimental results show that our composition outperformed the traditional neural - network composition on the stanford sentiment treebank .",
        "it has relations with neural networks but works in a different way , requiring only a single pass through the classifier to generate the weight sets .",
        "also , the high number of factors , incomplete and unbalanced dataset , and black boxing issues as in artificial neural networks and fuzzy logic systems exposes the need for more efficient tools .",
        "as a step toward this goal , we propose convolutional neural network models for matching two sentences , by adapting the convolutional strategy in vision and speech .",
        "recent work on end - to - end neural network - based architectures for machine translation has shown promising results for english - french and english - german translation .",
        "in this work , we focus on applying neural machine translation to challenging / low - resource languages such as chinese and turkish .",
        "compared to multilayer neural networks with real weights , binary multilayer neural networks ( bmnns ) can be implemented more efficiently on dedicated hardware .",
        "the performances of binary neural networks with multiple hidden layers and different numbers of hidden units are examined on mnist .",
        "several variants of the long short - term memory ( lstm ) architecture for recurrent neural networks have been proposed since its inception in 1995 .",
        "we present a neural network architecture and training method designed to enable very rapid training and low implementation complexity .",
        "different from previous work on neural network - based language modeling and generation ( e .",
        "instead , we use a convolutional neural network to predict the next word with the history of words of variable length .",
        "we propose an efficient method for approximating natural gradient descent in neural networks which we call kronecker - factored approximate curvature ( k - fac ) .",
        "k - fac is based on an efficiently invertible approximation of a neural network ' s fisher information matrix which is neither diagonal nor low - rank , and in some cases is completely non - sparse .",
        "in this paper , we propose to solve the corresponding inversion problem by utilizing the disagreements of an ensemble of neural networks to represent the prediction error in the unexplored component space .",
        "here , we train a convolutional deep neural network to re - synthesize input time - domain speech signals at its output layer .",
        "here , we trained two separate convolutive autoencoder deep neural networks ( dnn ) to separate monaural and binaural mixtures of two concurrent speech streams .",
        "our simulations demonstrate that very simple neural networks are capable of exploiting monaural and binaural information available in a cocktail party listening scenario .",
        "here , we train a convolutional deep neural network , on a two - speaker cocktail party problem , to make probabilistic predictions about binary masks .",
        "our results approach ideal binary mask performance , illustrating that relatively simple deep neural networks are capable of robust binary mask prediction .",
        "we propose a new way of incorporating temporal information present in videos into spatial convolutional neural networks ( convnets ) trained on images , that avoids training spatio - temporal convnets from scratch .",
        "this framework includes specific assumptions about the mechanisms that contribute to the evolution of ( artificial ) neural networks to generate topologies that allow the networks to learn large - scale complex problems using only information about the quality of their performance .",
        "in this paper , we refer to convolutional neural networks , and use an adaptation technique based on a stacked convolutional auto - encoder that exploits unlabeled real - world images combined with synthetic data .",
        "we train a recurrent neural network ( rnn ) to map dictionary definitions ( phrases ) to ( lexical ) representations of the words those definitions define .",
        "this strong performance highlights the general effectiveness of both neural language models and definition - based training for training machines to understand phrases and sentences .",
        "this paper proposes a new convolutional neural architecture based on tree - structures , called the tree - based convolutional neural network ( tbcnn ) .",
        "compared with traditional \" flat \" convolutional neural networks ( cnns ) , tbcnns explore explicitly the structural information of sentences ; compared with recursive neural networks , tbcnns have much shorter propagation paths , enabling more effective feature learning and extraction .",
        "based on this theory , we propose a new semi - supervised learning framework that learns a multi - view embedding of small text regions with convolutional neural networks .",
        "to facilitate the process , the proposed approach leverages with densenet , an efficient implementation of multiscale convolutional neural networks ( cnns ) , to extract an informative feature vector for each pixel and uses an svm classifier to accomplish contour detection .",
        "we present a novel network architecture , hashednets , that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes .",
        "our hashing procedure introduces no additional memory overhead , and we demonstrate on several benchmark data sets that hashednets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance .",
        "in this work we tackle the relation classification task using a convolutional neural network that performs classification by ranking ( cr - cnn ) .",
        "this paper presents an approach that reasons about conjunctions of multi - hop relations non - atomically , composing the implications of a path using a recursive neural network ( rnn ) that takes as inputs vector embeddings of the binary relation in the path .",
        "we learn the cltm tree structure using conditional pairwise probabilities for object co - occurrences , estimated through kernel methods , and we learn its node and edge potentials by training a new 3 - layer neural network , which takes fc7 features as input .",
        "this paper proposes an architecture for deep neural networks with hidden layer branches that learn targets of lower hierarchy than final layer targets .",
        "there is plenty of theoretical and empirical evidence that depth of neural networks is a crucial ingredient for their success .",
        "for example , deep neural networks have been more successful than shallow networks because they can perform a greater number of sequential computational steps ( each highly parallel ) .",
        "the neural turing machine ( ntm ) is a model that can compactly express an even greater number of sequential computational steps , so it is even more powerful than a dnn .",
        "we propose an object detection system that relies on a multi - region deep convolutional neural network ( cnn ) that also encodes semantic segmentation - aware features .",
        "the first uses a pipelined process where a set of candidate words is generated by a convolutional neural network ( cnn ) trained on images , and then a maximum entropy ( me ) language model is used to arrange these words into a coherent sentence .",
        "the second uses the penultimate activation layer of the cnn as input to a recurrent neural network ( rnn ) that then generates the caption sequence .",
        "in our work , we propose to use recurrent neural networks and visual semantic embeddings without intermediate stages such as object detection and image segmentation .",
        "deep neural networks have recently achieved state - of - the - art results in many machine learning problems , e .",
        "hitherto , work on rectified linear units ( relu ) provides empirical and theoretical evidence on performance increase of neural networks comparing to typically used sigmoid activation function .",
        "in this paper , we investigate a new manner of improving neural networks by introducing a bunch of copies of the same neuron modeled by the generalized kumaraswamy distribution .",
        "in the experimental study with mnist image corpora we evaluate the kumaraswamy unit applied to single - layer ( shallow ) neural network and report a significant drop in test classification error and test cross - entropy in comparison to sigmoid unit , relu and noisy relu .",
        "in this paper , we present a fully automatic brain tumor segmentation method based on deep neural networks ( dnns ) .",
        "we explore in particular different architectures based on convolutional neural networks ( cnn ) , i .",
        "one is the fully - connected neural network consists of multiple single neurons .",
        "our approach is based on the charwnn deep neural network , which uses word - level and character - level representations ( embeddings ) to perform sequential classification .",
        "our experimental results shade light on the contribution of neural character embeddings for ner .",
        "moreover , we demonstrate that the same neural network which has been successfully applied for pos tagging can also achieve state - of - the - art results for language - independet ner , using the same hyper - parameters , and without any handcrafted features .",
        "it can also work in a batch mode , with reduced training times and can be used as part of a neural network , or classifiers in general .",
        "our model contains four components : a long - short term memory ( lstm ) to extract the question representation , a convolutional neural network ( cnn ) to extract the visual representation , a lstm for storing the linguistic context in an answer , and a fusing component to combine the information from the first three components and generate the answer .",
        "we propose a recursive convolutional neural network ( rcnn ) architecture to capture syntactic and compositional - semantic representations of phrases and words in a dependency tree .",
        "different with the original recursive neural network , we introduce the convolution and pooling layers , which can model a variety of compositions by the feature maps and choose the most informative compositions by the pooling layers .",
        "some of the techniques that were found beneficial are : maxout networks with annealed dropout rates ; networks with a very large number of outputs trained on 2000 hours of data ; joint modeling of partially unfolded recurrent neural networks and convolutional nets by combining the bottleneck and output layers and retraining the resulting model ; and lastly , sophisticated language model rescoring with exponential and neural network lms .",
        "we introduce a neural network method to encode programs as a linear mapping from an embedded precondition space to an embedded postcondition space and propose an algorithm for feedback at scale using these linear maps as features .",
        "although deep neural networks ( dnn ) are able to scale with direct advances in computational power ( e .",
        "recent research shows that deep neural networks ( dnns ) can be used to extract deep speaker vectors ( d - vectors ) that preserve speaker characteristics and can be used in speaker verification .",
        "this paper aims to accelerate the test - time computation of convolutional neural networks ( cnns ) , especially very deep cnns that have substantially impacted the computer vision community .",
        "i used two different methods to predict the fantasy football scores of nfl players : support vector regression ( svr ) and neural networks .",
        "in this paper we present a convolutional neural network ( cnn ) , trained for the first time with the purpose of recognizing revisited locations under severe appearance changes , which maps images to a low dimensional space where euclidean distances represent place dissimilarity .",
        "our primary innovation is a new control structure for sequence - to - sequence neural networks - - - the stack lstm .",
        "recurrent neural networks ( rnns ) have become increasingly popular for the task of language understanding .",
        "we find that the simple side - conditioned generation approach is able to rival the state - of - the - art , and we are able to significantly advance the stat - of - the - art with bi - directional long short - term memory ( lstm ) neural networks that use the same alignment information that is used in conventional approaches .",
        "in this paper , we propose to employ the convolutional neural network ( cnn ) for learning to answer questions from the image .",
        "our method is based on two recently introduced neural network vector representation models for words and sentences .",
        "we present a three - pronged approach to improving statistical machine translation ( smt ) , building on recent success in the application of neural networks to smt .",
        "first , we propose new features based on neural networks to model various non - local translation phenomena .",
        "second , we augment the architecture of the neural network with tensor layers that capture important higher - order interaction among the network units .",
        "third , we apply multitask learning to estimate the neural network parameters jointly .",
        "8 bleu points for arabic - english and chinese - english translation over a state - of - the - art system that already includes neural network features .",
        "this paper proposes an ros learning approach based on deep neural networks ( dnn ) , which involves an ros feature as the input of the dnn model and so the spectrum distortion caused by ros can be learned and compensated for .",
        "we evaluate the reconstructed paragraph using standard metrics like rouge and entity grid , showing that neural models are able to encode texts in a way that preserve syntactic , semantic , and discourse coherence .",
        "while only a first step toward generating coherent text units from neural models , our work has the potential to significantly impact natural language generation and summarization \\ footnote { code for the three models described in this paper can be found at www .",
        "while neural networks have been successfully applied to many nlp tasks the resulting vector - based models are very difficult to interpret .",
        "in this paper we describe four strategies for visualizing compositionality in neural models for nlp , inspired by similar work in computer vision .",
        "a neuromorphic chip that combines cmos analog spiking neurons and memristive synapses offers a promising solution to brain - inspired computing , as it can provide massive neural network parallelism and density .",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning algorithm , learning to find the best structured object ( such as a label sequence ) given a structured input ( such as a vector sequence ) by globally considering the mapping relationships between the structure rather than item by item .",
        "it is known that the learning rate is the most important hyper - parameter to tune for training deep convolutional neural networks ( i .",
        "these methods are practical tools for everyone who trains convolutional neural networks .",
        "in this paper , we propose a universal recurrent neural network language model with user characteristic features , so all users share the same model , except each with different user characteristic features .",
        "convolutional neural networks ( cnn ) is one kind of deep neural network .",
        "in this article , we use convolutional neural network to implement the typical face recognition problem which can overcome the influence of pose or resolution in face recognition .",
        "recurrent neural networks ( rnns ) , and specifically a variant with long short - term memory ( lstm ) , are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data .",
        "we proffer a new , efficient deep structured model learning scheme , in which we show how deep convolutional neural networks ( cnns ) can be used to estimate the messages in message passing inference for structured prediction with conditional random fields ( crfs ) .",
        "deep neural networks trained on large - scale dataset can learn transferable features that promote learning multiple tasks for inductive transfer and labeling mitigation .",
        "in this work , we propose a novel deep relationship network ( drn ) architecture for multi - task learning by discovering correlated tasks based on multiple task - specific layers of a deep convolutional neural network .",
        "in this paper , we explore the inclusion of random variables into the dynamic latent state of a recurrent neural network ( rnn ) by combining elements of the variational autoencoder .",
        "we call this iterative system the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) which generates high quality features for track 1 of the challenge and acoustic tokens for track 2 of the challenge .",
        "we propose a new neural language model incorporating both word order and character order in its embedding .",
        "furthermore , the model includes several parallel training methods , most notably allowing a skip - gram network with 160 billion parameters to be trained overnight on 3 multi - core cpus , 14x larger than the previous largest neural network .",
        "along with this variance - reduction scheme , we use trust region algorithms to optimize the policy and value function , both represented as neural networks .",
        "in contrast to prior work that uses hand - crafted low - dimensional policy representations , our neural network policies map directly from raw kinematics to joint torques .",
        "deep learning with a convolutional neural network ( cnn ) has been proved to be very effective in feature extraction and representation of images .",
        "recently , strong results have been demonstrated by deep recurrent neural networks on natural language transduction problems .",
        "we revisit the choice of sgd for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights .",
        "neural networks are both computationally intensive and memory intensive , making them difficult to deploy on embedded systems .",
        "to address these limitations , we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy , by learning only the important connections .",
        "while our theoretical guarantees assume convexity , we discuss the applicability of our method to deep neural networks , and experimentally demonstrate its merits .",
        "this paper proposes a set of new error criteria and learning approaches , adaptive normalized risk - averting training ( anrat ) , to attack the non - convex optimization problem in training deep neural networks ( dnns ) .",
        "in practice , we show how this method improves training of deep neural networks to solve visual recognition tasks on the mnist and cifar - 10 datasets .",
        "in doing this , we introduce the pioneering concept referred to as neural promotion , where neurons gain prominence in",
        "recurrent neural networks can be trained to produce sequences of tokens given some input , as exemplified by recent results in machine translation and image captioning .",
        "we introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence .",
        "such problems cannot be trivially addressed by existent approaches such as sequence - to - sequence and neural turing machines , because the number of target classes in each step of the output depends on the length of the input , which is variable .",
        "our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention .",
        "this work presents a cognitive system , entirely based on a large - scale neural architecture , which was developed to shed light on how the procedural knowledge involved in language elaboration arises from neural processes .",
        "in our model , the central executive is a neural network that takes as input the neural activation states of the short - term memory and yields as output mental actions , which control the flow of information among the working memory components through neural gating mechanisms .",
        "we use the new framework to adapt powerful proposal distributions with rich parameterisations based upon neural networks leading to neural adaptive sequential monte carlo ( nasmc ) .",
        "finally we show that nasmc is able to train a neural network - based deep recurrent generative model achieving results that compete with the state - of - the -",
        "this allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure .",
        "we analyze the performance in a random matrix setting using results from the statistical mechanics of the hopfield neural network , and show in particular that macbeth efficiently detects the rank $ r $ of a large $ n \\ times m $ matrix from $ c ( r ) r \\ sqrt { nm } $ entries , where $ c ( r ) $ is a constant close to $ 1 $ .",
        ", the space defined by one of the top layers of a convolutional neural network ) .",
        "we construct our models using neural networks and train them using a form of guided policy search .",
        "the outputs of non - linear feed - forward neural network are positive , which could be treated as probability when they are normalized to one .",
        "as this paper defines two processes in feed - forward neural network , our limited condition is the abstracted features of samples which are worked out in the abstraction process .",
        "as entropy - based principle is considered into the feed - forward neural network , a clustering method is born .",
        "meanwhile , feed - forward neural network is a traditional classifier , which is very hot at present with a deeper architecture .",
        "however , the training algorithm of feed - forward neural network is developed and generated from widrow - hoff principle that means to minimize the squared error .",
        "in this paper , we propose a new training algorithm for feed - forward neural networks based on margin - based principle , which could effectively promote the accuracy and generalization ability of neural network classifiers with less labelled samples and flexible network .",
        "in this work , we demonstrate that , beyond its advantages for efficient computation , the spectral domain also provides a powerful representation in which to model and train convolutional neural networks ( cnns ) .",
        "secondly , each layer of data is fed into a deep neural network model for classification , where a graph regularization is imposed to the deep architecture for keeping local consistency between adjacent samples .",
        "our model is an alignment - based long short - term memory recurrent neural network ( attention - based lstm - rnn ) that encodes the free - form navigational instruction sentence and the corresponding representation of the environment state .",
        "we consider the problem of bayesian parameter estimation for deep neural networks , which is important in problem settings where we may have little data , and / or where we need accurate posterior predictive densities , e .",
        "convolutional neural networks ( cnn ) are increasingly used in many areas of computer vision .",
        "the online learning of deep neural networks is an interesting problem of machine learning because , for example , major it companies want to manage the information of the massive data uploaded on the web daily , and this technology can contribute to the next generation of lifelong learning .",
        "unfortunately , deep neural network learning through classical online and incremental methods does not work well in both theory and practice .",
        "distilling knowledge from a well - trained cumbersome network to a small one has become a new research topic recently , as lightweight neural networks with high performance are particularly in need in various resource - restricted systems .",
        "experimental results show our method is better than directly training neural networks with small embeddings .",
        "tree - structured neural networks encode a particular tree geometry for a sentence in the network design .",
        "we hypothesize that neural sequence models like lstms are in fact able to discover and implicitly use recursive compositional structure , at least for tasks with clear cues to that structure in the data .",
        "recurrent neural networks ( rnns ) are very good at modelling the flow of text , but typically need to be trained on a far larger corpus than is available for the pan 2015 author identification task .",
        "in this thesis , two artificial neural network ( ann ) based frameworks are proposed to model sand fraction from multiple seismic attributes without and with well tops information respectively .",
        "deep neural networks ( dnn ) have achieved huge practical success in recent years .",
        "however , its theoretical properties ( in particular generalization ability ) are not yet very clear , since existing error bounds for neural networks cannot be directly used to explain the statistical behaviors of practically adopted dnn models ( which are multi - class in their nature and may contain convolutional layers ) .",
        "to achieve this , we executed supervised training of a convolutional neural network to recover the removed center pixel label of patches sampled from a mdpm .",
        "based on the corpus , we introduce recurrent neural network for the summary generation and achieve promising results , which not only shows the usefulness of the proposed corpus for short text summarization research , but also provides a baseline for further research on this topic .",
        "in this paper we explore the utility of using recurrent neural networks ( rnns ) to model student learning .",
        "using neural networks results in substantial improvements in prediction performance on a range of knowledge tracing datasets .",
        "we present structured perceptron training for neural network transition - based dependency parsing .",
        "we learn the neural network representation using a gold corpus augmented by a large number of automatically parsed sentences .",
        "we propose neural transformation machine ( ntram ) , a novel architecture for sequence - to - sequence learning , which performs the task through a series of nonlinear transformations from the representation of the input sequence ( e .",
        "inspired by the recent neural turing machines [ 8 ] , we store the intermediate representations in stacked layers of memories , and use read - write operations on the memories to realize the nonlinear transformations of those representations .",
        "ntram is broad enough to subsume the state - of - the - art neural translation model in [ 2 ] as its special case , while significantly improves upon the model with its deeper architecture .",
        "remarkably , ntram , being purely neural network - based , can achieve performance comparable to the traditional phrase - based machine translation system ( moses ) with a small vocabulary and a modest parameter size .",
        "our approach applies convolution neural networks ( cnns ) to learning the joint representation of question - answer pair firstly , and then uses the joint representation as input of the long short - term memory ( lstm ) to learn the answer sequence of a question for labeling the matching quality of each answer .",
        "recent years have produced great advances in training large , deep neural networks ( dnns ) , including notable successes in training convolutional neural networks ( convnets ) to recognize natural images .",
        "progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets .",
        "a neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models , allowing the system to take into account previous dialog utterances .",
        "in this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market .",
        "we introduce the dynamic memory network ( dmn ) , a unified neural network framework which processes input sequences and questions , forms semantic and episodic memories , and generates relevant answers .",
        "convolutional neural networks ( cnns ) can be shifted across 2d images or 3d videos to segment them .",
        "previous neural network models often suffer from irrelevant information introduced when subjects and objects are in a long distance .",
        "in this paper , we propose to learn more robust relation representations from the shortest dependency path through a convolution neural network .",
        "we present a complimentary objective for training recurrent neural networks ( rnn ) with gating units that helps with regularization and interpretability of the trained model .",
        "a deep learning approach has been proposed recently to derive speaker identifies ( d - vector ) by a deep neural network ( dnn ) .",
        "this paper studies convolutional neural networks ( cnn ) to learn unsupervised feature representations for 44 different plant species , collected at the royal botanic gardens , kew , england .",
        "this provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data .",
        "we also describe two neural learning architectures suitable for analyzing this dataset , and provide benchmark performance on the task of selecting the best next response .",
        "we introduce natural neural networks , a novel family of algorithms that speed up convergence by adapting their internal representation during training to improve conditioning of the fisher matrix .",
        "in particular , we show a specific example that employs a simple and efficient reparametrization of the neural network weights by implicitly whitening the representation obtained at each layer , while preserving the feed - forward computation of the network .",
        "recent work on language modelling has shifted focus from count - based models to neural models .",
        "in this paper we show how we can improve the performance of the recurrent neural network ( rnn ) language model by incorporating the syntactic dependencies of a sentence , which have the effect of bringing relevant contexts closer to the word being predicted .",
        "47 bits per character on the wikipedia character prediction benchmark , which is state - of - the - art among neural approaches .",
        "in sentence modeling and classification , convolutional neural network approaches have recently achieved state - of - the - art results , but all such efforts process word vectors sequentially and neglect long - distance dependencies .",
        "to exploit both deep learning and linguistic structures , we propose a tree - based convolutional neural network model which exploit various long - distance relationships between words .",
        "we combine supervised learning with unsupervised learning in deep neural networks .",
        "this paper describes a parsing model that combines the exact dynamic programming of crf parsing with the rich nonlinear featurization of neural net approaches .",
        "our model is structurally a crf that factors over anchored rule productions , but instead of linear potential functions based on sparse features , we use nonlinear potentials computed via a feedforward neural network .",
        "using only dense features , our neural crf already exceeds a strong baseline crf model ( hall et al .",
        "to exploit the semantic representation behind the adp structure , we develop dependency - based neural networks ( depnn ) : a recursive neural network designed to model the subtrees , and a convolutional neural network to capture the most important features on the shortest path .",
        "to this end , we extend the recently proposed hierarchical recurrent encoder decoder neural network and demonstrate that this model is competitive with state - of - the - art neural language models and backoff n - gram models .",
        "theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success .",
        "we propose and evaluate two deep neural network architectures that consist of encoding , action - conditional transformation , and decoding layers based on convolutional neural networks and recurrent neural networks .",
        "starting with a high - performance transition - based parser that uses long short - term memory ( lstm ) recurrent neural networks to learn representations of the parser state , we replace look - up based word representations with representations constructed based on the orthographic representations of the words , also using lstms .",
        "in this paper , we present sdp - lstm , a novel neural network to classify the relation of two entities in a sentence .",
        "our neural architecture leverages the shortest dependency path ( sdp ) between two entities ; multichannel recurrent neural networks , with long short term memory ( lstm ) units , pick up heterogeneous information along the sdp .",
        "( 3 ) a customized dropout strategy regularizes the neural network to alleviate overfitting .",
        "this paper aims to compare different regularization strategies to address a common phenomenon , severe overfitting , in embedding - based neural networks for nlp .",
        "we chose two widely studied neural models and tasks as our testbed .",
        "the results provide a picture on tuning hyperparameters for neural nlp models .",
        "most existing word embedding methods can be categorized into neural embedding models and matrix factorization ( mf ) - based methods .",
        "we investigate an extension of continuous online learning in recurrent neural network language models .",
        "an attentional mechanism has been used in neural machine translation ( nmt ) to selectively focus on parts of the source sentence during translation .",
        "the distinctive features and advantages are summarised : simplification and integration of observations and concepts , and of structures and processes in computing systems ; the sp theory is itself a theory of computing ; a central role for information compression via the matching and unification of patterns , and for multiple alignment ; transparency in the representation and processing of knowledge ; the discovery of ' natural ' structures via information compression ( donsvic ) ; interpretation of aspects of mathematics ; interpretation of phenomena in human perception and cognition ; realisation of abstract concepts in terms of neurons and their inter - connections ( \" sp - neural \" ) .",
        "distinctive features and advantages of the sp system compared with alternatives in : minimum length encoding and related concepts ; deep learning in neural networks ; universal search ; bayesian networks and other models for ai ; analysis and production of natural language ; learning natural language ; exact and inexact reasoning ; representation and processing of diverse forms of knowledge ; ibm ' s watson ; problems associated with big data , and in the development of intelligence in autonomous robots .",
        "regularisation of deep neural networks ( dnn ) during training is critical to performance .",
        "neural networks have been shown to improve performance across a range of natural - language tasks .",
        "we also include these models in a machine translation decoder and show that these smaller neural models maintain the significant improvements of their unpruned versions .",
        "we propose a method combining relational - logic representations with deep neural network learning .",
        "the relational rule - set serves as a template for unfolding possibly deep neural networks whose structures also reflect the structure of given training or testing examples .",
        "contemporary deep neural networks exhibit impressive results on practical problems .",
        "we analyze this behavior in the context of deep , infinite neural networks .",
        "this increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models , and it allows a neural network - based model to perform competitively on natural language inference benchmarks for the first time .",
        "deep neural networks is a branch in machine learning that has seen a meteoric rise in popularity due to its powerful abilities to represent and model high - level abstractions in highly complex data .",
        "one area in deep neural networks that is ripe for exploration is neural connectivity formation .",
        "a pivotal study on the brain tissue of rats found that synaptic formation for specific functional connectivity in neocortical neural microcircuits can be surprisingly well modeled and predicted as a random formation .",
        "motivated by this intriguing finding , we introduce the concept of stochasticnet , where deep neural networks are formed via stochastic connectivity between neurons .",
        "such stochastic synaptic formations in a deep neural network architecture can potentially allow for efficient utilization of neurons for performing specific tasks .",
        "to evaluate the feasibility of such a deep neural network architecture , we train a stochasticnet using three image datasets .",
        "experimental results show that a stochasticnet can be formed that provides comparable accuracy and reduced overfitting when compared to conventional deep neural networks with more than two times the number of neural connections .",
        "we propose neural reasoner , a framework for neural network - based reasoning over natural language sentences .",
        "given a question , neural reasoner can infer over multiple supporting facts and find an answer to the question in specific forms .",
        "neural reasoner has 1 ) a specific interaction - pooling mechanism , allowing it to examine multiple facts , and 2 ) a deep architecture , allowing it to model the complicated logical relations in reasoning tasks .",
        "assuming no particular structure exists in the question and facts , neural reasoner is able to accommodate different types of reasoning and different forms of language expressions .",
        "despite the model complexity , neural reasoner can still be trained effectively in an end - to - end manner .",
        "our empirical studies show that neural reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks ( positional reasoning and path finding ) proposed in [ 8 ] .",
        "some novel strategies have recently been proposed for single hidden layer neural network training that set randomly the weights from input to hidden layer , while weights from hidden to output layer are analytically determined by pseudoinversion .",
        "for this reason , a hybrid neuro - fuzzy is used because it takes advantages of the neural networks learning and fuzzy logic human - like reasoning .",
        "this thesis describes the design and implementation of a smile detector based on deep convolutional neural networks .",
        "it starts with a summary of neural networks , the difficulties of training them and new training methods , such as restricted boltzmann machines or autoencoders .",
        "it then provides a literature review of convolutional neural networks and recurrent neural networks .",
        "we study a class of neural nets - gibbs machines - which are a type of variational auto - encoders , designed for gradual learning .",
        "combining them with classifiers gives rise to a brand of universal generative neural nets - stochastic auto - classifier - encoders ( ace ) .",
        "we describe a simple neural language model that relies only on character - level inputs .",
        "our model employs a convolutional neural network ( cnn ) over characters , whose output is given to a long short - term memory ( lstm ) recurrent neural network language model ( rnn - lm ) .",
        "recently proposed methodologies lack a satisfactory discussion of whether they actually produce the correct results according to their definition , especially in the context of convolutional neural networks .",
        "the tools developed in this paper are especially beneficial if convolutional neural networks are employed , but can also be used as a more general framework to validate related approaches to signal scanning .",
        "in this work , the trepan algorithm is enhanced and extended for extracting decision trees from neural networks .",
        "neural machine translation ( nmt ) models typically operate with a fixed vocabulary , so the translation of rare and unknown words is an open problem .",
        "we present an end - to - end , domain - independent neural encoder - aligner - decoder model for selective generation , i .",
        ", in weather forecasting and sportscasting ) via a memory - based recurrent neural network ( lstm ) , then utilizes a novel coarse - to - fine ( hierarchical ) , multi - input aligner to identify the small subset of salient records to talk about , and finally employs a decoder to generate free - form descriptions of the aligned , selected records .",
        "despite the promise of brain - inspired machine learning , deep neural networks ( dnn ) have frustratingly failed to bridge the deceptively large gap between learning and memory .",
        "in the second step , for plant classification , we employed different support vector machine ( svm ) kernels and two hybrid systems of neural networks .",
        "our experimental shows that mnce and gncl improve the efficiency of classical classifiers , however , some svm kernels function has better performance than classifiers based on neural network ensemble method .",
        "in this paper , we propose another version of help - training approach by employing a probabilistic neural network ( pnn ) that improves the performance of the main discriminative classifier in the semi - supervised strategy .",
        "next , we present a recursive neural network over the rst structure , which offers significant improvements over classification - based methods .",
        "comparisons are offered against traditional models such as bag of words , n - grams and their tfidf variants , and deep learning models such as word - based convnets and recurrent neural networks .",
        "the downfall of many supervised learning algorithms , such as neural networks , is the inherent need for a large amount of training data .",
        "evolution of visual object recognition architectures based on convolutional neural networks & amp ; convolutional deep belief networks paradigms has revolutionized artificial vision science .",
        "recently , many researches employ middle - layer output of convolutional neural network models ( cnn ) as features for different visual recognition tasks .",
        "in this paper , we present a system that employs a wearable acoustic sensor and a deep convolutional neural network for detecting coughs .",
        "in particular , we study reinforcement learning with deep neural networks , including rnn and lstm , which are equipped with the desired property of being able to capture long - term dependency on history , and thus providing an effective way of learning the representation of hidden states .",
        "in a recent article we described a new type of deep neural network - a perpetual learning machine ( plm ) - which is capable of learning ' on the fly ' like a brain by existing in a state of perpetual stochastic gradient descent ( psgd ) .",
        "recurrent neural network ( rnn ) is one of the most popular and simple approach to model the dynamics as well as to infer correct dependencies among genes .",
        "this work presents and analyzes three convolutional neural network ( cnn ) models for efficient pixelwise classification of images .",
        "when using convolutional neural networks to classify single pixels in patches of a whole image , a lot of redundant computations are carried out when using sliding window networks .",
        "multidimensional recurrent neural network ( mdrnn ) has shown a remarkable performance in speech and handwriting recognition .",
        "an unbalanced synergetic neural net - work classifies shapes and structures of human objects along with tuning its attention parameter by quantum particle swarm optimization ( qpso ) via initiation of centroidal voronoi tessellations .",
        "two configurations have been proposed for form pathway : applying multi - prototype human action templates using two time synergetic neural network for obtaining uniform template regarding each actions , and second scenario that it uses abstracting human action in four key - frames .",
        "automatic speech recognition ( asr ) is achieved by two multi - pass deep neural network systems with adaptation and rescoring techniques .",
        "with the impressive capability to capture visual content , deep convolutional neural networks ( cnn ) have demon - strated promising performance in various vision - based ap - plications , such as classification , recognition , and objec - t detection .",
        "in this paper , to address this problem , we proposed a new kernelized deep convolutional neural network .",
        "rectified linear units ( relu ) seem to have displaced traditional ' smooth ' nonlinearities as activation - function - du - jour in many - but not all - deep neural network ( dnn ) applications .",
        "we propose a convolutional neural network ( cnn ) architecture for facial expression recognition .",
        "the proposed architecture is independent of any hand - crafted feature extraction and performs better than the earlier proposed convolutional neural network based approaches .",
        "stochastic gradient descent ( sgd ) is arguably the most popular of the machine learning methods applied to training deep neural networks ( dnn ) today .",
        "training a denoising autoencoder neural network requires access to truly clean data , a requirement which is often impractical .",
        "motivated by the needs in leveraging large scale yet noisy training data to solve the extremely challenging problem of image sentiment analysis , we employ convolutional neural networks ( cnn ) .",
        "in the back - end , several techniques are taken advantage to improve the noisy automatic speech recognition ( asr ) performance including deep neural network ( dnn ) , convolutional neural network ( cnn ) and long short - term memory ( lstm ) using medium vocabulary , lattice rescoring with a big vocabulary language model finite state transducer , and rover scheme .",
        "in particular , we first show that the recent dqn algorithm , which combines q - learning with a deep neural network , suffers from substantial overestimations in some games in the atari 2600 domain .",
        "deep neural networks currently demonstrate state - of - the - art performance in several domains .",
        "end - to - end differentiable neural architectures have failed to approach state - of - the - art performance until very recently .",
        "in this paper , we propose a neural model that reads two sentences to determine entailment using long short - term memory units .",
        "we extend this model with a word - by - word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases .",
        "on a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin .",
        "despite their success , convolutional neural networks are computationally expensive because they must examine all image locations .",
        "using the simulation and programming environment netlogo , a software engine for the integrate and fire model was developed , which allowed us to monitor in discrete time steps the dynamics of each single neuron , synapse and spike in the proposed neural networks .",
        "these spiking neural networks ( snn ) served as simple brains for the experimental robots .",
        "in this paper the topological building blocks are presented as well as the neural parameters required to reproduce the experiments .",
        "this paper summarizes the resulting behaviour as well as the observed dynamics of the neural circuits .",
        "an artificial neural network ( ann ) with conjugate - gradient learning algorithm has been used to model the sand fraction .",
        "neural networks have shown its potential to model such nonlinear mappings ; however , uncertainties associated with the model and datasets are still a concern .",
        "more specifically , hybrid variants of artificial neural network ( ann ) and fuzzy logic , i .",
        "the state - of - the - art speech recognition techniques , namely recurrent neural network based acoustic and language modeling , state space minimum bayes risk based discriminative acoustic modeling , and i - vector based acoustic condition modeling , are carefully integrated into the speech recognition back - end .",
        ", in vivo neural recording and electrocorticography ( ecog ) , some measurement artifacts take the form of piecewise exponential transients .",
        "the chip is verified with neural data recorded in monkey finger movements experiment , achieving a decoding accuracy of 99 .",
        "the same co - processor is also used to decode time of movement from asynchronous neural spikes .",
        "we used tiled convolutional neural networks to learn high - level features from individual gaf , mtf , and gaf - mtf images on 12 benchmark time series datasets and two real spatial - temporal trajectory datasets .",
        "in this paper , we evaluate convolutional neural network ( cnn ) features using the alexnet architecture and very deep convolutional network ( vggnet ) architecture .",
        "deep neural network architectures have recently produced excellent results in a variety of areas in artificial intelligence and visual recognition , well surpassing traditional shallow architectures trained using hand - designed features .",
        "we implement the idea by formulating the problem as a single neural network architecture , including the estimation of a speaker model on only a few utterances , and evaluate it on our internal \" ok google \" benchmark for text - dependent speaker verification .",
        "because of their performance , deep neural networks are increasingly used for object recognition .",
        "convolutional neural networks ( cnns ) are a standard component of many current state - of - the - art large vocabulary continuous speech recognition ( lvcsr ) systems .",
        "however , cnns in lvcsr have not kept pace with recent advances in other domains where deeper neural networks provide superior performance .",
        "we introduce a convolutional neural network that operates directly on graphs , allowing end - to - end learning of the feature pipeline .",
        "neural language models are a powerful tool to meaningfully embed words into semantic vector spaces .",
        "over the past few years , neural networks have re - emerged as powerful machine - learning models , yielding state - of - the - art results in fields such as image recognition and speech processing .",
        "more recently , neural network models started to be applied also to textual natural language signals , again with very promising results .",
        "this tutorial surveys neural network models from the perspective of natural language processing research , in an attempt to bring natural - language researchers up to speed with the neural techniques .",
        "our best approach uses side information in the form of known word pairs to train a siamese convolutional neural network ( cnn ) : a pair of tied networks that take two speech segments as input and produce their embeddings , trained with a hinge loss that separates same - word pairs and different - word pairs by some margin .",
        "we propose a novel switching recurrent neural network with word - level regularization , which is able to produce emotional image captions using only 2000 + training sentences containing sentiments .",
        "furthermore , the proposed modeling and synthesis platform outperforms a leading - edge , vocoded , deep bidirectional long short - term memory recurrent neural network ( dblstm - rnn ) - based baseline system in various objective evaluation metrics conducted .",
        "in parallel , in the last few years , language models based on neural networks have been used to cope with complex natural language processing tasks like emotion and paraphrase detection .",
        "based on a recent work that proposed to learn a generic language model that can be modified through a set of document - specific parameters , we explore use of new neural network models that are adapted to ad - hoc ir",
        "deep cca is a recently proposed deep neural network extension to the traditional canonical correlation analysis ( cca ) , and has been successful for multi - view representation learning in several domains .",
        "we present a general technique that uses a neural network mapper with a weighted multiple - loss criterion .",
        "when training deep neural networks , it is typically assumed that the training examples are uniformly difficult to learn .",
        "in this article , using a deep neural network to encode a video , we show that oddball sgd can be used to enforce uniform error across the training set .",
        "we introduce a new structure for memory neural networks , called feedforward sequential memory networks ( fsmn ) , which can learn long - term dependency without using recurrent feedback .",
        "the proposed fsmn is a standard feedforward neural networks equipped with learnable sequential memory blocks in the hidden layers .",
        "experiments have shown that fsmn based language models can significantly outperform not only feedforward neural network ( fnn ) based lms but also the popular recurrent neural network ( rnn ) lms .",
        "faced with continuously increasing scale of data , original back - propagation neural network based machine learning algorithm presents two non - trivial challenges : huge amount of data makes it difficult to maintain both efficiency and accuracy ; redundant data aggravates the system workload .",
        "careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data , how mapreduce is implemented on deep learning neural network , and why this combination accelerates computation .",
        "in this theory , the continuous - valued latent variables correspond to averaged voltage potential ( across time , spikes , and possibly neurons in the same minicolumn ) , and neural computation corresponds to approximate inference and error back - propagation at the same time .",
        "despite being the appearance - based classifier of choice in recent years , relatively few works have examined how much convolutional neural networks ( cnns ) can improve performance on accepted expression recognition benchmarks and , more importantly , examine what it is they actually learn .",
        "since most of the computation in training neural networks is typically spent on floating point multiplications , we investigate an approach to training that eliminates the need for most of these .",
        "experimental results across 3 popular datasets ( mnist , cifar10 , svhn ) show that this approach not only does not hurt classification performance but can result in even better performance than standard stochastic gradient descent training , paving the way to fast , hardware - friendly training of neural networks .",
        "sequence - to - sequence neural network models for generation of conversational responses tend to generate safe , commonplace responses ( e .",
        "instead we propose using maximum mutual information ( mmi ) as objective function in neural models .",
        "we study the improper learning of multi - layer neural networks .",
        "suppose that the neural network to be learned has $ k $ hidden layers and that the $ \\ ell _ 1 $ - norm of the incoming weights of any neuron is bounded by $ l $ .",
        "we present a kernel - based method , such that with probability at least $ 1 - \\ delta $ , it learns a predictor whose generalization error is at most $ \\ epsilon $ worse than that of the neural network .",
        "it implies that any sufficiently sparse neural network is learnable in polynomial time .",
        "the language discriminative phonotactic information in the obtained phone sequences are modeled using statistical and recurrent neural network based language modeling approaches .",
        "convolutional neural networks ( cnns ) have recently achieved remarkably strong performance on sentence classification tasks ( kim , 2014 ; kalchbrenner et al .",
        "neural turing machines ( ntm ) contain memory component that simulates \" working memory \" in the brain to store and retrieve information to ease simple algorithms learning .",
        "additionally , it has also been shown that in highly non - convex problems , such as deep neural networks , there is a proliferation of high - error low curvature saddle points , which slows down learning dramatically .",
        "in this paper , we attempt to overcome the two above problems by proposing an optimization method for training deep neural networks which uses learning rates which are both specific to each layer in the network and adaptive to the curvature of the function , increasing the learning rate at low curvature points .",
        "in this paper we present an approach to multi - language image description bringing together insights from neural machine translation and neural image description .",
        "we approach the problem by learning a similarity measure on small image patches using a convolutional neural network .",
        "the output of the convolutional neural network is used to initialize the stereo matching cost .",
        "bidirectional long short - term memory recurrent neural network ( blstm - rnn ) has been shown to be very effective for tagging sequential data , e .",
        "this paper envisions an end - to - end program generation scenario using recurrent neural networks ( rnns ) : users can express their intention in natural language ; an rnn then automatically generates corresponding code in a characterby - by - character fashion .",
        "in this paper , a framework for testing deep neural network ( dnn ) design in python is presented .",
        "first , big data , machine learning ( ml ) , and artificial neural networks ( anns ) are discussed to familiarize the reader with the importance of such a system .",
        "we combine and compare three models , neural machine translation , neural turing machine , and memory networks for a simulated qa data set .",
        "this paper is the first one that uses neural machine translation and neural turing machines for solving qa tasks .",
        "we present a novel application of lstm recurrent neural networks to multilabel classification of diagnoses given variable - length time series of clinical measurements .",
        "this paper proposes a neural network based approach that models the attention and intention processes .",
        "this work presents an attention mechanism - based neural network approach for tracking objects in video .",
        "a recurrent neural network is trained to predict the position of an object at time t + 1 given a series of selective glimpses into video frames at time steps 1 to t .",
        "in this paper , we extend the deep long short - term memory ( dlstm ) recurrent neural networks by introducing gated direct connections between memory cells in adjacent layers .",
        "in this paper , we investigate the use of prediction - adaptation - correction recurrent neural networks ( pac - rnns ) for low - resource speech recognition .",
        "a pac - rnn is comprised of a pair of neural networks in which a { \\ it correction } network uses auxiliary information given by a { \\ it prediction } network to help estimate the state probability .",
        "our model outperforms other state - of - the - art neural networks ( dnns , lstms ) on iarpa - babel tasks .",
        "in this paper we develop a recurrent neural network ( treernn ) , which is designed to predict a tree rather than a linear sequence as is the case in conventional recurrent neural networks .",
        "we construct the tree incrementally by generating the left and right dependents of a node whose probability is computed using recurrent neural networks with shared hidden layers .",
        "bidirectional long short - term memory recurrent neural network ( blstm - rnn ) has been shown to be very effective for modeling and predicting sequential data , e .",
        "in this paper , we propose to use neural networks to predict prosodic boundary labels directly from chinese characters without any feature engineering .",
        "deep neural networks ( dnn ) have achieved state - of - the - art results in a wide range of tasks , with the best results obtained with large training sets and large models .",
        "- 1 or 1 ) , would bring great benefits to specialized dl hardware by replacing many multiply - accumulate operations by simple accumulations , as multipliers are the most space and power - hungry components of the digital implementation of neural networks .",
        "we present a novel and practical deep fully convolutional neural network architecture for semantic pixel - wise segmentation termed segnet .",
        "in this paper , we explore different neural network architectures that can predict if a speaker of a given utterance is asking a question or making a statement .",
        "we com - pare the outcomes of regularization methods that are popularly used to train deep neural networks and study how different context functions can affect the classification performance .",
        "we also compare the efficacy of gated activation functions that are favorably used in recurrent neural networks and study how to combine multimodal inputs .",
        "then the word embeddings which represent each comment are used as input in different machine learning methods for sentiment classification , including svm , logistic regression , convolutional neural network ( cnn ) and ensemble methods .",
        "we present a new deterministic relational model derived from convolutional neural networks .",
        "search - convolutional neural networks ( scnns ) extend the notion of convolution to graph search to construct a rich latent representation that extracts local behavior from general graph - structured data .",
        "unlike other neural network models that take graph - structured data as input , scnns have a parameterization that is independent of input size , a property that enables transfer learning between datasets .",
        "we show that models which store explicit representations of long - term contexts outperform state - of - the - art neural language models at predicting semantic content words , although this advantage is not observed for syntactic function words .",
        "for this issue , ai models , including supervised brain emotional learning ( bel ) , adaptive neuro - fuzzy inference system ( anfis ) and artificial neural networks ( anns ) , are compared in order to find the best model .",
        "here , we propose a brain - inspired winner - take - all emotional neural network ( wtaenn ) and prove the universal approximation property for the novel architecture .",
        "wtaenn is a single layered feedforward neural network that benefits from the excitatory , inhibitory , and expandatory neural connections as well as the winner - take - all ( wta ) competitions in the human brain s nervous system .",
        "in this paper we propose the structured deep neural network ( structured dnn ) as a structured and deep learning framework .",
        "in this paper , we have proposed a system based on matrix factorization ( mf ) and deep recurrent neural networks ( drnns ) for genotype imputation and phenotype sequences prediction .",
        "additionally , a method to measure naturalness can be complementary to convolutional neural network ( cnn ) based features , which are known to be insensitive to the naturalness of images .",
        "based on this assumption , we propose a novel method to evaluate the naturalness by building a variant of recurrent neural network language models on pre - trained cnn representations .",
        "our purpose is to create a rapid prototype of q - learning with neural network approximators for samu .",
        "this paper presents a new method for pre - training neural networks that can decrease the total training time for a neural network while maintaining the final performance , which motivates its use on deep neural networks .",
        "the proposed method is independent of the other aspects of the training , such as architecture of the neural network , training method , and objective , making it compatible with a wide range of existing approaches .",
        "following the recent successes of deep convolutional neural networks ( dcnn ) for large scale image classification , descriptors extracted from dcnns are increasingly used in place of the traditional hand crafted descriptors such as fisher vectors ( fv ) with better retrieval performances .",
        "recurrent neural networks ( rnns ) , particularly those using long short - term memory ( lstm ) hidden units , are powerful and increasingly popular models for learning from sequence data .",
        "we present a character - level recurrent neural network that generates relevant and coherent text given auxiliary information such as a sentiment or topic .",
        "we employ a pair of convolutional neural networks to model visual objects and speech signals at the word level , and tie the networks together with an embedding and alignment model which learns a joint semantic space over both modalities .",
        "in recent years significant progress has been made in successfully training recurrent neural networks ( rnns ) on sequence learning problems involving long range temporal dependencies .",
        "we present a large - scale study , exploring the capability of temporal deep neural networks in interpreting natural human kinematics and introduce the first method for active biometric authentication with mobile inertial sensors .",
        "we ( 1 ) compare several neural architectures for efficient learning of temporal multi - modal data representations , ( 2 ) propose an optimized shift - invariant dense convolutional mechanism ( dcwrnn ) and ( 3 ) incorporate the discriminatively - trained dynamic features in a probabilistic generative framework taking into account temporal characteristics .",
        "to simplify the number of times of optimization in experimental works , here , we use artificial neural network ( ann ) and support vector machine ( svm ) models for the prediction of yields of 3 \\ b { eta } - o - phthalic ester of betulinic acid synthesized by betulinic acid and phthalic anhydride using lipase as biocatalyst .",
        "general regression neural network ( grnn ) , multilayer feed - forward neural network ( mlfn ) and the svm models were trained based on experimental data .",
        "to that end , we introduce a simplified training objective for learning multimodal embeddings using the skip - gram architecture by introducing convolutional ' pseudowords : ' embeddings composed of the additive combination of distributed word representations and image features from convolutional neural networks projected into the multimodal space .",
        "one is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework , the other is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context .",
        "we use multi - layered recurrent neural networks ( rnns ) with long short - term memory ( lstm ) units which are deep both spatially and temporally .",
        "recent work has shown that deep neural networks are capable of approximating both value functions and policies in reinforcement learning domains featuring continuous state and action spaces .",
        "however , to the best of our knowledge no previous work has succeeded at using deep neural networks in structured ( parameterized ) continuous action spaces .",
        "over the past few years , artificial neural networks have seen a dramatic resurgence in popularity as a tool for solving hard learning problems in ai applications .",
        "while it is widely known that neural networks are computationally hard to train in the worst case , in practice , neural networks are trained efficiently using sgd methods and a variety of techniques which accelerate the learning process .",
        "we introduce a neural machine translation model that views the input and output sentences as sequences of characters rather than words .",
        "we present a neural network architecture based on bidirectional lstms to compute representations of words in the sentential contexts .",
        "the central idea of this paper is to put lda on top of a deep neural network .",
        "we propose to use the recently proposed stochastic optimization algorithm for linear cca and its neural - network extension to further alleviate the computation requirements of approximate kcca .",
        "several nonlinear extensions of the classical linear cca method have been proposed , including kernel and deep neural network methods .",
        "these approaches restrict attention to certain families of nonlinear projections , which the user must specify ( by choosing a kernel or a neural network architecture ) , and are computationally demanding .",
        ", and show that , due to intrinsic joint minimization , the results obtained from a convolutional neural network ( cnn ) or a fully connected neural network ( fnn ) , if well parameterized , surpass the conventional use of a rm with an ec .",
        "it accomplishes this goal using an encoder recurrent neural network ( rnn ) that computes features at the same frame rate as the input , and a transducer rnn that operates over blocks of input steps .",
        "this paper presents a new method for the discovery of latent domains in diverse speech data , for the use of adaptation of deep neural networks ( dnns ) for automatic speech recognition .",
        "we present experimental results to corroborate our claims : for pruning neural networks , divnet is seen to be notably superior to competing approaches .",
        "we show that the internal representations of an image in a deep neural network ( dnn ) can be manipulated to mimic those of other natural images with only minor , imperceptible perturbations to the original image .",
        "in this paper we show how deep architectures , specifically convolutional neural networks ( cnn ) , can be adapted to the task of simultaneous categorization and pose estimation of objects .",
        "deep neural networks are powerful parametric models that can be trained efficiently using the backpropagation algorithm .",
        "stochastic neural networks combine the power of large parametric functions with that of graphical models , which makes it possible to learn very complex distributions .",
        "this work shows how using reduced precision data in convolutional neural networks ( cnns ) affects network accuracy during classification .",
        "in this paper , we propose two neural network models targeted to retrieve oov pns relevant to an audio document : ( a ) document level continuous bag of words ( d - cbow ) , ( b ) document level continuous bag of weighted words ( d - cbow2 ) .",
        "this layer learns to assign importance to input words and has the ability to capture ( task specific ) key - words in a bag - of - word neural network model .",
        "deep neural networks with millions of parameters are at the heart of many state of the art machine learning models today .",
        "e ; learning the architecture of a neural network along with weights .",
        "methods of applying neural networks to control plants are considered .",
        "conditional belief networks introduce stochastic binary variables in neural networks .",
        "contrary to a classical neural network , a belief network can predict more than the expected value of the output $ y $ given the input $ x $ .",
        "in this paper , we introduce a new deep convolutional neural network ( convnet ) module that promotes competition among a set of multi - scale convolutional filters .",
        "we introduce techniques for rapidly transferring the information stored in one neural net into another neural net .",
        "the main purpose is to accelerate the training of a significantly larger neural net .",
        "during real - world workflows , one often trains very many different neural networks during the experimentation and design process .",
        "our techniques are based on the concept of function - preserving transformations between neural network specifications .",
        "this differs from previous approaches to to pre - training that altered the function represented by a neural net when adding layers to it .",
        "recently , convolutional and recurrent neural networks has provided very effective mechanisms to capture the hidden structures within sentences via continuous representations , thereby significantly advancing the performance of relation extraction .",
        "the advantage of convolutional neural networks is their capacity to generalize the consecutive k - grams in the sentences while recurrent neural networks are effective to encode long ranges of sentence context .",
        "this paper proposes to combine the traditional feature - based method , the convolutional and recurrent neural networks to simultaneously benefit from their advantages .",
        "towards this direction of modeling clinical bahavior of physicians , we develop a successful application of recurrent neural networks ( rnn ) to jointly forecast the future disease diagnosis and medication prescription along with their timing .",
        "here , we introduce a deep , differentiable , fully - connected neural network module composed of diagonal matrices of parameters , $ \\ mathbf { a } $ and $ \\ mathbf { d } $ , and the discrete cosine transform $ \\ mathbf { c } $ .",
        "in our experiments , we show that it can indeed be successfully interleaved with relu modules in convolutional neural networks for image recognition .",
        "we introduce segmental recurrent neural networks ( srnns ) which define , given an input sequence , a joint probability distribution over segmentations of the input and labelings of the segments .",
        ", contiguous subsequences of the input ) are computed by encoding their constituent tokens using bidirectional recurrent neural nets , and these \" segment embeddings \" are used to define compatibility scores with output labels .",
        "recent advances in neural variational inference have spawned a renaissance in deep latent variable models .",
        "our neural variational document model combines a continuous stochastic document representation with a bag - of - words generative model and achieves the lowest reported perplexities on two standard test corpora .",
        "the neural answer selection model employs a stochastic representation layer within an attention mechanism to extract the semantics between a question and answer pair .",
        ", bayesian models and neural models ) .",
        "although image compression has been actively studied for decades , there has been relatively little research on learning to compress images with modern neural networks .",
        "in this work , we revisit graph - based semi - supervised learning algorithms and propose an online graph construction technique which suits deep convolutional neural network better .",
        "we consider an em - like algorithm for semi - supervised learning on deep neural networks : in forward pass , the graph is constructed based on the network output , and the graph is then used for loss calculation to help update the network by back propagation in the backward pass .",
        "the task of labeling data for training deep neural networks is daunting and tedious , requiring millions of labels to achieve the current state - of - the - art results .",
        "we further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data .",
        "we propose the neural programmer - interpreter ( npi ) : a recurrent and compositional neural network that learns to represent and execute programs .",
        "the visually imperceptible perturbations that result in convolutional neural networks ( cnn ) fail , can be alleviated with a mechanism based on foveations - applying the cnn in a different image region .",
        "then , we corroborate the hypothesis that when the neural responses are in the linear region , applying the foveation mechanism to the adversarial example tends to reduce the effect of the perturbation .",
        "recurrent neural networks are convenient and efficient models for language modeling .",
        "recent studies have shown that convolutional neural networks ( cnns ) are vulnerable to a small perturbation of input called \" adversarial examples \" .",
        "using several variations of neural network classifier , we show that these combined methods lead to improved performance when used as input features for supervised term - matching .",
        "convolutional neural networks have achieved state - of - the - art performance on a wide range of tasks .",
        "unregularized deep neural networks ( dnns ) can be easily overfit with a limited sample size .",
        "in this paper , we propose deep embedded clustering ( dec ) , a method that simultaneously learns feature representations and cluster assignments using deep neural networks .",
        "the use of convolutional neural networks ( cnn ) in natural image classification systems has produced very impressive results .",
        "the standard unsupervised recurrent neural network language model ( rnnlm ) generates sentences one word at a time and does not work from an explicit global distributed sentence representation .",
        "complex - valued neural networks ( cvnns ) are an emerging field of research in neural networks due to their potential representational properties for audio , image , and physiological signals .",
        "learning meaningful representations using deep neural networks involves designing efficient training schemes and well - structured networks .",
        "neural word representations have proven useful in natural language processing ( nlp ) tasks due to their ability to efficiently model complex semantic and syntactic word relationships .",
        "however , recent neural approaches rarely focus on the application to a consuming nlp algorithm .",
        "we further evaluate part - of - speech disambiguated embeddings on neural dependency parsing , yielding a greater than 8 % average error reduction in unlabeled attachment scores across 6 languages .",
        "in this paper , we propose and investigate a new neural network architecture called neural random access machine .",
        "in this work , we present a neural attention network that directly combines multi - channel audio to generate phonetic states without requiring any prior knowledge of the microphone layout or any explicit signal preprocessing for speech enhancement .",
        "we embed an attention mechanism within a recurrent neural network ( rnn ) based acoustic model to automatically tune its attention to a more reliable input source .",
        "we evaluate our neural attention model on a subset of the chime - 3 challenge task , and we show that the model achieve",
        "we compare the consequences of using ssim versus se loss on representations formed in deep autoencoder and recurrent neural network architectures .",
        "a pure pattern - matching approach , based on a deep convolutional neural network ( dcnn ) that predicts the next move , can perform as well as monte carlo tree search ( mcts ) - based open source go engines such as pachi [ baudis & amp ; gailly ( 2012 ) ] if its search budget is limited .",
        "supervised training of deep neural nets typically relies on minimizing cross - entropy .",
        "in this paper we proposed a direct loss minimization approach to train deep neural networks , taking into account the application - specific loss functions .",
        "while the current trend is to increase the depth of neural networks to increase their performance , the size of their training database has to grow accordingly .",
        "in this paper , we present an active learning strategy based on query by committee and dropout technique to train a convolutional neural network ( cnn ) .",
        "although deep convolutional neural networks ( cnns ) have achieved remarkable results on object detection and segmentation , pre - and post - processing steps such as region proposals and non - maximum suppression ( nms ) , have been required .",
        "in this work , we propose a novel end - to - end trainable deep neural network architecture that generates the correct number of object instances and their bounding boxes ( or segmentation masks ) given an image , using only a single network evaluation without any pre - or post - processing steps .",
        "recurrent neural networks ( rnns ) are notoriously difficult to train .",
        "the complexity of deep neural network algorithms for hardware implementation can be much lowered by optimizing the word - length of weights and signals .",
        "in this work , the effects of retraining are analyzed for a feedforward deep neural network ( ffdnn ) and a convolutional neural network ( cnn ) .",
        "we find that the performance gap between the floating - point and the retrain - based ternary ( + 1 , 0 , - 1 ) weight neural networks exists with a fair amount in ' complexity limited ' networks , but the discrepancy almost vanishes in fully complex networks whose capability is limited by the training data , rather than by the number of connections .",
        "we propose a method for integration of features extracted using deep representations of convolutional neural networks ( cnns ) each of which is learned using a different image dataset of objects and materials for material recognition .",
        "although the latest high - end smartphone has powerful cpu and gpu , running deeper convolutional neural networks ( cnns ) for complex tasks such as imagenet classification on mobile devices is challenging .",
        "in this paper , we present a new neural network architecture for model - free reinforcement learning inspired by advantage learning .",
        "recent work on sequence to sequence translation using recurrent neural networks ( rnns ) based on long short term memory ( lstm ) architectures has shown great potential for learning useful representations of sequential data .",
        "these architectures , using one recurrent neural network to encode sequences into fixed - length representations , and one or more network ( s ) to decode representations into new sequences have the advantages of being modular , while also allowing modules to be jointly trained .",
        "neural machine translation ( nmt ) has obtained state - of - the art performance for several language pairs , while only using parallel data for training .",
        "monolingual data plays an important role in boosting fluency for phrase - based statistical machine translation , and we investigate the use of monolingual data for neural machine translation ( nmt ) .",
        "the method is less computationally demanding compared to similar gradient - based approaches to hyperparameter selection , only requires a few trials , and consistently finds solid hyperparameter values which makes it a useful tool for training neural network models .",
        "we propose a new method for creating computationally efficient convolutional neural networks ( cnns ) by using low - rank representations of convolutional filters .",
        "we propose a unified framework for neural net normalization , regularization and optimization , which includes path - sgd and batch - normalization and interpolates between them across two different dimensions .",
        "neural networks , in particular , have enormous expressive power and yet are notoriously challenging to train .",
        "connectionist temporal classification ( ctc ) based supervised sequence training of recurrent neural networks ( rnns ) has shown great success in many machine learning areas including end - to - end speech and handwritten character recognition .",
        "in this paper , we provide a method for understanding the internal representations of convolutional neural networks ( cnns ) trained on objects .",
        "convolutional neural networks spread through computer vision like a wildfire , impacting almost all visual tasks imaginable .",
        "we apply recurrent neural networks ( rnn ) on a new domain , namely recommendation system .",
        "we introduce a recurrent neural network architecture for automated road surface wetness detection from audio of tire - surface interaction .",
        "we propose a structured prediction architecture for images centered around deep recurrent neural networks .",
        "the reseg layer is composed of four recurrent neural networks that sweep the image horizontally and vertically in both directions , along with a final layer that expands the prediction back to the original image size .",
        "we use neural network ( nn ) as a model instance to carry out the study and the analysis shows that increasing the diversity of hidden units in nn would reduce estimation error and increase approximation error .",
        "for the controller , we explore a range of neural network - based models which vary in their ability to abstract the underlying algorithm from training instances and generalize to test examples with many thousands of digits .",
        "we introduce the \" exponential linear unit \" ( elu ) which speeds up learning in deep neural networks and leads to higher classification accuracies .",
        "in this work we show that deep convolutional neural networks can outperform humans on the task of boundary detection , as measured on the standard berkeley segmentation dataset .",
        "we deploy a range of neural models ( fully connected , convolutional network , memory network ) on these games , with and without a procedurally generated curriculum .",
        "convolutional neural networks ( cnns ) have recently emerged as the dominant model in computer vision .",
        "we present a regression framework which models the output distribution of neural networks .",
        "recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers .",
        "in this paper we investigate the extent to which neural networks exhibit what we call convergent learning , which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar low - dimensional spaces .",
        "we begin research into this question using three techniques to approximately align different neural networks on a feature level : a bipartite matching approach that makes one - to - one assignments between neurons , a sparse prediction approach that finds one - to - many mappings , and a spectral clustering approach that finds many - to - many mappings .",
        "this initial investigation reveals a few previously unknown properties of neural networks , and we argue that future research into the question of convergent learning will yield many more .",
        "we introduce the dynamic capacity network ( dcn ) , a neural network that can adaptively assign its capacity across different portions of the input data .",
        "our findings indicate that dcns are able to drastically reduce the number of computations , compared to traditional convolutional neural networks , while maintaining similar performance .",
        "we introduce a multi - resolution convolutional neural network for early detection of multiple diseases from irregularly measured sparse lab values .",
        "we study non - convex empirical risk minimization for learning halfspaces and neural networks .",
        "for loss functions that are $ l $ - lipschitz continuous , we present algorithms to learn halfspaces and multi - layer neural networks that achieve arbitrarily small excess risk $ \\ epsilon & gt ; 0 $ .",
        "we further show that if the data is separable by some neural network with constant margin $ \\ gamma & gt ; 0 $ , then there is a polynomial - time algorithm for learning a neural network that separates the training data with margin $ \\ omega ( \\ gamma ) $ .",
        "we present the interesting result that simple compositional architectures based on updated vector averaging vastly outperform long short - term memory ( lstm ) recurrent neural networks and that these simpler architectures allow us to learn models with superior generalization .",
        "recently it has been addressed using neural networks , in particular by neural turing machines ( ntms ) .",
        "in this paper , we present a novel neural network architecture that automatically detects word - and character - level features using a hybrid bidirectional lstm and cnn architecture , eliminating the need for most feature engineering .",
        "we also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing exact match approaches .",
        "this document provides a brief introduction to convolutional neural networks ( cnns ) , discussing recently published papers and newly form techniques in developing these brilliantly fantastic image recognition models .",
        "this introduction assumes you are familiar with the workings of neural networks and have some background in artificial intelligence .",
        "neural network models have been demon - strated to be capable of achieving remarkable performance in sentence and document mod - eling .",
        "convolutional neural network ( cnn ) and recurrent neural network ( rnn ) are two mainstream architectures for such modeling tasks , which adopt totally different ways of understanding natural languages .",
        "c - lstm utilizes cnn to ex - tract a sequence of higher - level phrase repre - sentations , and are fed into a long short - term memory recurrent neural network ( lstm ) to obtain the sentence representation .",
        "to tackle aspect mapping and sentiment classification , we propose two convolutional neural network ( cnn ) based methods , cascaded cnn and multitask cnn .",
        "in 2013 , our large rl recurrent neural networks ( rnns ) learned from scratch to drive simulated cars from high - dimensional video input .",
        "artificial neural networks are powerful models , which have been widely applied into many aspects of machine translation , such as language modeling and translation modeling .",
        "in this paper , we present a novel neural reordering model that directly models word pairs and alignment .",
        "by utilizing lstm recurrent neural networks , much longer context could be learned for reordering prediction .",
        "experimental results on nist openmt12 arabic - english and chinese - english 1000 - best rescoring task show that our lstm neural reordering feature is robust and achieves significant improvements over various baseline systems .",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "in this paper , a hybrid in - telligent model combining a neural network model integrated with fuzzy model ( neuro - fuzzy model ) has been used to improve the accuracy of estimating software cost .",
        "we proposed neural enquirer as a neural network architecture to execute a sql - like query on a knowledge - base ( kb ) for answers .",
        "basically , neural enquirer finds the distributed representation of a query and then executes it on knowledge - base tables to obtain the answer as one of the values in the tables .",
        "unlike similar efforts in end - to - end training of semantic parser , neural enquirer is fully neuralized : it not only gives distributional representation of the query and the knowledge - base , but also realizes the execution of compositional queries as a series of differentiable operations , with intermediate results ( consisting of annotations of the tables at different levels ) saved on multiple layers of memory .",
        "neural enquirer can be trained with gradient descent , with which not only the parameters of the controlling components and semantic parsing component , but also the embeddings of the tables and query words can be learned from scratch .",
        "neural enquirer is one step towards building neural network systems which",
        "we present a new perspective on neural knowledge base ( kb ) embeddings , from which we build a framework that can model symbolic knowledge in the kb together with its learning process .",
        "we show that this framework well regularizes previous neural kb embedding model for superior performance in reasoning tasks , while having the capabilities of dealing with unseen entities , that is , to learn their embeddings from natural language descriptions , which is very like human ' s behavior of learning semantic concepts .",
        "mxnet is a multi - language machine learning ( ml ) library to ease the development of ml algorithms , especially for deep neural networks .",
        "we demonstrate a convolutional neural network ( cnn ) model that is able perform the same task without the need for landmark features thereby greatly increasing efficiency .",
        "recurrent neural networks have shown excellent performance in many applications , however they require increased complexity in hardware or software based implementations .",
        "this work analyzes the fixed - point performance of recurrent neural networks using a retrain based quantization method .",
        "we suggest an effective architecture of the neural networks for approximating an action - value function with binary vector actions .",
        "the techniques in the domain include amongst others : expectation maximization , neural networks with evolutionary algorithms or optimization techniques and k - nearest neighbor approaches to solve the problem .",
        "in this article , considering arbitrary and monotone missing data patterns , we hypothesize that the use of deep neural networks built using autoencoders and denoising autoencoders in conjunction with genetic algorithms , swarm intelligence and maximum likelihood estimator methods as novel data imputation techniques will lead to better imputed values than existing techniques .",
        "we also intend to use fuzzy logic in tandem with deep neural networks to perform the missing data imputation tasks , as well as different building blocks for the deep neural networks like stacked restricted",
        "for deep convolutional neural networks , dropout is known to work well in fully - connected layers .",
        "a general approach to knowledge transfer is introduced in which an agent controlled by a neural network adapts how it reuses existing networks as it learns in a new domain .",
        "networks trained for a new domain can improve their performance by routing activation selectively through previously learned neural structure , regardless of how or for what it was learned .",
        "this approach is more general than previous approaches to neural transfer for reinforcement learning .",
        "the recently introduced deep q - networks ( dqn ) algorithm has gained attention as one of the first successful combinations of deep neural networks and reinforcement learning .",
        "we describe an application of an encoder - decoder recurrent neural network with lstm units and attention to generating headlines from the text of news articles .",
        "furthermore , we study how the neural network decides which input words to pay attention to , and specifically we identify the function of the different neurons in a simplified attention mechanism .",
        "we demonstrate how driverseat can crowdstrap a convolutional neural network on the lane - detection task .",
        "using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real - world complexity .",
        "we relate this phenomenon with the instabilities of neural networks when they are used in an approximate dynamic programming setting .",
        "when evaluated on the challenging vqa dataset [ 2 ] , it shows comparable performance to many recent approaches using recurrent neural networks .",
        "we propose minimum risk training for end - to - end neural machine translation .",
        "experiments on chinese - english and english - french translation show that our approach achieves significant improvements over maximum likelihood estimation on a state - of - the - art neural machine translation system .",
        "given i - vectors as inputs , the authors proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on deep belief networks ( dbn ) and deep neural networks ( dnn ) to discriminatively model each target speaker .",
        "because it replaces entire pipelines of hand - engineered components with neural networks , end - to - end learning allows us to handle a diverse variety of speech including noisy environments , accents and different languages .",
        "the key components include a visual question generation ( vqg ) module and a visual question answering module , in which recurrent neural networks ( rnn ) and convolutional neural network ( cnn ) are used .",
        "for speech recognition , deep neural network ( dnn ) have significantly improved the recognition accuracy in most of benchmark datasets and application domains .",
        "the highway neural networks constantly outperformed their plain dnn counterparts , and the number of model parameters can be reduced significantly without sacrificing the recognition accuracy .",
        "current trends in cv clearly show a rise of neural network - based algorithms , which have recently broken many object detection and localization records .",
        "we extend two related , model - free algorithms for continuous control - - deterministic policy gradient and stochastic value gradient - - to solve partially observed domains using recurrent neural networks trained with backpropagation through time .",
        "by using this new algorithm we show that there are two ways of classification by a neural network , for a large dimension feature space , both of which are non - iterative and deterministic and we apply both these methods to a classical pattern recognition problem and present the results .",
        "it is expected these methods will now be widely used for the training of neural networks for deep learning not only because of their non - iterative and deterministic nature but also because of their efficiency and speed and will supercede other classification methods which are iterative in nature and rely on error minimization .",
        "training neural network language models over large vocabularies is still computationally very costly compared to count - based models such as kneser - ney .",
        "at the same time , neural language models are gaining popularity for many applications such as speech recognition and machine translation whose success depends on scalability .",
        "this work presents a general attention based convolutional neural network ( abcnn ) for modeling a pair of sentences .",
        "in this paper , we propose a deep convolutional neural network for active object recognition that simultaneously predicts the object label , and selects the next action to perform on the object with the aim of improving recognition performance .",
        "this paper explores the performance of fitted neural q iteration for reinforcement learning in several partially observable environments , using three recurrent neural network architectures : long short - term memory , gated recurrent unit and mut1 , a recurrent neural architecture evolved from a pool of several thousands candidate architectures .",
        "our evaluation demonstrates that our model yields 10 \\ % gain over a standard ir baseline , and 6 \\ % over standard neural network architectures ( including cnns and lstms ) trained analogously .",
        "convolutional neural networks demonstrated outstanding empirical results in computer vision and speech recognition tasks where labeled training data is abundant .",
        "we model the problem of inflection generation as a character sequence to sequence learning problem and present a variant of the neural encoder - decoder model for solving it .",
        "a number of frameworks have been developed to expedite the process of designing and training deep neural networks ( dnns ) , such as caffe , torch and theano .",
        "recent language models , especially those based on recurrent neural networks ( rnns ) , make it possible to generate natural language from a learned probability .",
        "deep neural networks have proved very successful in domains where large training sets are available , but when the number of training samples is small , their performance suffers from overfitting .",
        "empirical rademacher complexity is used to connect the generalization error of the neural network to spectral properties of the graph learned from the input data .",
        "it explains principles and implementations with details of restricted boltzmann machine , deep neural network , deep belief network , denoising autoencoder , deep boltzmann machine , deep canonical correlation analysis , and modal prediction model .",
        "among different types of deep neural networks , convolutional neural networks have been most extensively studied .",
        "due to the lack of training data and computing power in early days , it is hard to train a large high - capacity convolutional neural network without overfitting .",
        "recently , with the rapid growth of data size and the increasing power of graphics processor unit , many researchers have improved the convolutional neural networks and achieved state - of - the - art results on various tasks .",
        "in this paper , we provide a broad survey of the recent advances in convolutional neural networks .",
        "besides , we also introduce some applications of convolutional neural networks in computer vision .",
        "first , contextual and semantic information is extracted for each image by employing a convolutional neural networks approach .",
        "recently , the renewed prosperity neural networks has made many improvements in a variety of nlp tasks .",
        "in particular , the tree - based convolutional neural network ( tbcnn ) proposed in our previous work has achieved high performance in several sentence - level classification tasks .",
        "recurrent neural networks ( rnns ) have proven to be powerful models in problems involving sequential data .",
        "we propose a simplified model of attention which is applicable to feed - forward neural networks and demonstrate that it can solve some long - term memory problems ( specifically , those where temporal order doesn ' t matter ) .",
        "the recently released stanford natural language inference ( snli ) corpus has made it possible to develop and evaluate learning - centered methods such as deep neural networks for the nli task .",
        "in this paper , we propose a context - aware keyword spotting model employing a character - level recurrent neural network ( rnn ) for spoken term detection in continuous speech .",
        "experimental results show that the proposed keyword spotter significantly outperforms the deep neural network ( dnn ) and hidden markov model ( hmm ) based keyword - filler model even with less computations .",
        "sequence - to - sequence neural translation models learn semantic and syntactic relations between sentence pairs by optimizing the likelihood of the target given the source , i .",
        "we introduce an alternative objective function for neural mt that maximizes the mutual information between the source and target sentences , modeling the bi - directional dependency of sources and targets .",
        "applied to the wmt german / english and french / english tasks , both mechanisms offer a consistent performance boost on both standard lstm and attention - based neural mt architectures .",
        "the result is the best published performance for a single ( non - ensemble ) neural mt system , as well as the potential application of our diverse decoding algorithm to other nlp re - ranking tasks .",
        "however , we can train a neural network to address the problem if we restrict our attention to specific object categories ( in our case faces and chairs ) for which we can gather ample training data .",
        "using the neural encoder - decoder framework , we explore several combination methods and report up to + 4 .",
        "8 bleu increases on top of a very strong attention - based neural translation model .",
        "we present a novel end - to - end neural model to extract entities and relations between them .",
        "our recurrent neural network based model stacks bidirectional sequential lstm - rnns and bidirectional tree - structured lstm - rnns to capture both word sequence and dependency tree substructure information .",
        "we also show improvements over the state - of - the - art convolutional neural network based model on nominal relation classification ( semeval - 2010 task 8 ) , with 2 .",
        "we propose multi - way , multilingual neural machine translation .",
        "the proposed approach enables a single neural translation model to translate between multiple languages , with a number of parameters that grows only linearly with the number of languages .",
        "neural encoder - decoder models of machine translation have achieved impressive results , rivalling traditional translation models .",
        "in this paper we extend the attentional neural translation model to include structural biases from word based alignment models , including positional bias , markov conditioning , fertility and agreement over translation directions .",
        "we present a novel method to perform multi - class pattern classification with neural networks and test it on a challenging 3d hand gesture recognition problem .",
        "recurrent neural networks ( rnn ) have obtained excellent result in many natural language processing ( nlp ) tasks .",
        "we encode input sentences into vector representations using recurrent neural networks , and generate their logical forms by conditioning the output on the encoding vectors .",
        "recurrent neural network ( rnn ) and one of its specific architectures , long short - term memory ( lstm ) , have been widely used for sequence labeling .",
        "the model uses natural language strings to automatically assemble neural networks from a collection of composable modules .",
        "our approach , which we term a dynamic neural model network , achieves state - of - the - art results on benchmark datasets in both visual and structured domains .",
        "to tackle the issue , we propose two novel models using deep neural networks ( dnns ) to automatically learn effective patterns from categorical feature interactions and make predictions of users ' ad clicks .",
        "recently , recurrent neural networks ( rnns ) as powerful sequence models have re - emerged as a potential acoustic model for statistical parametric speech synthesis ( spss ) .",
        "although recent studies have demonstrated that lstms can achieve significantly better performance on spss than deep feed - forward neural networks , little is known about why .",
        "we propose a novel deep neural network architecture for speech recognition that explicitly employs knowledge of the background environmental noise within a deep neural network acoustic model .",
        "a deep neural network is used to predict the acoustic environment in which the system in being used .",
        "the discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model .",
        "we formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point - cloud , natural language , and manipulation trajectory data into a shared embedding space using a deep neural network .",
        "this work presents a broad study on the adaptation of neural network acoustic models by means of learning hidden unit contributions ( lhuc ) - - a method that linearly re - combines hidden units in a speaker - or environment - dependent manner using small amounts of unsupervised adaptation data .",
        "these include n - grams , justeson & amp ; katz pos tag filter , recurrent neural networks , and latent dirichlet allocation .",
        "neural machine translation has shown very promising results lately .",
        "we present asystem based on a global ranking objective function which uses a combinationof convolutional neural networks ( cnn ) and multi layer perceptrons ( mlp ) .",
        "nowadays , neural networks play an important role in the task of relation classification .",
        "by designing different neural architectures , researchers have improved the performance to a large extent , compared with traditional methods .",
        "however , existing neural networks for relation classification are usually of shallow architectures ( e .",
        ", one - layer convolution neural networks or recurrent networks ) .",
        "in this paper , we propose deep recurrent neural networks ( drnns ) to tackle this challenge .",
        "traditional neural networks assume vectorial inputs as the network is arranged as layers of single line of computing units called neurons .",
        "to address these issues , we propose matrix neural networks ( matnet ) , which takes matrices directly as inputs .",
        "each neuron senses summarised information through bilinear mapping from lower layer units in exactly the same way as the classic feed forward neural networks .",
        "image similarity is computed by a convolutional neural network and incorporated into a target - side translation memory retrieval model where descriptions of most similar images are used to rerank translation outputs .",
        "this work presents a new algorithm for training recurrent neural networks ( although ideas are applicable to feedforward networks as well ) .",
        "in the context of speech processing , a deep neural network ( dnn ) is an effective computational method to infer the probability of individual phonological classes from a short segment of speech signal .",
        "based on the assumption that there exists a neural network that efficiently represents a set of boolean functions between all binary inputs and outputs , we propose a process for developing and deploying neural networks whose weight parameters , bias terms , input , and intermediate hidden layer output signals , are all binary - valued , and require only basic bit logic for the feedforward pass .",
        "the proposed bitwise neural network ( bnn ) is especially suitable for resource - constrained environments , since it replaces either floating or fixed - point arithmetic with significantly more efficient bitwise operations .",
        "the algorithm employs a speech - to - character unidirectional recurrent neural network ( rnn ) , which is end - to - end trained with connectionist temporal classification ( ctc ) , and an rnn - based character - level language model ( lm ) .",
        "we specifically consider one form of deep networks widely used in computer vision - convolutional neural networks ( cnns ) .",
        "we present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions .",
        "convolutional neural networks ( cnns ) are currently state - of - the - art for various classification tasks , but are computationally expensive .",
        "the recurrent neural networks ( rnn ) can be used to solve the sequence to sequence problem , where both the input and the output have sequential structures .",
        "we present datagrad , a general back - propagation style training procedure for deep neural architectures that uses regularization of a deep jacobian - based penalty .",
        "more importantly , it unifies previous proposals for adversarial training of deep neural nets - - this list includes directly modifying the gradient , training on a mix of original and adversarial examples , using contractive penalties , and approximately optimizing constrained adversarial objective functions .",
        "in the last two years , there have been numerous papers that have looked into using deep neural networks to replace the acoustic model in traditional statistical parametric speech synthesis .",
        "in this paper , we investigate the use of recurrent neural networks as a potential postfilter for synthesis .",
        "speech recognition from visual - only recordings of a speaker ' s face , can be achieved with a processing pipeline based solely on neural networks , yielding significantly better accuracy than conventional methods .",
        "feed - forward and recurrent neural network layers ( namely long short - term memory ; lstm ) are stacked to form a single structure which is trained by back - propagating error gradients through all the layers .",
        "6 % using the end - to - end neural network - based solution ( 11 .",
        "inspired by recent successes of deep learning in computer vision , we propose a novel application of deep convolutional neural networks to facial expression recognition , in particular smile recognition .",
        "we propose a neural network architecture that utilizes both convolution and recurrent layers to efficiently encode character inputs .",
        "the multiple sets of token labels are then used as the targets of a multi - target deep neural network ( mdnn ) trained on low - level acoustic features .",
        "we call this iterative deep learning framework the multi - layered acoustic tokenizing deep neural network ( mat - dnn ) , which generates both high quality speech features for the track 1 of the challenge and acoustic tokens for the track 2 of the challenge .",
        "we achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks .",
        "previous work on this problem has proposed several techniques based on deep neural networks , typically involving either autoencoder - like networks with a reconstruction objective or paired feedforward networks with a batch - style correlation - based objective .",
        "we also explore a stochastic optimization procedure for minibatch correlation - based objectives and discuss the time / performance trade - offs for kernel - based and neural network - based implementations .",
        "second - order optimization methods such as natural gradient descent have the potential to speed up training of neural networks by correcting for the curvature of the loss function .",
        "recurrent neural networks ( rnn ) are known to produce state of the art results for language modelling , outperforming their traditional n - gram counterparts in many cases .",
        "second , we model a full trajectory of the agent using a recurrent neural network , where unexplained factors are modeled as ( additive ) input nodes .",
        "we propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers .",
        "we present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor - learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers .",
        "the traditional way is to use the convolutional neural network ( cnn ) to extract image features , followed by recurrent neural network ( rnn ) to generate sentences .",
        "in this paper , we present a new model that added memory cells to gate the feeding of image features to the deep neural network .",
        "the current paper proposes a novel dynamic neural network model , multiple spatio - temporal scales recurrent neural network ( mstrnn ) used for categorization of complex human action pattern in video image .",
        "the mstrnn has been developed by newly introducing recurrent connectivity to a prior - proposed model , multiple spatio - temporal scales neural network ( mstnn ) [ 1 ] such that the model can learn to extract latent spatio - temporal structures more effectively by developing adequate recurrent contextual dynamics .",
        "given the i - vectors , several classifiers are adopted for the language detection task including support vector machines ( svm ) , multi - class logistic regression ( mclr ) , probabilistic linear discriminant analysis ( plda ) and deep neural networks ( dnn ) .",
        "we obtain promising empirical results in multi - label classification problems and in attention - based neural networks for natural language inference .",
        "we introduce and compare different neural network based linear - chain crfs and we present experiments on two complex sequence classification and structured prediction tasks to support this claim .",
        "recurrent neural networks are increasing popular models for sequential learning .",
        "dropout has been witnessed with great success in training deep neural networks by independently zeroing out the outputs of neurons at random .",
        "we evaluate two different agents based on neural networks on the wikinav and provide the human performance .",
        "next , to address the more general case , where classifiers may strongly violate the conditional independence assumption , we propose to apply rbm - based deep neural net ( dnn ) .",
        "one - hot cnn ( convolutional neural network ) has been shown to be effective for text categorization in our previous work .",
        "representation learning is the foundation for the recent success of neural network models .",
        "however , the distributed representations generated by neural networks are far from ideal .",
        "these methods allow neural methods to learn representations which are easy to interpret and reuse , yet they incur little or no penalty to performance .",
        "in this work we explore recent advances in recurrent neural networks for large scale language modeling , a task central to language understanding .",
        "we perform an exhaustive study on techniques such as character convolutional neural networks or long - short term memory , on the one billion word benchmark .",
        "in this work we introduce a binarized deep neural network ( bdnn ) model .",
        "instead of computing distances in the image space , we compute distances between image features extracted by deep neural networks .",
        "moreover we are able to understand and describe the policies learned by dqns for three different atari2600 games and suggest ways to interpret , debug and optimize of deep neural networks in reinforcement learning .",
        "convolutional neural networks are sometimes trained using data augmentation to exploit this , but they are still required to learn the rotation equivariance properties from the data .",
        "we introduce four operations which can be inserted into neural network models as layers , and which can be combined to make these models partially equivariant to rotations .",
        "recurrent neural networks ( rnns ) have proven to be very successful for modelling sequences of data in many areas of machine learning .",
        "we compared different types of rnns that we developed for this work , a model based on a feedforward neural network and a logistic regression model .",
        "deep learning is increasingly used in several machine learning tasks as deep neural networks ( dnns ) frequently outperform other techniques .",
        "deep artificial neural networks have made remarkable progress in different tasks in the field of computer vision .",
        "we focus on convolutional neural networks ( cnn ) as the state - of - the - art models in object recognition and classification ; investigate this problem in more detail , and hypothesize that training cnn models suffer from unstructured loss minimization .",
        "we introduce the value iteration network : a fully differentiable neural network with a ` planning module ' embedded within .",
        "key to our approach is a novel differentiable approximation of the value - iteration algorithm , which can be represented as a convolutional neural network , and trained end - to - end using standard backpropagation .",
        "extreme learning machine ( elm ) classification algorithm is a relatively new learning method built on feed - forward neural - network .",
        "attention mechanisms in neural networks have proved useful for problems in which the input and output do not have fixed dimension .",
        "we introduce an attentional neural network that employs convolution on the input tokens to detect local time - invariant and long - range topical attention features in a context - dependent way .",
        "we demonstrate our convolutional attention neural network ' s performance on 10 popular java projects showing that it achieves better performance compared to previous attentional mechanisms .",
        "in this paper , we propose and investigate a novel memory architecture for neural networks called hierarchical attentive memory ( ham ) .",
        "the convolutional neural network ( convnet or cnn ) is a powerful discriminative learning machine .",
        "in the context of pair - wise ranking or classification with neural networks , ap enables the pooling layer to be aware of the current input pair , in a way that information from the two input items can directly influence the computation of each other ' s representations .",
        "our two - way attention mechanism is a general framework independent of the underlying representation learning , and it has been applied to both convolutional neural networks ( cnns ) and recurrent neural networks ( rnns ) in our studies .",
        "we study the adaptation of convolutional neural networks to the complex temporal radio signal domain .",
        "we show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task .",
        "deep gaussian processes ( dgps ) are multi - layer hierarchical generalisations of gaussian processes ( gps ) and are formally equivalent to neural networks with multiple , infinitely wide hidden layers .",
        "we evaluate the new method for non - linear regression on eleven real - world datasets , showing that it always outperforms gp regression and is almost always better than state - of - the - art deterministic and sampling - based approximate inference methods for bayesian neural networks .",
        "as a by - product , this work provides a comprehensive analysis of six approximate bayesian methods for training neural networks .",
        "we start with the best - performing approaches from prior work , based on tandem models and segmental conditional random fields ( scrfs ) , with features based on deep neural network ( dnn ) classifiers of letters and phonological features .",
        "we come up with a neural network framework , named hierarchical attention - based convolutional neural network ( habcnn ) , to address this task without any manually designed features .",
        "the recent success of deep neural networks relies on massive amounts of labeled data .",
        "using pareto speed - accuracy curves , we show that cte can provide better accuracy than convolutional neural networks ( cnn ) for a certain range of classification time constraints , or alternatively provide similar error rates with 5 - 200x speedup .",
        "recurrent neural network ( rnn ) has been broadly applied to natural language processing ( nlp ) problems .",
        "this kind of neural network is designed for modeling sequential data and has been testified to be quite efficient in sequential tagging tasks .",
        "we show experimentally that energy - based neural networks with several hidden layers can be trained at discriminative tasks by using iterative inference and an stdp - like learning rule .",
        "the main result of this paper is that we can train neural networks with 1 , 2 and 3 hidden layers on the permutation - invariant mnist task and get the training error down to 0 .",
        "in such cases , neural network language models ( nnlms ) , generally outperform the traditional non - parametric n - gram models .",
        "deep generative models parameterized by neural networks have recently achieved state - of - the - art performance in unsupervised and semi - supervised learning .",
        "we develop a general duality between neural networks and compositional kernels , striving towards a better understanding of deep learning .",
        "our dual view also reveals a pragmatic and aesthetic perspective of neural networks and underscores their expressive power .",
        "it has been generally believed that training deep neural networks is hard with saturated activation functions , including sigmoid and tanh .",
        "we propose to train bi - directional neural network language model ( nnlm ) with noise contrastive estimation ( nce ) .",
        "in this paper , we present clstm ( contextual lstm ) , an extension of the recurrent neural network lstm ( long - short term memory ) model , where we incorporate contextual features ( e .",
        "inspired by the success of convolutional neural network in image recognition , where neurons can capture many complicated patterns based on the extracted elementary visual patterns such as oriented edges and corners , we propose to model text matching as the problem of image recognition .",
        "then a convolutional neural network is utilized to capture rich matching patterns in a layer - by - layer way .",
        "we propose two novel techniques - - - stacking bottleneck features and minimum trajectory error training criterion - - - to improve the performance of deep neural network ( dnn ) - based speech synthesis .",
        "the subjective results show that combining the two techniques leads to significantly more natural synthetic speech than from conventional dnn or long short - term memory ( lstm ) recurrent neural network ( rnn ) systems .",
        "in this work , we propose a semi - supervised method for short text clustering , where we represent texts as distributed vectors with neural networks , and use a small amount of labeled data to specify our intention for clustering .",
        "we design a novel objective to combine the representation learning process and the k - means clustering process together , and optimize the objective with both labeled data and unlabeled data iteratively until convergence through three steps : ( 1 ) assign each short text to its nearest centroid based on its representation from the current neural networks ; ( 2 ) re - estimate the cluster centroids based on cluster assignments from step ( 1 ) ; ( 3 ) update neural networks according to the objective by keeping centroids and cluster assignments fixed .",
        "we introduce a neural network architecture and a learning algorithm to produce factorized symbolic representations .",
        "as neural networks are typically over - complete , it ' s easy to show the existence of vast continuous regions through weight space with equal loss .",
        "in this paper , we build on recent work empirically characterizing the error surfaces of neural networks .",
        "while it ' s trivial to show that neural network error surfaces are globally non - convex , we show that error surfaces are also locally non - convex , even after breaking symmetry with a random initialization and also after partial training .",
        "recent research on deep neural networks has focused primarily on improving accuracy .",
        "recently , the deep neural network ( derived from the artificial neural network ) has attracted many researchers ' attention by its outstanding performance .",
        "in order to improve the deep neural network , many trials have been made by refining the network structure or training strategy .",
        "unlike those trials , in this paper , we focused on the basic propagation function of the artificial neural network and proposed the binarized deep neural network .",
        "new language modeling methods based on neural networks alleviate the curse of dimensionality and usually outperform conventional n - gram methods .",
        "in this paper , we present a novel setup of a neural network language model ( nnlm ) and apply it to a database of text samples from different authors .",
        "we introduce group equivariant convolutional neural networks ( g - cnns ) , a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries .",
        "in this work , we investigate the robustness of the mention detection systems , one of the fundamental tasks in information extraction , via recurrent neural networks ( rnns ) .",
        "we introduce recurrent neural network grammars , probabilistic models of sentences with explicit phrase structure .",
        "we present weight normalization : a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction .",
        "recurrent neural networks ( rnn ) are capable of learning to encode and exploit activation history over an arbitrary timescale .",
        "the increasing complexity of deep neural networks ( dnns ) has made it challenging to exploit existing large - scale data process pipelines for handling massive data and parameters involved in dnn training .",
        "in this paper , we systematically analyse the connecting architectures of recurrent neural networks ( rnns ) .",
        "second , we propose three architecture complexity measures of rnns : ( a ) the recurrent depth , which captures the rnn ' s over - time nonlinear complexity , ( b ) the feedforward depth , which captures the local input - output nonlinearity ( similar to the \" depth \" in feedforward neural networks ( fnns ) ) , and ( c ) the recurrent skip coefficient which captures how rapidly the information propagates over time .",
        "here , we apply this formalism for the first time to multilayer feedforward neural networks .",
        "in experiments on the mnist benchmark classification task for handwritten digits , we show that such information - theoretic regularization successfully prevents overfitting across different architectures and attains state - of - the - art results for both ordinary and convolutional neural networks .",
        "in this paper , we propose the neural knowledge dna , a framework that tailors the ideas underlying the success of neural networks to the scope of knowledge representation .",
        "the proposed neural knowledge dna is designed to support discovering , storing , reusing , improving , and sharing knowledge among machines and organisation .",
        "as the dna produces phenotypes , the neural knowledge dna carries information and knowledge via its four essential elements , namely , networks , experiences , states , and actions .",
        "recently , neural turing machine and memory networks have shown that adding an external memory can greatly ameliorate a traditional recurrent neural network ' s tendency to forget after a long period of time .",
        "an lstm controller performs read and write via specialized structures called read and write heads , following the design of neural turing machine .",
        "for this reason , we name this new model the lie access neural turing machine , or lantm .",
        "convolutional neural networks with rectified linear activation and max or average pooling , are the cornerstone of modern deep learning .",
        "we study the segmental recurrent neural network for end - to - end acoustic modelling .",
        "this model connects the segmental conditional random field ( crf ) with a recurrent neural network ( rnn ) used for feature extraction .",
        "we suggest a compositional vector representation of parse trees that relies on a recursive combination of recurrent - neural network encoders .",
        "common activation functions used in neural networks can yield to training difficulties due to the saturation behavior of the activation function , which may hide dependencies which are not visible to first order ( using only gradients ) .",
        "recursive neural networks ( rnn ) and their recently proposed extension recursive long short term memory networks ( rlstm ) are models that compute representations for sentences , by recursively combining word embeddings according to an externally provided parse tree .",
        "to address the former challenge , we present an algorithm capable of learning arbitrary nonlinear cost functions , such as neural networks , without meticulous feature engineering .",
        "model - free reinforcement learning has been successfully applied to a range of challenging problems , and has recently been extended to handle large neural network policies and value functions .",
        "new state - of - the - art word segmentation systems use neural models to learn representations for predicting word boundaries .",
        "this is all the more surprising that neural networks are able to discover latent variables in large and heterogeneous datasets .",
        "in this paper , we introduce a collaborative filtering neural network architecture aka cfn which computes a non - linear matrix factorization from sparse rating inputs and side information .",
        "we provide an implementation of the algorithm as a reusable plugin for torch , a popular neural network framework .",
        "neural machine translation ( mt ) has reached state - of - the - art results .",
        "however , one of the main challenges that neural mt still faces is dealing with very large vocabularies and morphologically rich languages .",
        "in this paper , we propose a neural mt system using character - based embeddings in combination with convolutional and highway layers to replace the standard lookup - based word representations .",
        "the resulting unlimited - vocabulary and affix aware source word embeddings are tested in a state - of - the - art neural mt based on an attention - based bidirectional recurrent neural network .",
        "however the number of unknowns at the output of the translation network is dramatically reduced ( by a relative 66 % ) with a significant overall improvement over both neural and phrase - based baselines .",
        "in this paper we examine the use of long short - term memory recurrent neural networks ( lstms ) for the purpose of generating levels trained from a corpus of super mario brothers levels .",
        "we first present a novel neural network based relation extractor to retrieve the candidate answers from freebase , and then develop a refinement model to validate answers using wikipedia .",
        "we introduce a novel , simple convolution neural network ( cnn ) architecture - multi - group norm constraint cnn ( mgnc - cnn ) that capitalizes on multiple sets of word embeddings for sentence classification .",
        "while classical methods typically derive gait signatures from sequences of binary silhouettes , in this work we explore the use of convolutional neural networks ( cnn ) for learning high - level descriptors from low - level motion features ( i .",
        "recent advances in convolutional neural networks have considered model complexity and hardware efficiency to enable deployment onto embedded systems and mobile devices .",
        "when applied to leduc poker , neural fictitious self - play ( nfsp ) approached a nash equilibrium , whereas common reinforcement learning methods diverged .",
        "the emergence of collective dynamics in neural networks is a mechanism of the animal and human brain for information processing .",
        "in this paper , we propose a procedure to train multi - domain , recurrent neural network - based ( rnn ) language generators via multiple adaptation steps .",
        "this paper investigates the connections between two state of the art classifiers : decision forests ( dfs , including decision jungles ) and convolutional neural networks ( cnns ) .",
        "in this paper , we introduce two new neural architectures - - - one based on bidirectional lstms and conditional random fields , and the other that constructs and labels segments using a transition - based approach inspired by shift - reduce parsers .",
        "neural network architectures with memory and attention mechanisms exhibit certain reasoning capabilities required for question answering .",
        "we present in this paper a systematic study on how to morph a well - trained neural network to a new one so that its network function can be completely preserved .",
        "to meet this requirement , we first introduce the network morphism equations , and then develop novel morphing algorithms for all these morphing types for both classic and convolutional neural networks .",
        "experimental results on benchmark datasets and typical neural networks demonstrate the effectiveness of the proposed network morphism scheme .",
        "to learn hand - eye coordination for grasping , we trained a large convolutional neural network to predict the probability that task - space motion of the gripper will result in successful grasps , using only monocular camera images and independently of camera calibration or the current robot pose .",
        "we propose a convolutional neural network ( cnn ) based detector for this task .",
        "to exploit the combination of different discourse corpora , we design related discourse classification tasks specific to a corpus , and propose a novel convolutional neural network embedded multi - task learning system to synthesize these tasks by learning both unique and shared representations for each task .",
        "deep neural networks are capable of modelling highly non - linear functions by capturing different levels of abstraction of data hierarchically .",
        "in contrast to that , during the \" night \" phase the stored information is been transferred to the supercomputing system to update the realistic neural network : emotional and behavioral strategies .",
        "deep learning consists in training neural networks to perform computations that sequentially unfold in many steps over a time dimension or an intrinsic depth dimension .",
        "when a convolutional neural network is used for on - the - fly evaluation of continuously updating time - sequences , many redundant convolution operations are performed .",
        "we discuss some modifications needed in order to get training with exploration to work well for a probabilistic neural - network .",
        "recent approaches based on artificial neural networks ( anns ) have shown promising results for short - text classification .",
        "in this work , we present a model based on recurrent neural networks and convolutional neural networks that incorporates the preceding short texts .",
        "inspired by this , we propose a neural recognizer for implicit discourse relation analysis , which builds upon a semantic memory that stores knowledge in a distributed fashion .",
        "using the surface and semantic representations as input , semder finally predicts implicit discourse relations via a neural recognizer .",
        "in this paper , instead , we explore generative models and propose a variational neural discourse relation recognizer .",
        "in order to perform efficient inference and learning , we introduce a neural discourse relation model to approximate the posterior of the latent variable , and employ this approximated posterior to optimize a reparameterized variational lower bound .",
        "we use deep neural networks to address both tasks , quantitatively and qualitatively measure the results in a variety of novel manners , and present a thorough investigation of the weaknesses and strengths of the approach .",
        "convolutional neural networks have been shown to develop internal representations , which correspond closely to semantically meaningful objects and parts , although trained solely on class labels .",
        "recently , several works in the field of natural language processing suggested to learn a latent representation of words using neural embedding algorithms .",
        "in this paper , we show that item - based cf can be cast in the same framework of neural word embedding .",
        "the system is flexible and can be used to express a wide variety of algorithms , including training and inference algorithms for deep neural network models , and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields , including speech recognition , computer vision , robotics , information retrieval , natural language processing , geographic information extraction , and computational drug discovery .",
        "we propose mvcnn , a convolution neural network ( cnn ) architecture for sentence classification .",
        "deep neural networks ( dnn ) have shown unprecedented success in various computer vision applications such as image classification and object detection .",
        "this paper presents a novel approach to recurrent neural network ( rnn ) regularization .",
        "many deep convolutional neural networks ( cnn ) make incorrect predictions on adversarial samples obtained by imperceptible perturbations of clean samples .",
        "we propose a convolutional neural network which splits the input sentence into three parts according to the relation arguments and compare it to state - of - the - art and traditional approaches of relation classification .",
        "recently , convolutional neural networks ( cnns ) have been used as a powerful tool to solve many problems of machine learning and computer vision .",
        "in this paper , we aim to provide insight on the property of convolutional neural networks , as well as a generic method to improve the performance of many cnn architectures .",
        "in this paper , we present a neural aggregation network ( nan ) for video face recognition .",
        "the neural aggregation module is composed of two content based attention blocks which is driven by a memory storing all the features extracted from the face video through the feature embedding module .",
        "tree - structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences .",
        "we address these issues by introducing the stack - augmented parser - interpreter neural network ( spinn ) , which combines parsing and interpretation within a single tree - sequence hybrid model by integrating tree - structured sentence interpretation into the linear sequential structure of a shift - reduce parser .",
        "we introduce a globally normalized transition - based neural network model that achieves state - of - the - art part - of - speech tagging , dependency parsing and sentence compression results .",
        "our model is a simple feed - forward neural network that operates on a task - specific transition system , yet achieves comparable or better accuracies than recurrent models .",
        "in this paper we propose a technique for domain adaptation in stacked autoencoder ( sae ) based deep neural networks ( dnn ) performed in two stages : ( i ) unsupervised weight adaptation using systematic dropouts in mini - batch training , ( ii ) supervised fine - tuning with limited number of labeled samples in target domain .",
        "most of the existing neural machine translation ( nmt ) models focus on the conversion of sequential data and do not directly take syntax into consideration .",
        "we suggest an improved path - based algorithm , in which the dependency paths are encoded using a recurrent neural network , and achieve results comparable to distributional methods .",
        "in computer vision , convolutional neural networks ( cnns ) have recently achieved new levels of performance for several inverse problems where rgb pixel appearance is mapped to attributes such as positions , normals or reflectance .",
        "it is particularly important to neural networks because neural models are very likely to be overfitting .",
        "in some fields like image processing , many studies have shown the effectiveness of neural network - based transfer learning .",
        "for neural nlp , however , existing studies have only casually applied transfer learning , and conclusions are inconsistent .",
        "in this paper , we conduct a series of empirical studies and provide an illuminating picture on the transferability of neural networks in nlp .",
        "we augment procedural models with neural networks : these networks control how the model makes random choices based on what output it has generated thus far .",
        "we call such a model a neurally - guided procedural model .",
        "given a desired quality threshold , neurally - guided models can generate satisfactory results up to 10x faster than unguided models .",
        "the existing machine translation systems , whether phrase - based or neural , have relied almost exclusively on word - level modelling with explicit segmentation .",
        "in this paper , we ask a fundamental question : can neural machine translation generate a character sequence without any explicit segmentation ?",
        "furthermore , the ensembles of neural models with a character - level decoder outperform the state - of - the - art non - neural machine translation systems on en - cs , en - de and en - fi and perform comparably on en - ru .",
        "we present persona - based models for handling the issue of speaker consistency in neural response generation .",
        "we present a deep hierarchical recurrent neural network for sequence tagging .",
        "combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce unpredictability of the neural models .",
        "we propose a general framework capable of enhancing various types of neural networks ( e .",
        "specifically , we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks .",
        "we propose a novel algorithm that allows us to blend and select a subset of the most feasible demonstrations to learn to imitate on the hardware , which we use with an extension of the guided policy search framework to use multiple demonstrations to learn generalizable neural network policies .",
        "in this paper , we incorporate copying into neural network - based seq2seq learning and propose a new model called copynet with encoder - decoder structure .",
        "in this paper we present architectures based on deep neural nets for gesture recognition in videos , which are invariant to local scaling .",
        "we provide superior results over known methods , including recent reported approaches based on neural nets .",
        "in this paper , we propose a scalable bayesian neural word embedding algorithm that can be beneficial to general item similarity tasks as well .",
        "we propose information theoretic - learning ( itl ) divergence measures for variational regularization of neural networks .",
        "in this paper , we propose a novel joint model that integrates recursive neural networks and conditional random fields into a unified framework for aspect - based sentiment analysis .",
        "we present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions .",
        "in this paper we present the 30m factoid question - answer corpus , an enormous question - answer pair corpus produced by applying a novel neural network architecture on the knowledge base freebase to transduce facts into natural language questions .",
        "we present a new action recognition deep neural network which adaptively learns the best action velocities in addition to the classification .",
        "while deep neural networks have reached maturity for image understanding tasks , we are still exploring network topologies and features to handle the richer environment of video clips .",
        "in this paper , we present wsd algorithms which use neural network language models to achieve state - of - the - art precision .",
        "we apply a general recurrent neural network ( rnn ) encoder framework to community question answering ( cqa ) tasks .",
        "further improvements are observed when we extend the rnn encoders with a neural attention mechanism that encourages reasoning over entire sequences .",
        "developing intelligent systems involves artificial intelligence approaches including artificial neural networks .",
        "here , we present a tutorial of deep neural networks ( dnns ) , and some insights about the origin of the term \" deep \" ; references to deep learning are also given .",
        "in this work we propose a data - driven approach based on neural networks and continuous sentence features .",
        "this system has the capability to process key machine learning algorithms such as deep neural network , autoencoder , and k - means clustering .",
        "memristor crossbars are utilized to provide low power high throughput execution of neural networks .",
        "defe can be viewed as a deep ensemble learning scheme that trains a strongly diverse set of neural feature learners without explicitly encouraging diversity and penalizing correlations .",
        "this is achieved by adopting an implicit neural controller ( not involved in feedforward compuation ) that directly controls and distributes gradient flows from higher level deep prediction network .",
        "defe makes the ensembles ' deep ' in the sense that it allows deep post - process of these features that tries to learn to select and abstract the ensemble of neural feature learners .",
        "in comparison of the classic deep neural network , defe shows a state - of - the - art performance : the error rate has decreased by about 37 \\ % , the accuracy has broken through 90",
        "the results reveal that neural embedding based document representations work better on this analogy task than conventional methods , and we provide some preliminary explanations over these observations .",
        "recently , various neural representation learning models such as wsabie and its variants show promising performance , mainly due to compact feature representations learned in a semantic space .",
        "in this work , we propose a neural feedback relevance model for learning tag representations with weighted feature representations .",
        "in this paper , we propose a new deep learning approach , called neural association model ( nam ) , for probabilistic reasoning in artificial intelligence .",
        "we propose to use neural networks to model association between any two events in a domain .",
        "neural networks take one event as input and compute a conditional probability of the other event to model how likely these two events are associated .",
        "in this work , as two case studies , we have investigated two nam structures , namely deep neural networks ( dnns ) and relation modulated neural nets ( rmnns ) , on several probabilistic reasoning tasks in ai , including recognizing textual entailment , triple classification in multirelational knowledge bases and common - sense reasoning .",
        "this paper introduces a neural model for concept - to - text generation that scales to large , rich domains .",
        "our model builds upon recent work on conditional neural language model for text genera - tion .",
        "our neural model significantly out - performs a classical kneser - ney language model adapted to this task by nearly 15 bleu .",
        "considering that recurrent neural networks ( rnns ) with long short - term memory ( lstm ) can learn feature representations and model long - term temporal dependencies automatically , we propose an end - to - end fully connected deep lstm network for skeleton based action recognition .",
        "we study the problem of compressing recurrent neural networks ( rnns ) .",
        "we propose a novel way to deal with the rare and unseen words for the neural network models with attention .",
        "using our proposed model , we observe improvements in two tasks , neural machine translation on the europarl english to french parallel corpora and text summarization on the gigaword dataset .",
        "the long short term memory recurrent neural network ( lstm - rnn ) is employed as the main classification architecture .",
        "sparseness is a useful regularizer for learning in a wide range of applications , in particular in neural networks .",
        "in this paper , we provide a multi - class schema , an annotated dataset , and supervised classifiers based on convolutional neural network ( cnn ) and other models for the task of classifying discussion topics .",
        "this paper introduces the visually informed embedding of word ( view ) , a continuous vector representation for a word extracted from a deep neural model trained using the microsoft coco data set to forecast the spatial arrangements between visual objects , given a textual description .",
        "we achieve this by performing probabilistic inference using a recurrent neural network that attends to scene elements and processes them one at a time .",
        ", decomposing 3d images with various numbers of objects in a single forward pass of a neural network .",
        "deep neural networks ( dnns ) are powerful types of artificial neural networks ( anns ) that use several hidden layers .",
        "we tackle the dataset with a neural approach , harnessing simple neural networks arranged in a parallel hierarchy .",
        "when trained with a methodology designed to help cope with limited training data , our parallel - hierarchical model sets a new state of the art for { \\ it mctest } , outperforming previous feature - engineered approaches slightly and previous neural approaches by a significant margin ( over 15 \\ % absolute ) .",
        "we propose a reparameterization of lstm that brings the benefits of batch normalization to recurrent neural networks .",
        "we report an implementation of a clinical information extraction tool that leverages deep neural network to annotate event spans and their attributes from raw clinical notes and pathology reports .",
        "then we hire temporal ( 1d ) convolutional neural network to learn hidden feature representations .",
        "neural network based approaches for sentence relation modeling automatically generate hidden matching features from raw sentence pairs .",
        "to address this challenge , we propose a new deep neural network architecture that jointly leverage pre - trained word embedding and auxiliary character embedding to learn sentence meanings .",
        "recently recurrent neural networks ( rnn ) has been very successful in handling sequence data .",
        "we present a deep neural network ( dnn ) acoustic model including parametrised and differentiable pooling operators .",
        "on the other hand , word and phrase - based machine translation methods are not designed to cope with orthographic errors , and have recently been outpaced by neural models .",
        "motivated by these issues , we present a neural network - based approach to language correction .",
        "the core component of our method is an encoder - decoder recurrent neural network with an attention mechanism .",
        "recurrent neural network architectures combining with attention mechanism , or neural attention model , have shown promising performance recently for the tasks including speech recognition , image caption generation , visual question answering and machine translation .",
        "in this paper , neural attention model is applied on two sequence classification tasks , dialogue act detection and key term extraction .",
        "the efficiency and differentiability of the model make it especially well - suited for integration with convolutional neural networks , even allowing it to be used in interior , feature - generating layers and stacked multiple times .",
        "given this new evaluation metric , we report more than 100 % improvement across distortion levels over current state of the art recurrent neural network based language models .",
        "in this study we address the problem of training a neuralnetwork for language identification using both labeled and unlabeled speech samples in the form of i - vectors .",
        "we propose a neural network architecture that can also handle out - of - set languages .",
        "inspired by the recent success of methods that employ shape priors to achieve robust 3d reconstructions , we propose a novel recurrent neural network architecture that we call the 3d recurrent reconstruction neural network ( 3d - r2n2 ) .",
        "like previous learned approaches to language generation , our model uses a simple feature - driven architecture ( here a pair of neural \" listener \" and \" speaker \" models ) to ground language in the world .",
        "a way for dealing with this problem is through neuroevolution , a method which trains artificial neural networks using evolutionary algorithms .",
        "we present a model that uses convolutional neural networks to capture semantic correspondence between a mention ' s context and a proposed target entity .",
        "nearly all previous work in neural machine translation ( nmt ) has used quite restricted vocabularies , perhaps with a subsequent method to patch in unknown words .",
        "our character - level recurrent neural networks compute source word representations and recover unknown target words when needed .",
        "our model builds on a deep convolutional neural network ( cnn ) and two separate lstm networks .",
        "in this paper we present an approach to polyphonic sound event detection in real life recordings based on bi - directional long short term memory ( blstm ) recurrent neural networks ( rnns ) .",
        "in this paper , we propose convolutional neural networks for learning an optimal representation of question and answer sentences .",
        "we address these two problems jointly by engaging the low - dimensional semantic representation capabilities of the sequence to sequence neural translation models .",
        "to enable joint multi - task learning for multilingual neural translation of morphologically rich languages we replace the attention mechanism with the sliding - window mechanism and operate the sequence to sequence neural translation model on the character - level rather than on the word - level .",
        "the story segmentation and storyline clustering problem is tackled by examining the low - dimensional vectors produced as a side - product of the neural translation process .",
        "4 % gain when ap - plied to outputs of two nondeterministic amr parsers : a camr + wrapper parser and a novel character - level neural translation amr parser .",
        "for amr parsing task the character - level neural translation attains surprising 7 % gain over the carefully optimized word - level neural translation .",
        "residual learning has recently surfaced as an effective means of constructing very deep neural networks for object recognition .",
        "based on the alternating direction method of multipliers ( admm ) , we formulate the original convex minimization problem as a feed - forward neural network , named \\ textit { deep $ \\ ell _ \\ infty $ encoder } , by introducing the novel bounded linear unit ( blu ) neuron and modeling the lagrange multipliers as network biases .",
        "specifically , we integrate both a neural language model and distributional semantics trained on large text corpora into a recent lstm - based architecture for video description .",
        "recently , neural headline generation models have been proposed to take advantage of well - trained neural networks in learning sentence representations and mapping sequence to sequence .",
        "nevertheless , traditional neural network encoder utilizes maximum likelihood estimation for parameter optimization , which essentially constraints the expected training objective within word level instead of sentence level .",
        "as recurrent neural networks become larger and deeper , training times for single networks are rising into weeks or even months .",
        "different from conventional topic models that largely ignore the sequential order of words or their topic coherence , slrtm gives full characterization to them by using a recurrent neural networks ( rnn ) based framework .",
        "the encoder - decoder framework for neural machine translation ( nmt ) has been shown effective in large data scenarios , but is much less effective for low - resource languages .",
        "we compare a family of irt - based proficiency estimation methods with a recently proposed approach using recurrent neural networks ( rnns ) on two publicly available and one proprietary data set , evaluating each model according to how well a student ' s future response is predicted given previous responses .",
        "the success of deep neural networks is mostly due their ability to learn meaningful features from the data .",
        "features learned in the hidden layers of deep neural networks trained in computer vision tasks have been shown to be similar to mid - level vision features .",
        "here we assume that such interface for ai emerges from an adequate neural - symbolic integration .",
        "for the train of such neural networks we changed the levenderg - marquardt algorithm , restricting the knowledge dissemination in the network structure using soft crystallization .",
        "this procedure reduces neural network plasticity without drastically damaging the learning performance , allowing the emergence of symbolic patterns .",
        "this makes the descriptive power of produced neural networks similar to the descriptive power of { \\ l } ukasiewicz logic language , reducing the information lost on translation between symbolic and connection",
        "we compare these systems with recent recurrent neural net models that directly operate on raw tokens to predict sentences , finding the latter to be roughly comparable to the former in terms of predicting missing events in documents .",
        "we instead propose to use recurrent neural networks ( rnns ) to learn latent , global representations of entity clusters directly from their mentions .",
        "we trained binarized neural networks ( bnns ) on the high resolution imagenet lsvrc - 2102 dataset classification task and achieved a good performance .",
        "rather than training the network node connections and weights via backpropagation in traditional recurrent neural networks , reservoirs instead have fixed connections and weights among the ` hidden layer ' nodes , and traditionally only the weights to the output layer of neurons are trained using linear regression .",
        "for that we trained a neural networks using the levenderg - marquardt algorithm , where we restricted the knowledge dissemination in the network structure .",
        "this procedure reduces neural network plasticity without drastically damaging the learning performance , thus making the descriptive power of produced neural networks similar to the descriptive power of { \\ l } ukasiewicz logic language and simplifying the translation between symbolic and connectionist structures .",
        "we introduce a new approach for disfluency detection using a bidirectional long - short term memory neural network ( blstm ) .",
        "the combination of convolutional and recurrent neural networks in these models has proven to outperform the previous state of the art , obtaining more accurate video descriptions .",
        "first , producing richer image representations by combining object and location information from convolutional neural networks and second , introducing bidirectional recurrent neural networks for capturing both forward and backward temporal relationships in the input frames .",
        "in this paper , we describe a novel deep convolutional neural networks ( cnn ) based approach called contextual deep cnn that can jointly exploit spatial and spectral features for hyperspectral image classification .",
        "we discuss relations between residual networks ( resnet ) , recurrent neural networks ( rnns ) and the primate visual cortex .",
        "we introduce a novel type of artificial neural network structure and training procedure that results in networks that are provably , quantitatively more robust to adversarial samples than classical , end - to - end trained classifiers .",
        "specifically , deep recurrent neural networks were used for improving joint positions and velocities of kinect skeleton , and three methods were proposed to integrate the refined positions and velocities for further enhancement .",
        "more specifically , the generation is two - phase : ( 1 ) dp position detection , which is modeled as a sequential labelling task with recurrent neural networks ; and ( 2 ) dp prediction , which employs a multilayer perceptron with rich features .",
        "in this paper , we propose a modification of the popular and efficient multi - dimensional long short - term memory recurrent neural networks ( mdlstm - rnns ) to enable end - to - end processing of handwritten paragraphs .",
        "in the proposed model , a neural network performs a kind of implicit line segmentation by computing attention weights on the image representation .",
        "we train a number of neural networks to play games bowling , breakout and seaquest using information stored in the memory of a video game console atari 2600 .",
        "we consider four models of neural networks which differ in size and architecture : two networks which use only information contained in the ram and two mixed networks which use both information in the ram and information from the screen .",
        "we experiment shrinking deep learning with recall ( sdlr ) using deep neural network ( dnn ) , deep belief network ( dbn ) and convolution neural network ( cnn ) on 4 data sets .",
        "the iterations of many sparse estimation algorithms are comprised of a fixed linear filter cascaded with a thresholding nonlinearity , which collectively resemble a typical neural network layer .",
        "we illustrate this general approach with an application to dialogue where we integrate a neural chat model , good at conversational aspects , with a neural question - answering model , good at retrieving precise information from a knowledge - base , and show how the integration combines the strengths of the independent components .",
        "the purported \" black box \" nature of neural networks is a barrier to adoption in applications where interpretability is essential .",
        "here we present deeplift ( learning important features ) , an efficient and effective method for computing importance scores in a neural network .",
        "with the growing importance of large network models and enormous training datasets , gpus have become increasingly necessary to train neural networks .",
        "the recent advances in deep neural networks have led to effective vision - based reinforcement learning methods that have been employed to obtain human - level controllers in atari 2600 games from pixel data .",
        "using convolutional deep neural networks with q - learning and experience replay , for both scenarios , we were able to train competent bots , which exhibit human - like behaviors .",
        "in this paper , we propose a neural recovery machine ( nrm ) to model and recover dps in chinese , so that to avoid the non - trivial feature engineering process .",
        "an asynchronous and momentum variant of the easgd method is applied to train deep convolutional neural networks for image classification on the cifar and imagenet datasets .",
        "we present neural autoregressive distribution estimation ( nade ) models , which are neu - ral network architectures applied to the problem of unsupervised distribution and density esitmation .",
        "the recent breakthrough made by alphago , which incorporates convolutional neural networks with bandit algorithms in mcts , also highlights the necessity of bandit algorithms in mcts .",
        "we then suggest two frameworks for solving multiple - instance learning , one based on neural networks , and the second on support vector machines .",
        "while the recent successes of many computer vision related tasks are due to the adoption of convolutional neural networks ( cnns ) , visual emotion analysis has not achieved the same level of success .",
        "the implemented framework supports major deep learning architectures such as multilayer perceptron networks ( mlp ) , convolutional neural networks ( cnn ) and recurrent neural networks ( rnn ) .",
        "taking inspiration from the image classification domain we propose a deep convolutional neural network architecture , must - cnn , to predict protein properties .",
        "in this paper , we enhance the attention - based neural machine translation by adding an explicit coverage embedding model to alleviate issues of repeating and dropping translations in nmt .",
        "in order to capture rich language phenomena , neural machine translation models have to use a large vocabulary size , which requires high computing time and large memory usage .",
        "experimental results on the large - scale english - to - french task show that our method achieves better translation performance by 1 bleu point over the large vocabulary neural machine translation system of jean et al .",
        "this cognitive model is based on multiple time - scale recurrent neural networks ( mtrnn ) .",
        "a novel recurrent neural network called recurrent neural network with parametric bias units ( rnnpb ) runs in three modes , constructing a two - level emotion regulated learning model , was further applied to testify this theory in two different cases .",
        "by introducing perturbations to image descriptions extracted from a deep convolutional neural network , we change their precision and number of dimensions , measuring how it affects the final score .",
        "we introduce polyglot language models , recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted .",
        "we demonstrate these results computationally with a multilayer feedforward neural network .",
        "we present a new convolutional neural network ( cnn ) model for text classification that jointly exploits labels on documents and their component sentences .",
        "we investigate the use of hierarchical phrase - based smt lattices in end - to - end neural machine translation ( nmt ) .",
        "in this paper we present deeplearningkit - an open source framework that supports using pretrained deep learning models ( convolutional neural networks ) for ios , os x and tvos .",
        "we explore the application of neural translation models to the ape problem and achieve good results by treating different models as components in a log - linear model , allowing for multiple inputs ( the mt - output and the source ) that are decoded to the same target language ( post - edited translations ) .",
        "we explore methods of decode - time integration of attention - based neural translation models with phrase - based statistical machine translation .",
        "for english - russian , the phrase - based system cannot surpass state - of - the - art stand - alone neural models .",
        "for the russian - english task , our submission achieves the top bleu result , outperforming the best pure - neural system by 1 .",
        "deep neural networks are typically represented by a much larger number of parameters than shallow models , making them prohibitive for small footprint devices .",
        "recent research shows that there is considerable redundancy in the parameter space of deep neural networks .",
        "in this paper , we propose a method to compress deep neural networks by using the fisher information metric , which we estimate through a stochastic optimization method that keeps track of second - order information in the network .",
        "we evaluate our method on a classification task with a convolutional neural network trained on the mnist data set .",
        "in this paper , a deep neural network is proposed to incorporate background knowledge for conversation modeling .",
        "we propose a framework for learning convolutional neural networks for arbitrary graphs .",
        "in this paper , we present a hybrid architecture of convolutional neural networks ( cnn ) and stacked autoencoders ( sae ) to learn a sequence of actions that nonlinearly transforms an input shape or distribution into a target shape or distribution with the same support .",
        "recently , there is rising interest in modelling the interactions of two sentences with deep neural networks .",
        "self - organizing map ( som ) is a neural network model which is used to obtain a topology - preserving mapping from the ( usually high dimensional ) input / feature space to an output / map space of fewer dimensions ( usually two or three in order to facilitate visualization ) .",
        "despite recent breakthroughs in the applications of deep neural networks , one setting that presents a persistent challenge is that of \" one - shot learning . \"",
        "architectures with augmented memory capacities , such as neural turing machines ( ntms ) , offer the ability to quickly encode and retrieve new information , and hence can potentially obviate the downsides of conventional models .",
        "here , we demonstrate the ability of a memory - augmented neural network to rapidly assimilate new data , and leverage this data to make accurate predictions after only a few samples .",
        "in an effort to model this kind of generative process , we propose a neural network - based generative architecture , with latent stochastic variables that span a variable number of time steps .",
        "we apply the proposed model to the task of dialogue response generation and compare it with recent neural network architectures .",
        "the model is then evaluated in both uni - and multi - modality settings on two different classification tasks with off - the - shelf convolutional neural network ( cnn ) features which generate state - of - the - art results with extremely compact representations .",
        "as a result , we obtain a new type of convolutional neural network with the following properties : ( i ) at each layer , learning filters is equivalent to optimizing a linear subspace in a reproducing kernel hilbert space ( rkhs ) , where we project data , ( ii ) the network may be learned with supervision or without , ( iii ) the model comes with a natural regularization function ( the norm in the rkhs ) .",
        "56 % , by a neural encoder - decoder model ) while being trained on the same data .",
        "convolutional neural networks ( cnn ) have achieved major breakthroughs in recent years .",
        "deep neural networks can capture complex non - linear features ; however this ability comes at the cost of high computational and memory requirements .",
        "many hardware accelerators for deep neural networks have been proposed recently .",
        "this suggests that in addition to describing neural networks in terms of width and depth , there is a third dimension : multiplicity , the size of the implicit ensemble .",
        "we propose a new method for training computationally efficient and compact convolutional neural networks ( cnns ) using a novel sparse connection structure that resembles a tree root .",
        "as the complexity of deep neural networks ( dnns ) trend to grow to absorb the increasing sizes of data , memory and energy consumption has been receiving more and more attentions for industrial applications , especially on mobile devices .",
        "there are families of neural networks that can learn to compute any function , provided sufficient training data .",
        "through a neural implementation of the dual stack machine that underlies forth , programmers can write program sketches with slots that can be filled with learnable behaviour .",
        "as the program interpreter is end - to - end differentiable , we can optimize this behaviour directly through gradient descent techniques on user specified objectives , and also integrate the program into any larger neural computation graph .",
        "in addition , we introduce neural program optimisations based on symbolic computation and parallel branching that lead to significant speed improvements .",
        "by embracing deep neural networks , we are able to demonstrate end - to - end learning of protocols in complex environments inspired by communication riddles and multi - agent computer vision problems with partial observability .",
        "however , the size of the networks becomes increasingly large scale due to the demands of the practical applications , which poses significant challenge to construct a high performance implementations of deep learning neural networks .",
        "at the core of chor - rnn is a deep recurrent neural network trained on raw motion capture data and that can generate new dance sequences for a solo dancer .",
        "recent progress on many imaging and vision tasks has been driven by the use of deep feed - forward neural networks , which are trained by propagating gradients of a loss defined on the final output , back through the network up to the first layer that operates directly on the image .",
        "for an expected loss function of a deep nonlinear neural network , we prove the following statements under the independence assumption adopted from recent work : 1 ) the function is non - convex and non - concave , 2 ) every local minimum is a global minimum , 3 ) every critical point that is not a global minimum is a saddle point , and 4 ) the property of saddle points differs for shallow networks ( with three layers ) and deeper networks ( with more than three layers ) .",
        "moreover , we prove that the same four statements hold for deep linear neural networks with any depth , any widths and no unrealistic assumptions .",
        "instead of being passively exposed to large amounts of natural text , our learners ( implemented as feed - forward neural networks ) engage in cooperative referential games starting from a tabula rasa setup , and thus develop their own language from the need to communicate in order to succeed at the game .",
        "we show that this procedure can be used to train state estimators that use complex input , such as raw camera images , which must be processed using expressive nonlinear function approximators such as convolutional neural networks .",
        "our model can be viewed as a type of recurrent neural network , and the connection to probabilistic filtering allows us to design a network architecture that is particularly well suited for state estimation .",
        "we investigate the parameter - space geometry of recurrent neural networks ( rnns ) , and develop an adaptation of path - sgd optimization method , attuned to this geometry , that can learn plain rnns with relu activations .",
        "despite having high accuracy , neural nets have been shown to be susceptible to adversarial examples , where a small perturbation to an input can cause it to become mislabeled .",
        "we propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program .",
        "we show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the mnist and cifar - 10 datasets .",
        "finally , we show that our techniques can be used to additionally improve neural net robustness both according to the metrics that we propose , but also according to previously proposed metrics .",
        "this paper investigates two different neural architectures for the task of relation classification : convolutional neural networks and recurrent neural networks .",
        "we present a new context representation for convolutional neural networks for relation classification ( extended middle context ) .",
        "furthermore , we propose connectionist bi - directional recurrent neural networks and introduce ranking loss for their optimization .",
        "finally , we show that combining convolutional and recurrent neural networks using a simple voting scheme is accurate enough to improve results .",
        "our neural models achieve state - of - the - art results on the semeval 2010 relation classification task .",
        "this paper introduces a novel model for semantic role labeling that makes use of neural sequence modeling techniques .",
        "how can we efficiently propagate uncertainty in a latent state representation with recurrent neural networks ?",
        "this paper introduces stochastic recurrent neural networks which glue a deterministic recurrent neural network and a state space model together to form a stochastic and sequential neural generative model .",
        "by retaining both the nonlinear recursive structure of a recurrent neural network and averaging over the uncertainty in a latent path , like a state space model , we improve the state of the art results on the blizzard and timit speech modeling data sets by a large margin , while achieving comparable performances to competing methods on polyphonic music modeling .",
        "this gaussian process operates on a continuous space dialogue representation generated in an unsupervised fashion using a recurrent neural network encoder - decoder .",
        "we propose deep structured energy based models ( dsebms ) , where the energy function is the output of a deterministic deep neural network with structure .",
        "in this paper we explore a simple neural model , called commnn , that uses continuous communication for fully cooperative tasks .",
        "we present a new framework of applying deep neural networks ( dnn ) to devise a universal discrete denoiser .",
        "we experimentally show that our resulting algorithm , dubbed as neural dude , significantly outperforms the previous state - of - the - art in several applications with a systematic rule of choosing the hyperparameter , which is an attractive feature in practice .",
        "models of neural machine translation are often from a discriminative family of encoder - decoders that learn a conditional distribution of a target sentence given a source sentence .",
        "in this paper , we propose a variational model to learn this conditional distribution for neural machine translation : a variational encoder - decoder model that can be trained end - to - end .",
        "in order to perform an efficient posterior inference , we build a neural posterior approximator that is conditioned only on the source side .",
        "experiments on nist chinese - english translation tasks show that the proposed variational neural machine translation achieves significant improvements over both state - of - the - art statistical and neural machine translation baselines .",
        "based on the learned phrase representations , we further use a bilinear neural model , trained via a max - margin method , to measure bilingual semantic similarity .",
        "this paper proposes an adaptive neural - compilation framework to address the problem of efficient program learning .",
        "first steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made - - - for the continuous - time case - - - in mallat , 2012 , and wiatowski and b \\ \" olcskei , 2015 .",
        "this paper considers the discrete case , introduces new convolutional neural network architectures , and proposes a mathematical framework for their analysis .",
        "the core algorithms of our system are based on multi - dimensional recurrent neural networks ( mdrnn ) and connectionist temporal classification ( ctc ) .",
        "it has been proven that transfer learning provides an easy way to achieve state - of - the - art accuracies on several vision tasks by training a simple classifier on top of features obtained from pre - trained neural networks .",
        "the goal of this work is to generate better features for transfer learning from multiple publicly available pre - trained neural networks .",
        "to this end , we propose a novel architecture called stacked neural networks which leverages the fast training time of transfer learning while simultaneously being much more accurate .",
        "unlike feature - based svm and sequential neural models such as lstm , this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect .",
        "such importance degree and text representation are calculated with multiple computational layers , each of which is a neural attention model over an external memory .",
        "we explored various comparative methods , namely phrase - based systems and attentional recurrent neural networks models trained using monomodal or multimodal data .",
        "this paper presents research in progress investigating the viability and adaptation of reinforcement learning using deep neural network based function approximation for the task of radio control and signal detection in the wireless domain .",
        "deep neural networks ( dnns ) have demonstrated state - of - the - art results on many pattern recognition tasks , especially vision classification problems .",
        "one path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect .",
        "the activation function of deep neural networks ( dnns ) has undergone many changes during the last decades .",
        "while convolutional neural networks have gained impressive success recently in solving structured prediction problems such as semantic segmentation , it remains a challenge to differentiate individual object instances in the scene .",
        "techniques that combine large graphical models with low - level vision have been proposed to address this problem ; however , we propose an end - to - end recurrent neural network ( rnn ) architecture with an attention mechanism to model a human - like counting process , and produce detailed instance segmentations .",
        "this paper proposes cf - nade , a neural autoregressive architecture for collaborative filtering ( cf ) tasks , which is inspired by the restricted boltzmann machine ( rbm ) based cf model and the neural autoregressive distribution estimator ( nade ) .",
        "in this paper , we present a convolutional neural network framework for predominant instrument recognition in real - world polyphonic music .",
        "in addition , we conducted extensive experiments on several important factors that affect the performance , including analysis window size , identification threshold , and activation functions for neural networks to find the optimal set of parameters .",
        "using a dataset of 10k audio excerpts from 11 instruments for evaluation , we found that convolutional neural networks are more robust than conventional methods that exploit spectral features and source separation with support vector machines .",
        "road pixels are identified by training a multi - scale convolutional neural network on a large number of full - scene - labeled night - time road images including adverse weather conditions .",
        "in this paper we focus on evaluating and improving the correctness of attention in neural image captioning models .",
        "we propose a practical implementation , using variational inference in bayesian neural networks which efficiently handles continuous state and action spaces .",
        "non - linear extensions based on kernels and ( deep ) neural networks are derived , achieving better performance than the linear ones .",
        "while for some specific benchmarks , neural techniques seem to match if not outperform human judgement , challenges are still open for detecting arbitrary concepts in arbitrary videos .",
        "in this paper , we propose a system that combines neural techniques , a large scale visual concepts ontology , and an active learning loop , to provide on the fly model learning of arbitrary concepts .",
        "in addition , our model reasons about the question and consequently the image via the co - attention mechanism in a hierarchical fashion via a novel 1 - dimensional convolution neural networks ( cnn ) model .",
        "in this paper , we address these limitations by using two different yet complementary neural network models , namely a neural network global lexicon model and a neural network joint model .",
        "these neural networks can generalize better by using continuous space representation of words and learn non - linear mappings .",
        "we present a content - based automatic music tagging algorithm using fully convolutional neural networks ( fcns ) .",
        "our system does not rely on handwritten rules or engineered features ; instead , we train deep neural networks on a large conversational dataset .",
        "currently two major paradigms for language modeling exist : count - based n - gram models , which have advantages of scalability and test - time speed , and neural lms , which often achieve superior modeling performance .",
        "this formulation allows us to create novel hybrid models that combine the desirable features of count - based and neural lms , and experiments demonstrate the advantages of these approaches .",
        "in recent year , parallel implementations have been used to speed up the training of deep neural networks ( dnn ) .",
        "we propose a new way of modeling this task with neural encoder - decoder models .",
        "generative neural samplers are probabilistic models that implement sampling using feedforward neural networks : they take a random input vector and produce a sample from a probability distribution defined by the network weights .",
        "the generative - adversarial training method allows to train such models through the use of an auxiliary discriminative neural network .",
        "we show that any f - divergence can be used for training generative neural samplers .",
        "we introduce the multiresolution recurrent neural network , which extends the sequence - to - sequence framework to model natural language generation as two parallel discrete stochastic processes : a sequence of high - level coarse tokens , and a sequence of natural language tokens .",
        "such procedure allows training the multiresolution recurrent neural network by maximizing the exact joint log - likelihood over both sequences .",
        "we tested 14 very different classification algorithms ( random forest , gradient boosting machines , svm - linear , polynomial , and rbf - 1 - hidden - layer neural nets , extreme learning machines , k - nearest neighbors and a bagging of knn , naive bayes , learning vector quantization , elastic net logistic regression , sparse linear discriminant analysis , and a boosting of linear classifiers ) on 115 real life binary datasets .",
        "meantime , as the neural network - based ( nn - based ) methods develop , nn - based kb - qa has already achieved impressive results .",
        "hence , we present a neural attention - based model to represent the questions dynamically according to the different focuses of various candidate answer aspects .",
        "we extend the synthetic data approach to natural language by developing a neural generative model for such data .",
        "we propose a simple duality between this dense associative memory and neural networks commonly used in deep learning .",
        "on the deep learning side of the duality , this family corresponds to feedforward neural networks with one hidden layer and various activation functions , which transmit the activities of the visible neurons to the hidden layer .",
        "the proposed duality makes it possible to apply energy - based intuition from associative memory to analyze computational properties of neural networks with unusual activation functions - the higher rectified polynomials which until now have not been used for training neural networks .",
        "convolutional neural networks ( cnns ) have become the state - of - the - art in supervised learning vision tasks .",
        "in this paper , to mimic the human sentence composition process using a neural network approach , we propose to incorporate different categories of linguistic features into distributed representation of words in order to learn simultaneously the writing style representations based on unlabeled texts for authorship analysis .",
        "the main component of the model is a recurrent neural network ( an lstm ) , which maps from raw dialog history directly to a distribution over system actions .",
        "our model which we call dense ( as shorthand for dependency neural selection ) employs bidirectional recurrent neural networks for the head selection task .",
        "in this paper we propose a neural conversation model for conducting dialogues .",
        "experimental results indicate that the model outperforms previously proposed neural conversation architectures , and that using specificity in the objective function significantly improves performances for both generation and retrieval .",
        "we present a neural network based coreference system that produces high - dimensional vector representations for pairs of coreference clusters .",
        "in this work , we investigate several neural network architectures for fine - grained entity type classification .",
        "particularly , we consider extensions to a recently proposed attentive neural architecture and make three key contributions .",
        "previous work on attentive neural architectures do not consider hand - crafted features , we combine learnt and hand - crafted features and observe that they complement each other .",
        "in this paper , we show that by feeding the weights of a deep neural network ( dnn ) during training into a deep q - network ( dqn ) as its states , this dqn can learn policies to accelerate the training of that dnn .",
        "recent neural models of dialogue generation offer great promise for generating responses for conversational agents , but tend to be shortsighted , predicting utterances one at a time while ignoring their influence on future outcomes .",
        "this work marks a first step towards learning a neural conversational model based on the long - term success of dialogues .",
        "we introduce a new attention mechanism which uses multiplicative interactions between the query embedding and intermediate states of a recurrent neural network reader .",
        "in recent years deep neural networks have achieved great success in sentiment classification for english , thanks in part to the availability of copious annotated resources .",
        "we introduce a recurrent neural network language model ( rnn - lm ) with long short - term memory ( lstm ) units that utilizes both character - level and word - level inputs .",
        "in order to capture some of these advantages in machine perception , we ask two questions : whether deep neural networks can learn universal image representations , useful not only for a single task but for all of them , and how the solutions to the different tasks can be integrated in this framework .",
        "the dominant approach for many nlp tasks are recurrent neural networks , in particular lstms , and convolutional neural networks .",
        "in this paper , we propose phrasenet , a neural machine translator with a phrase memory which stores phrase pairs in symbolic form , mined from corpus or specified by human experts .",
        "the phrasenet not only approaches one step towards incorporating external knowledge into neural machine translation , but also makes an effort to extend the word - by - word generation mechanism of recurrent neural network .",
        "45 bleu improvement over the generic neural machine translator .",
        "we propose a simple neural architecture for natural language inference .",
        "we firstly design policy - based brokers and identify then a learning broker based on artificial neural networks .",
        "recent results show that deep neural networks achieve excellent performance even when , during training , weights are quantized and projected to a binary representation .",
        "previous neural models require parses , surface features , or a small label set to work well .",
        "here , we propose neural network models that are based on feedforward and long - short term memory architecture without any surface features .",
        "our models present the first neural chinese discourse parser in the style of chinese discourse treebank , showing that our results hold cross - linguistically .",
        "we propose cfo , a conditional focused neural - network - based approach to answering factoid questions with knowledge bases .",
        "powered by deep recurrent neural networks and neural embeddings , our proposed cfo achieves an accuracy of 75 .",
        "we propose to enhance the rnn decoder in a neural machine translator ( nmt ) with external memory , as a natural but powerful extension to the state in the decoding rnn .",
        "neural machine translation ( nmt ) often makes mistakes in translating low - frequency content words that are essential to understanding the meaning of the sentence .",
        "we investigate the potential of attention - based neural machine translation in simultaneous translation .",
        "we introduce a novel decoding algorithm , called simultaneous greedy decoding , that allows an existing neural machine translation model to begin translating before a full source sentence is received .",
        "this paper presents a first step toward building a full simultaneous translation system based on neural machine translation .",
        "we introduce a novel playlist generation algorithm that focuses on the quality of transitions using a recurrent neural network ( rnn ) .",
        "we propose a novel neural attention architecture to tackle machine comprehension tasks , such as answering cloze - style queries with respect to a document .",
        "the epireader is an end - to - end neural model comprising two components : the first component proposes a small set of candidate answers after comparing a question to its supporting text , and the second component formulates hypotheses using the proposed candidates and the question , then reranks the hypotheses based on their estimated concordance with the supporting text .",
        "we present experiments demonstrating that the epireader sets a new state - of - the - art on the cnn and children ' s book test machine comprehension benchmarks , outperforming previous neural models by a significant margin .",
        "despite the success of convolutional neural networks , selecting the optimal architecture for a given task remains an open problem .",
        "in this paper we study different types of recurrent neural networks ( rnn ) for sequence labeling tasks .",
        "disco nets allow us to efficiently sample from a posterior distribution parametrised by a neural network .",
        "we empirically show that ( i ) by modeling uncertainty on the output value , disco nets outperform equivalent non - probabilistic predictive networks and ( ii ) disco nets accurately model the uncertainty of the output , outperforming existing probabilistic models based on deep neural networks .",
        "neural machine translation has become a major alternative to widely used phrase - based statistical machine translation .",
        "we notice however that much of research on neural machine translation has focused on european languages despite its language agnostic nature .",
        "in this paper , we apply neural machine translation to the task of arabic translation ( ar & lt ; - & gt ; en ) and compare it against a standard phrase - based translation system .",
        "we run extensive comparison using various configurations in preprocessing arabic script and show that the phrase - based and neural translation systems perform comparably to each other and that proper preprocessing of arabic script has a similar effect on both of the systems .",
        "we however observe that the neural machine translation significantly outperform the phrase - based system on an out - of - domain test set , making it attractive for real - world deployment .",
        "a unified neural network framework is proposed to enable the system to first learn by supervision from a set of dialogue data and then continuously improve its behaviour via reinforcement learning , all using gradient - based algorithms on one single model .",
        "we propose an attention - based neural network model that is able to absorb information from multiple text units to construct informative , concise , and fluent summaries .",
        "( 2015 ) seek to solve this problem by creating over a million training examples by pairing cnn and daily mail news articles with their summarized bullet points , and show that a neural network can then be trained to give good performance on this task .",
        "we participated in the wmt 2016 shared news translation task by building neural translation systems for four language pairs , each trained in both directions : english & lt ; - & gt ; czech , english & lt ; - & gt ; german , english & lt ; - & gt ; romanian and english & lt ; - & gt ; russian .",
        "neural machine translation has recently achieved impressive results , while using little in the way of external linguistic information .",
        "in this paper we show that the strong learning capability of neural mt models does not make linguistic features redundant ; they can be easily incorporated to provide further improvements in performance .",
        "we add morphological features , part - of - speech tags , and syntactic dependency labels as input features to english & lt ; - & gt ; german neural machine translation systems .",
        "seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local , next - word distributions .",
        "recurrent neural networks such as the gru and lstm found wide adoption in natural language processing and achieve state - of - the - art results for many tasks .",
        "various systems using word overlap , neural embeddings and neural compositional models are evaluated on two datasets of learner writing .",
        "convolutional neural networks ( cnns ) with convolutional and pooling operations along the frequency axis have been proposed to attain invariance to frequency shifts of features .",
        "our design features several innovations including : a robust and smartphone - orientation - independent walking cycle extraction block , a novel feature extractor based on convolutional neural networks , a one - class support vector machine to classify walking cycles , and the coherent integration of these into a multi - stage authentication system .",
        "to the best of our knowledge , our system is the first exploiting convolutional neural networks as universal feature extractors for gait recognition , and using classification results from subsequent walking cycles into a multi - stage decision making framework .",
        "in this work we study various model architectures and different ways to represent and aggregate the source information in an end - to - end neural dialogue system framework .",
        "in fact selection , we match the subject entity in fact with the entity mention in question by a character - level convolutional neural network ( char - cnn ) , and match the predicate in fact with the question by a word - level cnn ( word - cnn ) .",
        "we propose a novel approach to reduce memory consumption of the backpropagation through time ( bptt ) algorithm when training recurrent neural networks ( rnns ) .",
        "modeling crisp logical regularities is crucial in semantic parsing , making it difficult for neural models with no task - specific prior knowledge to achieve good results .",
        "we present a new approach to natural language generation using recurrent neural networks in an encoder - decoder framework .",
        "here we compare the performances of four systems on datasets covering 16 languages , two of these systems being feature - based ( memms and crfs ) and two of them being neural - based ( bi - lstms ) .",
        "for morphologically rich languages ) , whereas neural - based results are higher on datasets with less lexical variability ( e .",
        "this shows that , under certain conditions , feature - based approaches enriched with morphosyntactic lexicons are competitive with respect to neural methods .",
        "we propose a novel neural belief tracking ( nbt ) framework which aims to overcome these problems by building on recent advances in semantic representation learning .",
        "we employed a recurrent neural network initialized with features learned via distant supervision on two large unlabeled datasets .",
        "we present an effective approach to generating color descriptions using recurrent neural networks and a fourier - transformed color representation .",
        "recent advances in building end - to - end neural architectures have been highly successful in solving such tasks .",
        "we derive am - rnns , a recurrent associative memory ( am ) which augments generic recurrent neural networks ( rnn ) .",
        "in this paper , we propose a framework for training multiple neural networks simultaneously .",
        "the parameters from all models are regularised by the tensor trace norm , so that one neural network is encouraged to reuse others ' parameters if possible - - this is the main motivation behind multi - task learning .",
        "in this work , we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories .",
        "in this paper , we propose a novel finetuning algorithm for the recently introduced multi - way , mulitlingual neural machine translate that enables zero - resource machine translation .",
        "when used together with novel many - to - one translation strategies , we empirically show that this finetuning algorithm allows the multi - way , multilingual model to translate a zero - resource language pair ( 1 ) as well as a single - pair neural translation model trained with up to 1m direct parallel sentences of the same language pair and ( 2 ) better than pivot - based translation strategy , while keeping only one additional copy of attention - related parameters .",
        "deep neural networks have dramatically advanced the state of the art for many areas of machine learning .",
        "neural machine translation ( nmt ) aims at solving machine translation ( mt ) problems with purely neural networks and exhibits promising results in recent years .",
        "we propose a new active learning ( al ) method for text classification based on convolutional neural networks ( cnns ) .",
        "neural models capitalize on word embeddings as features , tuning these to the task at hand .",
        "we argue that al strategies for neural text classification should focus on selecting instances that most affect the embedding space ( i .",
        "in contrast to most modern neural systems of translation , which discard the identity for rare words , in this paper we propose several architectures for learning word representations from character and morpheme level word decompositions .",
        "large - scale supervised classification algorithms , especially those based on deep convolutional neural networks ( dcnns ) , require vast amounts of training data to achieve state - of - the - art performance .",
        "in an attempt to make our results more interpretable , and inspired by recent advances in visualizing neural networks , we introduce a novel method for identifying the regions of the text that the model has found more discriminative .",
        "in this paper , we propose a novel neural framework which thoroughly eliminates context windows and can utilize complete segmentation history .",
        "our model employs a gated combination neural network over characters to produce distributed representations of word candidates , which are then given to a long short - term memory ( lstm ) language scoring model .",
        "when evaluating the performances of several different neural network architectures in a parallel computing environment .",
        "we show how real logic can be implemented in deep tensor neural networks with the use of google ' s tensorflow primitives .",
        "deep neural networks have recently been shown to lack robustness against adversarially crafted inputs .",
        "these inputs are derived from regular inputs by minor yet carefully selected perturbations that deceive the neural network into desired misclassifications .",
        "we study the effectiveness of neural sequence models for premise selection in automated theorem proving , one of the main bottlenecks in the formalization of mathematics .",
        "we demonstrate this on a number of tasks , including simple convex problems , training neural networks , and styling images with neural art .",
        "given a specification of a convolutional neural network , we study how to minimize the time to train this model on a cluster of commodity cpus and gpus .",
        "we use long short - term memories ( lstm ) to induce distributed representations of each argument , and then combine these representations with surface features in a neural network .",
        "the architecture of the neural network is determined by bayesian hyperparameter search .",
        "deep neural networks ( dnn ) have shown promise in a wide range of machine learning tasks , but for behavioral signal processing ( bsp ) tasks their application has been constrained due to limited quantity of data .",
        "in this work we study variance in the results of neural network training on a wide variety of configurations in automatic speech recognition .",
        "we present query - regression network ( qrn ) , a variant of recurrent neural network ( rnn ) that is suitable for end - to - end machine comprehension .",
        "while end - to - end neural machine translation ( nmt ) has made remarkable progress recently , nmt systems only rely on parallel corpora for parameter estimation .",
        "specifically , we first devise a joint visual modelling approach to encode video data by combining a forward lstm pass , a backward lstm pass , together with visual features from convolutional neural networks ( cnns ) .",
        "we present the siamese continuous bag of words ( siamese cbow ) model , a neural network for efficient estimation of high - quality sentence embeddings .",
        "the underlying neural network learns word embeddings by predicting , from a sentence representation , its surrounding sentences .",
        "we present a novel deep recurrent neural network architecture that learns to build implicit plans in an end - to - end manner by purely interacting with an environment in reinforcement learning setting .",
        "deep neural networks ( dnn ) have been successful in en - hancing noisy speech signals .",
        "in the proposed unified hybrid architecture , features from a convolution neural network ( cnn ) that processes the visual cues and features from a fully connected dnn that processes the audio signal are integrated using a bidirectional long short - term memory ( bilstm ) network .",
        "in this work we explore this idea in the context of neural encoder decoder architectures , albeit on a smaller scale and without mt as the end goal .",
        "to address this issue , we explore new and powerful generative models for three popular deep visualization tasks using untrained , random weight convolutional neural networks .",
        "to our knowledge this is the first demonstration of image representations using untrained deep neural networks .",
        "our goal is to be able to build a generative model from a deep neural network architecture to try to create music that has both harmony and melody and is passable as music composed by humans .",
        "in particular , there has been a lot of work based off of recurrent neural networks combined with restricted boltzmann machines ( rnn - rbm ) and other similar recurrent energy based models .",
        "our approach , however , is to perform end - to - end learning and generation with deep neural nets alone .",
        "motivated by the complementary nature of syntactical machine translation and neural machine translation ( nmt ) , we exploit the synergies of hiero and nmt in different combination schemes .",
        "starting out with a simple neural lattice rescoring approach , we show that the hiero lattices are often too narrow for nmt ensembles .",
        "experimental results show that the proposed method which is based on semi - supervised training of a deep neural network largely outperforms phoneme based continuous speech recognition on the timit dataset .",
        "while this does not seem like a challenging task , many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35 % - 65 % on benchmark sets .",
        "based on this assumption of the structure , our simple yet effective approach trains two recurrent neural networks to outperform state of the art by significant margins - - - relative improvement reaches 16 % for webquestions , and surpasses 38 % for simplequestions .",
        "infinite - - layer networks ( iln ) have recently been proposed as an architecture that mimics neural networks while enjoying some of the advantages of kernel methods .",
        "we study the expressivity of deep neural networks with random weights .",
        "the latter , a notion defined in this paper , is further studied using properties of hyperplane arrangements , which also help precisely characterize the effect of the neural network on the input space .",
        "these results also suggest that the remaining depth of a neural network is an important determinant of expressivity , supported by experiments on mnist and cifar - 10 .",
        "we combine riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic , deep neural networks with random weights .",
        "over the last years convolutional neural networks have achieved almost human performance in recognizing concrete classes ( i .",
        "the concept tree - symbolic neural network relation is also extended further .",
        "for each model , we investigate four implementations : a \" standard \" n - gram language model and three discriminatively trained \" neural \" language models that generate embeddings for semantic frames .",
        "we further trained a phrase - based smt system using state - of - the - art features and components such as operation sequence model , class - based language model , sparse features , neural network joint model , genre - based hierarchically - interpolated language model , unsupervised transliteration mining , phrase - table merging , and hypothesis combination .",
        "we experiment with various aggregation functions , including neural network attention models .",
        "recent progress in neural learning demonstrated that machines can do well in regularized tasks , e .",
        "in this paper , we demonstrate that a simple neural model can imitate human in some tasks of art generation .",
        "our method is based on an attention - based recurrent neural network , which accepts a set of keywords as the theme and generates poems by looking at each keyword during the generation .",
        "in conventional deep neural network based speech synthesis , the input text features are repeated for the entire duration of phoneme for mapping text and speech parameters .",
        "using recurrent neural network based auto - encoder , we show that it is indeed possible to map units of varying duration to a single vector .",
        "we then use this acoustic representation at unit - level to synthesize speech using deep neural network based statistical parametric speech synthesis technique .",
        "recently , bidirectional recurrent neural network ( brnn ) has been widely used for question answering ( qa ) tasks with promising performance .",
        "we propose a new training method for a feedforward neural network having the activation functions with the geometric contraction property .",
        "acoustic models based on long short - term memory recurrent neural networks ( lstm - rnns ) were applied to statistical parametric speech synthesis ( spss ) and showed significant improvements in naturalness and latency over those based on hidden markov models ( hmms ) .",
        "fisher information and natural gradient provided deep insights and powerful tools to artificial neural networks .",
        "this concept is important because the geometry structure is much simplified and it can be easily applied to guide the learning of neural networks .",
        "we propose dorefa - net , a method to train convolutional neural networks that have low bitwidth weights and activations using low bitwidth parameter gradients .",
        "moreover , as bit convolutions can be efficiently implemented on cpu , fpga , asic and gpu , dorefatnet opens the way to accelerate training of low bitwidth neural network on these hardware .",
        "designing and implementing efficient , provably correct parallel neural network processing is challenging .",
        "however , the diversity and large - scale data size have posed a significant challenge to construct a flexible and high - performance implementation of deep learning neural networks .",
        "compared to state - of - the - art models such as neural tensor network and holographic embeddings , our approach based on complex embeddings is arguably simpler , as it only uses the hermitian dot product , the complex counterpart of the standard dot product between real vectors .",
        "recently , neural network approaches for parsing have largely automated the combination of individual features , but still rely on ( often a larger number of ) atomic features created from human linguistic intuition , and potentially omitting important global context .",
        "however , as high - capacity supervised neural networks trained with a large amount of labels have achieved remarkable success in many computer vision tasks , the availability of large - scale labeled images reduced the significance of unsupervised learning .",
        "inspired by the recent trend toward revisiting the importance of unsupervised learning , we investigate joint supervised and unsupervised learning in a large - scale setting by augmenting existing neural networks with decoding pathways for reconstruction .",
        "we introduce a general and simple structural design called multiplicative integration ( mi ) to improve recurrent neural networks ( rnns ) .",
        "this paper investigates neural character - based morphological tagging for languages with complex morphology and large tag sets .",
        "we systematically explore a variety of neural architectures ( dnn , cnn , cnnhighway , lstm , blstm ) to obtain character - based word vectors combined with bidirectional lstms to model across - word context in an end - to - end setting .",
        "increasing the model capacity by adding depth , for example , and carefully optimizing the neural networks can lead to substantial improvements , and the differences in accuracy ( but not training time ) become much smaller or even negligible .",
        "both the accordion annealing and the pem methods are used during training of a recurrent neural network which is then evaluated on three databases .",
        "we present a comprehensive study of deep bidirectional long short - term memory ( lstm ) recurrent neural network ( rnn ) based acoustic models for automatic speech recognition ( asr ) .",
        "recently , the rapid development of word embedding and neural networks has brought new inspiration to various nlp and ir tasks .",
        "in this paper , we describe a staged hybrid model combining recurrent convolutional neural networks ( rcnn ) with highway layers .",
        "the highway network module is incorporated in the middle takes the output of the bi - directional recurrent neural network ( bi - rnn ) module in the first stage and provides the convolutional neural network ( cnn ) module in the last stage with the input .",
        "the experiment shows that our model outperforms common neural network models ( cnn , rnn , bi - rnn ) on a sentiment analysis task .",
        "word embeddings and convolutional neural networks ( cnn ) have attracted extensive attention in various classification tasks for twitter , e .",
        "in this paper , we introduce a model that employs information retrieval by utilizing convolutional deep structured semantic neural network - based features in the ranker to present human - like responses in ongoing conversation with a user .",
        "stability evaluation of a weight - update system of higher - order neural units ( honus ) with polynomial aggregation of neural inputs ( also known as classes of polynomial neural networks ) for adaptation of both feedforward and recurrent honus by a gradient descent method is introduced .",
        "assuring stability of the weight - update system ( at every single adaptation step ) naturally results in adaptation stability of the whole neural architecture that adapts to target data .",
        "as an aside , the used approach highlights the fact that the weight optimization of honu is a linear problem , so the proposed approach can be generally extended to any neural architecture that is linear in its adaptable parameters .",
        "with this in mind , we argue that embedding kbs within deep neural architectures supporting documentquery matching would give rise to fine - grained latent representations of both words and their semantic relations .",
        "in this paper , we review the main approaches of neural - based document ranking as well as those approaches for latent representation of entities and relations via kbs .",
        "we then propose some avenues to incorporate kbs in deep neural approaches for document ranking .",
        "unlike previous works that optimized mrfs using iterative algorithm , we solve mrf by proposing a convolutional neural network ( cnn ) , namely deep parsing network ( dpn ) , which enables deterministic end - to - end computation in a single forward pass .",
        "we propose text2vis , a neural network that generates a visual representation , in the visual feature space of the fc6 - fc7 layers of imagenet , from a short descriptive text .",
        "we propose a novel approach based on deep neural networks for modeling the dynamics of robot ' s interactions directly from images , by jointly estimating forward and inverse models of dynamics .",
        "recurrent neural networks , and in particular long short - term memory networks ( lstms ) , are a remarkably effective tool for sequence modeling that learn a dense black - box hidden representation of their sequential input .",
        "in this work , we present lstmvis a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics .",
        "neural sequence to sequence learning recently became a very promising paradigm in machine translation , achieving competitive results with statistical phrase - based systems .",
        "in this system description paper , we attempt to utilize several recently published methods used for neural sequential learning in order to build systems for wmt 2016 shared tasks of automatic post - editing and multimodal machine translation .",
        "deep neural networks ( dnn ) are capable of learning ideal representations of data during the training process , removing the need for independently extracting features .",
        "in the last decades , few attempts where done to handle that objective with neural networks , but recently an architecture based on autoencoders proved to be a promising approach .",
        "in this paper we propose to use a fully deep neural network ( dnn ) framework to handle the multi - label classification task in a regression way .",
        "inspired by natural language processing ( nlp ) techniques , we propose a novel neural network ( nn ) based next - song recommender , cnn - rec , in this paper .",
        "vanishing ( and exploding ) gradients effect is a common problem for recurrent neural networks with nonlinear activation functions which use backpropagation method for calculation of derivatives .",
        "deep feedforward neural networks with many hidden layers also suffer from this effect .",
        "we investigate the usage of convolutional neural networks ( cnns ) for the slot filling task in spoken language understanding .",
        "our proposed cnn architecture outperforms even the previously best ensembling recurrent neural network model and achieves state - of - the - art results with an f1 - score of 95 .",
        "here we propose a power - efficient approach for real - time inference , in which deep neural networks ( dnns ) are implemented through low - power analog circuits .",
        "we apply our evaluation methodology to the comparison of a count vector model and several neural network models and demonstrate important properties of these models .",
        "neural machine translation ( nmt ) offers a novel alternative formulation of translation that is potentially simpler than statistical approaches .",
        ", 2015 ) that have proven successful for reducing the size of neural models in other domains to the problem of nmt .",
        "in this application , we explored various recurrent neural network frameworks and show that they significantly outperformed the crf models .",
        "we describe an implementation of this framework using a combination of restricted boltzmann machines and feedforward neural networks .",
        "in the realm of neural networks , the invention of connectionist temporal classification ( ctc ) made it possible to train recurrent neural networks on unsegmented sequences with great success .",
        "an important class of problems involves training deep neural networks with sparse prediction targets of very high dimension d .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "recurrent neural networks ( rnns ) were recently proposed for the session - based recommendation task .",
        "gradient descent training techniques are remarkably successful in training analog - valued artificial neural networks ( anns ) .",
        "we propose the gaussian error linear unit ( gelu ) , a high - performing neural network activation function .",
        "the supervised learning of the discriminative convolutional neural network ( convnet ) is powered by back - propagation on the parameters .",
        "this paper discusses models for dialogue state tracking using recurrent neural networks ( rnn ) .",
        "we introduce a neural network model that , given a definite description and a set of objects represented by natural images , points to the intended object if the expression has a unique referent , or indicates a failure , if it does not .",
        "in our simulations , we train a vector - space model on either an english or a chinese corpus and then feed the resulting representations to a feed - forward neural network .",
        "the task of the neural network was to find a mapping between the word representations and the novel words .",
        "neural machine translation ( nmt ) , like many other deep learning domains , typically suffers from over - parameterization , resulting in large storage sizes .",
        "our main objective is to exploit the power of convolution neural network ( cnn ) to learn features automatically and thus reduce the dependency on manual feature engineering .",
        "our results indicate that convolution neural network can be a good model for relation exaction in clinical text without being dependent on expert ' s knowledge on defining quality features .",
        "in particular , we propose various end - to - end recurrent neural network ( rnn ) models for the tasks of disease name recognition and their classification into four pre - defined categories .",
        "we also utilize convolution neural network ( cnn ) in cascade of rnn to get character - based embedded features and employ it with word - embedded features in our model .",
        "convolutional neural networks ( cnns ) have greatly improved state - of - the - art performances in a number of fields , notably computer vision and natural language processing .",
        "we present a simple neural network for word alignment that builds source and target word window representations to compute alignment scores for sentence pairs .",
        "in this paper , we extend neural turing machine ( ntm ) into a dynamic neural turing machine ( d - ntm ) by introducing a trainable memory addressing scheme .",
        "this paper introduces a data - driven user simulator based on an encoder - decoder recurrent neural network .",
        "a catastrophic forgetting problem makes deep neural networks forget the previously learned information , when learning data collected in new environments , such as by different sensors or in different light conditions .",
        "finally , we show our less - forgetting learning method is also helpful to improve the performance of deep neural networks in terms of recognition rates .",
        "recently neural network based models have been proposed which do not require handcrafted features but still require annotated corpora .",
        "in this paper , we propose a neural network based model which allows sharing the decoder as well as word and character level parameters between two languages thereby allowing a resource fortunate language to aid a resource deprived language .",
        "however , from gaussian mixture models hmms ( gmm - hmm ) to deep neural network hmms ( dnn - hmm ) , the underlying markovian chain of state - of - the - art models did not changed much .",
        "we propose a simple domain adaptation method for neural networks in a supervised setting .",
        "recently , recurrent neural networks have been shown to be successful on a variety of nlp tasks such as caption generation ; however , the existing domain adaptation techniques are limited to ( 1 ) tune the model parameters by the target dataset after the training by the source dataset , or ( 2 ) design the network to have dual output , one for the source domain and the other for the target domain .",
        "reformulating the idea of the domain adaptation technique proposed by daume ( 2007 ) , we propose a simple domain adaptation method , which can be applied to neural networks trained with a cross - entropy loss .",
        "we first observe a potential weakness of continuous vector representations of symbols in neural machine translation .",
        "this has the consequence that the encoder and decoder recurrent networks in neural machine translation need to spend substantial amount of their capacity in disambiguating source and target words based on the context which is defined by a source sentence .",
        "the experiments on en - fr and en - de reveal that the proposed approaches of contextualization and symbolization improves the translation quality of neural machine translation systems significantly .",
        "we present a new theoretical framework for analyzing and learning artificial neural networks .",
        "we introduce the first global recursive neural parsing model with optimality guarantees during decoding .",
        "we demonstrate that charagram embeddings outperform more complex architectures based on character - level recurrent and convolutional neural networks , achieving new state - of - the - art performance on several similarity tasks .",
        "however , recurrent neural networks with such ' deep ' transition functions remain difficult to train , even when using long short - term memory networks .",
        "over the past few months , we have seen much progress that utilizing neural network approach to solve cloze - style questions .",
        "unlike the previous works , our neural network model requires less pre - defined hyper - parameters and uses an elegant architecture for modeling .",
        "guided policy search algorithms can be used to optimize complex nonlinear policies , such as deep neural networks , without directly computing policy gradients in the high - dimensional parameter space .",
        "a major challenge in the training of recurrent neural networks is the so - called vanishing or exploding gradient problem .",
        "in this paper , we present the first experiments using neural network models for the task of error detection in learner writing .",
        "we present an approach to training neural networks to generate sequences using actor - critic methods from reinforcement learning ( rl ) .",
        "in this paper , we improve the attention or alignment accuracy of neural machine translation by utilizing the alignments of training sentence pairs .",
        "our experiments on large - scale chinese - to - english task show that our model improves both translation and alignment qualities significantly over the large - vocabulary neural machine translation system , and even beats a state - of - the - art traditional syntax - based system .",
        "we propose a novel unsupervised algorithm based on sequence prediction models such as markov chains and recurrent neural network .",
        "in this work we experimented with various crf based structured learning models with recurrent neural networks .",
        "as examples , we studied neural data with real - valued observations , count data from a market basket analysis , and ratings data from a movie recommendation system .",
        "on all three applications - neural activity of zebrafish , users ' shopping behavior , and movie ratings - we found exponential family embedding models to be more effective than other types of dimension",
        "inspired by the findings from the cmabrigde uinervtisy effect , we propose a word recognition model based on a semi - character level recursive neural network ( scrnn ) .",
        "in contrast to prior work , the proposed neural model does not utilize domain - specific crafting , learning to translate directly from a parallel corpus .",
        "to fully explore the potential of neural models , we propose a methodology for collecting a large corpus of regular expression , natural language pairs .",
        "the task contains a rich variety of challenging classification and extraction sub - tasks , making it well - suited for end - to - end models such as deep neural networks ( dnns ) .",
        "high demand for computation resources severely hinders deployment of large - scale deep neural networks ( dnn ) in resource constrained devices .",
        "such groundings are easily achieved for recurrent neural language model architectures , which can be further conditioned on incomplete background knowledge bases .",
        "recent studies show that the 1 - nearest neighbor with dynamic time warping ( 1nn - dtw ) and the long short term memory ( lstm ) neural network can achieve a better performance than other machine learning algorithms .",
        "two common methods include representations based on averaging word vectors , and representations based on the hidden states of recurrent neural networks such as lstms .",
        "the ability of deep convolutional neural networks ( cnn ) to learn discriminative spectro - temporal patterns makes them well suited to environmental sound classification .",
        "this study has two primary contributions : first , we propose a deep convolutional neural network architecture for environmental sound classification .",
        "unsupervised neural networks , such as restricted boltzmann machines ( rbms ) and deep belief networks ( dbns ) , are powerful tools for feature selection and pattern recognition tasks .",
        "we demonstrate that overfitting occurs in such models just as in deep feedforward neural networks , and discuss possible regularization methods to reduce overfitting .",
        "our aims are to develop new machine learning approaches based on neural networks and graphical models , and to understand the capabilities of machine learning techniques relative to traditional alternatives , such as those based on constraint solving from the programming languages community .",
        "a recurrent neural network that has been trained to separately model the language of several documents by unknown authors is used to measure similarity between the documents .",
        "within the field of statistical machine translation ( smt ) , the neural approach ( nmt ) has recently emerged as the first technology able to challenge the long - standing dominance of phrase - based approaches ( pbmt ) .",
        "to understand in what respects nmt provides better translation quality than pbmt , we perform a detailed analysis of neural versus phrase - based smt outputs , leveraging high quality post - edits performed by professional translators on the iwslt data .",
        "for the first time , our analysis provides useful insights on what linguistic phenomena are best modeled by neural models - - such as the reordering of verbs - - while pointing out other aspects that remain to be improved .",
        "in the field of language modelling , traditional n - gram techniques and modern recurrent neural network ( rnn ) approaches have been applied to algorithmically find structure in language and predict the next word given the previous words in the sentence or paragraph as input .",
        "the different types of features are integrated in a neural network that uses a novel architecture to learn latent modes of discussion structure that perform as well as deep neural networks but are more interpretable .",
        "the optimization of deep neural networks can be more challenging than traditional convex optimization problems due to the highly non - convex nature of the loss function , e .",
        "in this paper , we attack the problem of optimization of highly non - convex neural networks by starting with a smoothed - - or \\ textit { mollified } - - objective function that gradually has a more non - convex energy landscape during the training .",
        "we show improvements on various difficult optimization tasks and establish a relationship with recent works on continuation methods for neural networks and mollifiers .",
        "in order to cope with a wide range of reverberations in real - world situations , we present novel approaches for acoustic modeling including an ensemble of deep neural networks ( dnns ) and an ensemble of jointly trained dnns .",
        "we follow the recent success of an integrated neural method for hypernymy detection ( shwartz et al .",
        "we confirm the effectiveness of our method using two benchmark tasks with neural networks as function approximation .",
        "training directed neural networks typically requires forward - propagating data through a computation graph , followed by backpropagating error signal , to produce weight updates .",
        "we realise decoupled neural interfaces .",
        "we show results for feed - forward models , where every layer is trained asynchronously , recurrent neural networks ( rnns ) where predicting one ' s future gradient extends the time over which the rnn can effectively model , and also a hierarchical rnn system with ticking at different timescales .",
        "these methods first convert the ascii text to a phonetic script , and then learn a deep neural network to synthesize speech from that .",
        "recently , a multi - level fuzzy min max neural network ( mlf ) was proposed , which improves the classification accuracy by handling an overlapped region ( area of confusion ) with the help of a tree structure .",
        "the sequence to sequence architecture is widely used in the response generation and neural machine translation to model the potential relationship between two sentences .",
        "in this paper , we propose a novel approach that models both skipping and reading , using an unsupervised architecture that combines a neural attention with autoencoding , trained on raw text using reinforcement learning .",
        "most existing works have to suffer the tradeoff between the two by either picking complex black box models such as recurrent neural networks ( rnn ) or relying on less accurate traditional models with better interpretation such as logistic regression .",
        "retain is a two - level neural attention model that can find influential past visits and significant clinical variables within those visits ( e .",
        "recurrent neural nets are widely used for predicting temporal data .",
        "in neural machine translation ( nmt ) , generation of a target word depends on both source and target contexts .",
        "we propose local binary convolution ( lbc ) , an efficient alternative to convolutional layers in standard convolutional neural networks ( cnn ) .",
        "empirically , cnns with lbc layers , called local binary convolutional neural networks ( lb",
        "we further propose an attention - based multi - hop recurrent neural network ( amrnn ) architecture for this task , achieving encouraging results in the initial tests .",
        "the generator is based on recurrent neural networks and the sequence - to - sequence approach .",
        "we benchmark the running performance of these tools with three popular types of neural networks on two cpu platforms and three gpu platforms .",
        "we show that collaborative filtering can be viewed as a sequence prediction problem , and that given this interpretation , recurrent neural networks offer very competitive approach .",
        "recurrent neural networks have recently been used for learning to describe images using natural language .",
        "recent approaches usually leverage neural networks based on structure features such as syntactic or dependency features to solve this problem .",
        "therefore , this paper proposes a bi - directional long - short - term - memory recurrent - neural - network ( bi - lstm - rnn ) model based on low - cost sequence features to address relation classification .",
        "an attention - based multi - hop recurrent neural network ( amrnn ) architecture was also proposed for this task , which considered only the sequential relationship within the speech utterances .",
        "motivated to tackle the problems causing the rd phenomenon , we propose the pomdp - rec framework , which is a neural - optimized partially observable markov decision process algorithm for recommender systems .",
        "we propose an end - to - end neural architecture for the task .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "the signer - independent setting is much more challenging , but with neural network adaptation we achieve up to 17 % letter error rates .",
        "convolutional neural networks ( cnns ) are extensively used in image and video recognition , natural language processing and other machine learning applications .",
        "in this paper a high speed neural network classifier based on extreme learning machines for multi - label classification problem is proposed and dis - cussed .",
        "there are no real - time online neural network based multi - label classifier available in the literature .",
        "we perform experiments and show that the derived bounds provide very accurate estimates when applied to various state - of - the - art deep neural networks and datasets .",
        "deep neural networks have shown striking progress and obtained state - of - the - art results in many ai research fields in the recent years .",
        "in generation , we convert a formula into natural language using a sequence - to - sequence recurrent neural network .",
        "whenever a new class ( non - native to the knowledge learnt thus far ) is encountered , the neural network structure gets remodeled automatically by facilitating new neurons and interconnections , and the parameters are calculated in such a way that it retains the knowledge learnt thus far .",
        "in this paper , a high - speed online neural network classifier based on extreme learning machines for multi - label classification is proposed .",
        "experiments on speech recognition and machine translation for neural sequence to sequence models show notable improvements over a maximum likelihood baseline by using edit distance augmented maximum likelihood .",
        "the computation and storage requirements for deep neural networks ( dnns ) are usually high .",
        "in this paper , we propose ternary neural networks ( tnns ) in order to make deep learning more resource - efficient .",
        "during training , a ternary neural network inherently prunes the smaller weights by setting them to zero .",
        "recent works using artificial neural networks based on word distributed representation greatly boost the performance of various natural language learning tasks , especially question answering .",
        "in this paper , we propose to straightforwardly model sentences by means of character sequences , and then utilize convolutional neural networks to integrate character embedding learning together with point - wise answer selection training .",
        "with the rise of big data sets , the popularity of kernel methods declined and neural networks took over again .",
        "however , such symbolic operations break the differentiability of the system and prevent end - to - end training of neural dialogue agents .",
        "we describe the class of convexified convolutional neural networks ( ccnns ) , which capture the parameter sharing of convolutional neural networks in a convex manner .",
        "for learning two - layer convolutional neural networks , we prove that the generalization error obtained by a convexified cnn converges to that of the best possible cnn .",
        "empirically , ccnns achieve performance competitive with cnns trained by backpropagation , svms , fully - connected neural networks , stacked denoising auto - encoders , and other baseline methods .",
        "attention - based encoder - decoder neural network models have recently shown promising results in machine translation and speech recognition .",
        "in this work , we propose an attention - based neural network model for joint intent detection and slot filling , both of which are critical steps for many speech understanding and dialog systems .",
        "predictive coding ( pdc ) has recently attracted attention in the neuroscience and computing community as a candidate unifying paradigm for neuronal studies and artificial neural network implementations particularly targeted at unsupervised learning systems .",
        "the mismatch negativity ( mmn ) has also recently been studied in relation to pc and found to be a useful ingredient in neural predictive coding systems .",
        "however , most neural systems still do not account for large number of synapses even though this has been shown by a few machine learning researchers as an effective and very important component of any neural system if such a system is to behave properly .",
        "our major point here is that pdc systems with the mmn effect in addition to a large number of synapses can greatly improve any neural learning system ' s performance and ability to make decisions in the machine world .",
        "in this paper , we describe a recurrent neural network ( rnn ) model that jointly performs intent detection , slot filling , and language modeling .",
        "the neural network model keeps updating the intent estimation as word in the transcribed utterance arrives and uses it as contextual features in the joint model .",
        "learning both hierarchical and temporal representation has been among the long - standing challenges of recurrent neural networks .",
        "multiscale recurrent neural networks have been considered as a promising approach to resolve this issue , yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence .",
        "in this paper , we propose a novel multiscale approach , called the hierarchical multiscale recurrent neural networks , which can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism .",
        "our approach effectively captures the multimodal semantics of queries and videos using state - of - the - art deep neural networks and creates a summary that is both semantically coherent and visually attractive .",
        "computation is classically studied in terms of automata , formal languages and algorithms ; yet , the relation between neural dynamics and symbolic representations and operations is still unclear in traditional eliminative connectionism .",
        "therefore , we suggest a unique perspective on this central issue , to which we would like to refer as to transparent connectionism , by proposing accounts of how symbolic computation can be implemented in neural substrates .",
        "finally , we present a mapping between nonlinear dynamical automata and recurrent artificial neural networks .",
        "in this work , the goal is to predict the score of food reviews on a scale of 1 to 5 with two recurrent neural networks that are carefully tuned .",
        "for a more robust and accurate approach , we propose the light weight convolutional neural networks , an end to end system , for estimating human body orientation .",
        "through theoretical analysis , we reveal an inherent connection between this model and recurrent neural networks , and thereon derive an approximated feed - forward network that couples multiple rnns along opposite directions .",
        "this formulation combines the expressive power of deep neural networks and the cyclic dependency structure of mrf in a unified model , bringing the modeling capability to a new level .",
        "in this work we introduce a convolutional neural network ( cnn ) that jointly handles low - , mid - , and high - level vision tasks in a unified architecture that is trained end - to - end .",
        "to bring learning models into this new paradigm , a novel elaboration of standard architectures called the competitive overcomplete output layer ( cool ) neural network is introduced .",
        "experiments demonstrate the effectiveness of cool by applying it to fooling , separable concept learning , one - class neural networks , and standard classification benchmarks .",
        "our approach is based on a deep neural network architecture that ingests curated article information such as tags and images , and is trained to predict sales for a large set of frequent customers .",
        "we also explain how neural networks fit into our framework , although the current implementation does not scale to provide guarantees for real - world neural networks .",
        "we use a convolutional neural network to determine sentiment and participate in all subtasks , i .",
        "we use a convolutional neural network ( cnn ) for both aspect extraction and aspect - based sentiment analysis .",
        "recently recurrent neural networks ( rnn ) obtained strong results on nlu due to their superior ability of preserving sequential information over time .",
        "we describe a novel approach to stride length estimation that uses deep convolutional neural networks to map stride - specific inertial sensor data to the resulting stride length .",
        "to overcome this , we present a method to translate the abstract information provided by wearable sensors to context - related expert features based on deep convolutional neural networks .",
        "a generic and scalable reinforcement learning scheme for artificial neural networks is presented , providing a general purpose learning machine .",
        "we present a dependency parser implemented as a single deep neural network that reads orthographic representations of words and directly generates dependencies and their labels .",
        "this paper introduces wavenet , a deep neural network for generating raw audio waveforms .",
        "we describe microsoft ' s conversational speech recognition system , in which we combine recent developments in neural - network - based acoustic and language modeling to advance the state of the art on the switchboard recognition task .",
        "inspired by machine learning ensemble techniques , the system uses a range of convolutional and recurrent neural networks .",
        "since deep neural networks are powerful models that have achieved excellent performance over many difficult tasks , in this paper , we propose to use the long short - term memory ( lstm ) encoder - decoder model for sentence level ts , which makes minimal assumptions about word sequence .",
        "to accurately capture the fine grained nonlinear coevolution of these features , we propose a recurrent coevolutionary feature embedding process model , which combines recurrent neural network ( rnn ) with a multidimensional point process model .",
        "recurrent neural network ( rnn ) based character - level language models ( clms ) are extremely useful for modeling unseen words by nature .",
        "convolutional neural networks ( cnns ) were recently shown to provide state - of - the - art results for object category viewpoint estimation .",
        "the attention mechanism is an important part of the neural machine translation ( nmt ) where it was reported to produce richer source representation compared to fixed - length encoding sequence - to - sequence models .",
        "the attention mechanisim is appealing for neural machine translation , since it is able to dynam - ically encode a source sentence by generating a alignment between a target word and source words .",
        "we introduce a convolutional recurrent neural network ( crnn ) for music tagging .",
        "crnns take advantage of convolutional neural networks ( cnns ) for local feature extraction and recurrent neural networks for temporal summarisation of the extracted features .",
        "in this paper a character - based encoder - decoder model has been proposed that consists of two recurrent neural networks .",
        "the encoder is a bidirectional recurrent neural network that encodes a sequence of symbols into a fixed - length vector representation , and the decoder generates the target sequence using an attention - based recurrent neural network .",
        "we propose an approximate strategy to efficiently train neural network based language models over very large vocabularies .",
        "many success stories involving deep neural networks are instances of supervised learning , where available labels power gradient - based learning methods .",
        "we present a new approach for neural machine translation ( nmt ) using the morphological and grammatical decomposition of the words ( factors ) in the output side of the neural network .",
        "the model employs a convolutional network for text and layout recognition in tandem with an attention - based neural machine translation system .",
        "many research works have successfully extended algorithms such as evolutionary algorithms , reinforcement agents and neural networks using \" opposition - based learning \" ( obl ) .",
        "in this paper , we introduce an approach to learn type - ii opposites from the given inputs and their outputs using the artificial neural networks ( anns ) .",
        "then we propose a select - additive learning ( sal ) procedure that improves the generalizability of trained discriminative neural networks .",
        "we make a step towards a general learning - based solution that can be adapted to specific situations and present a metric based on a convolutional neural network .",
        "deep reinforcement learning ( drl ) brings the power of deep neural networks to bear on the generic task of trial - and - error learning , and its effectiveness has been convincingly demonstrated on tasks such as atari video games and the game of go .",
        "in this paper , we propose an end - to - end reinforcement learning architecture comprising a neural back end and a symbolic front end with the potential to overcome each of these shortcomings .",
        "inspired by the recent success of deep reinforcement learning , we present neural - based models that jointly learn a policy and the behavior of opponents .",
        "we introduce a new approach to supervising neural networks by specifying constraints that should hold over the output space , rather than direct examples of input - output pairs .",
        "we are able to train a convolutional neural network to detect and track objects without any labeled examples .",
        "we instead propose to build graphs over the scene objects and over the question words , and we describe a deep neural network that exploits the structure in these representations .",
        "recently , recurrent neural networks ( rnn ) based methods have been successfully applied in several sequential modeling tasks .",
        "in this paper , we propose a novel model , named context - aware recurrent neural networks ( ca - rnn ) .",
        "this paper advances the design of ctc - based all - neural ( or end - to - end ) speech recognizers .",
        "with the availability of large annotated data , neural network models have recently advanced the field significantly .",
        "deep neural networks have achieved remarkable results across many language processing tasks , however these methods are highly sensitive to noise and adversarial attacks .",
        "empirical evaluation over a range of sentiment datasets with a convolutional neural network shows that , compared to a baseline model and the dropout method , our method achieves superior performance over noisy inputs and out - of - domain data .",
        "this paper presents an overview of political event data , including methods and ontologies , and a set of experiments to determine the applicability of deep neural networks to the extraction of political events from news text .",
        "a convolutional recurrent neural network is trained to predict depth from monocular video input , which , along with the current video image and the camera trajectory , can then be used to compute the next frame .",
        "to mimic the repeated reading strategy , we propose the neural networks with multi - level attention ( nnma ) , combining the attention mechanism and external memories to gradually fix the attention on some specific words helpful to judging the discourse relations .",
        "neural machine translation ( nmt ) becomes a new state - of - the - art and achieves promising translation results using a simple encoder - decoder neural network .",
        "this neural network is trained once on the parallel corpus and the fixed network is used to translate all the test sentences .",
        "convolutional neural networks ( cnns ) have demonstrated superior capability for extracting information from raw signals in computer vision .",
        "deep neural networks are learning models with a very high capacity and therefore prone to over - fitting .",
        "softtarget regularization proved to be an effective tool in various neural network architectures .",
        "we investigate the ' digital synaptic neural substrate ' ( dsns ) computational creativity approach further with respect to the size and quality of images that can be used to seed the process .",
        "more specifically , for each image of an entity , we construct image - based representations via a neural image encoder , and these representations with respect to multiple image instances are then integrated via an attention - based method .",
        "we introduce a method to train quantized neural networks ( qnns ) - - - neural networks with extremely low precision ( e .",
        "quantized recurrent neural networks were tested over the penn treebank dataset , and achieved comparable accuracy as their 32 - bit counterparts using only 4 - bits .",
        "given each reference sentence of an entity , we first utilize recurrent neural network with pooling or long short - term memory network to encode the semantic information of the sentence with respect to the entity .",
        "specifically , we propose using fully convolutional neural networks , which consist of lesser number of parameters than fully connected networks .",
        "this paper presents the input convex neural network architecture .",
        "these are scalar - valued ( potentially deep ) neural networks with constraints on the network parameters such that the output of the network is a convex function of ( some of ) the inputs .",
        "we show that many existing neural network architectures can be made input - convex with only minor modification , and develop specialized optimization algorithms tailored to this setting .",
        "new output neurons corresponding to new labels are added and the neural network connections and parameters are automatically restructured as if the label has been introduced from the beginning .",
        "neural network based models have achieved impressive results on various specific tasks .",
        "more specifically , we augment neural model with an external memory , which is shared by several tasks .",
        "we use dependency parsing and lstm recurrent neural network to predict a set of sound concepts for a given acoustic scene .",
        "we present the first reinforcement - learning model to self - improve its reward - modulated training implemented through a continuously improving \" intuition \" neural network .",
        "an agent was trained how to play the arcade video game pong with two reward - based alternatives , one where the paddle was placed randomly during training , and a second where the paddle was simultaneously trained on three additional neural networks such that it could develop a sense of \" certainty \" as to how probable its own predicted paddle position will be to return the ball .",
        "if the agent was less than 95 % certain to return the ball , the policy used an intuition neural network to place the paddle .",
        "through this , we found that the reinforcement learning model that uses an intuition neural network for placing the paddle during reward training quickly overtakes the simple architecture in its ability to outplay the near - perfect opponent , additionally outscoring that opponent by an increasingly wide margin after additional epochs of training .",
        "we propose a neural network approach to price eu call options that significantly outperforms some existing pricing models and comes with guarantees that its predictions are economically reasonable .",
        "to achieve this , we introduce a class of gated neural networks that automatically learn to divide - and - conquer the problem space for robust and accurate pricing .",
        "to address this issue , we build inference chains between two target entities via intermediate entities , and propose a path - based neural relation extraction model to encode the relational semantics from both direct sentences and inference chains .",
        "we developed a character - level neural network for this task .",
        "for this reason , this paper investigates the effectiveness of contemporary recurrent neural architectures - the elman and jordan networks and the bidirectional lstm with crf decoding - at performing dnr straight from the text .",
        "in this work , we compare standard phrase - based and neural systems on arabic - hebrew translation .",
        "we experiment with tokenization by external tools and sub - word modeling by character - level neural models , and show that both methods lead to improved translation performance , with a small advantage to the neural models .",
        "learning based on networks of real neurons , and by extension biologically inspired models of neural networks , has yet to find general learning rules leading to widespread applications .",
        "in this paper , we argue for the existence of a principle allowing to steer the dynamics of a biologically inspired neural network .",
        "we show that lsa has a higher explanatory power than existing hypotheses about the response of biological neural networks to external simulation , and can be used as a learning rule for an embodied application : learning of wall avoidance by a simulated robot .",
        "the surge in popularity of artificial neural networks is mostly directed to disembodied models of neurons with biologically irrelevant dynamics : to the authors ' knowledge , this is the first work demonstrating sensory - motor",
        "in this paper we examine learning methods combining the random neural network , a biologically inspired neural network and the extreme learning machine that achieve state of the art classification performance while requiring much shorter training time .",
        "the random neural network is a integrate and fire computational model of a neural network whose mathematical structure permits the efficient analysis of large ensembles of neurons .",
        "neural machine translation ( nmt ) heavily relies on word level modelling to learn semantic representations of input sentences .",
        "to handle these issues , we propose word - lattice based recurrent neural network ( rnn ) encoders for nmt , which generalize the standard rnn to word lattice topology .",
        "implementing an accurate and fast activation function with low cost is a crucial aspect to the implementation of deep neural networks ( dnns ) on fpgas .",
        "recent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies .",
        "we introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier .",
        "our best - performing models are segmental ( semi - markov ) conditional random fields using deep neural network - based features .",
        "the multi - signer setting is much more challenging , but with neural network adaptation we achieve up to 83 % letter accuracies in this setting .",
        "we propose a highly structured neural network architecture for semantic segmentation of images that combines i ) a haar wavelet - based tree - like convolutional neural network ( cnn ) , ii ) a random layer realizing a radial basis function kernel approximation , and iii ) a linear classifier .",
        "these vectors are incorporated into a neural structured prediction model , which captures structural constraints that are inherent in the entity linking task .",
        "in an extremely low - resource scenario , our model performs significantly better than both a neural model and a strong baseline .",
        "neural machine translation ( nmt ) is an end - to - end learning approach for automated translation , with the potential to overcome many of the weaknesses of conventional phrase - based translation systems .",
        "in this work , we present gnmt , google ' s neural machine translation system , which attempts to address many of these issues .",
        "this paper proposes new nonnegative ( shallow and multi - layer ) autoencoders by combining the model of spiking random neural network ( rnn ) , the network architecture in the deep - learning area and the training technique in the nonnegative matrix factorization ( nmf ) area .",
        "we introduce an online neural sequence to sequence model that learns to alternate between encoding and decoding segments of the input as it is read .",
        "our results show that neural network - based models underperform when the data is small , and that the most reliable model over data of varying sizes and frequency ranges is the inverted factorized model .",
        "with the fast development of deep learning , people have started to train very big neural networks using massive data .",
        "based on the database and another two free data resources ( thchs30 and the cmu dictionary ) , a speech recognition ( asr ) baseline was constructed with the deep neural network - hidden markov model ( dnn - hmm ) hybrid system .",
        "experimental results show that the proposed method delivers substantial performance improvement over the baseline system , especially when a deep neural network ( dnn ) is used as the decision maker , and the dnn input involves some statistical features derived from the cohort scores .",
        "the model is based on a multi - task recurrent neural network where the output of one task is fed as the input of the other , leading to a collaborative learning framework that can improve both language and speaker recognition by borrowing information from each other .",
        "in this abstract we present an investigation in learning genomic representations with neural networks to predict patient survival in cancer .",
        "in this paper we instead apply reinforcement learning to directly optimize a neural mention - ranking model for coreference evaluation metrics .",
        "we present a neural network architecture to predict a point in color space from the sequence of characters in the color ' s name .",
        "recurrent neural networks ( rnns ) have shown clear superiority in sequence modeling , particularly the ones with gated units , such as long short - term memory ( lstm ) and gated recurrent unit ( gru ) .",
        "in this work , we present the first results for neuralizing an unsupervised hidden markov model .",
        "we introduce a novel tracking system based on similarity mapping by enhanced siamese neural network ( esnn ) , which accounts for both appearance and geometric information , and is trainable end - to - end .",
        "recurrent neural networks have achieved state - of - the - art results for many problems in nlp and two most popular rnn architectures are tail model and pooling model .",
        "inspired by the recently presented deeptracking approach [ ondruska , 2016 ] , we employ a recurrent neural network ( rnn ) to capture the temporal evolution of the state of the environment , and propose to use spatial transformer modules to exploit estimates of the egomotion of the vehicle .",
        "we experiment several cross - lingual annotation projection methods using recurrent neural networks ( rnn ) models .",
        "for this , we develop a novel contextual generative adversarial network based on recurrent neural networks ( context - rnn - gans ) , where both the generator and the discriminator modules are based on contextual history ( modeled as rnns ) and the adversarial discriminator guides the generator to produce realistic images for the particular time step in the image sequence .",
        "in the proposed approach , we segment and label multiple views of a scene with a fully convolutional neural network , and then fit pre - scanned 3d object models to the resulting segmentation to get the 6d object pose .",
        "training a deep neural network for segmentation typically requires a large amount of training data .",
        "the system drastically improves learning in a range of deep neural networks on various data - sets in comparison to non - cpn neural networks .",
        "neural encoder - decoder models have shown great success in many sequence generation tasks .",
        "in this paper , we propose methods for controlling the output sequence length for neural encoder - decoder models : two decoding - based methods and two learning - based methods .",
        "we introduce a unified algorithm to efficiently learn a broad class of linear and non - linear state space models , including variants where the emission and transition distributions are modeled by deep neural networks .",
        "our learning algorithm simultaneously learns a compiled inference network and the generative model , leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution .",
        "recent work on improving the efficiency of neural translation models adopted a similar strategy by restricting the output vocabulary to a subset of likely candidates given the source .",
        "this brings the time to decode with a state of the art neural translation system to just over 140 msec per sentence on a single cpu core for english - german .",
        "more specifically , we employ the framework of the residual neural networks to model the temporal closeness , period , and trend properties of the crowd traffic , respectively .",
        "st - resnet learns to dynamically aggregate the output of the three residual neural networks based on data , assigning different weights to different branches and regions .",
        "in this work , we propose very deep convolutional neural networks ( cnns ) that directly use time - domain waveforms as inputs .",
        "we propose a neural machine translation ( nmt ) framework for simultaneous translation in which an agent learns to make decisions on when to translate from the interaction with a pre - trained nmt environment .",
        "the model and the neural architecture reflect the time , space and color structure of video tensors and encode it as a four - dimensional dependency chain .",
        "in this paper , a neural network based real - time speech recognition ( sr ) system is developed using an fpga for very low - power operation .",
        "the implemented system employs two recurrent neural networks ( rnns ) ; one is a speech - to - character rnn for acoustic modeling ( am ) and the other is for character - level language modeling ( lm ) .",
        "by applying deep recurrent neural networks we learn to discriminate between several application layer traffic types on top of a constant envelope modulation without using an expert demodulation algorithm .",
        "in this paper , we develop a chinese event extraction system that uses word embedding vectors to represent language , and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering .",
        "in this paper , we propose to use deep neural network ( dnn ) to address two types of information needs of response organizations : 1 ) identifying informative tweets and 2 ) classifying them into topical classes .",
        "in this tutorial , we build a neural - based approach to answer questions about images .",
        "in this paper we provide the largest published comparison of translation quality for phrase - based smt and neural machine translation across 30 translation directions .",
        "in the second part of the paper we investigate aspects of translation speed , introducing amunmt , our efficient neural machine translation decoder .",
        "we demonstrate that current neural machine translation could already be used for in - production systems when comparing words - per - second ratios .",
        "we study how approximation errors of neural networks with relu activation functions depend on the depth of the network .",
        "deep learning is a branch of artificial intelligence employing deep neural network architectures that has significantly advanced the state - of - the - art in computer vision , speech recognition , natural language processing and other domains .",
        "and then we investigate the advancement of multi - view representation learning that ranges from shallow methods including multi - modal topic learning , multi - view sparse coding , and multi - view latent space markov networks , to deep methods including multi - modal restricted boltzmann machines , multi - modal autoencoders , and multi - modal recurrent neural networks .",
        "sample complexity and safety are major challenges when learning policies with reinforcement learning for real - world tasks - - especially when the policies are represented using rich function approximators like deep neural networks .",
        "as another improvement , it uses deep neural networks for joint - speaker identification and gain estimation which makes these two steps easier than before producing competitive results for these steps .",
        "we introduce a neural network model that marries together ideas from two prominent strands of research on domain adaptation through representation learning : structural correspondence learning ( scl , ( blitzer et al .",
        ", 2006 ) ) and autoencoder neural networks .",
        "particularly , our model is a three - layer neural network that learns to encode the nonpivot features of an input example into a low - dimensional representation , so that the existence of pivot features ( features that are prominent in both domains and convey useful information for the nlp task ) in the example can be decoded from that representation .",
        "learning - based exploration methods , including convolutional neural networks , provide excellent strategies without human - designed logic for the feature extraction .",
        "on this study , we perform the ability of 1d convolutional neural network ( 1dcnn ) to construct classification model that can distinguish the eeg and eog stroke data from eeg and eog control data .",
        "the word denoising embeddings are obtained by strengthening salient information and weakening noise in the original word embeddings , based on a deep feed - forward neural network filter .",
        "however , implementation strategy of metaheuristic for accuracy improvement on convolution neural networks ( cnn ) , a famous deep learning method , is still rarely investigated .",
        "deep neural networks have proven to be quite effective in a wide variety of machine learning tasks , ranging from improved speech recognition systems to advancing the development of autonomous vehicles .",
        "these samples are constructed by manipulating real examples from the training data distribution in order to \" fool \" the original neural model , resulting in misclassification ( with high confidence ) of previously correctly classified samples .",
        "addressing this weakness is of utmost importance if deep neural architectures are to be applied to critical applications , such as those in the domain of cybersecurity .",
        "in this paper , we present an analysis of this fundamental flaw lurking in all neural architectures to uncover limitations of previously proposed defense mechanisms .",
        "more importantly , we present a unifying framework for protecting deep neural models using a non - invertible data transformation - - developing two adversary - resilient architectures utilizing both linear and nonlinear dimensionality reduction .",
        ", hidden - state crf ( hcrf ) and latent - dynamic crf ( ldcrf ) ; and conditional neural fields ( cnf ) and its variant ( ldcnf ) .",
        "using state of the art convolutional neural networks , we provide impressive baseline performances at scene classification .",
        "garnett , editors , advances in neural information processing systems 28 , pages 2116 - - 2124 .",
        "parallel implementations of stochastic gradient descent ( sgd ) have received significant research attention , thanks to excellent scalability properties of this algorithm , and to its efficiency in the context of training deep neural networks .",
        "in this paper , we present a simple and efficient method for training deep neural networks in a semi - supervised setting where only a small portion of training data is labeled .",
        "in this paper , we proposed the adaptive convolutional elm method ( acnnelm ) as enhancement of convolutional neural network ( cnn ) with a hybrid extreme learning machine ( elm ) model plus adaptive capability .",
        "we propose a technique for making convolutional neural network ( cnn ) - based models more transparent by visualizing the regions of input that are \" important \" for predictions from these models - or visual explanations .",
        "neural sequence models are widely used to model time - series data in many fields .",
        "we describe recurrent neural networks ( rnns ) , which have attracted great attention on sequential tasks , such as handwriting recognition , speech recognition and image to text .",
        "however , compared to general feedforward neural networks , rnns have feedback loops , which makes it a little hard to understand the backpropagation step .",
        "we present an interpretable neural network approach to predicting and understanding politeness in natural language requests .",
        "our models are based on simple convolutional neural networks directly on raw text , avoiding any manual identification of complex sentiment or syntactic features , while performing better than such feature - based models from previous work .",
        "further , this analysis reveals multiple novel , high - scoring politeness strategies which , when added back as new features , reduce the accuracy gap between the original featurized system and the neural model , thus providing a clear quantitative interpretation of the success of these neural networks .",
        "for this purpose , we explore the vgg - 16 and k - cnn convolutional neural networks to extract visual features from the image .",
        "we describe an attentive encoder that combines tree - structured recursive neural networks and sequential recurrent neural networks for modelling sentence pairs .",
        "we introduce a neural machine translation ( nmt ) model that maps a source character sequence to a target character sequence without any segmentation .",
        "in this paper , we propose a novel neural approach for paraphrase generation .",
        "towards this goal , we leverage the power of recurrent neural networks and multimodal information present in the interaction , and propose a predictive model to recognize social norm violation .",
        "we then \" translate \" this information into a natural language instruction using a neural sequence - to - sequence model that learns to generate free - form instructions from natural language corpora .",
        "long short - term memory ( lstm ) recurrent neural networks ( rnns ) have been shown to give state - of - the - art performance on many speech recognition tasks , as they are able to provide the learned dynamically changing contextual window of all sequence history .",
        "on the other hand , the convolutional neural networks ( cnns ) have brought significant improvements to deep feed - forward neural networks ( ffnns ) , as they are able to better reduce spectral variation in the input signal .",
        "in this paper , a network architecture called as convolutional recurrent neural network ( crnn ) is proposed by combining the cnn and lstm rnn .",
        "recently , attempts have been made to remove gaussian mixture models ( gmm ) from the training process of deep neural network - based hidden markov models ( hmm / dnn ) .",
        "we present a model of visually - grounded language learning based on stacked gated recurrent neural networks which learns to predict visual features given an image description in the form of a sequence of phonemes .",
        "we present deep variational canonical correlation analysis ( vcca ) , a deep multi - view learning model that extends the latent variable model interpretation of linear cca ~ \\ citep { bachjordan05a } to nonlinear observation models parameterized by deep neural networks ( dnns ) .",
        "our approach uses a novel convolutional neural network ( cnn ) architecture , that only needs volume - level labels to be trained to automatically asses whether an oct volume is healthy or contains amd .",
        "in this work we implement a training of a language model ( lm ) , using recurrent neural network ( rnn ) and glove word embeddings , introduced by pennigton et al .",
        "we develop several strong baselines , relying on logistic regression and state - of - the - art recurrent neural networks .",
        "we propose a neural - network based model for coordination boundary prediction .",
        "neural networks are among the state - of - the - art techniques for language modeling .",
        "existing neural language models typically map discrete words to distributed , dense vector representations .",
        "in this paper , we propose to compress neural language models by sparse word representations .",
        "the proposed architecture uses a convolutional neural network for the sentence representation and a long - short term memory network for the context representation .",
        "recently there has been much interest in understanding why deep neural networks are preferred to shallow networks .",
        "first , we consider univariate functions on a bounded interval and require a neural network to achieve an approximation error of $ \\ varepsilon $ uniformly over the interval .",
        "our results are derived for neural networks which use a combination of rectifier linear units ( relus ) and binary step units",
        "we propose low - rank bilinear neural networks using hadamard product ( element - wise multiplication ) , commonly implemented in many scientific computing frameworks .",
        "a feed - forward neural network based methodology is adopted in this paper .",
        "the multi - layer perceptron ( mlp ) neural network model was trained using matlab .",
        "2953 m has been achieved with a 12 - 12 - 2 neural network structure .",
        "to recover the ` clustering - friendly ' latent representations and to better cluster the data , we propose a joint dr and k - means clustering approach in which dr is accomplished via learning a deep neural network ( dnn ) .",
        "the motivation is to keep the advantages of jointly optimizing the two tasks , while exploiting the deep neural network ' s ability to approximate any nonlinear function .",
        "in this paper , we propose a novel approach for word level quality estimation using recurrent neural network language model ( rnn - lm ) architecture .",
        "recently , neural networks have achieved great success on sentiment classification due to their ability to alleviate feature engineering .",
        "to address this problem , we present a cached long short - term memory neural networks ( clstm ) to capture the overall semantic information in long texts .",
        "conventional attention - based neural machine translation ( nmt ) conducts dynamic alignment in generating the target sentence .",
        "and neural machine translator with our interactive attention can outperform the open source attention - based nmt system groundhog by 4 .",
        "neural machine translation ( nmt ) is a new approach to machine translation that has made great progress in recent years .",
        "recently , the development of neural machine translation ( nmt ) has significantly improved the translation quality of automatic machine translation .",
        "the key to our system ' s performance is the systematic use of convolutional and lstm neural networks , combined with a novel spatial smoothing method and lattice - free mmi acoustic training .",
        "the proposed methods are evaluated on the application of training a deep neural network to perform image classification .",
        "since the first online demonstration of neural machine translation ( nmt ) by lisa , nmt development has recently moved from laboratory to production systems as demonstrated by several entities announcing roll - out of nmt engines to replace their existing technologies .",
        "conventional deep neural networks ( dnn ) for speech acoustic modeling rely on gaussian mixture models ( gmm ) and hidden markov model ( hmm ) to obtain binary class labels as the targets for dnn training .",
        "morden state - of - the - art speech recognition systems usually employ neural networks for acoustic modeling .",
        "however , compared to the conventional gaussian mixture models , deep neural network ( dnn ) based acoustic models usually have much larger number of model parameters , making it challenging for their applications in resource constrained platforms such as mobile devices .",
        "in this paper , we study the application of the recently proposed highway deep neural network ( hdnn ) for training small - footprint acoustic models .",
        "hdnn is a type of depth - gated feedforward neural network , which introduces two type of gate functions to facilitate the information flow through different layers .",
        "until recently , research on artificial neural networks was largely restricted to systems with only two types of variable : neural activities that represent the current or recent input and weights that learn to capture regularities among inputs , outputs and payoffs .",
        "synapses have dynamics at many different time - scales and this suggests that artificial neural networks might benefit from variables that change slower than activities but much faster than the standard weights .",
        "these \" fast weights \" can be used to store temporary memories of the recent past and they provide a neurally plausible way of implementing the type of attention to the past that has recently proved very helpful in sequence - to - sequence models .",
        "by using fast weights we can avoid the need to store copies of neural activity patterns .",
        "this paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into convolutional neural networks .",
        "in this paper , we investigate how grounded and conditional extensions to standard neural language models can bring improvements in the tasks of word prediction and completion .",
        "though this is not normally a problem for a neural network designed for a specific task , such a bound is undesirable for a system that continually learns over an open range of domains .",
        "an enfn distinctive feature is its computational simplicity compared to other artificial neural networks and neuro - fuzzy systems .",
        "a new architecture and learning algorithms for the multidimensional hybrid cascade neural network with neuron pool optimization in each cascade are proposed in this paper .",
        "the developed system combines reinforcement learning with a neural network for learning to predict the possible outcomes of its actions .",
        "this year , the nara institute of science and technology ( naist ) / carnegie mellon university ( cmu ) submission to the japanese - english translation track of the 2016 workshop on asian translation was based on attentional neural machine translation ( nmt ) models .",
        "most existing neural machine translation models use groups of characters or whole words as their unit of input and output .",
        "we parameterize our model as a convolutional neural network that predicts discrete substitutions to an existing translation based on an attention mechanism over both the source sentence as well as the current translation output .",
        "we experiment with various models including a neural generative model as well as a semantic graph matching one .",
        "experiments on synthetic data and deep neural networks validate our theory , demonstrating the effectiveness and scalability of sg - mcmc with stale gradients .",
        "we ask whether neural networks can learn to use secret keys to protect information from other neural networks .",
        "thus , a system may consist of neural networks named alice and bob , and we aim to limit what a third neural network named eve learns from eavesdropping on the communication between alice and bob .",
        "we do not prescribe specific cryptographic algorithms to these neural networks ; instead , we train end - to - end , adversarially .",
        "we demonstrate that the neural networks can learn how to perform forms of encryption and decryption , and also how to apply these operations selectively in order to meet confidentiality goals .",
        "we quantify a source of ineffectual computations when processing the multiplications of the convolutional layers in deep neural networks ( dnns ) and propose pragmatic ( pra ) , an architecture that exploits it improving performance and energy efficiency .",
        "generative approaches , typically based on recurrent neural networks ( rnns ) , can synthesize new replies , but they suffer from the problem of generating short , meaningless utterances .",
        "in our approach , the retrieved candidate , in addition to the original query , is fed to an rnn - based reply generator , so that the neural model is aware of more information .",
        "these models have broad applications in image registration , and they are a fundamental aspect of novel machine vision or deep learning algorithms , such as convolutional neural networks ( cnn ) , which perform shift and scale invariant functions followed by classification .",
        "deconvolutional networks fully exploit the advantage the powerful expressiveness of deep neural networks in the manner of unsupervised learning .",
        "neural machine translation ( nmt ) has become the new state - of - the - art in several language pairs .",
        "we propose a novel method of regularization for recurrent neural networks called suprisal - driven zoneout .",
        "we analyze the performance of encoder - decoder neural models and compare them with well - known established methods .",
        "we explore the suitability of a deep neural network architecture for this task , particularly a deep bi - lstm network applied on a character level .",
        "we propose a neural architecture that is composed of two modules trained jointly : a recurrent neural network ( rnn ) module and a structured prediction model .",
        "recently , distributed representation of sentences learned by neural models from unlabeled data has been shown to outperform the traditional bag - of - words representation .",
        "a general purpose image segmentation approach is used , including two feature learning algorithms ; multi - scale multi - layered perceptrons ( mlp ) and convolutional neural networks ( cnn ) .",
        "in the second part we implement a convolutional neural network trained on top of pre - trained word vectors .",
        "we view the lambada task as a reading comprehension problem and apply off - the - shelf comprehension models based on neural networks .",
        "we analyze 100 instances , finding that neural network readers perform well in cases that involve selecting a name from the context based on dialogue or discourse cues but struggle when coreference resolution or external knowledge is needed .",
        "distributed representation learned with neural networks has recently shown to be effective in modeling natural languages at fine granularities such as words , phrases , and even sentences .",
        "this paper aims to enhance neural network models for such a purpose .",
        "in this paper , we propose neural models to train computers not just to pay attention to specific regions and content of input documents with attention models , but also distract them to traverse between different content of a document so as to better grasp the overall meaning for summarization .",
        "in this paper , we employ knowledge - based approaches that also exploit recent advances in neural word / concept embeddings to improve over the state - of - the - art in biomedical wsd using the msh wsd dataset as the test set .",
        "several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years .",
        "attention has improved image classification , image captioning , speech recognition , generative models , and learning algorithmic tasks , but it had probably the largest impact on neural machine translation .",
        "in this work , we develop models based on a pre - trained convolutional neural network for extracting sentiment , emotion and personality features for sarcasm detection .",
        "while convolutional neural networks can categorize scenes well , they also learn an intermediate representation not aligned across modalities , which is undesirable for cross - modal transfer applications .",
        "we present methods to regularize cross - modal convolutional neural networks so that they have a shared representation that is agnostic of the modality .",
        "neural networks augmented with external memory have the ability to learn algorithmic solutions to complex tasks .",
        "as well , we show how our approach can be adapted for models that maintain temporal associations between memories , as with the recently introduced differentiable neural computer .",
        "in second part the article describes a research carried out with the data collected from quench detection system by means of using an lstm recurrent neural network .",
        "the optimization problem behind neural networks is highly non - convex .",
        "in contrast we show under quite weak assumptions on the data that a particular class of feedforward neural networks can be trained globally optimal with a linear convergence rate with our nonlinear spectral method .",
        "recurrent neural networks ( rnns ) have become the state - of - the - art choice for extracting patterns from temporal sequences .",
        "this paper demonstrates that neural sequence - to - sequence models obtain state of the art or close to state of the art results on existing datasets .",
        "a biological neural network is constituted by numerous subnetworks and modules with different functionalities .",
        "for an artificial neural network , the relationship between a network and its subnetworks is also important and useful for both theoretical and algorithmic research , i .",
        "in this paper we explore the relationship between an elm neural network and its subnetworks .",
        "to the best of our knowledge , we are the first to prove a theorem that shows an elm neural network can be scattered into subnetworks and its optimal solution can be constructed recursively by the optimal solutions of these subnetworks .",
        "based on the theorem we also present two algorithms to train a large elm neural network efficiently : one is a parallel network training algorithm and the other is an incremental network training algorithm .",
        "the learning capability of a neural network improves with increasing depth at higher computational costs .",
        "we propose feature map and kernel level pruning for reducing the computational complexity of a deep convolutional neural network .",
        "building large models with parameter sharing accounts for most of the success of deep convolutional neural networks ( cnns ) .",
        "in this paper , we propose doubly convolutional neural networks ( dcnns ) , which significantly improve the performance of cnns by further exploring this idea .",
        "in this paper we describe an end to end neural model for named entity recognition ner ) which is based on bi - directional rnn - lstm ' s .",
        "we provide a depth - based separation result for feed - forward relu neural networks , showing that a wide family of non - linear , twice - differentiable functions on $ [ 0 , 1 ] ^ d $ , which can be approximated to accuracy $ \\ epsilon $ by relu networks of depth and width $ \\ mathcal { o } ( \\ text { poly } ( \\ log ( 1 / \\ epsilon ) ) ) $ , cannot be approximated to similar accuracy by constant - depth relu networks , unless their width is at least $ \\ omega ( 1 / \\ epsilon ) $ .",
        "in this paper , we propose a novel two - stage poetry generating method which first plans the sub - topics of the poem according to the user ' s writing intent , and then generates each line of the poem sequentially , using a modified recurrent neural network encoder - decoder framework .",
        "recurrent neural networks ( rnns ) have achieved state - of - the - art performances in many natural language processing tasks , such as language modeling and machine translation .",
        "we show that the ctc word models work very well as an end - to - end all - neural speech recognition model without the use of traditional context - dependent sub - word phone units that require a pronunciation lexicon , and without any language model removing the need to decode .",
        "this paper proposes dynamic chunk reader ( dcr ) , an end - to - end neural reading comprehension ( rc ) model that is able to extract and rank a set of answer candidates from a given document to answer questions .",
        "dcr is able to predict answers of variable lengths , whereas previous neural rc models primarily focused on predicting single tokens or entities .",
        "dcr encodes a document and an input question with recurrent neural networks , and then applies a word - by - word attention mechanism to acquire question - aware representations for the document , followed by the generation of chunk representations and a ranking module to propose the top - ranked chunk as the answer .",
        "we present a novel neural network algorithm , the tensor switching ( ts ) network , which generalizes the rectified linear unit ( relu ) nonlinearity to tensor - valued hidden units .",
        "we present a neural architecture for sequence processing .",
        "the bytenet is a stack of two dilated convolutional neural networks , one to encode the source sequence and one to decode the target sequence , where the target network unfolds dynamically to generate variable length outputs .",
        "the bytenet decoder attains state - of - the - art performance on character - level language modelling and outperforms the previous best results obtained with recurrent neural networks .",
        "the bytenet also achieves a performance on raw character - level machine translation that approaches that of the best neural translation models that run in quadratic time .",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "recent neural program induction approaches have attempted to address this problem , but are typically limited to differentiable memory , and consequently cannot scale beyond small synthetic tasks .",
        "in this work , we propose the manager - programmer - computer framework , which integrates neural networks with non - differentiable memory to support abstract , scalable and precise operations through a friendly neural computer interface .",
        "specifically , we introduce a neural symbolic machine , which contains a sequence - to - sequence neural \" programmer \" , and a non - differentiable \" computer \" that is a lisp interpreter with code assist .",
        "recurrent neural networks are powerful models for processing sequential data , but they are generally plagued by vanishing and exploding gradient problems .",
        "unitary recurrent neural networks ( urnns ) , which use unitary recurrence matrices , have recently been proposed as a means to avoid these issues .",
        "we propose a convolutional recurrent neural network , with winner - take - all dropout for high dimensional unsupervised feature learning in multi - dimensional time series .",
        "our contributions can be summarized as a scalable reinterpretation of the deep predictive coding networks trained end - to - end with backpropagation through time , an extension of the previously proposed winner - take - all autoencoders to sequences in time , and a new technique for initializing and regularizing convolutional - recurrent neural networks .",
        "we propose a framework for detecting action patterns from motion sequences and modeling the sensory - motor relationship of animals , using a generative recurrent neural network .",
        "we develop a multi - level sentiment - enriched word embedding learning method , which uses parallel asymmetric neural network to model n - gram , word level sentiment and tweet level sentiment in learning process .",
        "owing to these variations , the pedestrian data is distributed as highly - curved manifolds in the feature space , despite the current convolutional neural networks ( cnn ) ' s capability of feature extraction .",
        "deep models like deep neural networks , on the other hand , cannot be directly applied for the high - dimensional input because of the huge feature space .",
        "in this paper , we propose a product - based neural networks ( pnn ) with an embedding layer to learn a distributed representation of the categorical data , a product layer to capture interactive patterns between inter - field categories , and further fully connected layers to explore high - order feature interactions .",
        "while neural machine translation ( nmt ) is making good progress in the past two years , tens of millions of bilingual sentence pairs are needed for its training .",
        "this paper proposes a novel distributed vector representation of a document : a simple recurrent - neural - network language model ( rnn - lm ) or a long short - term memory rnn language model ( lstm - lm ) is first created from all documents in a task ; some of the lm parameters are then adapted by each document , and the adapted parameters are vectorized to represent the document .",
        "we introduce a powerful recurrent neural network based method for novelty detection to the application of detecting radio anomalies .",
        "specifically , we apply additive base kernels to subsets of output features from deep neural architectures , and jointly learn the parameters of the base kernels and deep network through a gaussian process marginal likelihood objective .",
        "neural networks ( nn ) have achieved state - of - the - art performance in various applications .",
        "one effective way to alleviate this problem is to exploit the bayesian approach by using bayesian neural networks ( bnn ) .",
        "to address these problems , we propose a class of probabilistic neural networks , dubbed natural - parameter networks ( npn ) , as a novel and lightweight bayesian treatment of nn .",
        "we propose novel methods of solving two tasks using convolutional neural networks , firstly the task of generating hdr map of a static scene using differently exposed ldr images of the scene captured using conventional cameras and secondly the task of finding an optimal tone mapping operator that would give a better score on the tmqi metric compared to the existing methods .",
        "we describe a framework for extracting common - sense knowledge for corpora , which is then used to construct a dataset for this ordinal entailment task , which we then use to train and evaluate a sequence to sequence neural network model .",
        "despite their advantages in terms of computational resources , latency , and power consumption , event - based implementations of neural networks have not been able to achieve the same performance figures as their equivalent state - of - the - art deep network models .",
        "the neural gpu is a recent model that can learn algorithms such as multi - digit binary addition and binary multiplication in a way that generalizes to inputs of arbitrary length .",
        "we show that there are two simple ways of improving the performance of the neural gpu : by carefully designing a curriculum , and by increasing model size .",
        "the latter requires careful memory management , as a naive implementation of the neural gpu is memory intensive .",
        "we find that these techniques to increase the set of algorithmic problems that can be solved by the neural gpu : we have been able to learn to perform all the arithmetic operations ( and generalize to arbitrarily long numbers ) when the arguments are given in the decimal representation ( which , surprisingly , has not been possible before ) .",
        "we have also been able to train the neural gpu to evaluate long arithmetic expressions with multiple operands that require respecting the precedence order of the operands , although these have succeeded only in their binary representation , and not with 100 \\ % accuracy .",
        "afterwards , a simple feedforward neural network is used to reject or predict entity label for each individual fragment .",
        "here , we are attempting to bridge this gap by mining the collective knowledge contained in recent deep learning research to discover underlying principles for designing neural network architectures .",
        "many models such as svm , random forest , and deep neural nets have been proposed and achieved great success .",
        "experimental results show that the neural network - based parsers perform significantly better than the traditional parsers .",
        "inspired by this work we present binary paragraph vectors , simple neural networks that learn short binary codes for fast information retrieval .",
        "the discrete traffic state encoding is used as input to a deep convolutional neural network , trained using q - learning with experience replay .",
        "our agent was compared against a one hidden layer neural network traffic signal control agent and reduces average cumulative delay by 82 % , average queue length by 66 % and average travel time by 20 % .",
        "latent representation learned from multi - layered neural networks via hierarchical feature abstraction enables recent success of deep learning .",
        "we designed a neural network model based on the assumption that good base representation can be attained by maximizing the total correlation between the input , latent , and output variables .",
        "the success of long short - term memory ( lstm ) neural networks in language processing is typically attributed to their ability to capture long - distance statistical regularities .",
        "recent work on program induction has proposed neural architectures , based on abstractions like stacks , turing machines , and interpreters , that operate on abstract computational machines or on execution traces .",
        "combining abstract , symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning .",
        "as a step in this direction , we propose a new architecture , called neural equivalence networks , for the problem of learning continuous semantic representations of mathematical and logical expressions .",
        "the challenge is that semantic representations must be computed in a syntax - directed manner , because semantics is compositional , but at the same time , small changes in syntax can lead to very large changes in semantics , which can be difficult for continuous neural architectures .",
        "recently deep neural networks have received considerable attention due to their ability to extract and represent high - level abstractions in data sets .",
        "deep neural networks such as fully - connected and convolutional neural networks have shown excellent performance on a wide range of recognition and classification tasks .",
        "the power / energy consumption of neural networks is dominated by memory accesses , the majority of which occur in fully - connected networks .",
        "in fact , they contain most of the deep neural network parameters .",
        "the proposed architecture can save up to 90 % of memory compared to the conventional implementations of fully - connected neural networks .",
        "for our model , we also present a new kind of recurrent neural network inspired by residual networks that decouples memory from computation allowing to model complex environments that do not require lots of memory .",
        "we present a supervised sequence to sequence transduction model with a hard attention mechanism which combines the more traditional statistical alignment methods with the power of recurrent neural networks .",
        "we evaluate the model on the task of morphological inflection generation and show that it provides state of the art results in various setups compared to the previous neural and non - neural approaches .",
        "we specifically apply this idea to modify adam , a popular algorithm for training deep neural networks .",
        "recurrent neural networks are a powerful tool for modeling sequential data , but the dependence of each timestep ' s computation on the previous timestep ' s output limits parallelism and makes rnns unwieldy for very long sequences .",
        "we introduce quasi - recurrent neural networks ( qrnns ) , an approach to neural sequence modeling that alternates convolutional layers , which apply in parallel across timesteps , and a minimalist recurrent pooling function that applies in parallel across channels .",
        "experiments on language modeling , sentiment classification , and character - level neural machine translation demonstrate these advantages and underline the viability of qrnns as a basic building block for a variety of sequence tasks .",
        "neural networks are powerful and flexible models that work well for many difficult learning tasks in image , speech and natural language understanding .",
        "despite their success , neural networks are still hard to design .",
        "in this paper , we use a recurrent network to generate the model descriptions of neural networks and train this rnn with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set .",
        "deep neural network models , though very powerful and highly successful , are computationally expensive in terms of space and time .",
        "neural network is one of the techniques which are widely used for diagnosis in medical field .",
        "in this article efficiency of nine algorithms , which are basis of neural network learning in diagnosing cardiovascular diseases , will be assessed .",
        "in this paper we present a technique to train neural network models on small amounts of data .",
        "current methods for training neural networks on small amounts of rich data typically rely on strategies such as fine - tuning a pre - trained neural network or the use of domain - specific hand - engineered features .",
        "while deep learning parsing approaches have proven very successful at finding the structure of sentences , most neural dependency parsers use neural networks only for feature extraction , and then use those features in traditional parsing algorithms .",
        "in contrast , this paper builds off recent work using general - purpose neural network components , training an attention mechanism over an lstm to attend to the head of the phrase .",
        "in this paper , we present a general \" compare - aggregate \" framework that performs word - level matching followed by aggregation using convolutional neural networks .",
        "we find that some simple comparison functions based on element - wise operations can work better than standard neural network and neural tensor network .",
        "while most successful neural approaches to this problem rely on recurrent neural networks ( rnns ) , training rnns over long documents can be prohibitively slow .",
        "recent years have seen the proposal of a number of neural architectures for the problem of program induction .",
        "while achieving impressive results , these approaches have a number of important limitations : ( a ) they are computationally expensive and hard to train , ( b ) a model has to be trained for each task ( program ) separately , and ( c ) it is hard to interpret or verify the correctness of the learnt mapping ( as it is defined by a neural network ) .",
        "our method is based on two novel neural modules .",
        "the second module , the recursive - reverse - recursive neural network ( r3nn ) , given the continuous representation of",
        "we devise a novel neural network architecture for this task which we train end - to - end .",
        "although end - to - end neural machine translation ( nmt ) has achieved remarkable progress in the past two years , it suffers from a major drawback : translations generated by nmt systems often lack of adequacy .",
        "in this work , we propose a novel framework called ac - blstm for modeling setences and documents , which combines the asymmetric convolution neural network ( acnn ) with the bidirectional long short - term memory network ( blstm ) .",
        "moreover , since our regularization is directly performed on the weights , it is especially suitable for fully convolutional neural networks , where the weight space is constant compared to the feature map space .",
        "in recent years , deep neural networks ( dnns ) based methods have achieved remarkable performance in a wide range of tasks and have been among the most powerful and widely used techniques in computer vision , speech recognition and natural language processing .",
        "the approach is to train a neural network to predict properties of the program that generated the outputs from the inputs .",
        "we use the neural network ' s predictions to augment search techniques from the programming languages community , including enumerative search and an smt - based solver .",
        "empirically , we show that our approach leads to an order of magnitude speedup over the strong non - augmented baselines and a recurrent neural network approach , and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites .",
        "artificial neural networks have gone through a recent rise in popularity , achieving state - of - the - art results in various fields , including image classification , speech recognition , and automated control .",
        "in our work , machine learning is leveraged by training an artificial neural network to predict the performance",
        "at present , designing convolutional neural network ( cnn ) architectures requires both human expertise and labor .",
        "we present a novel layerwise optimization algorithm for the learning objective of a large class of convolutional neural networks ( cnns ) .",
        "recent works on neural architectures have demonstrated the utility of attention mechanisms for a wide variety of tasks .",
        "the prevalent approach to neural machine translation relies on bi - directional lstms to encode the source sentence .",
        "the key technical tool is the neural taylor approximation - - a straightforward application of taylor expansions to neural networks - - and the associated taylor loss .",
        "experiments on a range of optimizers , layers , and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization .",
        "in this work , we present dependency sensitive convolutional neural networks ( dscnn ) as a general - purpose classification system for both sentences and documents .",
        "compared with existing recursive neural models with tree structures , dscnn does not rely on parsers and expensive phrase labeling , and thus is not restricted to sentence - level tasks .",
        "recently , spiking neural networks ( snns ) have been attracting a great deal of attention , notably owning to their power efficiency , which can potentially allow us to implement a low - power deep learning engine suitable for real - time / mobile applications .",
        "consequently , most of the previous studies employ a workaround technique , which first trains a conventional weighted - sum deep neural network and then maps the learning weights to the snn under training , instead of training snn parameters directly .",
        "in this paper we present new discriminative embedding models based on recurrent neural networks ( rnns ) .",
        "we formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models .",
        "in this work we propose an end - to - end neural approach based on the recently proposed set to sequence mapping framework to address the sentence ordering problem .",
        "we used the latest deep neural network algorithms which provide a leap in performance over the traditional gmm approach , and apply data augmentation methods to improve robustness to noise and speaker variation .",
        "an intriguing property of deep neural networks is the existence of adversarial examples , which can transfer among different architectures .",
        "these transferable adversarial examples may severely hinder deep neural network - based applications .",
        "recent work has demonstrated the effectiveness of employing explicit external memory structures in conjunction with deep neural models for algorithmic learning ( graves et al .",
        "in this work , we propose an alternative model , lie - access memory , that is explicitly designed for the neural setting .",
        "to experiment with this approach , we implement several simplified lie - access neural turing machine ( lantm ) with different lie groups .",
        "in this work , we propose a training algorithm for an audio - visual automatic speech recognition ( av - asr ) system using deep recurrent neural network ( rnn ) .",
        "deep neural networks ( dnns ) have come to outperform humans in visual classifications tasks .",
        "to sidestep the curse of dimensionality , we propose an algorithm that leverages a neural network to approximate the minimum time - to - reach function to synthesize controls .",
        "we show that our neural network generates near optimal controls which are guaranteed to successfully drive the system to a target state .",
        "unlike many previous neural network reachability formulations , our approximation is conservative and hence any trajectories we generate will be strictly feasible .",
        "convolutional neural networks excel in image recognition tasks , but this comes at the cost of high computational and memory complexity .",
        "recent advances in language technology have given rise to unsupervised neural models for learning representations of words as well as bigger textual units .",
        "this survey is meant as an introduction to the use of neural models for semantic matching .",
        "we detail the required background and terminology , a taxonomy grouping the rapidly growing body of work in the area , and then survey work on neural models for semantic matching in the context of three tasks : query suggestion , ad retrieval , and document retrieval .",
        "our model is a hierarchical recurrent neural network , where the layers and the structure of the hierarchy encode our prior knowledge about how pop music is composed .",
        "we additionally show two applications of our framework : neural dancing and karaoke , as well as neural story singing .",
        "despite their massive size , successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance .",
        "three consonant voicing classifiers were developed : ( 1 ) manually selected acoustic features anchored at a phonetic landmark , ( 2 ) mfccs ( either averaged across the segment or anchored at the landmark ) , and ( 3 ) acoustic features computed using a convolutional neural network ( cnn ) .",
        "the entity linking ( el ) system consists of two modules : a rule based candidate generation and a neural networks probability ranking model .",
        "most neural network models for document classification on social media focus on text infor - mation to the neglect of other information on these platforms .",
        "in this paper , we classify post stance on social media channels and develop utcnn , a neural network model that incorporates user tastes , topic tastes , and user comments on posts .",
        "moreover , our work compares two different strategies to extract features from a convolutional neural network for each region proposal : a first one that computes new feature maps for each region proposal , and a second one that computes the feature maps for the whole image to later generate crops for each region proposal .",
        "we present a learning to learn approach for training recurrent neural networks to perform black - box global optimization .",
        "in the meta - learning phase we use a large set of smooth target functions to learn a recurrent neural network ( rnn ) optimizer , which is either a long - short term memory network or a differentiable neural computer .",
        "though a variety of neural network models have been proposed very recently , however , previous models either depend on expensive phrase - level annotation , whose performance drops substantially when trained with only sentence - level annotation ; or do not fully employ linguistic resources ( e .",
        "we compare the performance of using audio spectrum in the log scale and using polyphonic sound sequences from raw audio samples to train the neural network and to classify speech as either english or spanish .",
        "to achieve this , we use the novel approach of using a convolutional recurrent neural network using long short term memory ( lstm ) or a gated recurrent unit ( gru ) for forward propagation of the neural network .",
        "our hypothesis is that the performance of using polyphonic sound sequence as features and both lstm and gru as the gating mechanisms for the neural network outperform the traditional mfcc features using a unidirectional deep neural network .",
        "the collision prediction model is represented by a deep convolutional neural network that directly processes raw image inputs .",
        "in this paper , we take a first step towards bridging this gap , by developing flavors of competitive hebbian learning which produce sparse , distributed neural codes using online adaptation with minimal tuning .",
        "we present summarunner , a recurrent neural network ( rnn ) based sequence model for extractive summarization of documents and show that it achieves performance better than or comparable to state - of - the - art .",
        "conditional random field ( crf ) and recurrent neural models have achieved success in structured prediction .",
        "more recently , there is a marriage of crf and recurrent neural models , so that we can gain from both non - linear dense features and globally normalized crf objective .",
        "these recurrent neural crf models mainly focus on encode node features in crf undirected graphs .",
        "in this work , we introduce a new recurrent neural crf model , which learns non - linear edge features , and thus makes non - linear features encoded completely .",
        "we compare our model with different neural models in well - known structured prediction tasks .",
        "with massive unlabeled text and quite limited labelled corpus , we propose a semi - supervised learning model based on b - lstm neural network .",
        "we present two novel and contrasting recurrent neural network ( rnn ) based architectures for extractive summarization of documents .",
        "a shared component of many powerful generative models is a decoder network , a parametric deep neural net that defines a generative distribution .",
        "this article provides an interesting exploration of character - level convolutional neural network solving chinese corpus text classification problem .",
        "we constructed a large - scale chinese language dataset , and the result shows that character - level convolutional neural network works better on chinese corpus than its corresponding pinyin format dataset .",
        "this is the first time that character - level convolutional neural network applied to text classification problem .",
        "recent work has begun exploring neural acoustic word embeddings - - fixed - dimensional vector representations of arbitrary - length speech segments corresponding to words .",
        "we propose an approach to build a neural machine translation system with no supervised resources ( i .",
        "we propose a simple , elegant solution to use a single neural machine translation ( nmt ) model to translate between multiple languages .",
        "training time on large datasets for deep neural networks is the principal workflow bottleneck in a number of important applications of deep learning , such as object classification and detection in automatic driver assistance systems ( adas ) .",
        "to minimize training time , the training of a deep neural network must be scaled beyond a single machine to as many machines as possible by distributing the optimization method used for training .",
        "to this end , we propose a knowledge enhanced hybrid neural network ( kehnn ) .",
        "the three channels are processed by a convolutional neural network to generate high level features for matching , and the features are synthesized as a matching score by a multilayer perceptron .",
        "in this work we use the recent advances in representation learning to propose a neural architecture for the problem of natural language inference .",
        "the model uses variants of long short term memory ( lstm ) , attention mechanism and composable neural networks , to carry out the task .",
        "in this paper , we present our first attempts in building a multilingual neural machine translation framework under a unified approach .",
        "the nonlinearity of the model is revealed by its connection to rectified linear unit ( relu ) neural networks .",
        "we further extend the model to deep structures and show that deep models can be used for unsupervised pre - training of rectifier neural networks .",
        "neural machine translation systems typically rely on the size of parallel corpora .",
        "in this paper , we propose an end - to - end neural approach to address the sentence ordering problem , which uses the pointer network ( ptr - net ) to alleviate the error propagation problem and utilize the whole contextual information .",
        "in this paper , we propose an approach to pos tag code - mixed social media text using recurrent neural network language model ( rnn - lm ) architecture .",
        "nevertheless , the neural network has its advantages : it uses only tactile and proprioceptive feedback but no visual feedback about the object ( i .",
        "various deep neural architectures underperform human baselines on these tasks , suggesting that comics contains fundamental challenges for both vision and language .",
        ", max pooling ) in convolutional neural networks ( cnns ) serve the dual purpose of providing increasingly abstract representations as well as yielding computational savings in subsequent convolutional layers .",
        "our method for transforming deep artificial neural networks into spiking networks is scalable and works with a wide range of neural nonlinearities .",
        "we achieve these results by softening the neural response function , such that its derivative remains bounded , and by training the network with noise to provide robustness against the variability introduced by spikes .",
        "in the context of deep neural networks , this idea is often realized by hand - designed network architectures with layers that are shared across tasks and branches that encode task - specific features .",
        "in this work , we present a shared variable neural network model called proje that fills - in missing information in a knowledge graph by learning joint embeddings of the knowledge graph ' s entities and edges , and through subtle , but important , changes to the standard loss function .",
        "inspired by such capability , we propose deluge networks ( delugenets ) , a novel class of neural networks facilitating massive cross - layer information inflows from preceding layers to succeeding layers .",
        "we then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow .",
        "the current trend in object detection and localization is to learn predictions with high capacity deep neural networks trained on a very large amount of annotated data and using a high amount of processing power .",
        "in this work , we propose a new neural model which directly predicts bounding box coordinates .",
        "recurrent neural network grammars ( rnng ) are a recently proposed probabilistic generative modeling family for natural language .",
        "researchers have recently started investigating deep neural networks for dialogue applications .",
        "in support of this goal , we review recently proposed models based on generative encoder - decoder neural network architectures , and show that these models have better ability to incorporate long - term dialogue history , to model uncertainty and ambiguity in dialogue , and to generate responses with high - level compositional structure .",
        "a novel data representation method of convolutional neural net - work ( cnn ) is proposed in this paper to represent data of different modalities .",
        "the complexity of deep neural network algorithms for hardware implementation can be lowered either by scaling the number of units or reducing the word - length of weights .",
        "for this study , the performances of fully - connected deep neural networks ( fcdnns ) and convolutional neural networks ( cnns ) are evaluated while changing the network complexity and the word - length of weights .",
        "7x ( on gpu / cpu ) relative to a state - of - the - art convolutional neural network , at competitive accuracy .",
        "neural network based models are a very powerful tool for creating word embeddings , the objective of these models is to group similar words together .",
        "neural language models are able to learn word representations which have been used to capture semantic shifts across time and geography .",
        "we will train a neural language model on texts from a diverse set of disciplines philosophy , religion , fiction etc .",
        "deep neural network architectures with external memory components allow the model to perform inference and capture long term dependencies , by storing information explicitly .",
        "the difficulty in analyzing lstm - like recurrent neural networks lies in the complex structure of the recurrent unit , which induces highly complex nonlinear dynamics .",
        "recently published methods enable training of bitwise neural networks which allow reduced representation of down to a single bit per weight .",
        "we present a method that exploits ensemble decisions based on multiple stochastically sampled network models to increase performance figures of bitwise neural networks in terms of classification accuracy at inference .",
        "our work contributes to efficient embedded bitwise neural networks .",
        "we develop a model that decomposes both images and paragraphs into their constituent parts , detecting semantic regions in images and using a hierarchical recurrent neural network to reason about language .",
        "recurrent neural network ( rnn ) is one of the most popular architectures used in natural language processsing ( nlp ) tasks because its recurrent structure is very suitable to process variable - length text .",
        "adaptive stochastic gradient methods such as adagrad have gained popularity in particular for training deep neural networks .",
        "on the task of training convolutional neural networks as well as recurrent neural networks , radagrad achieves faster convergence than diagonal adagrad .",
        "deep neural networks with lots of parameters are typically used for large - scale computer vision tasks such as image classification .",
        "in this work , we train and build neural networks which implicitly use sparse computations .",
        "we experimentally validate our method on both small and large networks and achieve state - of - the - art compression results for sparse neural network models .",
        "in addition , we highlight a direct link of the proposed non - local models to convolutional neural networks .",
        "deep neural networks often require good regularizers to generalize well .",
        "another member of this family selects the width of neural network layers .",
        "we describe a new rl learning framework called bi - pomdp , and a new learning model called budgeted option neural network ( bonn ) able to discover options based on a budgeted learning objective .",
        "convolutional neural networks ( cnns ) exhibit remarkable performance in various machine learning tasks .",
        "performance of end - to - end automatic speech recognition ( asr ) systems can significantly be improved by the increasing large speech corpus and deeper neural network .",
        "given the arising problem of training speed and recent success of deep convolutional neural network in asr , we build a novel deep recurrent convolutional network for acoustic modeling and apply deep residual learning framework to it , our experiments show that it has not only faster convergence speed but better recognition accuracy over traditional deep convolutional recurrent network .",
        "deep convolutional neural networks have become a widespread tool to address high - level computer vision tasks very successfully .",
        "we are the first to propose such a formulation : training a neural network to rank points in a transformation - invariant manner .",
        "we propose a multigrid extension of convolutional neural networks ( cnns ) .",
        "we propose incorporating this idea of tunable sensitivity for hard examples in neural network learning , using a new generalization of the cross - entropy gradient step , which can be used in place of the gradient in any gradient - based training method .",
        "we therefore conclude that tunable sensitivity can be helpful for neural network learning .",
        "a new model for video captioning is developed , using a deep three - dimensional convolutional neural network ( c3d ) as an encoder for videos and a recurrent neural network ( rnn ) as a decoder for captions .",
        "the word - to - vector representation is used , and convolutional neural networks are employed as sentence encoders , mapping an input sentence into a fixed - length vector .",
        "this representation is decoded using long short - term memory recurrent neural networks , considering several tasks , such as reconstructing the input sentence , or predicting the future sentence .",
        "a significant number of neural architectures for this task ( neural readers ) have recently been developed and evaluated on large cloze - style datasets .",
        "in an independent contribution , we show that the addition of linguistics features to the input to existing neural readers significantly boosts performance yielding the best results to date on the who - did - what datasets .",
        "recurrent neural networks ( rnns ) have shown promising performance for language modeling .",
        "more specifically , we apply random walk based learning method with recurrent neural network to match the similarities between askers question and historical questions proposed by other users .",
        "this paper introduces a neural language model with a sparse pointer network aimed at capturing very long - range dependencies .",
        "on this corpus , we found standard neural language models to perform well at suggesting local phenomena , but struggle to refer to identifiers that are introduced many tokens in the past .",
        "by augmenting a neural language model with a pointer network specialized in referring to predefined classes of identifiers , we obtain a much lower perplexity and a 5 percentage points increase in accuracy for code suggestion compared to an lstm baseline .",
        "based on these datasets , we propose and compare several recurrent neural networks ( rnns ) based multimodal ( text and image ) models .",
        "although attention - based neural machine translation have achieved great success , attention - mechanism cannot capture the entire meaning of the source sentence because the attention mechanism generates a target word depending heavily on the relevant parts of the source sentence .",
        "the report of earlier studies has introduced a latent variable to capture the entire meaning of sentence and achieved improvement on attention - based neural machine translation .",
        "as described herein , we propose a neural machine translation model that introduces a continuous latent variable containing an underlying semantic extracted from texts and images .",
        "in this paper , we propose a simple , fast decoding algorithm that fosters diversity in neural generation .",
        "we propose a neural network framework for high - dimensional conditional density estimation .",
        "recurrent neural networks ( rnns ) have achieved great success in language modeling .",
        "dpn is a deep neural network that consists of two important layers : template projection layer and dense aggregate layer .",
        "we approach the problem of learning synthetic driving using generative neural networks .",
        "in this work , we propose to utilize unlabeled data to train neural network based grammatical error detection models .",
        "we introduce an attention - based neural network to capture long - distance dependencies that influence the word being detected .",
        "we define a likelihood for a set distribution and learn its parameters using a deep neural network .",
        "we use reinforcement learning to learn tree - structured neural networks for computing representations of natural language sentences .",
        "in this work , we employ a recurrent neural network ( rnn ) to predict real estate price using the state - of - the - art visual features .",
        "convolutional neural networks achieve good performance on this task , while being computationally efficient .",
        "here we study greedy algorithms for unsupervised learning of dictionaries of shift - invariant atoms and propose a new method where each atom is selected with the same probability on average , which corresponds to the homeostatic regulation of a recurrent convolutional neural network .",
        "this generalisation has two mathematically equivalent views in multi - linear algebra and gated neural networks respectively .",
        "moreover , by exploiting the semantic descriptor , it provides neural networks the capability of zero - shot learning ( zsl ) , where a classifier is generated for an unseen class without any training data ; as well as zero - shot domain adaptation ( zsda ) , where a model is generated for an unseen domain without any training data .",
        "we propose a single neural network architecture for two tasks : on - line keyword spotting and voice activity detection .",
        "we develop novel inference algorithms for an end - to - end recurrent neural network trained with the connectionist temporal classification loss function which allow our model to achieve high accuracy on both keyword spotting and voice activity detection without retraining .",
        "we describe a neural attention model with a learnable retinal sampling lattice .",
        "the computational mechanisms by which nonlinear recurrent neural networks ( rnns ) achieve their goals remains an open question .",
        "we concatenate this layer with a convolutional neural network ( cnn ) model .",
        "we train input specific state - of - the - art deep neural networks for each input source , show the potential of forging them together into a multi - modal architecture and train a novel policy network that learns to choose between them .",
        "an associative memory is a framework of content - addressable memory that stores a collection of message vectors ( or a dataset ) over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version .",
        "designing an associative memory requires addressing two main tasks : 1 ) learning phase : given a dataset , learn a concise representation of the dataset in the form of a graphical model ( or a neural network ) , 2 ) recall phase : given a noisy version of a message vector from the dataset , output the correct message vector via a neurally feasible algorithm over the network learnt during the learning phase .",
        "this paper studies the problem of designing a class of neural associative memories which learns a network representation for a large dataset that ensures correction against a large number of adversarial errors during the recall phase .",
        "we measure human performance on the dataset and compare it to several strong neural models .",
        "we proposed two novel approaches which encode the contexts into a continuous semantic representation and then decode the semantic representation into text sequences with recurrent neural networks .",
        "generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks .",
        "reducing bit - widths of weights , activations , and gradients of a neural network can shrink its storage size and memory usage , and also allow for faster training and inference by exploiting bitwise operations .",
        "sequence modeling with neural networks has lead to powerful models of symbolic music data .",
        "recurrent neural networks ( rnns ) have been successfully used in many applications .",
        "fully convolutional neural networks give accurate , per - pixel prediction for input images and have applications like semantic segmentation .",
        "we propose a method to train bit fully convolution network ( bfcn ) , a fully convolutional neural network that has low bit - width weights and activations .",
        "our model takes graphs as input , performs object - and relation - centric reasoning in a way that is analogous to a simulation , and is implemented using deep neural networks .",
        "recent literature has pointed out that machine learning classifiers , including deep neural networks ( dnn ) , are vulnerable to adversarial samples that are maliciously created inputs that force a machine learning classifier to produce wrong output labels .",
        "we present the neural physics engine ( npe ) , an object - based neural network architecture for learning predictive models of intuitive physics .",
        "our approach draws on the strengths of both symbolic and neural approaches : like a symbolic physics engine , the npe is endowed with generic notions of objects and their interactions , but as a neural network it can also be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds .",
        "recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables , such as variational autoencoders .",
        "we present several definition model architectures based on recurrent neural networks , and experiment with the models over multiple data sets .",
        "in this work , we present how convolutional neural networks can be used to directly classify pre - segmented breast masses in mammograms as benign or malignant , using a combination of transfer learning , careful pre - processing and data augmentation to overcome limited training data .",
        "to address this limitation , we leverage a fast neural model to extract lookahead features .",
        "in this paper , we propose a new neural network to estimate distributed word representations using a lexicon and a corpus .",
        "the proposed neural network can be trained using negative sampling , which maximizing the log probabilities of target words given the context words , by distinguishing the target words from random noises .",
        "we compare the proposed neural network",
        "in order to handle the patients ' historical information as sequential data , we apply the so - called encoder - decoder - framework which is based on recurrent neural networks ( rnn ) as encoders and a tensor factorization model as a decoder , a combination which is novel in machine learning .",
        "this paper presents a systematic evaluation of neural network ( nn ) for classification of real - world data .",
        "we present probabilistic neural programs , a framework for program induction that permits flexible specification of both a computational model and inference algorithm while simultaneously enabling the use of deep neural networks .",
        "probabilistic neural programs combine a computation graph for specifying a neural network with an operator for weighted nondeterministic choice .",
        "thus , a program describes both a collection of decisions as well as the neural network architecture used to make each one .",
        "we evaluate our approach on a challenging diagram question answering task where probabilistic neural programs correctly execute nearly twice as many programs as a baseline model .",
        "multiple extensions of recurrent neural networks ( rnns ) have been proposed recently to address the difficulty of storing information over long time periods .",
        "in this paper , we experiment with the capacity of neural turing machines ( ntms ) to deal with these long - term dependencies on well - balanced strings of parentheses .",
        "the significant computational costs of deploying neural networks in large - scale or resource constrained environments , such as data centers and mobile devices , has spurred interest in model compression , which can achieve a reduction in both arithmetic operations and storage memory .",
        "several techniques have been proposed for reducing or compressing the parameters for feed - forward and convolutional neural networks , but less is understood about the effect of parameter compression on recurrent neural networks ( rnn ) .",
        "to address the issues , we propose an end - to - end deep recurrent neural network with limited contextual dialogue memory by jointly training nlu and sap on dstc4 multi - domain human - human dialogues .",
        "deep neural networks are widely used in machine learning applications .",
        "however , the deployment of large neural networks models can be difficult to deploy on mobile devices with limited power budgets .",
        "to solve this problem , we propose trained ternary quantization ( ttq ) , a method that can reduce the precision of weights in neural networks to ternary values .",
        "this paper presents some techniques using fuzzy logic and neural networks to improve the accuracy of the use case points method .",
        "as a proof of concept for the proposed scheme , we designed a system consisting of deep convolutional neural networks , and applied it to successfully learn a computerized agent capable of autonomous highway steering over the",
        "extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory .",
        "recent neural program induction approaches have attempted to address this problem , but are typically limited to differentiable memory , and consequently cannot scale beyond small synthetic tasks .",
        "in this work , we propose the manager - programmer - computer framework , which integrates neural networks with non - differentiable memory to support abstract , scalable and precise operations through a friendly neural computer interface .",
        "specifically , we introduce a neural symbolic machine , which contains a sequence - to - sequence neural \" programmer \" , and a non - differentiable \" computer \" that is a lisp interpreter with code assist .",
        "network quantization is one of network compression techniques employed to reduce the redundancy of deep neural networks .",
        "it compresses the size of the storage for a large number of network parameters in a neural network by quantizing them and encoding the quantized values into binary codewords of smaller sizes .",
        "to this end , we analyze the quantitative relation of quantization errors to the loss function of a neural network and identify that the hessian - weighted distortion measure is locally the right objective function that we need to optimize for minimizing the loss due to quantization .",
        "the vectors are then accumulated in a chronological order through a recurrent neural network ( rnn ) which models the relationships among the utterances .",
        "we introduce condensed memory neural networks ( c - memnns ) , a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory .",
        "we demonstrate that max - sum inference in the drmm yields an algorithm that exactly reproduces the operations in deep convolutional neural networks ( dcns ) , providing a first principles derivation .",
        "cross - entropy loss together with softmax is arguably one of the most common used supervision components in convolutional neural networks ( cnns ) .",
        "building neural networks to query a knowledge base ( a table ) with natural language is an emerging research topic in nlp .",
        "the neural enquirer typically necessitates multiple steps of execution because of the compositionality of queries .",
        "in summary , the coupled neural enquirer takes advantages of both distributed and symbolic exec",
        "like a neural turing machine or differentiable neural computer ( graves et al .",
        "we propose an extension to neural network language models to adapt their prediction to the recent history .",
        "we also draw a link between the use of external memory in neural network and cache models used with count based language models .",
        "we present a method for implementing an efficient unitary neural network ( eunn ) whose computational complexity is merely $ \\ mathcal { o } ( 1 ) $ per parameter and has full tunability , from spanning part of unitary space to all of it .",
        "we apply the eunn in recurrent neural networks , and test its performance on the standard copying task and the mnist digit recognition benchmark , finding that it significantly outperforms a non - unitary rnn , an lstm network , an exclusively partial space urnn and a projective urnn with comparable parameter numbers .",
        "we introduce an exceptionally simple gated recurrent neural network ( rnn ) that achieves performance comparable to well - known gated architectures , such as lstms and grus , on the word - level language modeling task .",
        "parsing accuracy using efficient greedy transition systems has improved dramatically in recent years thanks to neural networks .",
        "despite striking results in dependency parsing , however , neural models have not surpassed state - of - the - art approaches in constituency parsing .",
        "research has shown that convolutional neural networks contain significant redundancy , and high classification accuracy can be obtained even when weights and activations are reduced from floating point to binary values .",
        "by utilizing a novel set of optimizations that enable efficient mapping of binarized neural networks to hardware , we implement fully connected , convolutional and pooling layers , with per - layer compute resources being tailored to user - provided throughput requirements .",
        "in this work , to leverage class ties , we propose to make joint relation extraction with a unified model that integrates convolutional neural network with a general pairwise ranking framework , in which two novel ranking loss functions are introduced .",
        "we show that our model , which profits from combining memory - less modules , namely autoregressive multilayer perceptrons , and stateful recurrent neural networks in a hierarchical structure is able to capture underlying sources of variations in the temporal sequences over very long time spans , on three datasets of different nature .",
        "the pre - dominant approach to language modeling to date is based on recurrent neural networks .",
        "the predictron yielded significantly more accurate predictions than conventional deep neural network architectures .",
        "this work provides the first neural network - based approach to argumentation mining , focusing on the two tasks of extracting links between argument components , and classifying types of argument components .",
        "the above limitations can be overcome by using deep cases and neural network .",
        "hence we propose a modified qas in which we create a deep artificial neural network with associative memory from text documents .",
        "we present an end - to - end graph - based neural network dependency parser that can be trained to reproduce matrices of edge scores , which can be directly projected across word alignments .",
        "we introduce a tree - structured attention neural network for sentences and small phrases and apply it to the problem of sentiment classification .",
        "neural machine translation ( nmt ) is a new approach for machine translation ( mt ) , and due to its success , it has absorbed the attention of many researchers in the field .",
        "we present a natural representation of to reinforcement learning ( rl ) problems using recurrent convolutional neural networks ( rcnns ) , to better exploit this inherent structure .",
        "more specifically , we employ the residual neural network framework to model the temporal closeness , period , and trend properties of crowd traffic .",
        "st - resnet learns to dynamically aggregate the output of the three residual neural networks based on data , assigning different weights to different branches and regions .",
        "we introduce a simple and accurate neural model for dependency - based semantic role labeling .",
        "we describe an open - source toolkit for neural machine translation ( nmt ) .",
        "in this work , we propose a novel decoding approach for neural machine translation ( nmt ) based on continuous optimisation .",
        "our approach is general and can be applied to other sequence - to - sequence neural models as well .",
        "we aim to shed light on the strengths and weaknesses of the newly introduced neural machine translation paradigm .",
        "to that end , we conduct a multifaceted evaluation in which we compare outputs produced by state - of - the - art neural machine translation and phrase - based machine translation systems for 9 language directions across a number of dimensions .",
        "we find out that translations produced by neural machine translation systems are considerably different , more fluent and more accurate in terms of word order compared to those produced by phrase - based systems .",
        "neural machine translation systems are also more accurate at producing inflected forms , but they perform poorly when translating very long sentences .",
        "in this paper , we present a novel neural network model antsynnet that exploits lexico - syntactic patterns from syntactic parse trees .",
        "currently successful methods for video description are based on encoder - decoder sentence generation using recur - rent neural networks ( rnns ) .",
        "we feed the word vectors into a simple neural network with a long short - term memory ( lstm ) architecture .",
        "without any attempts to extract manually crafted features and considering that our medical dataset is too small to be fed into neural network , we obtained promising results .",
        "neural conversation models - - purely data - driven systems trained end - to - end on dialogue corpora - - have shown great promise recently , yet they often produce short and generic responses .",
        "in this paper , a novel architecture for a deep recurrent neural network , residual lstm is introduced .",
        "in this paper , we propose an efficient transfer leaning methods for training a personalized language model using a recurrent neural network with long short - term memory architecture .",
        "therefore , we would like to omit it and use deep neural networks that learn from simple features .",
        "credit assignment in traditional recurrent neural networks usually involves back - propagating through a long chain of tied weight matrices .",
        "we built both phrase - based and neural machine translation models , in an effort to probe whether the newly emerged nmt framework surpasses the traditional phrase - based systems in arabic - english language pairs .",
        "we trained a very strong phrase - based system including , a big language model , the operation sequence model , neural network joint model and class - based models along with different domain adaptation techniques such as mml filtering , mixture modeling and using fine tuning over nnjm model .",
        "however , a neural mt system , trained by stacking data from different genres through fine - tuning , and applying ensemble over 8 models , beat our very strong phrase - based system by a significant 2 bleu points margin in arabic - & gt ; english direction .",
        "this paper examines bypassing such an explicit representation by depending on a latent neural embedding of state and learning selective attention to dialogue history together with copying to incorporate relevant prior context .",
        "we complement recent work by showing the effectiveness of simple sequence - to - sequence neural architectures with a copy mechanism .",
        "most of the current deep neural network ( dnn ) based methods consider these tasks as a sequence labeling problem , in which a word , rather than a chunk , is treated as the basic unit for labeling .",
        "in this paper , we propose an alternative approach by investigating the use of dnn for sequence chunking , and propose three neural models so that each chunk can be treated as a complete unit for labeling .",
        "experimental results show that the proposed neural sequence chunking models can achieve start - of - the - art performance on both the text chunking and slot filling tasks .",
        "we design recurrent neural network ( rnn ) based contextual language models that specially track the interactions between speakers in a dialog .",
        "end - to - end ( e2e ) systems have achieved competitive results compared to conventional hybrid hidden markov model ( hmm ) - deep neural network based automatic speech recognition ( asr ) systems .",
        "the first sub - system is a recurrent neural network ( rnn ) - based acoustic auto - encoder trained to reconstruct the audio through a finite - dimensional representation .",
        "the second sub - system is a character - level rnn language model using embeddings learned from a convolutional neural network .",
        "since the acoustic and text query embeddings occupy different representation spaces , they are input to a third feed - forward neural network that predicts whether the query occurs in the acoustic utterance or not .",
        "how much can pruning algorithms teach us about the fundamentals of learning representations in neural networks ?",
        "neural network model compression has become a topic of great interest in recent years , and many different techniques have been proposed to address this problem .",
        "at the same time , the decision of what to prune and when to prune necessarily forces us to confront our assumptions about how neural networks actually learn to represent patterns in data .",
        "in this work we set out to test several long - held hypotheses about neural network learning representations and numerical approaches to pruning .",
        "recently , convolutional neural networks ( cnn ) , have shown success in this task .",
        "the proposed model , named deep cooperative neural networks ( deepconn ) , consists of two parallel neural networks coupled in the last layers .",
        "for the latter claim , two paradigmatic examples are presented : logic programming with kleene semantics for modelling reasoning from information in a discourse , to an interpretation of the state of affairs of the intended model , and a neural - symbolic implementation of input / output logic for dealing with uncertainty in dynamic normative contexts .",
        "introduction to deep neural networks and their history .",
        "this work aims to investigate the use of deep neural network to detect commercial hobby drones in real - life environments by analyzing their sound data .",
        ", a gaussian mixture model ( gmm ) , convolutional neural network ( cnn ) , and recurrent neural network ( rnn ) , for drone sound detection .",
        "we address a problem of optimization on product of embedded submanifolds of convolution kernels ( pems ) in convolutional neural networks ( cnns ) .",
        "to address this problem , we propose a multichannel convolutional neural networks ( cnn ) architecture , in which we treat english and chinese language as different input channels of one single cnn model .",
        "we introduce multi - modal , attention - based neural machine translation ( nmt ) models which incorporate visual features into different parts of both the encoder and the decoder .",
        "we utilise global image features extracted using a pre - trained convolutional neural network and incorporate them ( i ) as words in the source sentence , ( ii ) to initialise the encoder hidden state , and ( iii ) as additional data to initialise the decoder hidden state .",
        "to the best of our knowledge , it is the first time a purely neural model significantly improves over a pbsmt model on all metrics evaluated on this data set .",
        "we systematically explore regularizing neural networks by penalizing low entropy output distributions .",
        "we introduce a general strategy for improving neural sequence generation by incorporating knowledge about the future .",
        "in this study , an artificial neural network ( ann ) approach is utilized to perform a parametric study on the process of extraction of lubricants from heavy petroleum cuts .",
        "a feed - forward multi - layer perceptron neural network was successfully applied to capture the relationship between inputs and output parameters .",
        "in this paper , we propose a graph - based recursive neural network framework for collective vertex classification .",
        "in this framework , we generate hidden representations from both attributes of vertices and representations of neighbouring vertices via recursive neural networks .",
        "under this framework , we explore two types of recursive neural units , naive recursive neural unit and long short - term memory unit .",
        "we propose a neural network based approach for learning topics from text and image datasets .",
        "furthermore , since the approach utilizes neural networks , it can be implemented on gpu with ease , and hence it is very scalable .",
        "we train and compare several deep neural network models on the traces of existing atp proofs of mizar statements and use them to select processed clauses during proof search .",
        "using a few proof guidance strategies that leverage deep neural networks , we have found first - order proofs of 7 .",
        "an analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with ai techniques including artificial neural networks ( ann ) , ensembling and reinforcement learning ( rl ) to evolve control strategies for ucavs .",
        "in this work , we study the effect of discretization on the performance of linear classifiers optimizing three distinct discriminative objective functions - - - logistic regression ( optimizing negative log - likelihood ) , support vector classifiers ( optimizing hinge loss ) and a zero - hidden layer artificial neural network ( optimizing mean - square - error",
        "convolutional neural networks ( cnns ) has shown a great success in many areas including complex image classification tasks .",
        "in this paper , we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural - network - based statistical machine - learning techniques .",
        "chatbot ) , machine translation , text sequence prediction , neural architecture design , personalized web services , healthcare , finance , and music generation .",
        "an artificial visual system was built based on a fully recurrent neural network set within a reinforcement learning protocol , and learned to attend to regions of interest while solving a classification task .",
        "the application of deep neural networks for ranking in search engines may obviate the need for the extensive feature engineering common to current learning - to - rank methods .",
        "however , we show that combining simple relevance matching features like bm25 with existing deep neural net models often substantially improves the accuracy of these models , indicating that they do not capture essential local relevance matching signals .",
        "we describe a novel deep recurrent neural net - based model that we call match - tensor .",
        "machine learning models , such as neural networks , decision trees , random forests and gradient boosting machines accept a feature vector and provide a prediction .",
        "proposed approach uses deep recurrent neural network trained on a sequence of acoustic features calculated over small speech intervals .",
        "automatic phoneme recognition for bengali language using multilayer neural network is reviewed .",
        "usefulness of multilayer neural network over single layer neural network is discussed .",
        "experiments using deep neural network models trained on social media data show that the combination of visual and textual context can enhance the quality of generated conversational turns .",
        "in human evaluation , a gap between human performance and that of both neural and retrieval architectures suggests that igc presents an interesting challenge for vision and language research .",
        "recently neural network models using latent features has shown to be perform similar or better than the other existing models using handcrafted features .",
        "the neural network characteristic of these systems provides appropriate tool for automatically adjusting the membership functions .",
        "for artificial general intelligence ( agi ) it would be efficient if multiple users trained the same giant neural network , permitting parameter reuse , without catastrophic forgetting .",
        "it is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re - use for new tasks .",
        "during learning , a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation .",
        "the recent success of deep convolutional neural networks on image classification and recognition tasks has led to new applications in very diversifying contexts .",
        "one of these is medical imaging where scarcity and imbalance of training data has hindered rapid development of neural network related applications .",
        "we show how neural network based rl enables the control of discretized pdes whose parameters are unknown , random , and time - varying .",
        "subsequently , high dimensional non - linear function approximators like neural networks have been used to learn policies from scratch .",
        "convolutional neural network ( cnn ) models have achieved tremendous success in many visual detection and recognition tasks .",
        "recurrent neural network ( rnn ) models , on the other hand , are often used to process text and voice data due to their ability to learn intrinsic representations of sequential and temporal data .",
        "here , we propose a novel neural network tracking model that is capable of integrating information over time and tracking a selected target in video .",
        "we compare our model with an existing neural - network based tracking method and show that the proposed tracking approach works well in various scenarios by performing rigorous validation experiments on artificial video sequences",
        "we show that dsfs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks ( dnns ) .",
        "skip connections made the training of very deep neural networks possible and have become an indispendable component in a variety of neural architectures .",
        "here , we present an explanation for the benefits of skip connections in training very deep neural networks .",
        "it is well known that it is challenging to train deep neural networks and recurrent neural networks for tasks that exhibit long term dependencies .",
        "traditionally , first - order models such as hidden markov models were used for this task , with recent works suggesting to apply recurrent neural networks instead .",
        "we have developed and trained a convolutional neural network to automatically and simultaneously segment optic disc , fovea and blood vessels .",
        "the image is first decomposed into regions using selective search and these regions are classified as containing textual and / or graphical information using a convolutional neural network .",
        "this set is finally passed to a second convolutional neural network to classify the graphemes , based on a standard corpus .",
        "multiple pcgml methods are covered , including neural networks , long short - term memory ( lstm ) networks , autoencoders , and deep convolutional networks ; markov models , $ n $ - grams , and multi - dimensional markov chains ; clustering",
        "this is the right time to revitalize the area of interpreting how symbols are represented inside neural networks .",
        "attention networks have proven to be an effective approach for embedding categorical inference within a deep neural network .",
        "we experiment with two different classes of structured attention networks : a linear - chain conditional random field and a graph - based parsing model , and describe how these models can be practically implemented as neural network layers .",
        "experiments show that this approach is effective for incorporating structural biases , and structured attention networks outperform baseline attention models on a variety of synthetic and real tasks : tree transduction , neural machine translation , question answering , and natural language inference .",
        "the problem of quantizing the activations of a deep neural network is considered .",
        "we evaluate our embeddings on an image - sentence ranking ( isr ) , a semantic textual similarity ( sts ) , and a neural machine translation ( nmt ) task .",
        "neural machine translation ( nmt ) models are able to partially learn syntactic information from sequential lexical information .",
        "our predictive model is based on bootstrapped neural networks using dropout , allowing it to process raw sensory inputs from high - bandwidth sensors such as cameras .",
        "we introduce a multi - modal neural machine translation model in which a doubly - attentive decoder naturally incorporates spatial visual features obtained using pre - trained convolutional neural networks , bridging the gap between image description and translation .",
        "to solve multi - class problem we map pre - trained category - specific lhm classifiers to a multi - class neural network and adjust the weights with very fast tuning .",
        "a characteristic of opinion recommendation is the reliance of multiple data sources for multi - task joint learning , which is the strength of neural models .",
        "we use a single neural network to model users and products , capturing their correlation and generating customised product representations using a deep memory network , from which customised ratings and reviews are constructed jointly .",
        "in this paper we propose to exploit the automatic quality estimation ( qe ) of asr hypotheses to perform the unsupervised adaptation of a deep neural network modeling acoustic probabilities .",
        "the backbone of our system is a deep convolutional neural network that is not only computationally inexpensive , but also provides state - of - the - art results on several competitive benchmarks .",
        "in this work , we run experiments with different kinds of teacher net - works to enhance the translation performance of a student neural machine translation ( nmt ) network .",
        "the basic concept in neural machine translation ( nmt ) is to train a large neural network that maximizes the translation performance on a given parallel corpus .",
        "our approach uses a recursive neural network and a newly proposed attention mechanism to compute a representation of the text that focuses on salient content , from the perspective of both rst and the task .",
        "deep neural networks ( dnn ) have revolutionized the field of natural language processing ( nlp ) .",
        "convolutional neural network ( cnn ) and recurrent neural network ( rnn ) , the two main types of dnn architectures , are widely explored to handle various nlp tasks .",
        "neural network models are capable of generating extremely natural sounding conversational interactions .",
        "this paper presents a novel , fully data - driven , and knowledge - grounded neural conversation model aimed at producing more contentful responses without slot filling .",
        "this paper proposes an alternative to bi - lstms for this purpose : iterated dilated convolutional neural networks ( id - cnns ) , which have better capacity than traditional cnns for large context and structured prediction .",
        "this paper presents a novel neural machine translation model which jointly learns translation and source - side latent graph representations of sentences .",
        "unlike existing pipelined approaches using syntactic parsers , our end - to - end model learns a latent graph parser as part of the encoder of an attention - based neural machine translation model , so the parser is optimized according to the translation objective .",
        "two perspective , cmac as a neural network and cmac as a table look - up technique are presented .",
        "in this work we propose a novel model based on artificial neural networks to answer questions with multiple answers by exploiting multiple facts retrieved from a knowledge base .",
        "recent research in neural machine translation has largely focused on two aspects ; neural network architectures and end - to - end learning algorithms .",
        "in this paper , we solely focus on the problem of decoding given a trained neural machine translation model .",
        "more specifically , we design an actor that observes and manipulates the hidden state of the neural machine translation decoder and propose to train it using a variant of deterministic policy gradient .",
        "traditional optical - flow - based solutions often fail where flow estimation is challenging , while newer neural - network - based methods that hallucinate pixel values directly often produce blurry results .",
        "a fundamental advantage of neural models for nlp is their ability to learn representations from scratch .",
        "prior work on weight sharing in neural networks has considered it largely as a means of model compression .",
        "in contrast , we treat weight sharing as a flexible mechanism for incorporating prior knowledge into neural models .",
        "focusing on using lexical cues for humor recognition , we systematically compare a newly emerging text classification method based on convolutional neural networks ( cnns ) with a well - established conventional method using linguistic knowledge .",
        "specifically , we propose two variants of the deep conflation model , based on long - short - term memory ( lstm ) recurrent neural network ( rnn ) and convolutional neural network ( cnn ) , respectively .",
        "in recent years , machine learning techniques based on neural networks for mobile computing become increasingly popular .",
        "classical multi - layer neural networks require matrix multiplications at each stage .",
        "in this paper , we propose a new energy efficient neural network with the universal approximation property over space of lebesgue integrable functions .",
        "this network , called , additive neural network , is very suitable for mobile computing .",
        "the neural structure is based on a novel vector product definition , called ef - operator , that permits a multiplier - free implementation .",
        "the proposed additive neural network successfully solves the xor problem .",
        "the experiments on mnist dataset show that the classification performances of the proposed additive neural networks are very similar to the corresponding multi - layer perceptron and convolutional neural networks ( lenet )",
        "however , because different subjects have different neural responses to even the same stimulus , it is very difficult to build a generic erp classifier whose parameters fit all subjects .",
        "in this paper , we enhance the traditional confusion network system combination approach with an additional model trained by a neural network .",
        "we train a local system voting model by a neural network which is based on the words themselves and the combinatorial occurrences of the different system outputs .",
        "this paper presents incremental network quantization ( inq ) , a novel method , targeting to efficiently convert any pre - trained full - precision convolutional neural network ( cnn ) model into a low - precision version whose weights are constrained to be either powers of two or zero .",
        "in recent years , neural networks have enjoyed a renaissance as function approximators in reinforcement learning .",
        "two decades after teasauro ' s td - gammon achieved near top - level human performance in backgammon , the deep reinforcement learning algorithm dqn ( combining q - learning with a deep neural network , experience replay , and a separate target network ) achieved human - level performance in many atari 2600 games .",
        "first , based on the expected energy restricted boltzmann machine ( ee - rbm ) , we propose two activation functions for neural network function approximation in reinforcement learning : the sigmoid - weighted linear ( sil ) unit and its derivative function ( sild1 ) .",
        "several machine learning algorithms ( naive bayes , support vector machine and logistic regression ) alongside deep and convolutional neural networks were utilized in our experiments of sentiment analysis on our health dataset .",
        "end - to - end learning of recurrent neural networks ( rnns ) is an attractive solution for dialog systems ; however , current techniques are data - intensive and require thousands of dialogs to learn simple behaviors .",
        "in this paper we propose two neural embedding models in order to learn continuous concept vectors .",
        "in this work , we propose to train a deep neural network by distributed optimization over a graph .",
        "recently , machine learning methods have provided a broad spectrum of original and efficient algorithms based on deep neural networks ( dnn ) to automatically predict an outcome with respect to a sequence of inputs .",
        "recurrent hidden cells allow these dnn - based models to manage long - term dependencies such as recurrent neural networks ( rnn ) and long short - term memory ( lstm ) .",
        "there has been relatively little attention to incorporating linguistic prior to neural machine translation .",
        "in this paper , we propose a hybrid model , called nmt + rg , that learns to parse and translate by combining the recurrent neural network grammar into the attention - based neural machine translation .",
        "our approach encourages the neural machine translation model to incorporate linguistic prior during training , and lets it translate on its own afterward .",
        "in this paper we explore whether or not deep neural architectures can learn to classify boolean satisfiability ( sat ) .",
        "then , we define a graph representation for boolean formulas in conjunctive normal form , and train neural classifiers over general graph structures called graph neural networks , or gnns , to recognize features of satisfiability .",
        "in a weakly - supervised setting , that is , without problem specific feature engineering , graph neural networks can learn features of satisfiability .",
        "in this paper , we developed a deep neural network ( dnn ) that learns to solve simultaneously the three tasks of the cqa challenge proposed by the semeval - 2016 task 3 , i .",
        "the results on the official challenge test set show that our approach produces higher accuracy and faster convergence rates than the individual neural networks .",
        "in order to improve the reliability of speaker verification systems , we develop a new filter bank based cepstral feature , deep neural network filter bank cepstral coefficients ( dnn - fbcc ) , to distinguish between natural and spoofed speech .",
        "the deep neural network filter bank is automatically generated by training a filter bank neural network ( fbnn ) using natural and synthetic speech .",
        "we introduce a neural architecture for navigation in novel environments .",
        "cmp constructs a top - down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step .",
        "the backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive , but also provide state - of - the - art results on several competitive benchmarks .",
        "the goal of this work is to better understand the nature of neural networks through the examination of these new empirical results .",
        "recent works have been shown effective in using neural networks for chinese word segmentation .",
        "finally , given that insufficient data puts forward higher requirements for feature extraction , we propose a novel neural network which improves feature learning .",
        "besides , we explore an asynchronous parallel method on neural word segmentation to speed up training .",
        "in this paper , we present a novel reordering approach utilizing a neural network and dependency - based embeddings to predict whether the translations of two source words linked by a dependency relation should remain in the same order or should be swapped in the translated sentence .",
        "neural language models predict the next token using a latent representation of the immediate token history .",
        "recently , various methods for augmenting neural language models with an attention mechanism over a differentiable memory have been proposed .",
        "however , conventional attention mechanisms used in memory - augmented neural language models produce a single output vector per time step .",
        "in this paper , we propose a neural language model with a key - value attention mechanism that outputs separate representations for the key and value of a differentiable memory , as well as for encoding the next - word distribution .",
        "this model outperforms existing memory - augmented neural language models on two corpora .",
        "this led to the unexpected main finding that a much simpler model based only on the concatenation of recent output representations from previous time steps is on par with more sophisticated memory - augmented neural language models .",
        "this article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input .",
        "making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black - box classifiers in application areas such as medicine .",
        "while truncated back - propagation through time ( bptt ) is the most popular approach to training recurrent neural networks ( rnns ) , it suffers from being inherently sequential ( making parallelization difficult ) and from truncating gradient flow between distant time - steps .",
        "deep neural networks ( dnns ) have set state of the art results in many machine learning and nlp tasks .",
        "neural attention models have achieved great success in different nlp tasks .",
        "we show that our methods achieve significant improvement over a baseline neural atten - tion model and our results are also compet - itive against state - of - the - art systems that do not use extra linguistic resources .",
        "in this work , we introduce relation networks ( rns ) - a general purpose neural network architecture for object - relation reasoning .",
        "in humans , these two processes underlie fairly different cognitive and neural mechanisms .",
        "our model is a recurrent neural network ( rnn ) with long short - term memory ( lstm ) cells that labels clauses .",
        "recently , neural - network based methods have been proposed for learning this representation from large corpora .",
        "this paper focuses on the development of randomized approaches for building deep neural networks .",
        "deep neural networks are currently among the most commonly used classifiers .",
        "this paper presents a method to automatically segment liver and lesions in ct and mri abdomen images using cascaded fully convolutional neural networks ( cfcns ) enabling the segmentation of a large - scale medical trial or quantitative image analysis .",
        "neural networks have been successfully applied to this problem , and in this paper , we propose an attention - based deep neural network which better incorporates different embeddings of the queries and search results with an attention - based mechanism .",
        "the embeddings are trained with convolutional neural networks or the word2vec model .",
        "in this paper , we propose a novel and elegant solution to \" multi - source neural machine translation \" ( msnmt ) which only relies on preprocessing a n - way multilingual corpus without modifying the neural machine translation ( nmt ) architecture or training procedure .",
        "neural networks are able to process tasks like image recognition ( better than humans ) but in memory aspects are still limited ( by attention mechanism , size ) .",
        "recurrent neural network ( rnn ) and it ' s modified version lstm are able to solve small memory contexts , but as context becomes larger than a threshold , it is difficult to use them .",
        "still , it poses many challenges like , how to train neural networks for discrete memory representation , how to describe long term dependencies in sequential data etc .",
        "most prominent neural architectures for such tasks are memory networks : inference components combined with long term memory and neural turing machines : neural networks using external memory resources .",
        "preliminary results of above neural architectures on simple algorithms ( sorting , copying ) and question answering ( based on story , dialogs ) application are comparable with the state of the art .",
        "we train a recurrent neural network sequence - to - sequence model with attention to select facts and generate textual summaries .",
        "convolutional neural networks ( cnn ) are able to extract higher level features that are invariant to local spectral and temporal variations .",
        "recurrent neural networks ( rnns ) are powerful in learning the longer term temporal context in the audio signals .",
        "we combine these two approaches in a convolutional recurrent neural network ( crnn ) and apply it on a polyphonic sound event detection task .",
        "our architecture is inspired by previously proposed neural - network - based belief - tracking systems .",
        "in this paper , we train a recognition model by optimizing an interpolation between the scrf and ctc losses , where the same recurrent neural network ( rnn ) encoder used for feature extraction for both outputs .",
        "fpga - based hardware accelerators for convolutional neural networks ( cnns ) have obtained great attentions due to their higher energy efficiency than gpus .",
        "finally , we also research new dropout prediction architectures based on deep , fully - connected , feed - forward neural networks and find that ( 4 ) networks with as many as 5 hidden layers can",
        "we present a recurrent neural network based action - value function , and demonstrate its ability to learn how and when to request labels .",
        "advances in natural language processing tasks have gained momentum in recent years due to the increasingly popular neural network methods .",
        "second , paraphrases of logical forms and questions are embedded in a jointly learned vector space using word and character convolutional neural networks .",
        "a neural scoring function is further used to rank and retrieve the most probable logical form ( interpretation ) of a question .",
        "7 % , thus slightly surpassing both the engineered feature scoring baseline , as well as the neural programmer model of [ neelakantan et",
        "we present an encoder - - decoder style neural network to produce a derived form character - by - character , based on its corresponding character - level representation of the base form and the context .",
        "we propose an approach that gives a neural network - - based conversational agent this ability .",
        "we propose a neural network model that jointly learns entity mentions and their context representation to eliminate use of hand crafted features .",
        "we propose a novel progressive learning model which augments the progressive neural network with gated recurrent adapters .",
        "recent studies have shown that deep neural networks ( dnn ) are vulnerable to adversarial samples : maliciously - perturbed samples crafted to yield incorrect model outputs .",
        "reinforcement learning improves accuracy of both labeled and unlabeled dependencies of the stanford neural dependency parser , a high performance greedy parser , while maintaining its efficiency .",
        "deep neural nets have caused a revolution in many classification tasks .",
        "we present a neural network architecture for identifying the type of safety events which is the first step in understanding these narratives .",
        "our proposed model is based on a soft neural attention model to improve the effectiveness of encoding long sequences .",
        "the back - propagation ( bp ) algorithm has been considered the de facto method for training deep neural networks .",
        "in this work , we propose a more biologically plausible paradigm of neural architecture according to biological findings .",
        "our experimental results show that our neural model outperforms two baselines as well as humans solving the same task , suggesting that computational models are able to better capture the underlying semantics of emojis .",
        "a recurrent neural network model of phonological pattern learning is proposed .",
        "the model is a relatively simple neural network with one recurrent layer , and displays biases in learning that mimic observed biases in human learning .",
        "in non - recurrent models , capturing these biases requires the use of alpha features or some other representation of repeated features , but with a recurrent neural network , these elaborations are not necessary .",
        "the probability of a segmented sequence is calculated as the product of the probabilities of all its segments , where each segment is modeled using existing tools such as recurrent neural networks .",
        "recently , there was a paradigm shift towards using word embeddings and deep neural networks , where the use of surface features is very limited .",
        "in this paper , we show that a simple svm model with surface features outperforms more complex neural models for detecting anaphoric mentions .",
        "deep neural network ( dnn ) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene .",
        "in this paper , we propose to use a convolutional neural network ( cnn ) to extract robust features from mel - filter banks ( mfbs ) , spectrograms or even raw waveforms for audio tagging .",
        "gated recurrent unit ( gru ) based recurrent neural networks ( rnns ) are then cascaded to model the long - term temporal structure of the audio signal .",
        "especially , convolutional neural networks ( cnns ) have been revisited in asr recently .",
        "experimental results show that our proposed single system rcnn - ctc can achieve the lowest word error rate ( wer ) on wsj and tencent chat data sets , compared to several widely used neural network systems in asr .",
        "we present deep voice , a production - quality text - to - speech system constructed entirely from deep neural networks .",
        "deep voice lays the groundwork for truly end - to - end neural speech synthesis .",
        "for the segmentation model , we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification ( ctc ) loss .",
        "by using a neural network for each component , our system is simpler and more flexible than traditional text - to - speech systems , where each component requires laborious feature engineering and extensive domain expertise .",
        "we describe a rationalization technique that uses neural machine translation to translate internal state - action representations of the autonomous agent into natural language .",
        "modern parallel computing systems provide the capability to reduce the required training time of deep neural networks .",
        "in this paper , we present our parallelization scheme for training convolutional neural networks ( cnn ) named controlled hogwild with arbitrary order of synchronization ( chaos ) .",
        "we consider a neural net with one hidden layer and a convolutional structure with no overlap and a relu activation function .",
        "to the best of our knowledge , this is the first global optimality guarantee of gradient descent on a convolutional neural network with relu activations .",
        "on the theoretical side , we use results from statistical physics to carry out critical point calculations in feed - forward / fully connected networks , while on the experimental side we set out to find traces of criticality in deep neural networks .",
        "fixed - point optimization of deep neural networks plays an important role in hardware based design and low - power implementations .",
        "many deep neural networks show fairly good performance even with 2 - or 3 - bit precision when quantized weights are fine - tuned by retraining .",
        "the experiments are conducted for feed - forward deep neural networks ( ffdnns ) , convolutional neural networks ( cnns ) , and recurrent neural networks ( rnns ) .",
        "we introduce deepnat , a 3d deep convolutional neural network for the automatic segmentation of neuroanatomy in t1 - weighted magnetic resonance images .",
        "multi - task learning ( mtl ) in deep neural networks for nlp has recently received increasing interest due to some compelling benefits , including its potential to efficiently regularize models and to reduce the need for labeled data .",
        "this architecture , called the neural map , uses a spatially structured 2d memory image to learn to store arbitrary information about the environment over long time lags .",
        "we demonstrate empirically that the neural map surpasses previous drl memories on a set of challenging 2d and 3d maze environments and show that it is capable of generalizing to environments that were not seen during training .",
        "here we describe a neural controller system which learns how to sequentially compose the these primitive differentiable operations to solve reasoning tasks , and in particular , to perform knowledge base completion .",
        "in this paper , we propose an asymmetric tri - training method for unsupervised domain adaptation , where we assign pseudo - labels to unlabeled samples and train neural networks as if they are true labels .",
        "however , it is difficult to create a large dataset to train the ability of deep neural network models ( dnns ) .",
        "in this paper we propose the expose neural network , which uses a deep learning approach we have developed to take generic , raw short character strings as input ( a common case for security inputs , which include artifacts like potentially malicious urls , file paths , named pipes , named mutexes , and registry keys ) , and learns to simultaneously extract features and classify using character - level embeddings and convolutional neural network .",
        "in this paper , we propose a novel method to enrich the representation provided to the output layer of feedforward neural networks in the form of an auto - clustering output layer ( acol ) which enables the network to naturally create sub - clusters under the provided main class la - bels .",
        "in addition , a novel regularization term is introduced which allows acol to encourage the neural network to reveal its own explicit clustering objective .",
        "to address the first challenge , we present the scaffolding network , an attention - based neural network agent that can reason over a dynamic memory .",
        "deep neural networks require a large amount of labeled training data during supervised learning .",
        "recently low displacement rank ( ldr ) matrices , or so - called structured matrices , have been proposed to compress large - scale neural networks .",
        "empirical results have shown that neural networks with weight matrices of ldr matrices , referred as ldr neural networks , can achieve significant reduction in space and computational complexity while retaining high accuracy .",
        "first , we prove the universal approximation property of ldr neural networks with a mild condition on the displacement operators .",
        "we then show that the error bounds of ldr neural networks are as efficient as general neural networks with both single - layer and multiple - layer structure .",
        "finally , we propose back - propagation based training algorithm for general ldr neural networks .",
        "in contrast , we investigate the effectiveness of a single neural network for end - to - end long - term prediction of mechanical phenomena .",
        "we evaluate on two tasks : one supervised learning task , using a neural network to recognise users ' current activity from accelerometer traces ; and one unsupervised learning task , identifying topics in a large set of documents .",
        "sophisticated gated recurrent neural network architectures like lstms and grus have been shown to be highly effective in a myriad of applications .",
        "we also benchmark a set of simple baseline machine learning models suited for the tasks ( including logistic regression , convolutional neural networks and recurrent neural networks ) .",
        "in one particularly standout example , we show that the method is capable of learning to play sudoku given just input and output games , with no a priori information about the rules of the game ; this task is virtually impossible for other neural network architectures that we have experimented with , and highlights the representation capabilities of our approach .",
        "when training neural networks , the use of synthetic gradients ( sg ) allows layers or modules to be trained without update locking - without waiting for a true error gradient to be backpropagated - resulting in decoupled neural interfaces ( dnis ) .",
        "this unlocked ability of being able to update parts of a neural network asynchronously and with only local information was demonstrated to work empirically in jaderberg et al ( 2016 ) .",
        "we show that the incorporation of sgs does not affect the representational strength of the learning system for a neural network , and prove the convergence of the learning system for linear and deep linear models .",
        "the learned vector is then incorporated into neural attention models , which allows learning the mapping of syntactic structures between question and context pairs .",
        "we introduce a new metric called neural net distance for which generalization does occur .",
        "we suggest analyzing neural networks through the prism of space constraints .",
        "in this paper we describe how we use mixing complexity to obtain new results on what can and cannot be learned using neural networks .",
        "in this work we propose the first wii approach based upon deep convolutional neural networks ( cnns ) .",
        "in deep learning the ubiquitous architecture used for this task is the siamese neural network which maps each entity to a representation through a learnable function and expresses similarity through the distances among the entities in the representation space .",
        "we develop a novel neural model called attentive recurrent comparators ( arcs ) that dynamically compares two entities and test the model extensively on the omniglot dataset .",
        "in the challenging task of one - shot learning on the same dataset , an arc based model achieves the first super - human performance for a neural method with an error rate of 1 .",
        "in our experiments with deep neural networks , we obtained better performance compared to the popular stochastic gradient algorithms .",
        "despite their great success , there is still no com - prehensive theoretical understanding of learning with deep neural networks ( dnns ) or their in - ner organization .",
        "deep neural networks have been successfully applied in applications with a large amount of labeled data .",
        "however , there are major drawbacks of the neural networks that are related to rapid generalization with small data and continual learning of new concepts without forgetting .",
        "we propose a new neural generative model which combines variational auto - encoders and holistic attribute discriminators for effective imposition of semantic structures .",
        "the efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks .",
        "this paper presents an end - to - end learning framework for task - completion neural dialogue systems , which leverages supervised and reinforcement learning with various deep - learning models .",
        "as training data rapid growth , large - scale parallel training with multi - gpus cluster is widely applied in the neural network model learning currently .",
        "we present a new approach that applies exponential moving average method in large - scale parallel training of neural network model .",
        "fully - connected feed - forward neural networks ( dnns ) and deep unidirectional long short - term memory ( lstm ) recurrent neural networks ( rnns ) are successfully trained with proposed method for large vocabulary continuous speech recognition on shenma voice search data in mandarin .",
        ", robotics control , sequential prediction ) with deep neural network models .",
        "using both feedforward and recurrent neural network predictors , we present stochastic gradient procedures on a sequential prediction task , dependency - parsing from raw image data , as well as on various high dimensional robotics control problems .",
        "neural networks have proven effective at solving difficult problems but designing their architectures can be challenging , even for image classification problems alone .",
        "on the other hand , it is comparatively easy to build discriminative models on top of complex states such as images using standard deep neural networks .",
        "we present a new distributed representation in deep neural nets wherein the information is represented in native form as a matrix .",
        "this differs from current neural architectures that rely on vector representations .",
        "deep convolutional neural networks ( cnn ) have shown their good performances in many computer vision tasks .",
        "we frame the problem in the context of unsupervised domain adaptation and apply an adversarial framework to train a deep neural network with the additional objective to align features across domains .",
        "in this work , we build a generic architecture of convolutional neural networks to discover empirical properties of neural networks .",
        "recently , the end - to - end approach that learns hierarchical representations from raw data using deep convolutional neural networks has been successfully explored in the image , text and speech domains .",
        "to this end , we propose sample - level deep convolutional neural networks which learn representations from very small grains of waveforms ( e .",
        "considering this issue , we propose a convolutional neural networks ( cnn ) - based architecture that embraces multi - level and multi - scaled features .",
        "deep neural network is difficult to train and this predicament becomes worse as the depth increases .",
        "equipped with these two ingredients , we propose several novel optimization solutions that can be utilized for training a specific - structured ( repetitively triple modules of conv - bnrelu ) extremely deep convolutional neural network ( cnn ) without any shortcuts / identity mappings from scratch .",
        "we reinterpret multiplicative noise in neural networks as auxiliary random variables that augment the approximate posterior in a variational setting for bayesian neural networks .",
        "in experiments we show that with this new approximation we can significantly improve upon classical mean field for bayesian neural networks on both predictive accuracy as well as predictive uncertainty .",
        "we propose neural episodic control : a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them .",
        "in this work , we propose a novel metric learning method to evaluate distance between graphs that leverages the power of convolutional neural networks , while exploiting concepts from spectral graph theory to allow these operations on irregular graphs .",
        "although little is known , the author ' s group has propounded this framework for around 20 years and already has shown a variety of functions that emerge in a neural network ( nn ) through rl .",
        "data noising is an effective technique for regularizing neural network models .",
        "in this paper , we derive a connection between input noising in neural network language models and smoothing in $ n $ - gram models .",
        "training recurrent neural networks to model long term dependencies is difficult .",
        "we introduce a model that encodes such graphs as explicit memory in recurrent neural networks , and use it to model coreference relations in text .",
        "the performance of these trained policies are competitive with state of the art results , obtained with more elaborate parameterizations such as fully connected neural networks .",
        "deep neural networks coupled with fast simulation and improved computation have led to recent successes in the field of reinforcement learning ( rl ) .",
        "we represent the policy as a mixture of actor - critic neural network , which consists of n control policies and the corresponding value functions .",
        "taking advantage of specialised models such as bayesian convolutional neural networks , we demonstrate our active learning techniques with image data , obtaining a significant improvement on existing active learning approaches .",
        "we prove new upper and lower bounds on the vc - dimension of deep neural networks with the relu activation function .",
        "this paper develops a general framework for learning interpretable data representation via long short - term memory ( lstm ) recurrent neural networks over hierarchal graph structures .",
        "deep convolutional neural network ( cnn ) inference requires significant amount of memory and computation , which limits its deployment on embedded devices .",
        "despite recent advances , memory - augmented deep neural networks are still limited when it comes to life - long and one - shot learning , especially in remembering rare events .",
        "we demonstrate that this approach leads to state - of - the - art performance on a few - shot image classification benchmark , produces good results on few - shot regression , and accelerates fine - tuning for policy gradient reinforcement learning with neural network policies .",
        "training deep neural networks is a highly nontrivial task , involving carefully selecting appropriate training algorithms , scheduling step sizes and tuning other hyperparameters .",
        "in stark contrast , biological neural networks continually adapt to changing domains , and solve a diversity of tasks simultaneously .",
        "in this study , we take a first step toward bringing this biological complexity into artificial neural networks .",
        "on linear models and convolutional neural networks , we demonstrate that influence functions are useful for many different purposes : to understand model behavior , debug models and detect dataset errors , and even identify and exploit vulnerabilities to adversarial training - set attacks .",
        "the field of speech recognition is in the midst of a paradigm shift : end - to - end neural networks are challenging the dominance of hidden markov models as a core technology .",
        "we propose a version of graph convolutional networks ( gcns ) , a recent class of multilayer neural networks operating on graphs , suited to modeling syntactic dependency graphs .",
        "this paper proposes a new route for applying the generative adversarial nets ( gans ) to nlp tasks ( taking the neural machine translation as an instance ) and the widespread perspective that gans can ' t work well in the nlp area turns out to be unreasonable .",
        "we propose an approach wherein the outputs of multiple neural network classifiers are combined using a supervised machine learning model .",
        "in this paper , we propose a deep neural networks ( dnn ) based pbe model called neural programming by example ( npbe ) , which can learn from input - output strings and induce programs that solve the string manipulation problems .",
        "our npbe model has four neural network based components : a string encoder , an input - output analyzer , a program generator , and a symbol selector .",
        "deep learning with convolutional neural networks ( deep convnets ) has revolutionized computer vision through end - to - end learning , i .",
        "in this paper we show how the performance of tweet clustering can be improved by leveraging character - based neural networks .",
        "this paper presents a study of employing ranking svm and convolutional neural network for two missions : legal information retrieval and question answering in the competition on legal information extraction / entailment .",
        "for the legal question answering task , additional statistical features from information retrieval task integrated into convolutional neural network contribute to higher accuracy .",
        "current deep learning approaches have been very successful using convolutional neural networks ( cnn ) trained on large graphical processing units ( gpu ) - based computers .",
        "towards achieving them , we study convolutional recurrent neural networks ( crnns ) .",
        "this paper describes a neural - network model which performed competitively ( top 6 ) at the semeval 2017 cross - lingual semantic textual similarity ( sts ) task .",
        "our system employs an attention - based recurrent neural network model that optimizes the sentence similarity .",
        "first , we propose a convolutional neural network architecture for geometric matching .",
        "in this paper , we demonstrate that such data can be automatically extracted by deep neural networks ( aka deep learning ) , which is a cutting - edge type of artificial intelligence .",
        "in particular , we use the existing human - labeled images from the snapshot serengeti dataset to train deep convolutional neural networks for identifying 48 species in 3 .",
        "we train neural networks that automatically identify animals with over 92 % accuracy .",
        "in this paper we aim at filling this gap by comparing four popular parallel training algorithms in speech recognition , namely asynchronous stochastic gradient descent ( asgd ) , blockwise model - update filtering ( bmuf ) , bulk synchronous parallel ( bsp ) and elastic averaging stochastic gradient descent ( easgd ) , on 1000 - hour librispeech corpora using feed - forward deep neural networks ( dnns ) and convolutional , long short - term memory , dnns ( cldnns ) .",
        "taking advantage of the recent success of unsupervised learning in deep neural networks , we propose an end - to - end learning framework that is able to extract more robust multi - modal representations across domains .",
        "in this paper , we introduce two different convolutional neural network architectures for whole slide image segmentation to accurately identify the tissue sections .",
        "we propose and systematically evaluate three strategies for training dynamically - routed artificial neural networks : graphs of learned transformations through which different input signals may take different paths .",
        "this is achieved using recurrent neural networks ( rnns ) by forcing separated frames belonging to the same speaker to be aligned to the same output layer during training .",
        "recent papers have shown that neural networks obtain state - of - the - art performance on several different sequence tagging tasks .",
        "in this paper we explore the problem of transfer learning for neural sequence taggers , where a source task with plentiful annotations ( e .",
        "this makes it difficult to directly train a deep neural network for semantic segmentation , because it will be prone to overfitting .",
        "to cope with this , deep learning models typically use convolutional neural networks pre - trained on large - scale image classification datasets , which are then fine - tuned for semantic segmentation .",
        "in this paper , we developed two deep neural networks for semantic segmentation of multispectral remote sensing imagery .",
        "in this paper , we introduce recurrent collective classification ( rcc ) , a variant of ica analogous to recurrent neural network prediction .",
        "in the past few years , performance in image caption generation has seen significant improvement through the adoption of recurrent neural networks ( rnn ) .",
        "in machine learning and neuroscience , certain computational structures and algorithms are known to yield disentangled representations without us understanding why , the most striking examples being perhaps convolutional neural networks and the ventral stream of the visual cortex in humans and primates .",
        "for the step placement task , we combine recurrent and convolutional neural networks to ingest spectrograms of low - level audio features to predict steps , conditioned on chart difficulty .",
        "on these features , we apply five models : gaussian mixture model ( gmm ) , deep neural network ( dnn ) , recurrent neural network ( rnn ) , convolutional deep neural net - work ( cnn ) and i - vector .",
        "to our knowledge , this is the first successful transfer of a deep neural network trained only on simulated rgb images ( without pre - training on real images ) to the real world for the purpose of robotic control .",
        "we started with simple machine learning methods to estimate basic prediction performance and moved further by applying advanced methods based on shallow and deep neural networks .",
        "lstnet uses the convolution neural network ( cnn ) to extract short - term local dependency patterns among variables , and the recurrent neural network ( rnn ) to discover long - term patterns and trends .",
        "in this paper , we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task - oriented neural dialogue system in a reinforcement learning based setting .",
        "here the fact that multiple smiles represent the same molecule is explored as a technique for data augmentation of a molecular qsar dataset modeled by a long short term memory ( lstm ) cell based neural network .",
        "recurrent neural networks ( rnns ) , especially long short - term memory ( lstm ) rnns , are effective network for sequential task like speech recognition .",
        "this paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2d and 3d face alignment datasets .",
        "( c ) following that , we train a neural network for 3d face alignment and evaluate it on the newly introduced ls3d - w .",
        "large - scale deep convolutional neural networks ( cnns ) are widely used in machine learning applications .",
        "recently , two competing approaches for automatic program learning have received significant attention : ( 1 ) neural program synthesis , where a neural network is conditioned on input / output ( i / o ) examples and learns to generate a program , and ( 2 ) neural program induction , where a neural network generates new outputs directly using a latent program representation .",
        "moreover , using automatic phoneme - like tokenizations , we demonstrate that a convolutional neural network based framework for learning spoken document representations provides competitive performance compared to a standard bag - of - words representation , as evidenced by comprehensive topic id evaluations on both single - label and multi - label classification tasks .",
        "in this paper we analyze the gate activation signals inside the gated recurrent neural networks , and find the temporal structure of such signals is highly correlated with the phoneme boundaries .",
        "we develop an autoregressive convolutional neural network that learns to iteratively generate multiple frames .",
        "in this paper , we formulate the task as a matching problem of utterances before and after a certain decision point ; we propose a hierarchical recurrent neural network ( rnn ) with static sentence - level attention .",
        "experimental results show that neural networks consistently achieve better performance than feature - based approaches , and that our attention - based model significantly outperforms non - attention neural networks .",
        "we report the results of our classification - based machine translation model , built upon the framework of a recurrent neural network using gated recurrent units .",
        "the compositional kernels we use are inspired by the structure of convolutional neural networks and kernels .",
        "to address both concerns , we propose a novel architecture based on a network of deep neural networks , where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them .",
        "feedforward neural network ( fnn ) - based language models estimate the probability of the next word based on the history of the last n words , whereas recurrent neural networks ( rnn ) perform the same task based only on the last word and some context information that cycles in the network .",
        "extensive experiments conducted on the penn treebank ( ptb ) and the large text compression benchmark ( ltcb ) corpus showed a significant reduction of the perplexity when compared to state - of - the - art feedforward as well as recurrent neural network architectures .",
        "in state - of - the - art neural machine translation , an attention mechanism is used during decoding to enhance the translation .",
        "we propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the visual7w dataset .",
        "we start with lstm - encoding of input questions and answers ; build on this with context generation by lstm - encodings of neural image and question representations and attention over images ; and evaluate the diversity and predictive power of our models and the ensemble thereof .",
        "concretely , we use an image - to - words multi - label visual classifier to tag images with soft textual labels , and then train a neural network to map from the speech to these soft targets .",
        "deep convolutional neural networks are generally regarded as robust function approximators .",
        "here we explore the robustness of convolutional neural networks to perturbations to the internal weights and architecture of the network itself .",
        "to address this concern , a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network .",
        "catastrophic forgetting is a problem which refers to losing the information of the first task after training from the second task in continual learning of neural networks .",
        "to resolve this problem , we propose the incremental moment matching ( imm ) , which uses the bayesian neural network framework .",
        "imm assumes that the posterior distribution of parameters of neural networks is approximated with gaussian distribution and incrementally matches the moment of the posteriors , which are trained for the first and second task , respectively .",
        "to tackle the above problems , in this paper , we utilize the rich framework of ( temporal ) point processes to model event data and timely update its intensity function by the synergic twin recurrent neural networks ( rnns ) .",
        "furthermore , to enhance the interpretability of the model , the attention mechanism for the neural point process is introduced .",
        "large - scale deep neural networks ( dnn ) have been successfully used in a number of tasks from image recognition to natural language processing .",
        "with different information content ) such that the neural net can better learn using less bits .",
        "we model inference as a neural network and incorporate beacon placement as a differentiable neural layer .",
        "encouraged by the success of machine learning , and in particular convolutional neural networks , we propose to learn a matching function which directly maps multiple image patches to a scalar similarity score .",
        "learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling .",
        "the delta recurrent neural network ( delta - rnn ) framework is a simple and high - performing design that unifies previously proposed gated neural models .",
        "for retrieval we introduce a hand - crafted model and a neural model for ranking relevant articles .",
        "when a neural language model is used for caption generation , the image information can be fed to the neural network either by directly incorporating it in a recurrent neural network - - conditioning the language model by injecting image features - - or in a layer following the recurrent neural network - - conditioning the language model by merging the image features .",
        "furthermore , this suggests that recurrent neural networks should not be viewed as actually generating text , but only as encoding it for prediction in a subsequent layer .",
        "we survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition .",
        "especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real - life har application .",
        "multiple different approaches of generating adversarial examples have been proposed to attack deep neural networks .",
        "we efficiently train feed - forward neural networks in a self - supervised manner to generate adversarial examples against a target network or set of networks .",
        "the model , which is trained in a weakly supervised fashion , measures the similarity between customer questions and agent answers using a dual encoder network , a siamese - like neural network architecture .",
        "technically , we follow the current best practice and implement a convolutional neural network ( cnn ) , which is trained to carry out the end - to - end mapping from an entire rgb image to the corresponding hyperspectral image of",
        "artificial neural networks ( anns ) are trained to map damage fingerprints to damage characteristic parameters .",
        "frequency response function data after being reduced in size using pca is fed to individual neural networks to localize and predict the severity of damage on the structure .",
        "we analyze the performance of both baseline and state - of - the - art vqa models , including multi - modal compact bilinear pooling ( mcb ) , neural module networks , and recurrent answering units .",
        "in this paper , we propose a real time collective anomaly detection model based on neural network learning and feature operating .",
        "normally a long short term memory recurrent neural network ( lstm rnn ) is trained only on normal data and it is capable of predicting several time steps ahead of an input .",
        "we demonstrate superior results by a system which combines recurrent neural networks with convolutional neural networks in a voting approach .",
        "the gated - recurrent - unit - based neural networks are particularly well - suited to distinguish actions based on long - term information from optical tracking data ; the 3d - cnns focus more on detailed , recent information from video data .",
        "in this model , a preliminary trained convolutional neural network is essentially integrated with the adversarial framework , which can drive the generated textures to possess given perceptual attributes .",
        "one of them , the item response theory , is a well established method , while the other two , bayesian and neural networks , are new in the area of educational testing .",
        "they are based on the item response theory , bayesian networks , and neural networks .",
        "we propose two methods , which are based on recurrent neural networks , to learn the similarity function .",
        "previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima .",
        "however , the practical observation is that , at least for the most successful deep convolutional neural networks ( dcnns ) for visual processing , practitioners can always increase the network size to fit the training data ( an extreme example would be [ 1 ] ) .",
        "in visual recognition tasks , convolutional neural networks ( cnns ) have been successful to learn generalized feature extractors with shared parameters over the spatial domain .",
        "within hadid , a top - down hierarchical classification is applied , in which we use deep neural networks ( dnns ) method to build a local classifier for every parent node into the hierarchy dialect structure .",
        "in this paper , we study the use of recurrent neural networks ( rnns ) for modeling and forecasting time series .",
        "the proposed approach builds sentence representations using learned embeddings based on neural network .",
        "the results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance .",
        "we present a model of pragmatic referring expression interpretation in a grounded communication task ( identifying colors from descriptions ) that draws upon predictions from two recurrent neural network classifiers , a speaker and a listener , unified by a recursive pragmatic reasoning framework .",
        "an hybrid of a hidden markov model ( hmm ) and a deep neural network ( dnn ) is considered .",
        "biological neural networks are systems of extraordinary computational capabilities shaped by evolution , development , and lifetime learning .",
        "inspired by such intricate natural phenomena , evolved plastic artificial neural networks ( epanns ) use simulated evolution in - silico to breed plastic neural networks , artificial systems composed of sensors , outputs , and plastic components that change in response to sensory - output experiences in an environment .",
        "current scientific and technological advances in artificial neural networks are now setting the conditions for radically new approaches and results .",
        "in particular , the limitations of hand - designed structures and algorithms currently used in most deep neural networks could be overcome by more flexible and innovative solutions .",
        "though neural networks have seen success in computer vision and natural language processing , they have not been as useful in stock market trading .",
        "to demonstrate the applicability of a neural network in stock trading , we made a single - layer neural network that recommends buying or selling shares of a stock by comparing the highest high of 10 consecutive days with that of the next 10 days , a process repeated for the stock ' s year - long historical data .",
        "a chi - squared analysis found that the neural network can accurately and appropriately decide whether to buy or sell shares for a given stock , showing that a neural network can make simple decisions about the stock market .",
        "deep neural perception and control networks are likely to be a key component of self - driving vehicles .",
        "in this paper , we present midinet , a deep convolutional neural network ( cnn ) based generative adversarial network ( gan ) that is intended to provide a general , highly adaptive network structure for symbolic - domain music generation .",
        "while recent neural encoder - decoder models have shown great promise in modeling open - domain conversations , they often generate dull and generic responses .",
        "we return to an idea by langford and caruana ( 2001 ) , who used pac - bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two - layer two - hidden - unit neural networks via a sensitivity analysis .",
        "by optimizing the pac - bayes bound directly , we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples .",
        "our approach combines a search component based on bigram hashing and tf - idf matching with a multi - layer recurrent neural network model trained to detect answers in wikipedia paragraphs .",
        "we present a novel cross - lingual transfer method for paradigm completion , the task of mapping a lemma to its inflected forms , using a neural encoder - decoder model , the state of the art for the monolingual task .",
        "ensembles of neural networks are known to be much more robust and accurate than individual networks .",
        "in this paper , we propose a method to obtain the seemingly contradictory goal of ensembling multiple neural networks at no additional training cost .",
        "we achieve this goal by training a single neural network , converging to several local minima along its optimization path and saving the model parameters .",
        "we propose a feature imitation framework in which an implicit relation network is driven to learn from another neural network with access to connectives , and thus encouraged to extract similarly salient features for accurate classification .",
        "recent works have proved that synthetic parallel data generated by existing translation models can be an effective solution to various neural machine translation ( nmt ) issues .",
        "recurrent neural network ( rnn ) with long - short - term memory ( lstm ) only treats sentence as sequence data and can not utilize higher level syntactic information .",
        "to overcome this , we explore several auxiliary tasks , including semantic super - sense tagging and identification of multi - word expressions , and cast the task as a multi - task learning problem with deep recurrent neural networks .",
        "the input to a neural sequence - to - sequence model is often determined by an up - stream system , e .",
        "we showcase this method for two challenging applications : image compression and neural network compression .",
        "increasing the capacity of recurrent neural networks ( rnn ) usually involves augmenting the size of the hidden layer , resulting in a significant increase of computational cost .",
        "an alternative is the recurrent neural tensor network ( rntn ) , which increases capacity by employing distinct hidden layer weights for each vocabulary word .",
        "in this paper , we introduce restricted recurrent neural tensor networks ( r - rntn ) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words .",
        "recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence - to - sequence problems .",
        "more specifically , our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company .",
        "deep neural networks ( dnns ) have advanced the state - of - the - art in a variety of machine learning tasks and are deployed in increasing numbers of products and services .",
        "in this work , we propose dynamic variable effort deep neural networks ( dyvedeep ) to reduce the computational requirements of dnns during inference .",
        "although deep neural networks ( dnns ) have achieved great success in many computer vision tasks , recent studies have shown they are vulnerable to adversarial examples .",
        "luckily , several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature .",
        "in this paper , we reformulate existing models into a single common framework we call message passing neural networks ( mpnns ) and explore additional novel variations within this framework .",
        "regarding integration , we note that the most impactful recent contributions have been made possible through the integration of recent machine learning methods ( based in particular on deep learning and recurrent neural networks ) with more traditional ones ( e .",
        "it contains practical advice for those interested in testing the use of deep neural networks on applications that are novel for deep learning .",
        "in this paper , we propose two machine learning methods for automatic measurement of pre - aspiration duration : feedforward neural network , which works at the frame level ; and structured prediction model , which relies on manually designed feature functions , and works at the segment level .",
        "the generative model can use neural networks to handle both discrete and continuous latent variables to exploit various features of data .",
        "informed by previous work in semantic parsing , in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge .",
        "in this work , we propose to apply the neural encoder - decoder model to generate meaningful and diverse questions from natural language sentences .",
        "we conduct a preliminary study on neural question generation from text with the squad dataset , and the experiment results show that our method can produce fluent and diverse questions .",
        "is a powerful type of neural network that can capture long range dependencies and nonlinear dynamics .",
        "in this paper we present a novel application of software defined radio ( sdr ) based on lstm recurrent neural networks to decode audio signal from its noisy frequency demodulated version .",
        "an ensemble combining our neural semantic parser with an existing , traditional parser , yields a small gain in performance .",
        "we explored three different deep learning approaches : a character - level convolutional neural network ( cnn ) , a stacked learner with an mlp meta - classifier , and an attention based bi - lstm .",
        "however , we erroneously trained 2 out of 3 neural nets ( the stacker and the cnn ) on only roughly 15 % of the full data , namely , the original development set .",
        "for example , a recent model , deepconn , uses neural nets to learn one latent representation for the text of all reviews written by a target user , and a second latent representation for the text of all reviews for a target item , and then combines these latent representations to obtain state - of - the - art performance on recommendation tasks .",
        "based on the two - step framework , we implement a novel constrained neural generation model to simplify sentences given simplified words .",
        "the method exploits the temporal structure of a speech signal and more specifically , it trains deep neural networks ( dnns ) to discriminate temporal events obtained by uniformly segmenting the signal without using any label information , in contrast to conventional dnn based bn feature extraction methods that train dnns using labeled data to discriminate speakers or passphrases or phones or a combination of them .",
        "this paper explores the use of pyramid vector quantization ( pvq ) to reduce the computational cost for a variety of neural networks ( nns ) while , at the same time , compressing the weights that describe them .",
        "the purported \" black box \" ' nature of neural networks is a barrier to adoption in applications where interpretability is essential .",
        "here we present deeplift ( deep learning important features ) , a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input .",
        "we introduce an approach to implicit semantic role labeling ( isrl ) based on a recurrent neural semantic frame model that learns probability distributions over sequences of explicit semantic frame arguments .",
        "the theory of random vector functional link network ( rvfln ) has provided a breakthrough in the design of neural networks ( nns ) since it conveys solid theoretical justification of randomized learning .",
        "together with the proper choice of graph coarsening , we explore constructing deep neural networks for graph classification .",
        "to efficiently pre - train a large span of skills , we use stochastic neural networks combined with an information - theoretic regularizer .",
        "this complementarity is exploited in a new convolutional neural network ( cnn ) framework , which proposes the use of semantics as constraints for recognition .",
        "for computer vision applications , prior works have shown the efficacy of reducing the numeric precision of model parameters ( network weights ) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters .",
        "it has been believed that stochastic feedforward neural networks ( sfnns ) have several advantages beyond deterministic deep neural networks ( dnns ) : they have more expressive power allowing multi - modal mappings and regularize better due to their stochastic nature .",
        "ensembling is a well - known technique in neural machine translation ( nmt ) .",
        "instead of a single neural net , multiple neural nets with the same topology are trained separately , and the decoder generates predictions by averaging over the individual models .",
        "first , we show that the ensemble can be unfolded into a single large neural network which imitates the output of the ensemble system .",
        "as the first step to model emotional state of a person , we build sentiment analysis models with existing deep neural network algorithms and compare the models with psychological measurements to enlighten the relationship .",
        "the result shows that although cnn performed the best among other deep neural network algorithms ( lstm , gru ) , its results are not related to the psychological state .",
        "neural machine translation ( mt ) models obtain state - of - the - art performance while maintaining a simple , end - to - end architecture .",
        "in this work , we analyze the representations learned by neural mt models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part - of - speech and morphological tagging tasks .",
        "our data - driven , quantitative evaluation sheds light on important aspects in the neural mt system and its ability to capture word structure .",
        "although neural networks are well suited for sequential transfer learning tasks , the catastrophic forgetting problem hinders proper integration of prior knowledge .",
        "surprisingly , we find that first distilling a human made rule based sentiment engine into a recurrent neural network and then integrating the knowledge with the target task data leads to a substantial gain in generalization performance .",
        "we also discuss first submissions to the benchmark that use deep convolutional neural networks ( cnns ) as a work horse , which already show remarkable performance improvements over state - of - the - art .",
        "recent advances in deep neural networks have substantially improved the performance of this task .",
        "in order to adopt deep learning for ad - hoc information retrieval , it is essential to establish suitable representations of query - document pairs and to design neural architectures that are able to digest such representations .",
        "existing methods of neural word embeddings , including sngs , are multi - pass algorithms and thus cannot perform incremental model update .",
        "we propose a simple yet effective text - based user geolocation model based on a neural network with one hidden layer , which achieves state of the art performance over three twitter benchmark geolocation datasets , in addition to producing word and phrase embeddings in the hidden layer that we show to be useful for detecting dialectal terms .",
        "convolutional neural networks - cnns - on single images ) while only very few studies exist involving temporal deep learning approaches ( i .",
        "e recurrent neural networks - rnns ) to deal with remote sensing time series .",
        "in this letter we evaluate the ability of recurrent neural networks , in particular the long - short term memory ( lstm ) model , to perform land cover classification considering multi - temporal spatial data derived from a time series of satellite images .",
        "the obtained results show that recurrent neural networks are competitive compared to state - of - the - art classifiers , and may outperform classical approaches in presence of low represented and / or highly mixed classes .",
        "in this study we determined neural network weights and biases by imperialist competitive algorithm ( ica ) in order to train network for predicting earthquake intensity in richter .",
        "the studied neural network has two hidden layer : its first layer has 16 neurons and the second layer has 24 neurons .",
        "in this work , we propose class - enhanced attentive response ( clear ) : an approach to visualize and understand the decisions made by deep neural networks ( dnns ) given a specific input .",
        "in this paper , we use the framework of neural machine translation to learn joint sentence representations across different languages .",
        "extracting per - frame features using convolutional neural networks for real - time processing of video data is currently mainly performed on powerful gpu - accelerated workstations and compute clusters .",
        "we then present a novel neural synthesis algorithm to search for programs in the dsl that are consistent with a given set of examples .",
        "the search algorithm uses recently introduced neural architectures to encode input - output examples and to model the program search in the dsl .",
        "in this paper , we present an entity - drivenrecursive deep modelfor the chinese discourse coherence evaluation based on current english discourse coherenceneural network model .",
        "specifically , to overcome the shortage of identifying the entity ( nouns ) overlap across sentences in the currentmodel , our combined modelsuccessfully investigatesthe entities information into the recursive neural network freamework .",
        "in this paper , we propose a cross - sentence context - aware approach and investigate the influence of historical contextual information on the performance of neural machine translation ( nmt ) .",
        "neural sequence - to - sequence models have provided a viable new approach for abstractive text summarization ( meaning they are not restricted to simply selecting and rearranging passages from the original text ) .",
        "while neural approaches can achieve ( almost ) human - like accuracy for certain tasks and conditions , they often are sensitive to small changes in the input such as non - canonical input ( e .",
        "moreover , we empirically evaluate the robustness of different models ( convolutional neural networks , recurrent neural networks , non - neural models ) , different basic units ( characters , byte pair encoding units ) , and different nlp tasks ( morphological tagging , machine translation ) .",
        "we show that by modifying the training objective of a competitive neural coreference system , we obtain a substantial gain in performance .",
        "this paper proposes a new data - driven approach for modeling detailed splashes for liquid simulations with neural networks .",
        "we use neural networks to model the regression of splash formation using a classifier together with a velocity modification term .",
        "neural machine translation ( nmt ) , a new approach to machine translation , has achieved promising results comparable to those of traditional approaches such as statistical machine translation ( smt ) .",
        "neural machine translation ( nmt ) , a new approach to machine translation , has achieved promising results comparable to those of traditional approaches such as statistical machine translation ( smt ) .",
        ", 2016 ) results in accurate performance on this task , while being far simpler than many competing neural architectures .",
        "in this approach image reconstruction is performed with a deep convolutional neural network ( cnn ) , whose weights are adjusted prior to the actual image reconstruction based on a set of training data .",
        "the agent uses a deep recurrent neural network for function approximation .",
        "we present a simple and effective approach to incorporating syntactic structure into neural attention - based encoder - decoder models for machine translation .",
        "we rely on graph - convolutional networks ( gcns ) , a recent class of neural networks developed for modeling graph - structured data .",
        ", on top of bidirectional rnns or convolutional neural networks ) .",
        "we present a simple method to incorporate syntactic information about the target language in a neural machine translation system by translating into linearized , lexicalized constituency trees .",
        "in this paper , we model this effect by creating embeddings for characters based on their visual characteristics , creating an image for the character and running it through a convolutional neural network to produce a visual character embedding .",
        "the purpose of this study is to investigate whether pseudorehearsal can increase performance of an actor - critic agent with neural - network based policy selection and function approximation in a pole balancing task and compare different pseudorehearsal approaches .",
        "we propose a novel deep learning model for joint document - level entity disambiguation , which leverages learned neural representations .",
        "key components are entity embeddings , a neural attention mechanism over local context windows , and a differentiable joint inference stage for disambiguation .",
        "neural networks are function approximators that have achieved state - of - the - art accuracy in numerous machine learning tasks .",
        "in this paper , we explore the idea of learning weight evolution pattern from a simple network for accelerating training of novel neural networks .",
        "we use a neural network to learn the training pattern from mnist classification and utilize it to accelerate training of neural networks used for cifar - 10 and imagenet classification .",
        "the results indicate a general trend in the weight evolution during training of neural networks .",
        "adversarial attack has cast a shadow on the massive success of deep neural networks .",
        "despite being almost visually identical to the clean data , the adversarial images can fool deep neural networks into wrong predictions with very high confidence .",
        "this paper proposes two monte carlo techniques for these \" likelihood - free \" models , one of which can use likelihood estimates from neural networks to accelerate inference .",
        "our experiment with a neural machine translation on 4 gpus achieved a 22 % speed boost without impacting bleu score .",
        "recurrent neural networks ( rnn ) are widely used to solve a variety of problems and as the quantity of data and the amount of available compute have increased , so have model sizes .",
        "at the end of training , the parameters of the network are sparse while accuracy is still close to the original dense neural network .",
        "to learn from the resulting rhetoric structure , we propose a tensor - based , tree - structured deep neural network ( named rst - lstm ) in order to process the complete discourse tree .",
        "convolutional neural networks provide visual features that perform remarkably well in many computer vision applications .",
        "such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets , where it outperforms the sophisticated neural network models , including skip - thought vectors , by 15 % on average .",
        "we study the performance of faulty implementations of certain deep neural networks based on pessimistic and optimistic models of the effect of hardware faults .",
        "end - to - end neural machine translation has overtaken statistical machine translation in terms of translation quality for some language pairs , specially those with a large amount of parallel data available .",
        "beside this palpable improvement , neural networks embrace several new properties .",
        "in this paper , we propose a novel mer method by using deep convolutional neural network ( cnn ) on the music spectrograms that contains both the original time and frequency domain information .",
        "we propose a novel convolutional neural network to classify the complex time series data and determine if it corresponds to a breathing activity , followed by a random forest estimator to determine breathing rate .",
        "neural network models have shown their promising opportunities for multi - task learning , which focus on learning the shared layers to extract the common and task - invariant features .",
        "recent studies have shown that embedding textual relations using deep neural networks greatly helps relation extraction .",
        "this paper presents a deep attention model on the basis of recurrent neural networks ( rnn ) to learn \\ textit { selectively } temporal hidden representations of sequential posts for identifying rumors .",
        "we discover two problems , small micro variance and large macro variance , of pre - trained word embeddings that hurdle their direct use in neural networks , and propose standardization techniques as a remedy .",
        "this work is the first to overcome this limitation by interpreting the correlation filter learner , which has a closed - form solution , as a differentiable layer in a deep neural network .",
        "during the development stage , a deep neural network ( dnn ) that will be used to extract j - vector , is initialized and trained with the speech frames as input and the actual side information of the utterance as flat output block - wise one - hot labels .",
        "we investigate neural techniques for end - to - end computational argumentation mining .",
        "in this paper , we propose a hierarchical recurrent neural network enhanced by residual learning that detects kb relations given an input question .",
        "we compare treatment policies from fitted q - iteration with extremely randomized trees and with feedforward neural networks , and demonstrate that the policies learnt show promise in recommending weaning protocols with improved outcomes , in terms of minimizing rates of reintubation and regulating physiological stability .",
        "neural machine translation ( nmt ) becomes a new approach to machine translation and generates much more fluent results compared to statistical machine translation ( smt ) .",
        "we advance this framework by lifting linear bandit learning to neural sequence - to - sequence learning problems using attention - based recurrent neural networks .",
        "we present an evaluation on a neural machine translation task that shows improvements of up to 5 .",
        "modeling attention in neural multi - source sequence - to - sequence learning remains a relatively unexplored area , despite its usefulness in tasks that incorporate multiple source languages or modalities .",
        "empirically , neural networks that attempt to learn programs from data have exhibited poor generalizability .",
        "in order to address these issues , we propose augmenting neural architectures with a key abstraction : recursion .",
        "as an application , we implement recursion in the neural programmer - interpreter framework on four tasks : grade - school addition , bubble sort , topological sort , and quicksort .",
        "recursion divides the problem into smaller pieces and drastically reduces the domain of each neural network component , making it tractable to prove guarantees about the overall system ' s behavior .",
        "our experience suggests that in order for neural architectures to robustly learn program semantics , it is necessary to incorporate a concept like recursion .",
        "we are using deep convolutional neural networks to represent complex features .",
        "there has been a lot of research in this direction but the problem of integrating state - of - the - art neural language models with affective information remains an area ripe for exploration .",
        "we present a deep neural architecture that parses sentences into three semantic dependency graph formalisms .",
        "recurrent neural networks are showing much promise in many sub - areas of natural language processing , ranging from document classification to machine translation to automatic question answering .",
        "in this paper , we propose a new method for calculating the output layer in neural machine translation systems .",
        "neural models with minimal feature engineering have achieved competitive performance against traditional methods for the task of chinese word segmentation .",
        "however , both training and working procedures of the current neural models are computationally inefficient .",
        "this paper presents a greedy neural word segmenter with balanced word and character embedding inputs to alleviate the existing drawbacks .",
        "our segmenter is truly end - to - end , capable of performing segmentation much faster and even more accurate than state - of - the - art neural models on chinese benchmark datasets .",
        "in this paper , we propose an efficient vehicle trajectory prediction framework based on recurrent neural network .",
        "our approach is data - driven and simple to use in that it learns complex behavior of the vehicles from the massive amount of trajectory data through deep neural network model .",
        "the proposed trajectory prediction method employs the recurrent neural network called long short - term memory ( lstm ) to analyze the temporal behavior and predict the future coordinate of the surrounding vehicles .",
        "recurrent neural network ( rnn ) are being extensively used over feed - forward neural networks ( ffnn ) because of their inherent capability to capture temporal relationships that exist in the sequential data such as speech .",
        "the sentence encoder and decoder are built with recurrent neural networks .",
        "we propose a neural encoder - decoder transition - based parser which is the first full - coverage semantic graph parser for minimal recursion semantics ( mrs ) .",
        "to model both structured knowledge and unstructured language , we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses .",
        "automatic and human evaluations show that our model is both more effective at achieving the goal and more human - like than baseline neural and rule - based models .",
        "we demonstrate the feasibility and flexibility of lexically constrained decoding by conducting experiments on neural interactive - predictive translation , as well as domain adaptation for neural machine translation .",
        "for automatically parsing a spoken utterance , we introduce a model that integrates transcribed text and acoustic - prosodic features using a convolutional neural network over energy and pitch trajectories coupled with an attention - based recurrent neural network that accepts text and word - based prosodic features .",
        "we use neural word embeddings to discover words that are morphologically derived from each other and thereby that are semantically similar .",
        "we use letter successor variety counts obtained from tries that are built by neural word embeddings .",
        "our results show that using different information sources such as neural word embeddings and letter successor variety as prior information improves morphological segmentation in a bayesian model .",
        "neural machine translation represents an exciting leap forward in translation quality .",
        "to exemplify this approach , we present an english - french challenge set , and use it to analyze phrase - based and neural systems .",
        "the resulting analysis provides not only a more fine - grained picture of the strengths of neural systems , but also insight into which linguistic phenomena remain out of reach .",
        "briefly , in a reasoning system , a deep feedforward neural network is used to guide rewriting processes after learning from algebraic reasoning examples produced by humans .",
        "to enable the neural network to recognise patterns of algebraic expressions with non - deterministic sizes , reduced partial trees are used to represent the expressions .",
        "experimental results reveal that the algebraic reasoning examples can be accurately learnt only if the feedforward neural network has enough hidden layers .",
        "in this paper , we propose an approach to joint pos tagging and dependency parsing using transition - based neural networks .",
        "three neural network based classifiers are designed to resolve shift / reduce , tagging , and labeling conflicts .",
        "we study unsupervised learning by developing introspective generative modeling ( igm ) that attains a generator using progressively learned deep convolutional neural networks .",
        "in order to represent the complexity of the full space of inputs , we use aligned deformations from optical flow solves , and we leverage the power of generative neural networks to synthesize additional deformations for refinement .",
        "as part of a complete software stack for autonomous driving , nvidia has created a neural - network - based system , known as pilotnet , which outputs steering angles given images of the road ahead .",
        "we apply our learning algorithm to a new neural semantic parser and show significant gains over existing state - of - the - art results on a recent context - dependent semantic parsing task .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "we present a neural language model that incorporates document context in the form of a topic model - like architecture , thus providing a succinct representation of the broader document context outside of the current sentence .",
        "while the optimization problem behind deep neural networks is highly non - convex , it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points .",
        "in recent years , deep learning based on artificial neural network ( ann ) has achieved great success in pattern recognition .",
        "however , there is no clear understanding of such neural computational models .",
        "the class - pathway of a class is obtained by connecting the activated neural nodes in each layer from input to output , where activation value of neural node ( node - value ) is defined by the weights of each layer in a trained ann - classifier .",
        "at last , from the neural encodes view , we define the importance of each neural node through the class - pathways , which is helpful to optimize the structure of a classifier .",
        "the machine learned features from fully convolutional neural network ( fcn ) and hand - designed texton fea - tures are used to classify the mri image voxels .",
        "in machine learning , the use of an artificial neural network is the mainstream approach .",
        "here we investigate the possibility of replacing the inner product with a quadratic function of the input vector , thereby upgrading the 1st order neuron to the 2nd order neuron , empowering individual neurons , and facilitating the optimization of neural networks .",
        "we introduce a neural semantic parser which is interpretable and scalable .",
        "neural machine translation ( nmt ) heavily relies on an attention network to produce a context vector for each target word prediction .",
        "to discover hidden representations for the smiles strings , we use convolutional neural networks ( cnns ) .",
        "among the suitable models for the framework , splice junction classification using deep recurrent neural networks ( rnns ) is most appropriate for performing dna steganalysis .",
        "this paper aims to catalyze the discussions about text feature extraction techniques using neural network architectures .",
        "the research questions discussed in the paper focus on the state - of - the - art neural network techniques that have proven to be useful tools for language processing , language generation , text classification and other computational linguistics tasks .",
        "in recent years , deep neural networks have been used with great success in determining emotional states .",
        "to this purpose , we utilize a convolutional neural network ( cnn ) to extract features from the speech , while for the visual modality a deep residual network ( resnet ) of 50 layers .",
        "to achieve this , we adapt neural sequence models to map utterances directly to sql with its full expressivity , bypassing any intermediate meaning representations .",
        "we use reinforcement learning in a contextual bandit setting to train a neural network agent .",
        "in this study , we propose a 3d convolutional neural network ( cnn ) based nodule characterization strategy .",
        "we introduce parseval networks , a form of deep neural networks in which the lipschitz constant of linear , convolutional and aggregation layers is constrained to be smaller than 1 .",
        "parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation .",
        "a proper initialization of the weights in a neural network is critical to its convergence .",
        "first , i derive a general weight initialization strategy for any neural network using activation functions differentiable at 0 .",
        "recent advances in combining deep neural network architectures with reinforcement learning techniques have shown promising potential results in solving complex control problems with high dimensional state and action spaces .",
        "neural word segmentation research has benefited from large - scale raw texts by leveraging them for pretraining character and word embeddings .",
        "we investigate the effectiveness of a range of external training sources for neural word segmentation by building a modular segmentation model , pretraining the most important submodule using rich external sources .",
        "neural conversational models require substantial amounts of dialogue data for their parameter estimation and are therefore usually learned on large corpora such as chat forums or movie subtitles .",
        "in this paper , we propose a deep multi - view convolutional neural network to classify glitches automatically .",
        "the suggested classifier is a multi - view deep neural network that exploits four different views for classification .",
        "pre - trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for nlp tasks .",
        "here , we introduce a neural machine for top - down generation of tree structures that aims to infer such tree structures without the specified leaf nodes .",
        "deep learning refers to a set of machine learning techniques that utilize neural networks with many hidden layers for tasks , such as image classification , speech recognition , language understanding .",
        "\\ gpus and clouds ) for implementing , training and deploying deep neural networks .",
        "we particularly focus on convolutional neural networks and computer vision use cases , such as the visual inspection process in manufacturing plants and the analysis of social media data .",
        "to train neural networks , curated and labeled datasets are essential .",
        "in this paper , we discuss a twin neural network for learning from large datasets that are unbalanced , while optimizing the feature map at the same time .",
        "our results clearly demonstrate the generalization ability and scalability obtained by the twin neural network on large unbalanced datasets .",
        "recent advances in gpu hardware have enabled neural networks to achieve significant gains over the previous best models , these models still fail to leverage gpus ' capability for massive parallelism due to their requirement of sequential processing of the sentence .",
        "in response , we propose dilated iterated graph convolutional neural networks ( dig - cnns ) for graph - based dependency parsing , a graph convolutional architecture that allows for efficient end - to - end gpu parsing .",
        "in experiments on the english penn treebank benchmark , we show that dig - cnns perform on par with some of the best neural network parsers .",
        "we propose a novel neural network model for joint training from both sources of data based on cross - lingual word embeddings , and show substantial empirical improvements over baseline techniques .",
        "the quality of a neural machine translation system depends substantially on the availability of sizable parallel corpora .",
        "two methods are studied : an end to end , deep neural network that directly uses audio waveforms as input versus a pipelined approach that performs asr ( automatic speech recognition ) on the question , followed by text - based visual question answering .",
        "this paper proposes a new residual convolutional neural network ( cnn ) architecture for single image depth estimation .",
        "learning a better representation with neural networks is a challenging problem , which was tackled extensively from different prospectives in the past few years .",
        "we evaluate them on two most common types of models , recurrent neural networks and convolutional neural networks , showing that the approach we propose consistently improves the quality of kmeans clustering in terms of adjusted mutual information score and outperforms previously proposed methods .",
        "we quantify relevance by measuring the distance between frames and queries in a common textual - visual semantic embedding space induced by a neural network .",
        "we have designed a novel , hybrid convolutional neural network to integrate meta - data with text .",
        "feed - forward neural networks using n - gram embedding features encode messages into vectors which are optimized to give message - response pairs a high dot - product value .",
        "using an implementation based on deep neural networks , we demonstrate that phantom sampling dramatically avoids catastrophic forgetting .",
        "we apply these strategies to competitive multi - class incremental learning of deep neural networks .",
        "while end - to - end neural machine translation ( nmt ) has made remarkable progress recently , it still suffers from the data scarcity problem for low - resource language pairs and domains .",
        "in the experiment , we show that a neural network trained using stair captions can generate more natural and better japanese captions , compared to those generated using english - japanese machine translation after generating english captions .",
        "deep neural networks ( dnns ) have provably enhanced the state - of - the - art neural machine translation ( nmt ) with their capability in modeling complex functions and capturing complex linguistic structures .",
        "even though a linguistics - free sequence to sequence model in neural machine translation ( nmt ) has certain capability of implicitly learning syntactic information of source sentences , this paper shows that source syntax can be explicitly incorporated into nmt effectively to provide further improvements .",
        "the deployment of artificial neural networks ( anns ) in safety - critical applications poses a number of new verification and certification challenges .",
        "we view intersection handling as a deep reinforcement learning problem , which approximates the state action q function as a deep neural network .",
        "we present an approach for the verification of feed - forward neural networks in which all nodes have a piece - wise linear activation function .",
        "recurrent neural network ( rnn ) has been widely applied for sequence modeling .",
        "we propose a simple technique called parallel cells ( pcs ) to enhance the learning ability of recurrent neural network ( rnn ) .",
        "in typical neural machine translation ~ ( nmt ) , the decoder generates a sentence word by word , packing all linguistic granularities in the same time - scale of rnn .",
        "recently , artificial neural networks , so called deep - learning approaches , have been proposed to address this challenge .",
        "popular deep learning frameworks require users to fine - tune their memory usage so that the training data of a deep neural network ( dnn ) fits within the gpu physical memory .",
        "here , we focus on efficient decoding , with a goal of achieving accuracy close the state - of - the - art in neural machine translation ( nmt ) , while achieving cpu decoding speed / throughput close to that of a phrasal decoder .",
        "we propose a recurrent neural model that generates natural - language questions from documents , conditioned on answers .",
        "this paper presents senti17 system which uses ten convolutional neural networks ( convnet ) to assign a sentiment label to a tweet .",
        "to tackle these problems , in this work , we formulate acbd as a sequence labeling problem and propose a variety of recurrent neural network ( rnn ) based methods , which do not use domain specific or handcrafted features beyond the relative position of the sentence in the document .",
        "this technique enables neural networks to learn from old and successful resolution processes and to use learnt experiences to guide new resolution processes .",
        "it includes a prolog library of deep feedforward neural networks and some essential functions of resolution .",
        "in the sldr - dl framework , users can define logical rules in the form of definite clauses and teach neural networks to use the rules in reasoning processes .",
        "in this paper we propose a neural network model with a novel sequential attention layer that extends soft attention by assigning weights to words in an input sequence in a way that takes into account not just how well that word matches a query , but how well surrounding words match .",
        "we present deep speaker , a neural speaker embedding system that maps utterances to a hypersphere where speaker similarity is measured by cosine similarity .",
        "we describe a neural network model that jointly learns distributed representations of texts and knowledge base ( kb ) entities .",
        "in this paper , we proposed a scene text erasing method to properly hide the information via an inpainting convolutional neural network ( cnn ) model .",
        "recently , several end - to - end neural models have been proposed for machine comprehension tasks .",
        "the prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks .",
        "we introduce an architecture based entirely on convolutional neural networks .",
        "it shows how to process the source data , train a neural network to learn the high - dimensional embeddings for individual languages and expands the framework for testing their quality beyond the english language .",
        "deep neural models , particularly the lstm - rnn model , have shown great potential in language identification ( lid ) .",
        "however , the phonetic information has been largely overlooked by most of existing neural lid methods , although this information has been used in the conventional phonetic lid systems with a great success .",
        "we present a phonetic temporal neural model for lid , which is an lstm - rnn lid system but accepts phonetic features produced by a phone - discriminative dnn as the input , rather than raw acoustic features .",
        "our experiments conducted on the babel database and the ap16 - olr database demonstrate that the temporal phonetic neural approach is very effective , and significantly outperforms existing acoustic neural models .",
        "pure acoustic neural models , particularly the lstm - rnn model , have shown great potential in language identification ( lid ) .",
        "however , the phonetic information has been largely overlooked by most of existing neural lid models , although this information has been used in the conventional phonetic lid systems with a great success .",
        "we present a phone - aware neural lid architecture , which is a deep lstm - rnn lid system but accepts output from an rnn - based asr system .",
        "inspired by the deep learning approaches in natural language processing , we propose a recurrent neural network model with multiple attention layers for ddi classification .",
        "in this paper , we explore novel approaches for modeling dialogue context in a re - current neural network ( rnn ) based lan - guage understanding system .",
        "we also present two baseline algorithms : a feature - based classifier and a state - of - the - art neural network , that performs well on squad reading comprehension .",
        "both the program generator and the execution engine are implemented by neural networks , and are trained using a combination of backpropagation and reinforce .",
        "recently deep neural networks ( dnns ) have been used to learn speaker features .",
        "however , the quality of the learned features is not sufficiently good , so a complex back - end model , either neural or probabilistic , has to be used to address the residual uncertainty when applied to speaker verification , just as with raw features .",
        "this paper presents a convolutional time - delay deep neural network structure ( ct - dnn ) for speaker feature learning .",
        "it has been shown that chinese poems can be successfully generated by sequence - to - sequence neural models , particularly with the attention mechanism .",
        "a potential problem of this approach , however , is that neural models can only learn abstract rules , while poem generation is a highly creative process that involves not only rules but also innovations for which pure statistical models are not appropriate in principle .",
        "this work proposes a memory - augmented neural model for chinese poem generation , where the neural model and the augmented memory work together to balance the requirements of linguistic accordance and aesthetic innovation , leading to innovative generations that are still rule - compliant .",
        "in this work , we present a minimal neural model for constituency parsing based on independent scoring of labels and spans .",
        "this paper demonstrates end - to - end neural network architectures for vietnamese named entity recognition .",
        "our best model is the combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which achieves an f1 score of 88 .",
        "given an existing trained neural network , it is often desirable to be able to add new capabilities without hindering performance of already learned tasks .",
        "our experiments show that the proposed method can achieve competitive results , comparable to neural embedding learning techniques , however , with only a fraction of the computational complexity of these methods .",
        "bridging this gap , we develop a method to predict human impressions of faces in 40 subjective social dimensions , using deep representations from state - of - the - art neural networks .",
        "we introduce a neural network model with intra - attention and a new training method .",
        "we achieve this by utilizing improved neural architectures for streaming inference , solving optimization issues , and employing strategies that increase audio and label modelling versatility .",
        "after that , the encoded image is fed to convolutional neural network ( cnn ) for automatic feature extraction and learning , reducing the expert ' s intervention .",
        "word - embedding or obtaining vector representation of words from a large corpora of free texts using neural network methods have been shown to give significant performance for several natural language processing tasks .",
        "in recent years , the deep neural network has enjoyed a great success in large - scale image and video recognitions .",
        "in this paper , we propose and experiment using deep convolutional neural network to imitate how human brain processes hierarchical structures in the auditory signals , such as music , speech , etc .",
        "in this paper , we compare established methods like bayes , rocchio , knn , svm , and logistic regression as well as recent methods like learning to rank and neural networks to the multi - label document classification problem .",
        "the best method on title data is a modern variant of neural networks .",
        "for one dataset , a stacking of logistic regression and decision trees performs slightly better than neural networks .",
        "neural task - oriented dialogue systems often struggle to smoothly interface with a knowledge base .",
        "in this work , we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded , multi - domain discourse through a novel key - value retrieval mechanism .",
        "our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule - based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics .",
        "expectation for the emergence of higher functions is getting larger in the framework of end - to - end reinforcement learning using a recurrent neural network .",
        "over the past two decades , the feedforward neural network ( fnn ) optimization has been a key interest among the researchers and practitioners of multiple disciplines .",
        "this article also tries to connect various research directions emerged out of the fnn optimization practices , such as evolving neural network ( nn ) , cooperative coevolution nn , complex - valued nn , deep learning , extreme learning machine , quantum n",
        "we treat the relation inference tasks as a machine learning problem and tackle it with neural networks .",
        "we propose a new neural network module , contrast association unit ( cau ) , which explicitly models the relations between two sets of input variables .",
        "experiments show that neural networks with caus are more effective in learning five fundamental image transformations than conventional neural networks .",
        "long short - term memory ( lstm ) is a specific recurrent neural network ( rnn ) architecture that is well - suited to learn from experience to classify , process and predict time series with time lags of unknown size .",
        "we train naive long short - term memory ( lstm ) recurrent neural networks ( rnns ) on six formal languages drawn from the strictly local ( sl ) and strictly piecewise ( sp ) classes .",
        "we present a novel neural network model that learns pos tagging and graph - based dependency parsing jointly .",
        "our extensive experiments , on 19 languages from the universal dependencies project , show that our model outperforms the state - of - the - art neural network - based stack - propagation model for joint pos tagging and transition - based dependency parsing , resulting in a new state of the art .",
        "frame stacking is broadly applied in end - to - end neural network training like connectionist temporal classification ( ctc ) , and it leads to more accurate models and faster decoding .",
        "however , it is not well - suited to conventional neural network based on context - dependent state acoustic model , if the decoder is unchanged .",
        "long short - term memory ( lstm ) recurrent neural networks ( rnns ) using it achieve almost linear training speedup and reduces relative 41 \\ % real time factor ( rtf ) .",
        "we present a semi - supervised way of training a character - based encoder - decoder recurrent neural network for morphological reinflection , the task of generating one inflected word form from another .",
        "the approach comprises data cleaning , normalization , capping , time - based compression , and finally classification with a recurrent neural network .",
        "we investigate dependency parsing of singlish by constructing a dependency treebank under the universal dependencies scheme , and then training a neural network model by integrating english syntactic knowledge into a state - of - the - art parser trained on the singlish treebank .",
        "to the best of our knowledge , we are the first to use neural stacking to improve cross - lingual dependency parsing on low - resource languages .",
        "in this work , we propose a novel two - stream 3d convolutional neural network ( cnn ) architecture by introducing the discriminative code layer and the corresponding discriminative code loss function .",
        "we conduct an elaborate analysis of different fusion schemes ( weighted average , single and double - layer neural nets ) applied to different 3d cnn outputs .",
        "in this work we present our results on learning strategies in atari games using a convolutional neural network , the math kernel library and tensorflow 0 .",
        "recently , deep convolutional neural network ( dcnn ) achieved increasingly remarkable success and rapidly developed in the field of natural image recognition .",
        "while the sparse coding principle can successfully model information processing in sensory neural systems , it remains unclear how learning can be accomplished under neural architectural constraints .",
        "we describe a neural network with spiking neurons that can address the aforementioned fundamental challenge and solve the l1 - minimizing dictionary learning problem , representing the first model able to do so .",
        "there are many applications scenarios for which the computational performance and memory footprint of the prediction phase of deep neural networks ( dnns ) needs to be optimized .",
        "binary neural networks ( bdnns ) have been shown to be an effective way of achieving this objective .",
        "in this paper , we show how convolutional neural networks ( cnns ) can be implemented using binary representations .",
        "we experimentally show that espresso is significantly faster than existing implementations of optimized binary neural networks ( $ \\ approx $ 2 orders of magnitude )",
        "recent research has shown that one can train a neural network with binary weights and activations at train time by augmenting the weights with a high - precision continuous latent variable that accumulates small changes from stochastic gradient descent .",
        "our main result is that the neural networks with binary weights and activations trained using the method of courbariaux , hubara et al .",
        "our theory serves as a foundation for understanding not only bnns but a variety of methods that seek to compress traditional neural networks .",
        "furthermore , a better understanding of multilayer binary neural networks serves as a starting point for generalizing bnns to other neural network architectures such as recurrent neural networks .",
        "deep neural networks ( dnns ) are presently the state - of - the - art for image classification tasks .",
        "as such , the design of a general defense strategy against a wide range of attacks for neural networks becomes a challenging problem .",
        "adjacency of the examples is inferred using the predictions of a neural network model which is first initialized by a supervised pretraining .",
        "ultimately , the proposed framework provides an effective and scalable graph - based solution which is natural to the operational mechanism of deep neural networks .",
        "a different parametrization of the hyperplanes is used in the neural net algorithm .",
        "the experimental results of pso - p on ib are compared to results of closed - form control policies derived from the model - based recurrent control neural network ( rcnn ) and the model - free neural fitted q - iteration ( nfq ) .",
        "neural networks are known to be vulnerable to adversarial examples : inputs that are close to valid inputs but classified incorrectly .",
        "in this paper , we extend an attention - based neural machine translation ( nmt ) model by allowing it to access an entire training set of parallel sentence pairs even after training .",
        "we address the problem of reconstructing sparse signals from noisy and compressive measurements using a feed - forward deep neural network ( dnn ) with an architecture motivated by the iterative shrinkage - thresholding algorithm ( ista ) .",
        "adversarial neural networks solve many important problems in data science , but are notoriously difficult to train .",
        "this model employs multi - layer recurrent neural networks as an encoder and a decoder .",
        "we propose a novel neural network structure called crossnets , which considers architectures on directed acyclic graphs .",
        "how to develop slim and accurate deep neural networks has become crucial for real - world applications , especially for those employed in embedded systems .",
        "in this paper , we propose a new layer - wise pruning method for deep neural networks .",
        "while previous contributions to feature extraction propose embeddings based on a single layer of the network , in this paper we propose a full - network embedding which successfully integrates convolutional and fully connected features , coming from all layers of a deep convolutional neural network .",
        "deep neural networks have been shown to succeed at a range of natural language tasks such as machine translation and text summarization .",
        "as first solutions , we design a set of deep neural models that learn to represent the context of each variable location and variable usage in a data flow - sensitive way .",
        "experiments show significant speed gains for various deep neural networks .",
        "batch normalization ( bn ) is very effective in accelerating the convergence of a neural network training phase that it has become a common practice .",
        "with the evolution of neural network based methods , automatic speech recognition ( asr ) field has been advanced to a level where building an application with speech interface is a reality .",
        "this paper highlights the significance of including memory structures in neural networks when the latter are used to learn perception - action loops for autonomous robot navigation .",
        "this work is a first thorough study of memory structures for deep - neural - network - based robot navigation , and offers novel tools to train such networks from supervision and quantify their ability to generalize to unseen scenarios .",
        "we analyze the separation and generalization abilities of feedforward , long short - term memory , and differentiable neural computer networks .",
        "recurrent neural network ( rnn ) are a popular choice for modeling temporal and sequential tasks and achieve many state - of - the - art performance on various complex problems .",
        "recently , sequence - to - sequence model by using encoder - decoder neural network has gained popularity for automatic speech recognition ( asr ) .",
        "these works mainly focused on the detection algorithms which use features with fixed dimension , while some researchers have begun to use recurrent neural networks ( rnn ) to detect malware based on sequential api features .",
        "in this paper , we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input , namely the indicators , that act as the hints to suggest logical outcomes .",
        "we used the mnist data to demonstrate the design and use of these indicators in a convolutional neural network .",
        "we trained a series of such hybrid neural networks with variations of the indicators .",
        "our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models .",
        "we propose to use a hierarchical semantic representation of the objects , coming from a convolutional neural network , to solve this ambiguity .",
        "our idea is to mark parts as \" matching \" if their features are close to each other at all the levels of convolutional feature hierarchy ( neural paths ) .",
        "deep neural networks ( dnns ) play a key role in many applications .",
        "we introduce an architecture in which internal representations , learned by end - to - end optimization in a deep neural network performing a textual question - answering task , can be interpreted using basic concepts from linguistic theory .",
        "planning new policies is performed by tree search , while a deep neural network generalises those plans .",
        "in contrast , standard deep reinforcement learning algorithms rely on a neural network not only to generalise plans , but to discover them too .",
        "recurrent neural networks architectures excel at processing sequences by modelling dependencies over different timescales .",
        "in particular , we compare both long short - term memory networks ( lstm ) and convolutional neural networks ( cnn ) for prediction of five intervention tasks : invasive ventilation , non - invasive ventilation , vasopressors , colloid boluses , and crystalloid boluses .",
        "selective classification techniques ( also known as reject option ) have not yet been considered in the context of deep neural networks ( dnns ) .",
        "in this paper we propose a method to construct a selective classifier given a trained neural network .",
        "in our evaluation , we use our algorithm to interpret random forests and neural nets trained on several datasets from the uci machine learning repository , as well as control policies learned for three classical reinforcement learning problems .",
        "a major challenge in designing neural network ( nn ) systems is to determine the best structure and parameters for the network given the data for the machine learning problem at hand .",
        "recent advances in generative sequential modeling have suggested to combine recurrent neural networks with state space models ( e .",
        "inheriting these advantages of stochastic neural sequential models , we propose a structured and stochastic sequential neural network , which models both the long - term dependencies via recurrent neural networks and the uncertainty in the segmentation and labels via discrete random variables .",
        "neural networks , with their distributed representations , are challenging these methods .",
        "we introduce a technique for augmenting neural text - to - speech ( tts ) with lowdimensional trainable speaker embeddings to generate different voices from a single model .",
        "as a starting point , we show improvements over the two state - ofthe - art approaches for single - speaker neural tts : deep voice 1 and tacotron .",
        "we improve tacotron by introducing a post - processing neural vocoder , and demonstrate a significant audio quality improvement .",
        "we show that a single neural tts system can learn hundreds of unique voices from less than half an hour of data per speaker , while achieving high audio quality synthesis and preserving the speaker identities almost perfectly .",
        "in this paper , we model the background by a recurrent neural network ( rnn ) with its units aligned with time series indexes while the history effect is modeled by another rnn whose units are aligned with asynchronous events to capture the long - range dynamics .",
        "we instantiate our framework using neural networks , and build a concrete model , dauto .",
        "the approach uses recurrent neural networks as its building blocks .",
        "the design of neural architectures for structured objects is typically guided by experimental insights rather than a formal process .",
        "in this work , we appeal to kernels over combinatorial structures , such as sequences and graphs , to derive appropriate neural operations .",
        "we introduce a class of deep recurrent neural operations and formally characterize their associated kernel spaces .",
        "similar to traditional neural operations , these reference objects are parameterized and directly optimized in end - to - end training .",
        "we empirically evaluate the proposed class of neural architectures on standard applications such as language modeling and molecular graph regression , achieving state - of - the - art or competitive results across these applications .",
        "we report results for learning the cdprs with a deep neural network and using them to solve two tasks with deep reinforcement learning .",
        "this paper proposes a simple neural model for rte problem .",
        "we introduce a neural network that represents sentences by composing their words according to induced binary parse trees .",
        "in this paper an image classification model based on convolutional neural network is applied to quantitative light - induced fluorescence images .",
        "the deep neural network outperforms other state of the art shallow classification models in predicting labels derived from three different dental plaque assessment scores .",
        "drawing inspiration from recent efforts to empower neural networks with a structural bias , we propose a model that can encode a document while automatically inducing rich structural dependencies .",
        "specifically , we embed a differentiable non - projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases .",
        "recurrent neural networks have achieved remarkable success at generating sequences with complex structures , thanks to advances that include richer embeddings of input and cures for vanishing gradients .",
        "an approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated asr confidence measures .",
        "it also shown that combining an slu approach based on conditional random fields with a neural encoder / decoder attention based architecture , it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy .",
        "in this paper we propose a method that takes the advantage of recurrent neural network ( rnn ) to extract higher level features present across the sentence .",
        "we explore several methods to detect and explain crisis using a combination of neural and non - neural techniques .",
        "in recent years , stochastic gradient descent ( sgd ) based techniques has become the standard tools for training neural networks .",
        "however , formal theoretical understanding of why sgd can train neural networks in practice is largely missing .",
        "we evaluate the character - level translation method for neural semantic parsing on a large corpus of sentences annotated with abstract meaning representations ( amrs ) .",
        "neural networks ( nn ) are constructed to parameterize a stochastic policy that directly maps sensory data collected by the robot to its velocity outputs , while respecting a set of social norms .",
        "we investigate the possibility of using deep residual convolutional neural network with spectrograms as an input features in the text - dependent speaker verification task .",
        "our work addresses two important issues with recurrent neural networks : ( 1 ) they are over - parameterized , and ( 2 ) the recurrence matrix is ill - conditioned .",
        "we show that a recently proposed neural dependency parser can be improved by joint training on multiple languages from the same family .",
        "the parser is implemented as a deep neural network whose only input is orthographic representations of words .",
        "in this paper , we propose a latent intention dialogue model ( lidm ) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference .",
        "to this end , we introduce a new model for statistical relational learning that is built upon deep recursive neural networks , and give experimental evidence that it can easily compete with , or even outperform , existing logic - based reasoners on the task of ontology reasoning .",
        "we show that a modular neural network ( mnn ) can combine various speech enhancement modules , each of which is a deep neural network ( dnn ) specialized on a particular enhancement job .",
        "deep learning tends to emphasize on sentence level semantics when learning a representation with models like recurrent neural network or recursive neural network , however from the success of tf - idf representation , it seems a bag - of - words type of representation has its strength .",
        "we apply the model on characters and our results show that our model is better than all the other character - based and word - based convolutional neural network models by \\ cite { zhang15 } across seven different datasets with only 1 \\ % of their parameters .",
        "deep neural networks trained on large supervised datasets have led to impressive results in recent years .",
        "in this paper , we investigate the behavior of deep neural networks on training sets with massively noisy labels .",
        "we propose a new linguistic stegosystem based on a long short - term memory ( lstm ) neural network .",
        "we present a transition - based dependency parser that uses a convolutional neural network to compose word representations from characters .",
        "in the neural network domain , methods for hyperparameter optimization and meta - modeling are computationally expensive due to the need to train a large number of neural network configurations .",
        "in this paper , we show that a simple regression model , based on support vector machines , can predict the final performance of partially trained neural network configurations using features based on network architectures , hyperparameters , and time - series validation performance data .",
        "we use this regression model to develop an early stopping strategy for neural network configurations .",
        "most of the previous studies focus on discriminative neural networks which unnecessarily require a separation of input / output variables .",
        "recent development of generative neural networks such as restricted boltzmann machines ( rbms ) has shown a capability of learning semantic abstractions directly from data , posing a promise for general symbolic learning and reasoning .",
        "we introduce neural networks for end - to - end differentiable theorem proving that operate on dense vector representations of symbols .",
        "these neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in prolog .",
        "by using gradient descent , the resulting neural network can be trained to infer facts from a given incomplete knowledge base .",
        "we demonstrate that this architecture outperforms complex , a state - of - the - art neural link prediction model , on four benchmark knowledge bases while at the same time inducing interpretable function - free first - order logic rules .",
        "we developed a hierarchical architecture based on neural networks that is simple to train .",
        "stochastic gradient descent ( sgd ) , which updates the model parameters by adding a local gradient times a learning rate at each step , is widely used in model training of machine learning algorithms such as neural networks .",
        "we propose an algorithm to automatically learn learning rates using neural network based actor - critic methods from deep reinforcement learning ( rl ) .",
        "in the past few years , attention mechanisms have become an indispensable component of end - to - end neural machine translation models .",
        "learning neural network architectures is a way to discover new highly predictive models .",
        "for instance , our approach is able to solve the following task : find the best neural network architecture ( in a very large set of possible architectures ) able to predict well in less than 100 milliseconds on my mobile phone .",
        "deep neural network ( dnn ) are currently of great inter - est in research and application .",
        "this paper presents a new approach to nlg by using recurrent neural networks ( rnn ) , in which a gating mechanism is applied before rnn computation .",
        "this paper presents a recurrent neural network based encoder - decoder architecture , in which an lstm - based decoder is introduced to select , aggregate semantic elements produced by an attention mechanism over the input elements , and to produce the required utterances .",
        "this paper presents alternative neural approaches to topic modelling by providing parameterisable distributions over topics which permit training by backpropagation in the framework of neural variational inference .",
        "experimental results on the mxm song lyrics , 20newsgroups and reuters news datasets demonstrate the effectiveness and efficiency of these neural topic models .",
        "in this paper , we explore the use of tensor contractions as neural network layers and investigate several ways to apply them to activation tensors .",
        "specifically , we propose the tensor contraction layer ( tcl ) , the first attempt to incorporate tensor contractions as end - to - end trainable neural network layers .",
        "in this paper , we present nmtpy , a flexible python toolkit based on theano for training neural machine translation and other neural sequence - to - sequence architectures .",
        "a deep convolutional neural network approach is developed to model the voxel - wise spatio - temporal tumor progression .",
        "stripes is a deep neural network ( dnn ) accelerator that uses bit - serial computation to offer performance that is proportional to the fixed - point precision of the activation values .",
        "for instance , non - parametric artificial neural networks .",
        "in this paper , we describe the \" pixelgan autoencoder \" , a generative autoencoder in which the generative path is a convolutional autoregressive neural network on pixels ( pixelcnn ) that is conditioned on a latent code , and the recognition path uses a generative adversarial network ( gan ) to impose a prior distribution on the latent code .",
        "deep neural networks are able to solve tasks across a variety of domains and modalities of data .",
        "in this work , we present a general method for visualizing an arbitrary neural network ' s inner mechanisms and their power and limitations .",
        "we demonstrate the effectiveness of our framework on a variety of deep neural network architectures in domains from computer vision , natural language processing , and reinforcement learning .",
        "in this work , we conduct extensive experiments using an attentive convolutional neural network with multi - view learning objective function .",
        "we overview dataflow matrix machines as a turing complete generalization of recurrent neural networks and as a programming platform .",
        "we describe vector space of finite prefix trees with numerical leaves which allows us to combine expressive power of dataflow matrix machines with simplicity of traditional recurrent neural networks .",
        "exploiting the great expressive power of deep neural network architectures , relies on the ability to train them .",
        "training a deep convolutional neural network ( cnn ) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence .",
        "this paper demonstrates the potential of convolutional neural networks ( cnn ) for detecting and classifying prosodic events on words , specifically pitch accents and phrase boundary tones , from frame - based acoustic features .",
        "unlike traditional singleton neural network , our model incorporates character - aware convolutional neural network ( char - cnn ) with character - aware recurrent neural network ( char - rnn ) to form a convolutional recurrent neural network ( crnn ) .",
        "a recently explored solution space lies in compressing ( approximating or simplifying ) deep neural networks in some manner before use on the device .",
        "first , unlike current solutions geared for compressing specific types of neural networks , deepiot presents a unified approach that compresses all commonly used deep learning structures for sensing applications , including fully - connected , convolutional , and recurrent neural networks , as well as their combinations .",
        "second , unlike solutions that either sparsify weight matrices or assume linear structure within weight matrices , deepiot compresses neural network structures into smaller dense matrices by finding the minimum number of non - redundant hidden elements , such as filters and dimensions required by each layer , while keeping the performance of sensing applications the same .",
        "we propose a novel method to learn a neural program operating a domain - specific non - differentiable machine , and demonstrate that this method can be applied to learn programs that are significantly more complex than the ones synthesized before : programming language parsers from input - output pairs without knowing the underlying grammar .",
        "the main challenge is to train the neural program without supervision on execution traces .",
        "to tackle it , we propose : ( 1 ) ll machines and neural programs operating them to effectively regularize the space of the learned programs ; and ( 2 ) a two - phase reinforcement learning - based search technique to train the model .",
        "this is the first successful demonstration of applying reinforcement learning to train a neural program operating a non - differentiable machine that can fully generalize to test sets on a non - trivial task .",
        "to date , recurrent neural networks that learn language models at character , word , or sentence levels have had little success generating coherent stories .",
        "while other works in the field rely on the use of a hand - written rule set or specialized features , we made use of artificial neural networks .",
        "training gans for text generation has proven to be more difficult , because of the non - differentiable nature of generating text with recurrent neural networks .",
        "in this work , we show that recurrent neural networks can be trained to generate text with gans from scratch by employing curriculum learning , slowly increasing the length of the generated text , and by training the rnn simultaneously to generate sequences of different lengths .",
        "relational reasoning is a central component of generally intelligent behavior , but has proven difficult for neural networks to learn .",
        "we present a novel training framework for neural sequence models , particularly for grounded dialog generation .",
        "across a variety of domains , a recurring problem with mle trained generative neural dialog models ( g ) is that they tend to produce ' safe ' and generic responses ( \" i don ' t know \" , \" i can ' t tell \" ) .",
        "in particular , the first two models employ a one - class svm algorithm and a recurrent neural network based deep learning model , respectively .",
        "we present a general - purpose tagger based on convolutional neural networks ( cnn ) , used for both composing word vectors and encoding context information .",
        "in the last few years , recurrent neural networks ( rnns ) have proved effective on several nlp tasks .",
        "we propose a web - based visualization tool , \\ textit { adversarial - playground } , to demonstrate the efficacy of common adversarial methods against a deep neural network ( dnn ) model , built on top of the tensorflow library .",
        "in this paper , we demonstrated that the speaker factor is also a short - time spectral pattern and can be largely identified with just a few frames using a simple deep neural network ( dnn ) .",
        "to assess whether unsupervised deep learning is appropriate , we first pose a smaller question : can unsupervised neural networks apply linguistic rules productively , using them in novel situations ?",
        "we use neural machine translation to generate sentential paraphrases via back - translation of bilingual sentence pairs .",
        "in the process , we explore how neural machine translation output differs from human - written sentences , finding clear differences in length , the amount of repetition , and the use of rare words .",
        "symbolic has been long considered as a language of human intelligence while neural networks have advantages of robust computation and dealing with noisy data .",
        "the integration of neural - symbolic can offer better learning and reasoning while providing a means for interpretability through the representation of symbolic knowledge .",
        "although previous works focus intensively on supervised feedforward neural networks , little has been done for the unsupervised counterparts .",
        "in this paper we show how to integrate symbolic knowledge into unsupervised neural networks .",
        "we implement a qg model based on sequence - to - sequence learning , and a qa model based on recurrent neural network .",
        "this paper studies the detection of bird calls in audio segments using stacked convolutional and recurrent neural networks .",
        "ladder networks are a notable new concept in the field of semi - supervised learning by showing state - of - the - art results in image recognition tasks while being compatible with many existing neural architectures .",
        "we present the recurrent ladder network , a novel modification of the ladder network , for semi - supervised learning of recurrent neural networks which we evaluate with a phoneme recognition task on the timit corpus .",
        "in order to adopt such models for artificial intelligence , researchers have handcrafted the relevant states , and then used neural networks to learn the state transitions using simulation runs as training data .",
        "in this work , we investigate if neural networks can implicitly learn physical states of real - world mechanical processes only based on visual data , and thus enable long - term physical extrapolation .",
        "we develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates .",
        "we extend the convolutional recurrent neural network to handle more than one type of these multichannel features by learning from each of them separately in the initial stages .",
        "we propose a method based on convolutional ( cnn ) and recurrent neural networks ( rnn ) , having significantly fewer parameters compared with the state - of - the - art method for the same task .",
        "in this paper , we propose the use of spatial and harmonic features in combination with long short term memory ( lstm ) recurrent neural network ( rnn ) for automatic sound event detection ( sed ) task .",
        "despite the promising power of deep neural networks ( dnn ) , how to alleviate overfitting during training has been a research topic of interest .",
        "deep neural networks ( dnn ) have been successfully applied for music classification including music tagging .",
        "in this article , we investigate specific aspects of neural networks to deepen our understanding of their properties .",
        "in this paper , we introduce a generalized value iteration network ( gvin ) , which is an end - to - end neural network planning module .",
        "we propose a deep dynamic neural network model built on a dynamic vision network , a motor generation network , and a higher - level network .",
        "to remedy this , we present a ranking based approach , and implement both carefully designed features and neural network architectures to measure the relevance between a query and the content of a table .",
        "we introduce a semantic relevance based neural model to encourage high semantic similarity between texts and summaries .",
        "despite the recent success of neural networks in tasks involving natural language understanding ( nlu ) there has only been limited progress in some of the fundamental challenges of nlu , such as the disambiguation of the meaning and function of words in context .",
        "deep learning thrives with large neural networks and large datasets .",
        "to achieve state - of - the - art results on challenges in vision , convolutional neural networks learn stationary filters that take advantage of the underlying image structure .",
        "the encoder is a deep convolutional neural network ( cnn ) based on the vgg network .",
        "we explore simple , efficient token embedding models based on standard neural network architectures .",
        "the iterations of many first - order algorithms , when applied to minimizing common regularized regression functions , often resemble neural network layers with pre - specified weights .",
        "deep convolutional neural networks are being actively investigated in a wide range of speech and audio processing applications including speech recognition , audio event detection and computational paralinguistics , owing to their ability to reduce factors of variations , such as speaker and environment information in signals , for speech recognition .",
        "however , studies have suggested to favor a certain type of convolutional operations when building a deep convolutional neural network for speech applications although there has been promising results using different types of convolutional operations .",
        "since affective behavioral information has been shown to reflect temporally varying of mental state and convolutional operation are applied locally in time , all deep neural networks share a deep recurrent sub - network architecture for further temporal modeling .",
        "finally we show that all of our deep neural networks provide state - of - the",
        "we present an end - to - end system for musical key estimation , based on a convolutional neural network .",
        "a novel method for learning optimal , orthonormal wavelet bases for representing 1 - and 2d signals , based on parallels between the wavelet transform and fully connected artificial neural networks , is described .",
        "in this work , we study how depthwise separable convolutions can be applied to neural machine translation .",
        "in this paper , we consider regression problems with one - hidden - layer neural networks ( 1nns ) .",
        "neural machine translation has meant a revolution of the field .",
        "post - editing offers a unique opportunity for improving neural machine translation systems , using online learning techniques and treating the post - edited translations as new , fresh training data .",
        "this paper aims at one - shot learning of deep neural nets , where a highly parallel setting is considered to address the algorithm calibration problem - selecting the best neural architecture and learning hyper - parameter values depending on the dataset at hand .",
        "we focus on progressive neural networks and compare these networks to the conventional deep learning method of pre - training and fine - tuning .",
        "progressive neural networks provide a way to transfer knowledge and avoid the forgetting effect present when pre - training neural networks on different tasks .",
        "neural networks and rational functions efficiently approximate each other .",
        "we show that multi - layer neural networks can learn almost - optimal auctions for settings for which there are analytical solutions , such as myerson ' s auction for a single item , manelli and vincent ' s mechanism for a single bidder with additive preferences over two items , or yao ' s auction for two additive bidders with binary support distributions and multiple items , even if no prior knowledge about the form of optimal auctions is encoded in the network and the only feedback during training is revenue and regret .",
        "popular independent ensembles ( ie ) relying on naive averaging / voting scheme have been of typical choice for most applications involving deep neural networks , but they do not consider advanced collaboration among ensemble models .",
        "in this paper , we propose new ensemble methods specialized for deep neural networks , called confident multiple choice learning ( cmcl ) : it is a variant of multiple choice learning ( mcl ) via addressing its overconfidence issue .",
        "our system is based on an attentional sequence - to - sequence neural network model using long short - term memory ( lstm ) cells , with joint training of morphological inflection and the inverse transformation , i .",
        "neural network models outperform traditional approaches in domains where large datasets exist , such as squad ( ca .",
        "in this work , we adapt a neural qa system trained on a large open - domain dataset ( squad , source ) to a biomedical dataset ( bioasq , target ) by employing various transfer learning techniques .",
        "the dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder - decoder configuration .",
        "we study the representation and encoding of phonemes in a recurrent neural network model of grounded speech .",
        "we consider an approach to query - by - example search that embeds both the query and database segments according to a neural model , followed by nearest - neighbor search to find the matching segments .",
        "we find that our embeddings , based on recurrent neural networks trained to optimize word discrimination , achieve substantial improvements in performance and run - time efficiency over the previous approaches .",
        "neural machine translation ( nmt ) models usually use large target vocabulary sizes to capture most of the words in the target language .",
        "we explore six challenges for neural machine translation : domain mismatch , amount of training data , rare words , long sentences , word alignment , and beam search .",
        "while going deeper has been witnessed to improve the performance of convolutional neural networks ( cnn ) , going smaller for cnn has received increasing attention recently due to its attractiveness for mobile / embedded applications .",
        "to address these difficulties , we propose bloom embeddings , a compression technique that can be applied to the input and output of neural network models dealing with sparse high - dimensional binary - coded instances .",
        "the first part is a novel deep alternative neural network ( dann ) used to generate candidates of next move .",
        "compared with existing deep convolutional neural network ( dcnn ) , dann inserts recurrent layer after each convolutional layer and stacks them in an alternative manner .",
        "this reduction has several advantages : we can ( 1 ) learn relation - extraction models by extending recent neural reading - comprehension techniques , ( 2 ) build very large training sets for those models by combining relation - specific crowd - sourced questions with distant supervision , and even ( 3 ) do zero - shot learning by extracting new relation types that are only specified at test - time , for which we have no labeled training examples .",
        "in this work , we explore multiple neural architectures adapted for the task of automatic post - editing of machine translation output .",
        "we focus on neural end - to - end models that combine both inputs $ mt $ and $ src $ in a single neural architecture , modeling $ \\ { mt , src \\ } \\ rightarrow pe $ directly .",
        "recurrent neural networks have recently been shown to perform very well in session - based settings .",
        "recent advances in convolutional neural networks ( cnn ) allow us to shift our focus to learning entities and relations from images , as they build robust models that require little or no pre - processing of the images .",
        "convolutional neural networks ( cnns ) have shown great success in computer vision , approaching human - level performance when trained for specific tasks via application - specific loss functions .",
        "the recent adaptation of deep neural network - based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks .",
        "we compare three approaches to statistical machine translation ( pure phrase - based , factored phrase - based and neural ) by performing a fine - grained manual evaluation via error annotation of the systems ' outputs .",
        "inter - annotator agreement is high for such a task , and results show that the best performing system ( neural ) reduces the errors produced by the worst system ( phrase - based ) by 54 % .",
        "we propose several neural models arranged in a two - stage framework to tackle question generation from documents .",
        "first , we estimate the probability of \" interesting \" answers in a document using a neural model trained on a question - answering corpus .",
        "empirically , our neural key phrase detection models significantly outperform an entity - tagging baseline system .",
        "we discover that modern neural networks , unlike those from a decade ago , are poorly calibrated .",
        "our analysis and experiments not only offer insights into neural network learning , but also provide a simple and straightforward recipe for practical settings : on most datasets , temperature scaling - - a single - parameter variant of platt scaling - - is surprisingly effective at calibrating predictions .",
        "we offer a generalized point of view on the backpropagation algorithm , currently the most common technique to train neural networks via stochastic gradient descent and variants thereof .",
        "in a systematic quantitative analysis , we compare to related approaches on a supervised visual learning task ( cifar - 10 ) for fully connected as well as convolutional neural networks and for an unsupervised autoencoder ( usps dataset ) .",
        "we use a wrist - mounted sensor to acquire depth images in front of the gripper and train a convolutional neural network that directly learns the value function for grasp pose candidates .",
        "ongoing research has proposed several methods to defend neural networks against adversarial examples , many of which researchers have shown to be ineffective .",
        "we build the answer extraction model with state - of - the - art neural networks for reading comprehension , and the answer generation model with sequence - to - sequence neural networks .",
        "at the heart of deep learning we aim to use neural networks as function approximators - training them to produce outputs from inputs in emulation of a ground truth function or data creation process .",
        "in many cases we only have access to input - output pairs from the ground truth , however it is becoming more common to have access to derivatives of the target output with respect to the input - for example when the ground truth function is itself a neural network such as in network compression or distillation .",
        "this paper introduces sobolev training for neural networks , which is a method for incorporating these target derivatives in addition the to target values while training .",
        "by optimising neural networks to not only approximate the function ' s outputs but also the function ' s derivatives we encode additional information about the target function within the parameters of the neural network .",
        "the state - of - the - art solutions to the vocabulary mismatch in information retrieval ( ir ) mainly aim at leveraging either the relational semantics provided by external resources or the distributional semantics , recently investigated by deep neural approaches .",
        "guided by the intuition that the relational semantics might improve the effectiveness of deep neural approaches , we propose the deep semantic resource inference model ( dsrim ) that relies on : 1 ) a representation of raw - data that models the relational semantics of text by jointly considering objects and relations expressed in a knowledge resource , and 2 ) an end - to - end neural architecture that learns the query - document relevance by leveraging the distributional and relational semantics of documents and queries .",
        "the experimental evaluation carried out on two trec datasets from trec terabyte and trec cds tracks relying respectively on wordnet and mesh resources , indicates that our model outperforms state - of - the - art semantic and deep neural ir models .",
        "deep neural networks are known to be difficult to train due to the instability of back - propagation .",
        "the past few years have witnessed a growth in size and computational requirements for training and inference with neural networks .",
        "importantly , the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions .",
        "our main result is that on inception - v3 for imagenet classification , and on rnn lstm , for language modeling and neural machine translation , our model finds non - trivial device placements that outperform hand - crafted heuristics and traditional algorithmic methods .",
        ", convolutional neural networks ) offer a promising solution .",
        "to deal with delayed reward , we propose a new neural architecture in the meta controller that learns when to update the subtask , which makes learning more efficient .",
        "this work presents a novel approach to jointly tackling automatic post - editing ( ape ) and word - level quality estimation ( qe ) using ensembles of specialized neural machine translation ( nmt ) systems .",
        "we show that it outperforms a strong baseline on three character - level decoder neural machine translation on wmt ' 15 corpus .",
        "in our experiments , we expose qualitative differences in gradient - based optimization of deep neural networks ( dnns ) on noise vs .",
        "adaptive gradient methods have become recently very popular , in particular as they have been shown to be useful in the training of deep neural networks .",
        "in this paper we have analyzed rmsprop , originally proposed for the training of deep neural networks , in the context of online convex optimization and show $ \\ sqrt { t } $ - type regret bounds .",
        "finally , we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or stochastic gradient descent in the optimization of strongly convex functions as well as in training of deep neural networks .",
        "we propose a simple yet effective technique for neural network learning .",
        "convolution is a critical component in modern deep neural networks , thus several algorithms for convolution have been developed .",
        "we instead propose a hierarchical policy class that automatically reasons about both long - term and short - term goals , which we instantiate as a hierarchical neural network .",
        "we present a method for training a convolutional neural network such that it takes in an input image and produces a full graph .",
        "deep neural networks ( dnns ) have advanced performance on a wide range of complex tasks , rapidly outpacing our understanding of the nature of their solutions .",
        "inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task .",
        "specifically , safetynets develops and implements a specialized interactive proof ( ip ) protocol for verifiable execution of a class of deep neural networks , i .",
        "our empirical results on three - and four - layer deep neural networks demonstrate the run - time costs of safetynets for both the client and server are low .",
        "safetynets detects any incorrect computations of the neural network by the untrusted server with high probability , while achieving state - of - the - art accuracy on the mnist digit recognition ( 99 .",
        "we propose a novel deep neural networks ( dnn ) based model , canonical correlated autoencoder ( c2ae ) , for solving this task .",
        "in state - of - the - art neural machine translation ( nmt ) , an attention mechanism is used during decoding to enhance the translation .",
        "we propose character - level neural sequence - to - sequence ( s2s ) methods for the task of portmanteau generation that are end - to - end - trainable , language independent , and do not explicitly use additional phonetic information .",
        "while natural languages are compositional , how state - of - the - art neural models achieve compositionality is still unclear .",
        "further developing upon recent work on neural machine translation , we propose a new hybrid neural model with nested attention layers for gec .",
        "experiments show that the new model can effectively correct errors of both types by incorporating word and character - level information , and that the model significantly outperforms previous neural models for gec as measured on the standard conll - 14 benchmark dataset .",
        "recent work has proposed several generative neural models for constituency parsing that achieve state - of - the - art results .",
        "this paper proposes a novel deep reinforcement learning ( rl ) architecture , called value prediction network ( vpn ) , which integrates model - free and model - based rl methods into a single neural network .",
        "the prnet first projects the drifted data to a feature space , and uses a powerful deep convolutional neural network to recover the estimated drift - free measurements .",
        "we also provide helpful insights for designing deep neural networks for sensor calibration .",
        "existing algorithms even though are accurate but they do not focus on utilizing the parameters of neural network efficiently .",
        "in this paper , we propose a novel deep neural network architecture which allows it to learn without any significant increase in number of parameters .",
        "both bottom - up and top - down strategies have been used for neural transition - based constituent parsing .",
        "this paper proposes a hierarchical attentional neural translation model which focuses on enhancing source - side hierarchical representations by covering both local and global semantic information using a bidirectional tree - based encoder .",
        "empirical results reveal that the proposed model significantly outperforms sequence - to - sequence attention - based and tree - based neural translation models in english - chinese translation tasks .",
        "most neural machine translation ( nmt ) models are based on the sequential encoder - decoder framework , which makes no use of syntactic information .",
        "in this paper , we show that a neural language model such as word2vec only necessitates minor modifications to its standard architecture to learn new terms from tiny data , using background knowledge from a previously learnt semantic space .",
        "sgnmt provides a generic interface to neural and symbolic scoring modules ( predictors ) with left - to - right semantic such as translation models like nmt , language models , translation lattices , $ n $ - best lists or other kinds of scores and constraints .",
        "we present a newly collected police fatality corpus , which we release publicly , and present a model to solve this problem that uses em - based distant supervision with logistic regression and convolutional neural network classifiers .",
        "we present a novel neural model hypervec to learn hierarchical embeddings for hypernymy detection and directionality .",
        "the context word sequence , together with a parts - of - speech tag sequence and a dependency relation sequence that are generated corresponding to the word sequence , are then provided as input to bidirectional recurrent neural network ( lstm ) models .",
        "the neural nets learn compositional syntactic and semantic representations of contexts surrounding the two events and predict the temporal relation between them .",
        "evaluation of the proposed approach on timebank corpus shows that sequential modeling is capable of accurately recognizing temporal relations between events , which outperforms a neural net model using various discrete features as input that imitates previous feature based models .",
        "yet , current neural machine translation training focuses on expensive human - generated reference translations .",
        "we describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback .",
        ", 2016 ) with the attention - based neural encoder - decoder architecture ( luong et al .",
        "we introduce globally normalized convolutional neural networks for joint entity classification and relation extraction .",
        "recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records .",
        "in particular , we introduce a new , large - scale corpus of data records paired with descriptive documents , propose a series of extractive evaluation methods for analyzing performance , and obtain baseline results using current neural generation methods .",
        "moreover , even templated baselines exceed the performance of these neural models on some metrics , though copy - and reconstruction - based extensions lead to noticeable improvements .",
        "our results suggest that neural representations are capable of spontaneously developing a \" syntax \" with functional analogues to qualitative properties of natural language .",
        "to ensure good interpretability and appropriate lexical usage we combine symbolic and neural representations , using a neural reasoning algorithm trained on commonsense causal tuples to predict the next cause step .",
        "deep residual learning ( resnet ) is a new method for training very deep neural networks using identity map - ping for shortcut connections .",
        "in this paper , we design a novel convolutional neural network ( cnn ) with residual learning , and investigate its impacts on the task of distantly supervised noisy relation extraction .",
        "generative neural models have recently achieved state - of - the - art results for constituency parsing .",
        "we describe an alternative to the conventional action - level beam search used for discriminative neural models that enables us to decode directly in these generative models .",
        "we argue that relevant law articles play an important role in this task , and therefore propose an attention - based neural network method to jointly model the charge prediction task and the relevant article extraction task in a unified framework .",
        "one central mystery of neural nlp is what neural models \" know \" about their subject matter .",
        "when a neural machine translation system learns to translate from one language to another , does it learn the syntax or semantics of the languages ?",
        "exploiting the existence of parallel texts in more than a thousand languages , we build a massive many - to - one neural machine translation ( nmt ) system from 1017 languages into english , and use this to predict information missing from typological databases .",
        "we investigate techniques for supervised domain adaptation for neural machine translation where an existing model trained on a large out - of - domain dataset is adapted to a small in - domain dataset .",
        "we apply these techniques , alone and in combination , to neural machine translation , obtaining improvements on iwslt datasets for english - & gt ; german and english - & gt ; russian .",
        "we show that small and shallow feed - forward neural networks can achieve near state - of - the - art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models .",
        "motivated by resource - constrained environments like mobile phones , we showcase simple techniques for obtaining such small neural network models , and investigate different tradeoffs when deciding how to allocate a small memory budget .",
        "with the recent increase in popularity of neural machine translation ( nmt ) , we explore in this paper to what extent and how nmt can also benefit from data selection .",
        "we experimented with l - dmv , a lexicalized version of dependency model with valence and l - ndmv , our lexicalized extension of the neural dependency model with valence .",
        "in the encoder - decoder architecture for neural machine translation ( nmt ) , the hidden states of the recurrent structures in the encoder and decoder carry the crucial information about the sentence .",
        "however , it is difficult to integrate them into current neural machine translation ( nmt ) which reads and generates sentences word by word .",
        "neural machine translation ( nmt ) has achieved notable success in recent times , however it is also widely recognized that this approach has limitations with handling infrequent words and word pairs .",
        "this paper presents a novel memory - augmented nmt ( m - nmt ) architecture , which stores knowledge about how words ( usually infrequently encountered ones ) should be translated in a memory and then utilizes them to assist the neural model .",
        "for this task , we make use of the visual storytelling dataset and a model composed of three hierarchically - attentive recurrent neural nets ( rnns ) to : encode the album photos , select representative ( summary ) photos , and compose the story .",
        "in this paper , we introduce a hybrid search for attention - based neural machine translation ( nmt ) .",
        "we propose a dynamic ranking paradigm , named as dnn - mab , that is composed of a pairwise deep neural network ( dnn ) $ \\ mathit { pre } $ - ranker connecting a revised multi - armed bandit ( mab ) dynamic $ \\ mathit { post } $ - ranker .",
        "we show how the robot can successfully perform a tight clearance peg - in - hole task through training a recurrent neural network with reinforcement learning .",
        "the neural network learns to take the optimal action by observing the robot sensors to estimate the system state .",
        "here we present a novel routing methodology that employs both hierarchical and mesh routing strategies and combines heterogeneous memory structures for minimizing both memory requirements and latency , while maximizing programming flexibility to support a wide range of event - based neural network architectures , through parameter configuration .",
        "finally , we demonstrate the use of the neuromorphic processor with a convolutional neural network for the real - time classification of visual symbols being flashed",
        "this paper introduces a corpus for text - based emotion detection on multiparty dialogue as well as deep neural models that outperform the existing approaches for document classification .",
        "we then suggest four types of sequence - based convolutional neural network models with attention that leverage the sequence information encapsulated in dialogue .",
        "we propose a method for embedding two - dimensional locations in a continuous vector space using a neural network - based model incorporating mixtures of gaussian distributions , presenting two model variants for text - based geolocation and lexical dialectology .",
        "character - based neural lms provide a straight forward solution for open vocabulary speech recognition and all - neural models , and can be decoded with beam search .",
        "neural networks are capable of learning rich , nonlinear feature representations shown to be beneficial in many predictive tasks .",
        "first , a biometric is applied to a neural network to create a feature vector .",
        "this neural network alone can be used for one - to - one matching ( authentication ) ,",
        "existing works based on deep neural network ( dnn ) mostly construct one common space for different modalities to find the latent alignments between them , which lose their exclusive modality - specific characteristics .",
        "we give initial baseline results for neural networks trained from this data to predict game outcomes and player actions .",
        "in particular , it considers the neural binding structure of an earlier paper .",
        "it is suggested that the simplest of linking between a tree and ensemble can explain neural binding and variable signal strengths .",
        "in this paper , we propose a novel multi - task neural network approach for both encoding and prediction of non - discrete attribute information in a relational setting .",
        "specifically , we train a neural network for triplet prediction along with a separate network for attribute value regression .",
        "compared to a hybrid of convolutional neural network and long - short - term - memory ( cnn - lstm ) , our proposed 3d cnns simultaneously extract short - term and long - term spectral features with a moderate number of parameters .",
        "inspired by convolutional neural networks , we propose a new mechanism to store relevant context in different memory slots to model context information .",
        "recent applications of neural language models have led to an increased interest in the automatic generation of natural language .",
        "however impressive , the evaluation of neurally generated text has so far remained rather informal and anecdotal .",
        "here , we present an attempt at the systematic assessment of one aspect of the quality of neurally generated text .",
        "we focus on a specific aspect of neural language generation : its ability to reproduce authorial writing styles .",
        "using established models for authorship attribution , we empirically assess the stylistic qualities of neurally generated text .",
        "in comparison to conventional language models , neural models generate fuzzier text that is relatively harder to attribute correctly .",
        "nevertheless , our results also suggest that neurally generated text offers more valuable perspectives for the augmentation of training data .",
        "convolutional neural network provides an end - to - end solution to train many computer vision tasks and has gained great successes .",
        "recently , bidirectional recurrent network language models ( bi - rnnlms ) have been shown to outperform standard , unidirectional , recurrent neural network language models ( uni - rnnlms ) on a range of speech recognition tasks .",
        "in this paper these issues are addressed by proposing a novel neural network structure , succeeding word rnnlms ( su - rnnlms ) .",
        "an efficient algorithm for recurrent neural network training is presented .",
        "an example is given for the online handwriting recognition task using an lstm recurrent neural network .",
        "neural machine translation ( nmt ) approaches have improved the state of the art in many machine translation settings over the last couple of years , but they require large amounts of training data to produce sensible output .",
        "we describe the 2017 version of microsoft ' s conversational speech recognition system , in which we update our 2016 system with recent developments in neural - network - based acoustic and language modeling to further advance the state of the art on the switchboard speech recognition task .",
        "we cast the problem as sequence tagging and introduce semi - supervised methods to a neural tagging model , which builds on recent advances in named entity recognition .",
        "in this series of notes , we try to model neural networks as as discretizations of continuous flows on the space of data , which can be called flow model .",
        "however , with the advent of neural machine translation ( nmt ) systems , which can theoretically take into account global sentential context , one may hypothesize that this problem has been alleviated .",
        "the deployment of deep convolutional neural networks ( cnns ) in many real world applications is largely hindered by their high computational cost .",
        "while hierarchy and partial observability are usually tackled separately , for instance by combining recurrent neural networks and options , we show that addressing both problems simultaneously is simpler and more efficient in many cases .",
        "our experiments show that oois allow agents to learn optimal policies in challenging pomdps , outperforming an human - provided policy in our robotic experiment , while learning much faster than a recurrent neural network over options .",
        "in this paper we show that outsourced training introduces new security risks : an adversary can create a maliciously trained network ( a backdoored neural network , or a \\ emph { badnet } ) that has state - of - the - art performance on the user ' s training and validation samples , but behaves badly on specific attacker - chosen inputs .",
        "we address the problem of anytime prediction in neural networks .",
        "recurrent neural networks ( rnns ) continue to show outstanding performance in sequence modeling tasks .",
        "the performance of neural network ( nn ) - based language models is steadily improving due to the emergence of new architectures , which are able to learn different natural language characteristics .",
        "extensive experiments conducted on the penn treebank ( ptb ) and the large text compression benchmark ( ltcb ) corpus showed a significant reduction of the perplexity when compared to state - of - the - art feedforward as well as recurrent neural network architectures .",
        "during the last years , convolutional neural networks ( cnns ) have achieved state - of - the - art performance in image classification .",
        "the techniques from the literature that are presented herein have great performances , however , instead of the machine learning techniques employed in these works , we propose to use deep learning techniques such as long - short term memory ( lstm ) recurrent neural network ( rnn ) , and show the improved performance .",
        "deep neural networks are generally trained using iterative gradient updates .",
        "this paper demonstrates neural network - based toolkit namely nnvlp for essential vietnamese language processing tasks including part - of - speech ( pos ) tagging , chunking , named entity recognition ( ner ) .",
        "our toolkit is a combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which outperforms previously published toolkits on these three tasks .",
        "an exhaustive study on neural network language modeling ( nnlm ) is performed in this paper .",
        "different architectures of basic neural network language models are described and examined .",
        "a number of different improvements over basic neural network language models , including importance sampling , word classes , caching and bidirectional recurrent neural network ( birnn ) , are studied separately , and the advantages and disadvantages of every technique are evaluated .",
        "then , the limits of neural network language modeling are explored from the aspects of model architecture and knowledge representation .",
        "part of the statistical information from a word sequence will loss when it is processed word by word in a certain order , and the mechanism of training neural network by updating weight matrixes and vectors imposes severe restrictions on any significant enhancement of nnlm .",
        "for knowledge representation , the knowledge represented by neural network language models is the approximate probabilistic distribution of word sequences from a certain training data set rather than the knowledge of a language itself or the information conveyed by word sequences in a natural language .",
        "finally , some directions for improving neural network language modeling further is discussed .",
        "neural network models have recently received heated research attention in the natural language processing community .",
        "compared with traditional models with discrete features , neural models have two main advantages .",
        "second , deep neural networks can be used to automatically combine input features , and including non - local features that capture semantic patterns that cannot be expressed using discrete indicator features .",
        "as a result , neural network models have achieved competitive accuracies compared with the best discrete models for a range of nlp tasks .",
        "for such domains , we propose to use deep neural networks in learning for planning , based on learning a reactive policy that imitates execution traces produced by a planner .",
        "to model changing customer and store environments , our recommendation method employs a pair of neural networks : to overcome the cold start problem , a feedforward network generates article embeddings in \" fashion space , \" which serve as input to a recurrent neural network that predicts a style vector in this space for each client , based on their past purchase sequence .",
        "we describe a recurrent neural network model that can capture long range context and compare it to a baseline logistic regression model corresponding to the current cloudscan production system .",
        "the recurrent neural network and baseline model achieve 0 .",
        "for the harder task of unseen invoice layouts , the recurrent neural network model outperforms the baseline with 0 .",
        "we design a siamese convolutional neural network architecture and feed it with title pairs of items , which are either compatible or incompatible .",
        "recent advances in deep neural networks ( dnns ) have led to the development of dnn - driven autonomous cars that , using sensors like camera , lidar , etc .",
        "the performance tests for the de facto standard mnist data set were carried out on h2o framework for deep learning algorithms designed for cpu and gpu platforms for single - threaded and multithreaded modes of operation also , we present the results of testing neural networks architectures on h2o platform for various activation functions , stopping metrics , and other parameters of machine learning algorithm .",
        "compared to current poisoning strategies , our approach is able to target a wider class of learning algorithms , trained with gradient - based procedures , including neural networks and deep learning architectures .",
        "in this paper , we explore alternative ways to train a neural machine translation system in a multi - domain scenario .",
        "a study to compare the reliability and efficiency of artificial neural network and support vector machine in detecting nontor traffic in unb - cic tor network traffic dataset is presented in this paper .",
        "a hybrid artificial neural network proved a better classifier than svm in detecting nontor traffic in unb - cic tor network traffic dataset .",
        "we also propose a new initialization method that uses the pre - trained weights from a feed - forward neural network to initialize our lstm - based model .",
        "specifically , we train convolutional neural networks to predict population in the usa at a $ 0 .",
        "the generation of complex derived word forms has been an overlooked problem in nlp ; we fill this gap by applying neural sequence - to - sequence models to the task .",
        "state - of - the - art neural models , adapted from the inflection task , are able to learn a range of derivation patterns , and outperform a non - neural baseline by 16 .",
        "in the work presented here , we explore a transfer learning scheme , whereby we train character - level recurrent neural taggers to predict morphological taggings for high - resource languages and low - resource languages together .",
        "the usefulness of this concept is illustrated over a number of applied areas , including generalized regression and classification ( support tensor machines , canonical correlation analysis , higher order partial least squares ) , generalized eigenvalue decomposition , riemannian optimization , and in the optimization of deep neural networks .",
        "the attention model has become a standard component in neural machine translation ( nmt ) and it guides translation process by selectively focusing on parts of the source sentence when predicting each target word .",
        "however , we find that the generation of a target word does not only depend on the source sentence , but also rely heavily on the previous generated target words , especially the distant words which are difficult to model by using recurrent neural networks .",
        "in this paper , we adapt neural machine translation ( nmt ) to automatically \" translate \" diffs into commit messages .",
        "we present a simple method to improve neural translation of a low - resource language pair using parallel data from a related , also low - resource one .",
        "in recent years researchers have achieved considerable success applying neural network methods to question answering ( qa ) .",
        "being inspired by the success of convolutional neural networks in computer vision , we use them to incorporate the spatio - structural patterns of chinese glyphs as rendered in raw pixels .",
        "we evaluate state - of - the - art deep convolutional neural network ( cnns ) on this novel dataset with its different spectral bands .",
        "we propose seq2sql , a deep neural network for translating natural language questions to corresponding sql queries .",
        "in recent studies , researchers use neural language models and encoder - decoder frameworks for table - to - text generation .",
        "however , these neural network - based approaches do not model the order of contents during text generation .",
        "in order to achieve a robust adi system , we explored both siamese neural network models to learn similarity and dissimilarities among arabic dialects , as well as i - vector post - processing to adapt domain mismatches .",
        "we present a neural transition - based parser for spinal trees , a dependency representation of constituent trees .",
        "there is an increasing interest on accelerating neural networks for real - time applications .",
        "this is done using multilayer perceptron neural network which can be adaptively trained to showcase the true nature of the compatibility index .",
        "also , a recurrent neural network in which a word is represented as a sum of embeddings of its patterns is on",
        "specifically , we utilize a convolutional neural network ( cnn ) as a quasi - projection operator within a least squares minimization procedure .",
        "we explore three language - independent alternatives to morphological segmentation using : i ) data - driven sub - word units , ii ) characters as a unit of learning , and iii ) word embeddings learned using a character cnn ( convolution neural network ) .",
        "in our analysis , we show that a neural machine translation system is sensitive to the ratio of source and target tokens , and a ratio close to 1 or greater , gives optimal performance .",
        "we combine a generative model parameterized by deep neural networks with non - linear embedding technique .",
        "we propose a methodology for designing dependable artificial neural networks ( ann ) by extending the concepts of understandability , correctness , and validity that are crucial ingredients in existing certification standards .",
        "in this paper , we use the optimal ratio mask as the training target of the deep neural network ( dnn ) for speech separation .",
        "we explain how the prototype automatic chess problem composer , chesthetica , successfully composed a rare and interesting chess problem using the new digital synaptic neural substrate ( dsns ) computational creativity approach .",
        "embed - rul utilizes a sequence - to - sequence model based on recurrent neural networks ( rnns ) to generate embeddings for multivariate time series subsequences .",
        "recent work on reinforcement learning and other gradient estimators for latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence , all without exposure to ground - truth parse trees at training time .",
        "for computer vision applications , prior works have shown the efficacy of reducing numeric precision of model parameters ( network weights ) in deep neural networks .",
        "in this context , exploiting deep neural network ( dnn ) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for hmm based decoding .",
        "we propose \\ emph { neural word salience } ( nws ) scores , unlike heuristics , are learnt from a corpus .",
        "we consider paragraph - level linguistic features to unveil the satire by incorporating neural network and attention mechanism .",
        "this study addresses the problem of identifying the meaning of unknown words or entities in a discourse with respect to the word embedding approaches used in neural language models .",
        "we proposed a method for on - the - fly construction and exploitation of word embeddings in both the input and output layers of a neural model by tracking contexts .",
        "deep neural networks are state of the art methods for many learning tasks due to their ability to extract increasingly better features at each network layer .",
        "even though sequence - to - sequence neural machine translation ( nmt ) model have achieved state - of - art performance in the recent fewer years , but it is widely concerned that the recurrent neural network ( rnn ) units are very hard to capture the long - distance state information , which means rnn can hardly find the feature with long term dependency as the sequence becomes longer .",
        "similarly , convolutional neural network ( cnn ) is introduced into nmt for speeding recently , however , cnn focus on capturing the local feature of the sequence ; to relieve this issue , we incorporate a relation network into the standard encoder - decoder framework to enhance information - propogation in neural network , ensuring that the information of the source sentence can flow into the decoder adequately .",
        "in this work , we present a neural framework for supporting and studying users in both types of communities .",
        "we introduce such a model for the task of machine translation , pairing a recurrent neural network grammar encoder with a novel attentional rnng decoder and applying policy gradient reinforcement learning to induce unsupervised tree structures on both the source and target .",
        "deep neural networks ( dnn ) have been successfully applied for music classification tasks including music tagging .",
        "in this paper , we investigate the effect of audio preprocessing on music tagging with neural networks .",
        "we further study the invariances in neural networks , suggest complexity measures and optimization algorithms that have similar invariances to those in neural networks and evaluate them on a number of learning tasks .",
        "due to the challenges , we train and translate the terminological expressions in the medial and financial domain with statistical as well as with neural machine translation methods .",
        "nevertheless , through the specific and unique terminological expressions , subword segmentation within nmt does not outperform a word based neural translation model .",
        "the patch extracted around this object is subsequently fed through an off - the - shelf deep convolutional neural network to obtain a high level feature representation , which is then combined with traditional surface electromyography in the classification stage .",
        "long - short term memory recurrent neural networks ( lstm - rnn ) is applied as the basic uni - modality model to capture long time dependencies .",
        "we study embedded binarized neural networks ( ebnns ) with the aim of allowing current binarized neural networks ( bnns ) in the literature to perform feedforward inference efficiently on small embedded devices .",
        "to accomplish this , ebnn reorders the computation of inference while preserving the original bnn structure , and uses just a single floating - point temporary for the entire neural network .",
        "we present a novel method to embed discourse features in a convolutional neural network text classifier , which achieves a state - of - the - art result by a substantial margin .",
        "when convolutional neural networks are used to tackle learning problems based on time series , e .",
        ", audio data , raw one - dimensional data are commonly pre - processed to obtain spectrogram or mel - spectrogram coefficients , which are then used as input to the actual neural network .",
        "an extensive set of experiments shows that the proposed deep neural networks are able to answer the visual - relational queries efficiently and accurately .",
        "we propose a neural embedding algorithm called network vector , which learns distributed representations of nodes and the entire networks simultaneously .",
        "the expressive power of neural networks is important for understanding deep learning .",
        "in this paper , we study how width affects the expressiveness of neural networks .",
        "several recent works demonstrate the benefits of depth by proving the depth - efficiency of neural networks .",
        "kernel methods have recently attracted resurgent interest , matching the performance of deep neural networks in tasks such as speech recognition .",
        "after initial pre - processing phase on data , packets are fed to deep packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic .",
        "recurrent neural networks scale poorly due to the intrinsic difficulty in parallelizing their state computations .",
        "we show how vector representations maintaining semantic characteristics of the original data can be obtained from a given graph using neural encoding architectures and considering the topological properties of the graph .",
        "existing neural approaches make use of expensive bi - directional attention mechanisms or score all possible answer spans , limiting scalability .",
        "we present joint end - to - end neural network architectures that combine long short - term memory ( lstm ) and a latent topic model to simultaneously train a classifier for mortality prediction and learn latent topics indicative of mortality from textual clinical notes .",
        "however , we achieve limited success with our method for interpreting topics from the trained models by looking at the neural network weights .",
        "we simulate multiple environments in parallel , and group them to perform the neural network computation on a batch rather than individual observations .",
        "although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices , they overlooked the reliability of mobile computing models .",
        "we propose simple and flexible training and decoding methods for influencing output style and topic in neural encoder - decoder based language generation .",
        "we decompose the neural generation process into empirically easier sub - problems : a faithfulness model and a decoding method based on selective - sampling .",
        "our system builds upon a state - of - the - art fully convolutional artificial neural network ( fcn ) as well as an active user model for training .",
        "vulnerability of state - of - the - art deep neural networks to adversarial attacks has been attracting a lot of attention recently .",
        "in this work , a computational intelligence ( ci ) technique named flexible neural tree ( fnt ) was developed to predict die filling performance of pharmaceutical granules and to identify significant die filling process variables .",
        "fnt resembles feedforward neural network , which creates a tree - like structure by using genetic programming .",
        "while some remarkable progress has been made in neural machine translation ( nmt ) research , there have not been many reports on its development and evaluation in practice .",
        "for visual features we used the hog ( histogram of gradients ) features , fisher encodings of sift ( scale - invariant feature transform ) features based on gaussian mixture model ( gmm ) and some pretrained convolutional neural network layers as features ; all these extracted for each video clip .",
        "then we trained fully connected neural network regression model on the dataset for all these different modalities .",
        "classification is done on fused as well as independent features using support vector machine ( svm ) and neural networks .",
        "recently , deep neural networks ( dnns ) have been demonstrated to achieve superior object detection performance compared to other approaches , with yolov2 ( an improved you only look once model ) being one of the state - of - the - art in dnn - based object detection methods in terms of both speed and accuracy .",
        "our approach explores sequence - to - sequence learning using a bidirectional multi - layer recurrent neural network ."
    ],
    "embed": [
        "we assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph ; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework , in polynomial time in the number of selected kernels .",
        "we implement a unified framework while delegating complex but well - understood subproblems ( planar embedding , maximum - weight perfect matching ) to established algorithms for which efficient implementations are freely available .",
        "a main drawback of manifold learning methods is , however , that there is no explicit mappings from the input data manifold to the output embedding .",
        "previously , in order to provide explicit mappings for manifold learning methods , many methods have been proposed to get an approximate explicit representation mapping with the assumption that there exists a linear projection between the high - dimensional data samples and their low - dimensional embedding .",
        "in particular , we apply this to the method of locally linear embedding ( lle ) and derive an explicit nonlinear manifold learning algorithm , named neighborhood preserving polynomial embedding ( nppe ) .",
        "we assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph ; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework , in polynomial time in the number of selected kernels .",
        "we implement a unified framework while delegating complex but well - understood subproblems ( planar embedding , maximum - weight perfect matching ) to established algorithms for which efficient implementations are freely available .",
        "a main drawback of manifold learning methods is , however , that there is no explicit mappings from the input data manifold to the output embedding .",
        "previously , in order to provide explicit mappings for manifold learning methods , many methods have been proposed to get an approximate explicit representation mapping with the assumption that there exists a linear projection between the high - dimensional data samples and their low - dimensional embedding .",
        "in particular , we apply this to the method of locally linear embedding ( lle ) and derive an explicit nonlinear manifold learning algorithm , named neighborhood preserving polynomial embedding ( nppe ) .",
        "ontological knowledge , which is necessary for text understanding , is not in general embedded into documents .",
        "to effectively visualize such data it is important to reduce its dimensionality and visualize the low dimensional embedding as a 2 - d or 3 - d scatter plot .",
        "in this paper we explore dimensionality reduction methods that draw upon domain knowledge in order to achieve a better low dimensional embedding and visualization of documents .",
        "whereas a lot of effort has been put in developing fast optimization methods when the groups are disjoint or embedded in a specific hierarchical structure , we address here the case of general overlapping groups .",
        "inspired by the hierarchical hidden markov models ( hhmm ) , we present the hierarchical semi - markov conditional random field ( hscrf ) , a generalisation of embedded undirectedmarkov chains tomodel complex hierarchical , nestedmarkov processes .",
        "despite its great success , the elastic net does not explicitly use correlation information embedded in data to select correlated variables .",
        "we examine the class of languages that can be defined entirely in terms of provability in an extension of the sorted type theory ( ty _ n ) by embedding the logic of phonologies , without introduction of special types for syntactic entities .",
        "mccain ' s embedding of definite propositional causal theories into logic programming paved the way to the use of answer set solvers for answering queries about actions described in such languages .",
        "in this paper we extend this embedding to nondefinite theories and to first - order causal logic .",
        "the output is an embedding of the objects into euclidean space ( like mds ) ; we refer to this as the \" crowd kernel . \"",
        "we describe our implementation of word level visually - grounded semantics and their embedding in a compositional parsing framework .",
        "the beliefs experienced by the controller often lie near a structured , low - dimensional subspace embedded in the high - dimensional belief space .",
        "specifically , we assume that the objects can be embedded into a $ d $ - dimensional euclidean space and that the rankings reflect their relative distances from a common reference point in $ r ^ d $ .",
        "while nowadays most ai researchers avoid discussing intelligence , the award - winning phd thesis ( legg , 2008 ) provided the philosophical embedding and investigated the uai - based universal measure of rational intelligence , which is formal , objective and non - anthropocentric .",
        "by representing these probability distributions as mean embeddings in the reproducing kernel hilbert space ( rkhs ) , we are able to apply many standard kernel - based learning techniques in straightforward fashion .",
        "a semantic embedding of ( constant domain ) quantified conditional logic in classical higher - order logic is presented .",
        "using a linear complexity algorithm to compute vectors for trees , we embed feature spaces of tree fragments in low - dimensional spaces where the kernel computation is directly done with dot product .",
        "we further show that embedded with",
        "this approach makes use of a recently developed representation of conditional distributions as \\ emph { embeddings } in a reproducing kernel hilbert space ( rkhs ) .",
        "this avoids the need to calculate intractable integrals , since expectations are represented as rkhs inner products whose computation has linear complexity in the number of points used to represent the embedding .",
        "we consider the scenario in which a watermark signal is repeatedly embedded in specific , possibly chosen based on a secret message bitstream , segments ( signals ) of the host data .",
        "we propose a probabilistic model that infers the embedded message bitstream and watermark signal , directly from the watermarked data , without access to the decoder .",
        "we illustrate the theoretical contributions through a series of experiments in feature selection and low - dimensional embedding of distributions .",
        "this paper proposes a framework dedicated to the construction of what we call discrete elastic inner product allowing one to embed sets of non - uniformly sampled multivariate time series or sequences of varying lengths into inner product space structures .",
        "this framework is based on a recursive definition that covers the case of multiple embedded time elastic dimensions .",
        "classification experimentations on time series and symbolic sequences datasets demonstrate the benefits that we can expect by embedding time series or sequences into elastic inner spaces rather than into classical euclidean spaces .",
        "in this paper , we address the problem of embedded feature selection for ranking on top of the list problems .",
        "intuitively , user preferences can be reasonably embedded in a coarse low - dimensional feature space that can be explored efficiently , requiring exploration in the high - dimensional space only as necessary .",
        "local linear embedding ( lle ) is a popular dimension reduction method .",
        "in this paper , we first show lle with nonnegative constraint is equivalent to the widely used laplacian embedding .",
        "specifically , we explicitly incorporate correlation measures as constraints and then propose an efficient embedded feature selection method using recently developed cutting plane strategy .",
        "given all of the ratings , our task is to embed all of the users and items as points in the same euclidean space .",
        "we pose this problem as a real - valued non - linear bayesian network and employ markov chain monte carlo and expectation maximization to find an embedding .",
        "we present a metric by which to judge the quality of a visualization and compare our results to local linear embedding and eigentaste on three real - world datasets .",
        "we study the problem of estimating , in the sense of optimal transport metrics , a measure which is assumed supported on a manifold embedded in a hilbert space .",
        "by embedding an original signal into a family of gradually coarsen signals parameterized with a continuous scale parameter , it provides a formal framework to capture the structure of a signal at different scales in a consistent way .",
        "in this paper , we present a new neural network architecture designed to embed multi - relational graphs into a flexible continuous vector space in which the original data is kept and enhanced .",
        "supervised ( linear ) embedding models like wsabie and psi have proven successful at ranking , recommendation and annotation tasks .",
        "we propose a new class of models which aim to provide improved performance while retaining many of the benefits of the existing class of embedding models .",
        "our new approach works by iteratively learning a linear embedding model where the next iteration ' s features and labels are reweighted as a function of the previous iteration .",
        "however , when a domain contains recursively embedded pi submodels , it may escape the detection of such an algorithm .",
        "in this paper , we propose an improved algorithm that ensures the learning of all embedded pi submodels whose sizes are upper bounded by a predetermined parameter .",
        "the mmse estimate is embedded within the optimization objective to form a novel regularized nmf cost function .",
        "issc adopts the assumption that high - dimensional data actually lie on the low - dimensional manifold such that out - of - sample data could be grouped in the embedding space learned from in - sample data .",
        "deliberation plays an important role in the design of rational agents embedded in the real - world .",
        "in this paper , we present a supervised model to learn the intrinsic structure of the tensors embedded in a high dimensional euclidean space .",
        "with the fixed point continuation procedures , our model automatically and jointly discovers the optimal dimensionality and the representations of the low dimensional embeddings .",
        "furthermore , the generalization of our model based on similarity between the learned low dimensional embeddings can be viewed as counterpart of recognition of human brain .",
        "distributed word representations ( word embeddings ) have recently contributed to competitive performance in language modeling and several nlp tasks .",
        "in this work , we train word embeddings for more than 100 languages using their corresponding wikipedias .",
        "we quantitatively demonstrate the utility of our word embeddings by using them as the sole features for training a part of speech tagger for a subset of these languages .",
        "moreover , we investigate the semantic features captured by these embeddings through the proximity of word groupings .",
        "we will release these embeddings publicly to help researchers in the development and enhancement of multilingual applications .",
        "also , the usage of aiml embedded tags for the handling of sequence dialogue limitations between humans and machines is shown .",
        "the algorithm embeds the trajectory of the markov chain into a reproducing kernel hilbert space ( rkhs ) , such that the feature space covariance of the samples informs the choice of proposal .",
        "in this paper we investigate the problem of estimating the cluster tree for a density $ f $ supported on or near a smooth $ d $ - dimensional manifold $ m $ isometrically embedded in $ \\ mathbb { r } ^ d $ .",
        "it allows for embedding externally defined calculations ( e .",
        "our model is based on two scoring functions that operate by learning low - dimensional embeddings of words and of entities and relationships from a knowledge base .",
        "the key idea of the method is to embed the joint distribution of a multi - view latent variable into a reproducing kernel hilbert space , and then the latent parameters are recovered using a robust tensor power method .",
        "rdfa was proposed as an extension to html for embedding non - intrusive rdf statements in human - readable documents .",
        "deep learning embeddings have been successfully used for many natural language processing ( nlp ) problems .",
        "embeddings are mostly computed for word forms although a number of recent papers have extended this to other linguistic units like morphemes and phrases .",
        "in this paper , we argue that learning embeddings for discontinuous linguistic units should also be considered .",
        "in an experimental evaluation on coreference resolution , we show that such embeddings perform better than word form embeddings .",
        "word embeddings resulting from neural language models have been shown to be successful for a large variety of nlp tasks .",
        "instead , we propose to drastically simplify the word embeddings computation through a hellinger pca of the word co - occurence matrix .",
        "we compare those new word embeddings with some well - known embeddings on ner and movie review tasks and show that we can reach similar or even better performance .",
        "although deep learning is not really necessary for generating good word embeddings , we show that it can provide an easy way to adapt embeddings to specific tasks .",
        "there are two main approaches to the distributed representation of words : low - dimensional deep learning embeddings and high - dimensional distributional models , in which each dimension corresponds to a context word .",
        "in this paper , we combine these two approaches by learning embeddings based on distributional - model vectors - as opposed to one - hot vectors as is standardly done in deep learning .",
        "several recent publications have proposed methods for mapping images into continuous semantic embedding spaces .",
        "in some cases the semantic embedding space is trained jointly with the image transformation , while in other cases the semantic embedding space is established independently by a separate task , such as a natural language processing task on a text corpus , and then the image transformation into that space is learned in a second stage .",
        "proponents of these image embedding systems have stressed their advantages over the traditional n - way classification framing of image understanding , particularly in terms of the promise of zero - shot learning - - the ability to correctly annotate images of previously unseen object categories .",
        "here we propose a simple method for constructing an image embedding system from any existing n - way image classification mechanism and any existing semantic embedding space which contains the n class labels in its vocabulary .",
        "our method maps images into the semantic embedding space via convex combination of the class label embedding vectors , and requires no additional learning .",
        "we show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes , and indeed outperforms state of the art methods on the imagenet zero - shot learning task .",
        "the sparse - to - dense module is a composition of a local spatial pooling step and a low - dimensional embedding process , which takes advantage of the spatial smoothness information in the image .",
        "our model learns to assign similar embeddings to aligned sentences and dissimilar ones to sentence which are not aligned while not requiring word alignments .",
        "the accuracy of the learned distribution depends both on the quantity of information embedded in $ h _ s $ and on the distance between $ h _ s $ and its mean $ h _ r $ .",
        "the selected instances can also be used for data preprocessing tasks such as learning a low - dimensional embedding of the data points or computing a low - rank approximation of the corresponding matrix .",
        "both approaches rely on learning deep semantic embeddings from a large amount of query click log data obtained from a search engine .",
        "finally , we use the dissimilarity metric to define a coordinate system on the embedded riemannian manifold , which gives us a low - dimensional encoding of our original data .",
        "our approach is based on embedding dl - lite logics in suitable fragments of the one - variable first - order logic , which provides useful insights into their properties and , in particular , computational behavior .",
        "we investigate embeddings of rdf in logic and show how standard logic programming and description logic technology can be used for reasoning with rdf .",
        "we use the embeddings and properties of the logics to establish novel upper bounds for the complexity of deciding entailment .",
        "to our knowledge , this work represents the first successful industrial application of embedded domain - independent temporal planning .",
        "it is typically embedded within a search procedure ( \" branch and prune \" ) and used at every node of the search tree to narrow down the search space , so it is critical that it be fast .",
        "the recently developed bayesian gaussian process latent variable model ( gplvm ) is a powerful generative model for discovering low dimensional embeddings in linear time complexity .",
        "in our paper , we introduce an algorithm that gives us the ability to handle huge state spaces and to use a heuristic concept which is easier to embed into search algorithms .",
        "we present a novel technique for learning semantic representations , which extends the distributional hypothesis to multilingual data and joint - space embeddings .",
        "our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences , while maintaining sufficient distance between those of dissimilar sentences .",
        "many of the previous works first embed the manifold to euclidean space and then learn the distance function .",
        "in this paper , we propose to learn the distance function directly on the manifold without embedding .",
        "to date , it has been used to embed in it default logic ( propositional case ) , autoepistemic logic , turner ' s logic of universal causation , and general logic programming under stable model semantics .",
        "besides showing the generality of gk as a logic for nonmonotonic reasoning , these embeddings shed light on the relationships among these other logics .",
        "in this paper , for the first time , we show how the logic of gk can be embedded into disjunctive logic programming in a polynomial but non - modular translation with new variables .",
        "these coding methods attempt to preserve either euclidean distance or angular ( cosine ) distance in the binary embedding space .",
        "binary embedding of high - dimensional data requires long codes to preserve the discriminative power of the input space .",
        "to address this problem , we propose circulant binary embedding ( cbe ) which generates binary codes by projecting the data with a circulant matrix .",
        "we study the convex relaxation of clustering and hamming embedding , focusing on the asymmetric case ( co - clustering and asymmetric hamming embedding ) , understanding their relationship to lsh as studied by ( charikar 2002 ) and to the max - norm ball , and the differences between their symmetric and asymmetric versions .",
        "spectral methods such as locally linear embedding ( lle ) can be useful in this context , as they preserve \" protrusions \" , i .",
        "digital elevation models ( dem ) are images having terrain information embedded into them .",
        "this embedding result has several important consequences : it not only provides a simple new proof theory for the calculus , thereby clarifying the proof - theoretic foundations of hybrid type - logical grammars , but , since the translation is simple and direct , it also provides several new parsing strategies for hybrid type - logical grammars .",
        "the main embedding result also sheds new light on problems with lambda grammars / abstract categorial grammars and shows lambda grammars / abstract categorial grammars suffer from problems of over - generation and from problems at the syntax - semantics interface unlike any other categorial grammar .",
        "accordingly , this work contributes with a regularized variant of moe that incorporates an embedded process for local feature selection using $ l1 $ regularization , with a simultaneous expert selection .",
        "examples are nonnegative matrix / tensor factorization , stochastic neighbor embedding , topic models , and bayesian network optimization .",
        "in this paper we propose a general framework for learning distributed representations of attributes : characteristics of text whose representations can be jointly learned with word embeddings .",
        "our model learns low - dimensional embeddings of words and knowledge base constituents ; these representations are used to score natural language questions against candidate answers .",
        "we introduce a model for bidirectional retrieval of images and sentences through a multi - modal embedding of visual and natural language data .",
        "unlike previous models that directly map images or sentences into a common embedding space , our model works on a finer level and embeds fragments of images ( objects ) and fragments of sentences ( typed dependency tree relations ) into a common space .",
        "some of these techniques we develop , such as a general transformation from a constant success probability subspace embedding to a high success probability subspace embedding with a dimension and sparsity independent of the success probability , may be of independent interest .",
        "in the more constrained tasks , co - occurrence vectors are competitive , although choice of compositional method is important ; on the larger - scale tasks , they are outperformed by neural word embeddings , which show robust , stable performance across the tasks .",
        "the minimum quartet tree cost problem is to construct an optimal weight tree from the $ 3 { n \\ choose 4 } $ weighted quartet topologies on $ n $ objects , where optimality means that the summed weight of the embedded quartet topologies is optimal ( so it can be the case that the optimal tree embeds all quartets as nonoptimal topologies ) .",
        "however , in addition to these semantic information , there are rich information embedded in source codes themselves .",
        "here we investigate the embeddings learned by neural machine translation models .",
        "we show that translation - based embeddings outperform those learned by cutting - edge monolingual models at single - language tasks requiring knowledge of conceptual similarity and / or syntactic role .",
        "we address this question using two neural network - based models for learning embeddings : plain neural networks and neural tensor networks .",
        "inspired by recent advances in multimodal learning and machine translation , we introduce an encoder - decoder pipeline that learns ( a ) : a multimodal joint embedding space with images and text and ( b ) : a novel language model for decoding distributed representations from our space .",
        "our pipeline effectively unifies joint image - text embedding models with multimodal neural language models .",
        "furthermore we show that with linear encoders , the learned embedding space captures multimodal regularities in terms of vector space arithmetic e .",
        "this paper describes an algorithm that is able to embed the preprocessing stage into the learningstage in order to get controllers directly starting from sensorial raw data with no expert knowledgeinvolved .",
        "an extension to the general pronoun resolution method performs inference as an embedded commonsense reasoning method .",
        "the general method and the embedded method utilize features of the ross representational scheme ; in particular the methods use ross ontology classes and the ross situation model .",
        "unlike previous approaches that map both sentences and images to a common embedding , we enable the generation of novel sentences given an image .",
        "we propose a novel parameter free , distance consistent locally linear embedding .",
        "furthermore , we propose a novel improved spectral clustering via embedded label propagation .",
        "a crucial problem for many results and tools about bigraphs and bigraphical reactive systems is bigraph embedding .",
        "an embedding is more informative than a bigraph matching , since it keeps track of the correspondence between the various components of the redex ( guest ) within the agent ( host ) .",
        "in this paper , we present an algorithm for computing embeddings based on a reduction to a constraint satisfaction problem .",
        "we also show how the affinity matrix can be learned from observed data with a simple convex optimization framework that is inspired by locally linear embedding .",
        "our approach learns the analogy - preserving embeddings between the abstract representations learned from each network , allowing for semantics - level transfer or reconstruction of the data among different modalities .",
        "the proposed model can be viewed as incorporating a more powerful compositional function for embedding acquisition in recursive neural networks .",
        "in this paper , we train recurrent neural networks with only raw features , and use word embedding to automatically learn meaningful representations .",
        "we show that a novel but simple feature embedding approach provides better performance , by exploiting the feature template structure common in nlp problems .",
        "this result assumes a planted sparse model , in which the target sparse vector is embedded in an otherwise random subspace .",
        "distributed word representations ( aka word embeddings ) are trained to optimally predict the contexts in which the corresponding words tend to appear .",
        "this prohibits the usage of deep cnns on resource limited hardware , especially cell phones or other embedded devices .",
        "all n - grams are thus embedded in a same semantic space .",
        "neural language models learn word representations , or embeddings , that capture rich linguistic and conceptual information .",
        "here we investigate the embeddings learned by neural machine translation models , a recently - developed class of neural language model .",
        "we show that embeddings from translation models outperform those learned by monolingual models at tasks that require knowledge of both conceptual similarity and lexical - syntactic role .",
        "we further show that these effects hold when translating from both english to french and english to german , and argue that the desirable properties of translation embeddings should emerge largely independently of the source and target languages .",
        "finally , we apply a new method for training neural translation models with very large vocabularies , and show that this vocabulary expansion algorithm results in minimal degradation of embedding quality .",
        "our embedding spaces can be queried in an online demo and downloaded from our web page .",
        "overall , our analyses indicate that translation - based embeddings should be used in applications that require concepts to be organised according to similarity and / or lexical function , while monolingual embeddings are better suited to modelling ( nonspecific ) inter - word relatedness .",
        "for these problems , label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency .",
        "in this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers fast label embedding algorithms and provides us with a unifying view of label embeddings in the multiclass and multilabel settings .",
        "leveraging techniques from randomized linear algebra , the running time of our label embedding algorithm is exponentially faster than naive algorithms .",
        "we consider learning representations of entities and relations in kbs using the neural - embedding approach .",
        "under this framework , we compare a variety of embedding models on the link prediction task .",
        "furthermore , we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules from the kb .",
        "we demonstrate that embeddings trained from the bilinear objective can effectively capture relation composition via matrix multiplication .",
        "we also show that our embedding - based approach can extract rules that involve relation transitivity more effectively than a state - of - the - art rule mining approach that is tailored for large - scale kbs .",
        "this paper advocates for density - based distributed embeddings and presents a method for learning representations in the space of gaussian distributions .",
        "we compare performance on various word embedding benchmarks , investigate the ability of these embeddings to model entailment and other asymmetric relationships , and explore novel properties of the representation .",
        "we investigate the problem of inducing word embeddings that are tailored for a particular bilexical relation .",
        "our learning algorithm takes an existing lexical vector space and compresses it such that the resulting word embeddings are good predictors for a target bilexical relation .",
        "in experiments we show that task - specific embeddings can benefit both the quality and efficiency in lexical prediction tasks .",
        "we propose diverse embedding neural network ( denn ) - a novel architecture for neural network language models ( lms ) .",
        "we also present an empirical analysis of the diverse word embeddings learned by denn - lm .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "further more , we also introduce a random embedding algorithm to scale our approach to sparse high dimensional feature sets .",
        "our model learns to embed image representations ( generated from a previously trained convolutional neural network ) into a multimodal space that is common to the images and the phrases that are used to described them .",
        "introduced the skip - gram model into the study of social network for the first time , and designed an algorithm named deepwalk for learning node embedding on a graph .",
        "we then propose two constraint programming formulation : the first formulation introduces a new global constraint called exists embedding that hides the complexity of the inclusion relation .",
        "we demonstrate the superior performance of our approach over pca , local linear embedding , kernel pca and isomap .",
        "the median variant relaxes the restriction of a metric space embedding for the objects but constrains the prototypes to be in the original data set .",
        "we build upon simon ' s notion of structural equations in order to extract the ( so - called ) causal ordering embedded in a hypothesis structure ( set of mathematical equations ) .",
        "the proposed strategy has been embedded in a local search based metaheuristic from the literature and tested in",
        "the key challenge of this problem is how to learn a metric , such that the instances sharing the same label are more likely close to each other on the embedded space .",
        "supervised manifold learning methods for data classification map data samples residing in a high - dimensional ambient space to a lower - dimensional domain in a structure - preserving way , while enhancing the separation between different classes in the learned embedding .",
        "most nonlinear supervised manifold learning methods compute the embedding of the manifolds only at the initially available training points , while the generalization of the embedding to novel points , known as the out - of - sample extension problem in manifold learning , becomes especially important in classification applications .",
        "the proposed algorithm computes a radial basis function ( rbf ) interpolator that minimizes an objective function consisting of the total embedding error of unlabeled test samples , defined as their distance to the embeddings of the manifolds of their own class , as well as a regularization term that controls the smoothness of the interpolation function in a direction - dependent way .",
        "these different approaches to decomposable cost functions are then embedded in a solver for extensive experiments that confirm the feasibility and efficiency",
        "in dan , hidden representations of all task - specific layers are embedded to a reproducing kernel hilbert space where the mean embeddings of different domain distributions can be explicitly matched .",
        "the domain discrepancy is further reduced using an optimal multi - kernel selection method for mean embedding matching .",
        "dan can learn invariant features with enhanced transferability , and can scale linearly by unbiased estimate of kernel embedding .",
        "specifically , we represent each topic as a cluster of multi - dimensional vectors and embed the corpus into a collection of vectors generated by the gaussian mixture model .",
        "each word is affected not only by its topic , but also by the embedding vector of its surrounding words and the context .",
        "in our experiments , we employ our inferred word embeddings as features in standard tagging tasks , obtaining significant accuracy improvements .",
        "here , we propose a novel model called temporal embedding - enhanced convolutional neural network ( tenet ) to learn repeatedly - occurring - yet - hidden structural elements in periodical time - series , called abstract snippets , for predicting future changes .",
        "our model uses convolutional neural networks and embeds a time - series with its potential neighbors in the temporal domain for aligning it to the dominant patterns in the dataset .",
        "this paper develops a model that addresses sentence embedding using recurrent neural networks ( rnn ) with long short term memory ( lstm ) cells .",
        "the proposed lstm - rnn model sequentially takes each word in a sentence , extracts its information , and embeds it into a semantic vector .",
        "visualization and analysis are performed to understand how the embedding process works .",
        "as a semantic representation of the sentence , the embedding vector can be used in many different applications .",
        "we present a novel learning method for word embeddings designed for relation classification .",
        "our word embeddings are trained by predicting words between noun pairs using lexical relation - specific features on a large unlabeled corpus .",
        "this allows us to explicitly incorporate relation - specific information into the word embeddings .",
        "the learned word embeddings are then used to construct feature vectors for a relation classification model .",
        "on a well - established semantic relation classification task , our method significantly outperforms a baseline based on a previously introduced word embedding method , and compares favorably to previous state - of - the - art models without syntactic information or manually constructed external resources .",
        "this is first carried out for target sets that are convex cones , and then generalized to any convex set by embedding it in a higher - dimensional convex cone .",
        "the model is embedded with a latent layer that is able to capture a richer class of contextual information in both state - state and observation - state pairs .",
        "factorial models can embed non - stationary noise models using markov chains as one of its source chain .",
        "a common strategy to overcome this problem is to perform dimensionality reduction on selected landmarks and to successively embed the entire dataset with the nystr \\ \" om method .",
        "the resulting neighborhood selection based on the bhattacharyya distance improves the embedding of sparsely sampled manifolds .",
        "due to its training speed and very few tunable parameters , the method has strong potential for embedded hardware applications requiring frequent retraining or online training .",
        "we explore the use of semantic word embeddings in text segmentation algorithms , including the c99 segmentation algorithm and new algorithms inspired by the distributed word vector representation .",
        "unsupervised word embeddings have been shown to be valuable as features in supervised learning problems ; however , their role in unsupervised problems has been less thoroughly explored .",
        "in this paper , we show that embeddings can likewise add value to the problem of unsupervised pos induction .",
        "in two representative models of pos induction , we replace multinomial distributions over the vocabulary with multivariate gaussian distributions over word embeddings and observe consistent improvements in eight languages .",
        "we also analyze the effect of various choices while inducing word embeddings on \" downstream \" pos induction results .",
        "it has gained its importance in e - government applications , mobile - based applications , embedded systems , and even business process development .",
        "this paper considers the problem of knowledge inference on large - scale imperfect repositories with incomplete coverage by means of embedding entities and relations at the first attempt .",
        "we propose iike ( imperfect and incomplete knowledge embedding ) , a probabilistic model which measures the probability of each belief , i .",
        "for these problems , label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency .",
        "in this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers a fast label embedding algorithm which works in both the multiclass and multilabel settings .",
        "this paper presents a theoretical analysis of multi - view embedding - - feature embedding that can be learned from unlabeled data through the task of predicting one view from another .",
        "the result explains the effectiveness of some existing methods such as word embedding .",
        "based on this theory , we propose a new semi - supervised learning framework that learns a multi - view embedding of small text regions with convolutional neural networks .",
        "additionally , our experimental results also evidence that : ( 1 ) our approach is more effective than cnn followed by a softmax classifier ; ( 2 ) omitting the representation of the artificial class other improves both precision and recall ; and ( 3 ) using only word embeddings as input features is enough to achieve state - of - the - art results if we consider only the text between the two target nominals .",
        "there is rising interest in vector - space word embeddings and their use in nlp , especially given recent methods for their fast estimation at very large scale .",
        "we present an extension to the skip - gram model that efficiently learns multiple embeddings per word type .",
        "it differs from recent related work by jointly performing word sense discrimination and embedding learning , by non - parametrically estimating the number of senses per word type , and by its efficiency and scalability .",
        "this paper presents an approach that reasons about conjunctions of multi - hop relations non - atomically , composing the implications of a path using a recursive neural network ( rnn ) that takes as inputs vector embeddings of the binary relation in the path .",
        "we assemble a new dataset of over 52m relational triples , and show that our method improves over a traditional classifier by 11 % , and a method leveraging pre - trained embeddings by 7 % .",
        "in our work , we propose to use recurrent neural networks and visual semantic embeddings without intermediate stages such as object detection and image segmentation .",
        "metric learning aims to embed one metric space into another to benefit tasks like classification and clustering .",
        "compositional embedding models build a representation ( or embedding ) for a linguistic structure based on its component word embeddings .",
        "we propose a feature - rich compositional embedding model ( \\ fct { } ) for relation extraction that is expressive , generalizes to new domains , and is easy - to - implement .",
        "the key idea is to combine both ( unlexicalized ) hand - crafted features with learned word embeddings .",
        "the model is able to directly tackle the difficulties met by traditional compositional embeddings models , such as handling arbitrary types of sentence annotations and utilizing global information for composition .",
        "this paper contributes a novel embedding model which measures the probability of each belief $ \\ langle h , r , t , m \\ rangle $ in a large - scale knowledge repository via simultaneously learning distributed representations for entities ( $ h $ and $ t $ ) , relations ( $ r $ ) , and the words in relation mentions ( $ m $ ) .",
        "given an imperfect belief , we can not only infer the missing entities , predict the unknown relations , but also tell the plausibility of the belief , just leveraging the learnt embeddings of remaining evidences .",
        "word embedding , which refers to low - dimensional dense vector representations of natural words , has demonstrated its power in many natural language processing tasks .",
        "to tackle this challenge , there have been quite a few works that leverage knowledge graphs as an additional information source to improve the quality of word embedding .",
        "our approach is based on the charwnn deep neural network , which uses word - level and character - level representations ( embeddings ) to perform sequential classification .",
        "our experimental results shade light on the contribution of neural character embeddings for ner .",
        "knowledge graph embedding refers to projecting entities and relations in knowledge graph into continuous vector spaces .",
        "state - of - the - art methods , such as transe , transh , and transr build embeddings by treating relation as translation from head entity to tail entity .",
        "we introduce a neural network method to encode programs as a linear mapping from an embedded precondition space to an embedded postcondition space and propose an algorithm for feedback at scale using these linear maps as features .",
        "in this paper we investigate the problem of localizing a mobile device based on readings from its embedded sensors utilizing machine learning methodologies .",
        ", word embedding ) could not achieve a good performance , mainly due to the multiple senses of words and the complex relations among words .",
        "second , we obtain distributed representations of words and relations by leveraging a novel word embedding method that considers the multi - sense nature of words and the relational knowledge among words ( or their senses ) contained in dictionaries .",
        "experiments results on 6 embeddings and 4 tasks with 10 datasets show that the proposed fine tuning framework may significantly improve the quality of the vector representation of words .",
        "like the conventional stack data structures used in transition - based parsing , elements can be pushed to or popped from the top of the stack in constant time , but , in addition , an lstm maintains a continuous space embedding of the stack contents .",
        "experiments using joint - embedding and deep learning methods show promising results on these tasks .",
        "representation learning of knowledge bases ( kbs ) aims to embed both entities and relations into a low - dimensional space .",
        "( 2 ) we represent relation paths via semantic composition of relation embeddings .",
        "we introduce an lstm model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words , then decodes this embedding to reconstruct the original paragraph .",
        "in this paper we introduce a pipelined architecture for incorporating multi - sense embeddings into language understanding , and test the performance of a state - of - the - art multi - sense embedding model ( based on chinese restaurant processes ) .",
        "recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces .",
        "to maximize the total data separability while preserving minimized within - class scatter simultaneously , we propose to embed kmeans into the framework generating pseudo class label information in a scenario of unsupervised feature selection .",
        "the resulting word - level distributed representations often ignore morphological information , though character - level embeddings have proven valuable to nlp tasks .",
        "we propose a new neural language model incorporating both word order and character order in its embedding .",
        "neural networks are both computationally intensive and memory intensive , making them difficult to deploy on embedded systems .",
        "embedding words in a vector space has gained a lot of research attention in recent years .",
        "while state - of - the - art methods provide efficient computation of word similarities via a low - dimensional matrix embedding , their motivation is often left unclear .",
        "in this paper , we argue that word embedding can be naturally viewed as a ranking problem .",
        "the performance of wordrank is measured in word similarity and word analogy benchmarks , and the results are compared to the state - of - the - art word embedding techniques .",
        "they allow for learning phrase embeddings as well as improved word embeddings .",
        "we introduce language - driven image generation , the task of generating an image visualizing the semantic contents of a word embedding , e .",
        ", given the word embedding of grasshopper , we generate a natural image of a grasshopper .",
        "the first takes as input a word embedding ( as produced , e .",
        "several user studies suggest that the current system produces images that capture general visual properties of the concepts encoded in the word embedding , such as color or typical environment , and are sufficient to discriminate between general categories of objects .",
        "the model consists of two gated recurrent unit networks with shared word embeddings , and uses a multi - task objective by receiving a textual description of a scene and trying to concurrently predict its visual representation and the next word in the sentence .",
        "on the other hand , word embedding has emerged as a newly favorite research subject because of its excellent performance in many natural language processing ( nlp ) - related tasks .",
        "a common thread of leveraging word embeddings in the summarization process is to represent the document ( or sentence ) by averaging the word embeddings of the words occurring in the document ( or sentence ) .",
        "beyond the continued efforts made to improve the representation of words , this paper focuses on building novel and efficient ranking models based on the general word embedding methods for extractive speech summarization .",
        "this paper addresses the problem of distilling embeddings for nlp tasks .",
        "we propose an encoding approach to distill task - specific knowledge from high - dimensional embeddings , which can retain high performance and reduce model complexity to a large extent .",
        "experimental results show our method is better than directly training neural networks with small embeddings .",
        "by means of pattern aggregation and probabilistic topic models , our siamese architecture captures contextualized semantics from the co - occurring descriptive terms via unsupervised learning , which leads to a concept embedding space of the terms in context .",
        "furthermore , the co - occurring oov concepts can be easily represented in the learnt concept embedding space .",
        "the main properties of the concept embedding space are demonstrated via visualization .",
        "to embed sequences of words ( i .",
        "in this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market .",
        "we introduce embed to control ( e2c ) , a method for model learning and control of non - linear dynamical systems from raw pixel images .",
        "recently , embedding methods have been proposed to represent words and documents by learning essential concepts and representations , such as word2vec and doc2vec .",
        "the embedded representations have shown more effectiveness than lda - style representations in many tasks .",
        "taking advantage of our characterization result , we embed the glp revision operators into structures of boolean lattices , that allow us to bring to light some",
        "we present \\ textit { autoextend } , a system to learn embeddings for synsets and lexemes .",
        "it is flexible in that it can take any word embeddings as input and does not need an additional training corpus .",
        "the synset / lexeme embeddings obtained live in the same vector space as the word embeddings .",
        "we show that its performance can be improved considerably by bootstrapping the learning from a larger question - answer pair corpus and from pretrained word embeddings .",
        "we detail a compositional distributional framework based on a rich form of word embeddings that aims at facilitating the interactions between words in the context of a sentence .",
        "embeddings and composition layers are jointly learned against a generic objective that enhances the vectors with syntactic information from the surrounding context .",
        "this paper aims to compare different regularization strategies to address a common phenomenon , severe overfitting , in embedding - based neural networks for nlp .",
        "we tried several frequently applied or newly proposed regularization strategies , including penalizing weights ( embeddings excluded ) , penalizing embeddings , re - embedding words , and dropout .",
        "most existing word embedding methods can be categorized into neural embedding models and matrix factorization ( mf ) - based methods .",
        "in addition , it is desirable to incorporate global latent factors , such as topics , sentiments or writing styles , into the word embedding model .",
        "since generative models provide a principled way to incorporate latent factors , we propose a generative word embedding model , which is easy to interpret , and can serve as a basis of more sophisticated latent factor models .",
        "we study the effectiveness of word embeddings to overcome this disadvantage of rouge .",
        "specifically , instead of measuring lexical overlaps , word embeddings are used to compute the semantic similarity of the words used in summaries instead .",
        "in this work , we innovatively develop two component - enhanced chinese character embedding models and their bigram extensions .",
        "distinguished from english word embeddings , our models explore the compositions of chinese characters , which often serve as semantic indictors inherently .",
        "it has been previously used to derive word embeddings , where one view indicates a word , and the other view indicates its context .",
        "we describe a way to incorporate prior knowledge into cca , give a theoretical justification for it , and test it by deriving word embeddings and evaluating them on a myriad of datasets .",
        "recent work on word embeddings has shown that simple vector subtraction over pre - trained embeddings is surprisingly effective at capturing different lexical relations , despite lacking explicit supervision .",
        "we find that word embeddings capture a surprising amount of information , and that , under suitable supervised training , vector subtraction generalises well to a broad range of relations , including over unseen lexical items .",
        "in this paper , we investigate whether distributional semantics in the form of word embeddings can enable a deeper , i .",
        "recently , knowledge graph embedding , which projects symbolic entities and relations into continuous vector space , has become a new , hot topic in artificial intelligence .",
        "this paper addresses a new issue of \\ textbf { multiple relation semantics } that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples , and proposes a novel gaussian mixture model for embedding , \\ textbf { transg } .",
        "the new model can discover latent semantics for a relation and leverage a mixture of relation component vectors for embedding a fact triple .",
        "to the best of our knowledge , this is the first generative model for knowledge graph embedding , which is able to deal with multiple relation semantics .",
        "to address this issue , we propose \\ textbf { transa } , an adaptive metric approach for embedding , utilizing the metric learning ideas to provide a more flexible embedding method .",
        "following the recent advances in word representation learning , our model learns dense real - valued word vectors , that is , bilingual word embeddings ( bwes ) .",
        "spectral embedding based on the singular value decomposition ( svd ) is a widely used \" preprocessing \" step in many learning tasks , typically leading to dimensionality reduction by projecting onto a number of dominant singular vectors and rescaling the coordinate axes ( by a predefined function of the singular value ) .",
        "in this paper , we propose a low - complexity it compressive spectral embedding algorithm , which employs random projections and finite order polynomial expansions to compute approximations to svd - based embedding .",
        "for an m times n matrix with t non - zeros , its time complexity is o ( ( t + m + n ) log ( m + n ) ) , and the embedding dimension is o ( log ( m + n ) ) , both of which are independent of the number of singular vectors whose effect we wish to capture .",
        "to the best of our knowledge , this is the first work to circumvent this dependence on the number of singular vectors for general svd - based embeddings .",
        "this prohibits their usage on resource limited hardware , including cell phones or other embedded devices .",
        "neural language models are a powerful tool to meaningfully embed words into semantic vector spaces .",
        "such whole - word segmental systems rely on a function that maps a variable - length speech segment to a vector in a fixed - dimensional space ; the resulting acoustic word embeddings need to allow for accurate discrimination between different word types , directly in the embedding space .",
        "our best approach uses side information in the form of known word pairs to train a siamese convolutional neural network ( cnn ) : a pair of tied networks that take two speech segments as input and produce their embeddings , trained with a hinge loss that separates same - word pairs and different - word pairs by some margin .",
        "to bypass this bottleneck in vocoded speech , this paper proposes a phase - embedded waveform representation framework and establishes a magnitude - phase joint modeling platform for high - quality spss .",
        "to investigate what the classifiers learn , we introduce ' intensional ' and ' denotational ' word vectors , and show that they capture meaning similarity in a way that is different from and complementary to word2vec word embeddings .",
        ", unsupervised embeddings ) , and that the supervised learning procedure updates them to task - specific representations for words contained in the training data .",
        "an experimental approach to studying the properties of word embeddings is proposed .",
        "recently , new upper bounds based on asymmetric locality - sensitive hashing ( alsh ) and asymmetric embeddings have emerged , but little has been known on the lower bound side .",
        "second makes use of the modern nonlinear t - distributed stochastic neighbor embedding method ( t - sne ) .",
        "learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs .",
        "in this work , we propose holographic embeddings ( hole ) to learn compositional vector space representations of entire knowledge graphs .",
        "in extensive experiments we show that holographic embeddings are able to outperform state - of - the - art methods for link prediction in knowledge graphs and relational learning benchmark datasets .",
        "the popular i - vector model represents speakers as lowdimensional continuous vectors ( i - vectors ) , and hence is a way of continuous speaker embedding .",
        "in this paper , we investigate binary speaker embedding , which transforms ivectors to binary vectors ( codes ) by a hash function .",
        "our experiments show that binary speaker embedding can deliver competitive or even better results on both speaker verification and identification tasks , while the memory usage and the computation cost are significant reduced .",
        "while word embedding has been demoed as a powerful representation for characterizing the statistical properties of natural language .",
        "in this study , we propose to use blstm - rnn with word embedding for part - of - speech ( pos ) tagging task .",
        "the embedding features learned from raw text further enhance the performance .",
        "web technology enables cloud - based solutions , embedding in tutorial web pages , atractive rendering of results , web - scale cooperative development , etc .",
        "we connected swish to the cliopatria semantic web toolkit , where it allows for collaborative development of programs and queries related to a dataset as well as performing maintenance tasks on the running server and we embedded swish in the learn prolog now !",
        "in this article , how word embeddings can be used as features in chinese sentiment classification is presented .",
        "then the word embeddings which represent each comment are used as input in different machine learning methods for sentiment classification , including svm , logistic regression , convolutional neural network ( cnn ) and ensemble methods .",
        "this study explores literary works as signals in word embedding space and tries to compare writing styles of popular classic novels using dynamic time warping .",
        "in a recent paper , levy and goldberg pointed out an interesting connection between prediction - based word embedding models and count models based on pointwise mutual information .",
        "we find that the most relevant differences from an optimization perspective are ( i ) predict models work in a low dimensional space where embedding vectors can interact heavily ; ( ii ) since predict models have fewer parameters , they are less prone to overfitting .",
        "we employ a pair of convolutional neural networks to model visual objects and speech signals at the word level , and tie the networks together with an embedding and alignment model which learns a joint semantic space over both modalities .",
        "to that end , we introduce a simplified training objective for learning multimodal embeddings using the skip - gram architecture by introducing convolutional ' pseudowords : ' embeddings composed of the additive combination of distributed word representations and image features from convolutional neural networks projected into the multimodal space .",
        "we present some preliminary results of the representational properties of these embeddings on various word similarity benchmarks .",
        "the basic framework is to build the embeddings of questions and answers based on bidirectional long short - term memory ( bilstm ) models , and measure their closeness by cosine similarity .",
        "to address this challenge , the drrn extracts high - level embedding vectors from the texts that describe states and actions , respectively , and computes the inner products between the state and action embedding vectors to approximate the q - function .",
        "a word embedding based correlation ( wec ) model is proposed by integrating advantages of both the translation model and word embedding , given a random pair of words , wec can score their co - occurrence probability in q \\ & amp ; a pairs and it can also leverage the continuity and smoothness of continuous space word representation to deal with new pairs of words that are rare in the training parallel text .",
        "in addition , to reduce the computational complexity , an over - relaxed monotone fast iterative shrinkage - thresholding technique is adapted and embedded in the iterative reweighted process .",
        "we consider the hashing mechanism for constructing binary data embeddings , that involves pseudo - random projections followed by nonlinear ( sign function ) mappings .",
        "it is a non - parametric and distribution free kernel method based on the hilbert space embedding of probability measures .",
        "with the d - cbow2 model we propose a new approach in which the input embedding layer is augmented with a context anchor layer .",
        "with experiments on french broadcast news videos we show that these two models outperform the baseline methods based on raw embeddings from lda , skip - gram",
        "we present a probabilistic language model that uses word embeddings to associate lingual verbs with their corresponding kinematic structures .",
        ", contiguous subsequences of the input ) are computed by encoding their constituent tokens using bidirectional recurrent neural nets , and these \" segment embeddings \" are used to define compatibility scores with output labels .",
        "we detect communities via standard graph clustering algorithms , and then exploit these communities by learning community - specific projections of word embeddings .",
        "however , it cannot reflect the rich relations between words by representing words as points in the embedded space .",
        "in this paper , we propose the gaussian mixture skip - gram ( gmsg ) model to learn the gaussian mixture embeddings for words based on skip - gram framework .",
        "each word can be regarded as a gaussian mixture distribution in the embedded space , and each gaussian component represents a word sense .",
        "in this paper , we propose deep embedded clustering ( dec ) , a method that simultaneously learns feature representations and cluster assignments using deep neural networks .",
        "to address this issue , we propose manifold regularized networks ( mrnet ) that utilize a novel training objective function that minimizes the difference between multi - layer embedding results of samples and those adversarial .",
        "furthermore , the training process of recent word - sense models is expensive relative to single - sense embedding processes .",
        "this paper presents a novel approach which addresses these concerns by modeling multiple embeddings for each word based on supervised disambiguation , which provides a fast and accurate way for a consuming nlp model to select a sense - disambiguated embedding .",
        "we demonstrate that these embeddings can disambiguate both contrastive senses such as nominal and verbal senses as well as nuanced senses such as sarcasm .",
        "we further evaluate part - of - speech disambiguated embeddings on neural dependency parsing , yielding a greater than 8 % average error reduction in unlabeled attachment scores across 6 languages .",
        "when building a knowledge base ( kb ) of entities and relations from multiple structured kbs and text , universal schema represents the union of all input schema , by jointly embedding all relation types from input kbs as well as textual patterns expressing relations .",
        "in previous work , textual patterns are parametrized as a single embedding , preventing generalization to unseen textual patterns .",
        "additional improvements are obtained by tying word embeddings across languages .",
        "a simple scheme is outlined that can reduce the memory footprint of a state - of - the - art embedding by a factor of 10 , with only minimal impact on performance .",
        "we embed an attention mechanism within a recurrent neural network ( rnn ) based acoustic model to automatically tune its attention to a more reliable input source .",
        "binary embeddings provide efficient and powerful ways to perform operations on large scale data .",
        "however binary embedding typically requires long codes in order to preserve the discriminative power of the input space .",
        "to address this problem , we propose circulant binary embedding ( cbe ) which generates binary codes by projecting the data with a circulant matrix .",
        "we demonstrate that the linear algebraic structure of word embeddings can be used to reduce data requirements for methods of learning facts .",
        "we propose a model to learn visually grounded word embeddings ( vis - w2v ) to capture visual notions of semantic relatedness .",
        "while word embeddings trained using text have been extremely successful , they cannot uncover notions of semantic relatedness implicit in our visual world .",
        "we find that the embeddings we learn capture fine - grained visually grounded notions of semantic relatedness .",
        "we show improvements over text only word embeddings ( word2vec ) on three tasks : common - sense assertion classification , visual paraphrasing and text - based image retrieval .",
        "we present and examine a result related to uncertainty reasoning , namely that a certain plausibility space of cox ' s type can be uniquely embedded in a minimal ordered field .",
        "embedding learning , a .",
        "in recent publications the embedding models were extended to also consider temporal evolutions , temporal patterns and subsymbolic representations .",
        "in this paper , we attempt to map these embedding models , which were developed purely as solutions to technical problems , to various cognitive memory functions , in particular to semantic and concept memory , episodic memory and sensory memory .",
        "in this paper , we show how to create paraphrastic sentence embeddings using the paraphrase database ( ganitkevitch et al .",
        "we make them available to the research community with the hope that they can serve as the new baseline for further work on universal paraphrastic sentence embeddings .",
        "we also learn high - quality category embeddings that reflect topical meanings .",
        "multitask cnn also contains multiple aspect cnns and a sentiment cnn , but different networks share the same word embeddings .",
        "recently , distributed word representations , or word embeddings , have been shown to successfully allow words to match on the semantic level .",
        "we therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching .",
        "we propose a new zero - shot event detection method by multi - modal distributional semantic embedding of videos .",
        "our model embeds object and action concepts as well as other available modalities from videos into a distributional semantic space .",
        "to our knowledge , this is the first zero - shot event detection model that is built on top of distributional semantics and extends it in the following directions : ( a ) semantic embedding of multimodal information in videos ( with focus on the visual modalities ) , ( b ) automatically determining relevance of concepts / attributes to a free text query , which could be useful for other applications , and ( c ) retrieving videos by free text event query ( e .",
        "we embed videos into a distributional semantic space and then measure the similarity between videos and the event query in a free text form .",
        "neural enquirer can be trained with gradient descent , with which not only the parameters of the controlling components and semantic parsing component , but also the embeddings of the tables and query words can be learned from scratch .",
        "we present a new perspective on neural knowledge base ( kb ) embeddings , from which we build a framework that can model symbolic knowledge in the kb together with its learning process .",
        "we show that this framework well regularizes previous neural kb embedding model for superior performance in reasoning tasks , while having the capabilities of dealing with unseen entities , that is , to learn their embeddings from natural language descriptions , which is very like human ' s behavior of learning semantic concepts .",
        "embedded in the host language , it blends declarative symbolic expression with imperative tensor computation .",
        "knowledge graph embedding aims to represent entities and relations in a large - scale knowledge graph as elements in a continuous vector space .",
        ", transe and transh , learn embedding representation by defining a global margin - based loss function over the data .",
        "moreover , embeddings over two knowledge graphs with different entities and relations share the same set of candidate loss functions , ignoring the locality of both graphs .",
        "this leads to the limited performance of embedding related applications .",
        "in this paper , we propose a locally adaptive translation method for knowledge graph embedding , called transa , to find the optimal loss function by adaptively determining its margin over different knowledge graphs .",
        "one key method for data analysis is dimensionality reduction , for example , to produce 2d embeddings that can be visualized and analyzed efficiently .",
        "t - distributed stochastic neighbor embedding ( tsne ) is a well - suited technique for the visualization of several high - dimensional data .",
        "this paper introduces driverseat , a technology for embedding crowds around learning systems for autonomous driving .",
        "in this paper , we present the first convolutional network accelerator which is scalable to network sizes that are currently only handled by workstation gpus , but remains within the power envelope of embedded systems .",
        "the aog embeds a context sensitive grammar that can describe the hierarchical composition of news topics by semantic elements about people involved , related places and what happened , and model contextual relationships between elements in the hierarchy .",
        "a generative model of object similarities based on the dirichlet distribution is proposed and embedded in the network for encoding the state of the system .",
        "embedding learning , a .",
        "hypothetical datalog is based on an intuitionistic semantics rather than on a classical logic semantics , and embedded implications are allowed in rule bodies .",
        ", the neck of a horn clause ) stands for inferring facts , an embedded implication plays the role of assuming its premise for deriving its consequence .",
        "for solving the problem , we introduce a multi - view embedding in which a latent factorization identifies which aspects in the two data views ( primary data and user data ) are related and which are specific to only one of them .",
        "instead of deriving sentence embeddings for the premise and the hypothesis to be used for classification , our solution uses a matching - lstm that performs word - by - word matching of the hypothesis with the premise .",
        "moreover , we show that our method learns an embedding in which high - level abstract visual features ( e .",
        "we provide the first extensive evaluation of how using different types of context to learn skip - gram word embeddings affects performance on a wide range of intrinsic and extrinsic nlp tasks .",
        "furthermore , for these extrinsic tasks , we find that once the benefit from increasing the embedding dimensionality is mostly exhausted , simple concatenation of word embeddings , learned with different context types , can yield further performance gains .",
        "as an additional contribution , we propose a new variant of the skip - gram model that learns word embeddings from weighted contexts of substitute words .",
        "in this paper , we propose a novel embedding method specifically designed for ned .",
        "by combining contexts based on the proposed embedding with standard ned features , we achieved state - of - the - art accuracy of 93 .",
        "similarly word embedding methods from natural language processing literature learn low - dimensional vector space representation of input elements .",
        "noticing the similarities among word embedding and matrix factorization techniques and based on the previous works that apply techniques from text processing for recommendation , word2vec ' s skip - gram technique is employed to make recommendations .",
        "we introduce trans - gram , a simple and computationally - efficient method to simultaneously learn and align wordembeddings for a variety of languages , using only monolingual data and a smaller set of sentence - aligned data .",
        "we use our new method to compute aligned wordembeddings for twenty - one languages using english as a pivot language .",
        "the discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model .",
        "we formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point - cloud , natural language , and manipulation trajectory data into a shared embedding space using a deep neural network .",
        "in order to learn semantically meaningful spaces throughout our network , we introduce a method for pre - training its lower layers for multimodal feature embedding and a method for fine - tuning this embedding space using a loss - based margin .",
        "it takes a pair of image and sentence and processes them in different channels , finally embedding it into a common multimodal vector space .",
        "these embeddingsencode abstract semantic information about the two inputs and can be comparedusing traditional information retrieval approaches .",
        "we propose a latent feature embedding based link recommendation model for prediction task and utilize bayesian personalized ranking based optimization technique for learning models for each predicate .",
        "the estimator is formulated as an inner product with a reproducing kernel hilbert space embedding and makes no assumption about the type or shape of the underlying data distribution .",
        "in many embedded systems , such as imaging sys - tems , the system has a single designated purpose , and same threads are executed repeatedly .",
        "we show how this objective can be understood in terms of graph embedding as well as how it corresponds to the information - theoretic measure of excess entropy in special cases .",
        "the parsing model uses multilingual word embeddings alongside learned and specified typological information , enabling generalization based on linguistic universals and based on typological similarities .",
        "we introduce new methods for estimating and evaluating embeddings of words from dozens of languages in a single shared embedding space .",
        "we present submatrix - wise vector embedding learner ( swivel ) , a method for generating low - dimensional feature embeddings from a feature co - occurrence matrix .",
        "this approach results in more accurate embeddings than can be achieved with methods that consider only observed co - occurrences , and can scale to much larger corpora than can be handled with sampling methods .",
        "we view it as a special case of a general framework which jointly trains a linear model with a non - linear feature generator consisting of ` text region embedding + pooling ' .",
        "under this framework , we explore a more sophisticated region embedding method using long short - term memory ( lstm ) .",
        "lstm can embed text regions of variable ( and possibly large ) sizes , whereas the region size needs to be fixed in a cnn .",
        "we seek the best use of lstm for the purpose in the supervised and semi - supervised settings , starting with the idea of one - hot lstm , which eliminates the customarily used word embedding layer .",
        "our results indicate that on this task , embeddings of text regions , which can convey higher concepts than single words in isolation , are more useful than word embeddings .",
        "we introduce the value iteration network : a fully differentiable neural network with a ` planning module ' embedded within .",
        "there is a wealth of information about financial systems that is embedded in document collections .",
        "we embed features of multiple layers into reproducing kernel hilbert spaces ( rkhss ) and match feature distributions for feature adaptation .",
        "a reproducing kernel can define an embedding of a data point into an infinite dimensional reproducing kernel hilbert space ( rkhs ) .",
        "to address this issue , we propose a method which learns a vector - space embedding of entities from wikipedia and constrains this embedding such that entities of the same semantic type are located in some lower - dimensional subspace .",
        "this basic problem lies at the core of a number of questions that are currently being considered by different communities , including community detection in sparse random graphs , learning structured models such as topic models or hidden markov models , and the efforts from the natural language processing community to compute \" word embeddings \" .",
        "in this paper , we present the latent skill embedding ( lse ) , a probabilistic model of students and educational content that can be used to recommend personalized sequences of lessons with the goal of helping students prepare for specific assessments .",
        "we formulate this problem as a regularized maximum - likelihood embedding of students , lessons , and assessments from historical student - content interactions .",
        "embeddings are generic representations that are useful for many nlp tasks .",
        "in this paper , we introduce densifier , a method that learns an orthogonal transformation of the embedding space that focuses the information relevant for a task in an ultradense subspace of a dimensionality that is smaller by a factor of 100 than the original space .",
        "we show that ultradense embeddings generated by densifier reach state of the art on a lexicon creation task in which words are annotated with three types of lexical information - sentiment , concreteness and frequency .",
        "the advantage of rnns over the traditional approaches is their capacity to capture long ranges of context and implicitly adapt the word embeddings , trained on a large corpus , into a task - specific word representation , but still preserve the original semantic generalization to be helpful across domains .",
        "as a case study , we use a multi - task gated recurrent network model consisting of two parallel pathways with shared word embeddings trained on predicting the representations of the visual scene corresponding to an input sentence , and predicting the next word in the same sentence .",
        "to demonstrate its effectiveness , we use the representation as the backbone of a greedy , bottom - up dependency parser , achieving state - of - the - art accuracies for english and chinese , without relying on external word embeddings .",
        "recursive neural networks ( rnn ) and their recently proposed extension recursive long short term memory networks ( rlstm ) are models that compute representations for sentences , by recursively combining word embeddings according to an externally provided parse tree .",
        "in this paper , we propose a neural mt system using character - based embeddings in combination with convolutional and highway layers to replace the standard lookup - based word representations .",
        "the resulting unlimited - vocabulary and affix aware source word embeddings are tested in a state - of - the - art neural mt based on an attention - based bidirectional recurrent neural network .",
        "we introduce a novel , simple convolution neural network ( cnn ) architecture - multi - group norm constraint cnn ( mgnc - cnn ) that capitalizes on multiple sets of word embeddings for sentence classification .",
        "mgnc - cnn extracts features from input embedding sets independently and then joins these at the penultimate layer in the network to form a final feature vector .",
        "we then adopt a group regularization strategy that differentially penalizes weights associated with the subcomponents generated from the respective embedding sets .",
        "furthermore , it is flexible in that it does not require input word embeddings to be of the same dimensionality .",
        "recent advances in convolutional neural networks have considered model complexity and hardware efficiency to enable deployment onto embedded systems and mobile devices .",
        "typically , this process is computationally expensive and the produced embedding is limited to the training data .",
        "in many real life scenarios , the ability to produce embedding of unseen samples is essential .",
        "to exploit the combination of different discourse corpora , we design related discourse classification tasks specific to a corpus , and propose a novel convolutional neural network embedded multi - task learning system to synthesize these tasks by learning both unique and shared representations for each task .",
        "in our approach , a potential word segment ( of arbitrary length ) is embedded in a fixed - dimensional acoustic vector space .",
        "we start from learning general embeddings for each entity mention , compose the embeddings of specific contexts using linguistic structures , link the mention to knowledge bases and learn its related knowledge representations .",
        "our paper presents a new method to find local symmetries in a low - dimensional 2 - d grid structure which is embedded in high - dimensional structure .",
        "starting from word embeddings of discourse arguments , semder employs a shallow encoder to generate a distributed surface representation for a discourse .",
        "recently , several works in the field of natural language processing suggested to learn a latent representation of words using neural embedding algorithms .",
        "in this paper , we show that item - based cf can be cast in the same framework of neural word embedding .",
        "inspired by sgns , we describe a method we name item2vec for item - based cf that produces embedding for items in a latent space .",
        "it ( i ) combines diverse versions of pretrained word embeddings and ( ii ) extracts features of multigranular phrases with variable - size convolution filters .",
        "we propose a new algorithm for topic modeling , vec2topic , that identifies the main topics in a corpus using semantic information captured via high - dimensional distributed word embeddings .",
        "the feature embedding module is a cnn which maps each face frame into a feature representation .",
        "the neural aggregation module is composed of two content based attention blocks which is driven by a memory storing all the features extracted from the face video through the feature embedding module .",
        "we present a novel method for jointly learning compositional and non - compositional phrase embeddings by adaptively weighting both types of embeddings using a compositionality scoring function .",
        "the scoring function is used to quantify the level of compositionality of each phrase , and the parameters of the function are jointly optimized with the objective for learning phrase embeddings .",
        "in experiments , we apply the adaptive joint learning method to the task of learning embeddings of transitive verb phrases , and show that the compositionality scores have strong correlation with human ratings for verb - object compositionality , substantially outperforming the previous state of the art .",
        "moreover , our embeddings improve upon the previous best model on a transitive verb disambiguation task .",
        "a speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style .",
        "recently , several works in the domain of natural language processing presented successful methods for word embedding .",
        "in this paper , we propose a scalable bayesian neural word embedding algorithm that can be beneficial to general item similarity tasks as well .",
        "we apply distributed language embedding methods from natural language processing to assign a vector to each database entity associated token ( for example , a token may be a word occurring in a table row , or the name of a column ) .",
        "the results reveal that neural embedding based document representations work better on this analogy task than conventional methods , and we provide some preliminary explanations over these observations .",
        "this paper proposes a model to learn word embeddings with weighted contexts based on part - of - speech ( pos ) relevance weights .",
        "however , state - of - the - art word embedding models fail to consider it .",
        "we utilize the pos relevance weights to model each word - context pairs during the word embedding training process .",
        "when learning nonlinear embeddings with siamese or triplet networks from similarities , we typically assume they are sourced from a single visual concept .",
        "in this paper , we are concerned with the hypothesis that it can be potentially harmful to ignore the heterogeneity of concepts affiliated with observed similarities when learning these embedding networks .",
        "we propose multi - query networks ( mqns ) that leverage recent advances in representation learning on factorized triplet embeddings in combination with convolutional networks in order to learn embeddings differentiated into semantically distinct subspaces , which are learned with a latent space attention mechanism .",
        "secondly , seven emotion embedding vectors , which are corresponding to each classification emotion type , are added to locate the perception attentions .",
        "this paper introduces the visually informed embedding of word ( view ) , a continuous vector representation for a word extracted from a deep neural model trained using the microsoft coco data set to forecast the spatial arrangements between visual objects , given a textual description .",
        "the model is composed of a deep multilayer perceptron ( mlp ) stacked on the top of a long short term memory ( lstm ) network , the latter being preceded by an embedding layer .",
        "we present a semi - supervised learning framework based on graph embeddings .",
        "given a graph between instances , we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph .",
        "in the transductive variant of our method , the class labels are determined by both the learned embeddings and input feature vectors , while in the inductive variant , the embeddings are defined as a parametric function of the feature vectors , so predictions can be made on instances not seen during training .",
        "perspectives range from the word level to sentence fragments to sequences of sentences ; the networks operate only on word - embedding representations of text .",
        "we present an approach to learning multi - sense word embeddings relying both on monolingual and bilingual information .",
        "we propose an unsupervised algorithm based on lesk which performs visual sense disambiguation using textual , visual , or multimodal embeddings .",
        "we find that textual embeddings perform well when gold - standard textual annotations ( object labels and image descriptions ) are available , while multimodal embeddings perform well on unannotated images .",
        "we also verify our findings by using the textual and multimodal embeddings as features in a supervised setting and analyse the performance of visual sense disambiguation task .",
        "to address this challenge , we propose a new deep neural network architecture that jointly leverage pre - trained word embedding and auxiliary character embedding to learn sentence meanings .",
        "this model enables us to naturally exploit the semantic structures of word embeddings while flexibly discovering the number of topics .",
        "despite interest in using cross - lingual knowledge to learn word embeddings for various tasks , a systematic comparison of the possible approaches is lacking in the literature .",
        "we perform an extensive evaluation of four popular approaches of inducing cross - lingual embeddings , each requiring a different form of supervision , on four typographically different language pairs .",
        "this work , concerning paraphrase identification task , on one hand contributes to expanding deep learning embeddings to include continuous and discontinuous linguistic phrases .",
        "on the other hand , it comes up with a new scheme tf - kld - knn to learn the discriminative weights of words and phrases specific to paraphrase task , so that a weighted sum of embeddings can represent sentences more effectively .",
        "importantly , we achieve these results even though our character - level model has 16x less parameters than an equivalent word - embedding model , uses significantly less training data than previous work which relies on data augmentation , and encounters only 1 .",
        "two novel deep bidirectional variant models , in which we increase the depth of nonlinearity transition in different way , are proposed to learn hierarchical visual - language embeddings .",
        "we employ distributional semantic representations of query entities through two models : 1 ) contextual vectors generated from encyclopedic corpora like wikipedia , and 2 ) high dimensional word embedding vectors generated from millions of job postings using word2vec .",
        "the matches are encoded as embeddings with additional parameters ( dimensions ) , which are tuned by the network .",
        "a currently successful approach to computational semantics is to represent words as embeddings in a machine - learned vector space .",
        "we present an ensemble method that combines embeddings produced by glove ( pennington et al .",
        "the embeddings it produces achieve state - of - the - art performance on many word - similarity evaluations .",
        "our results show that the online embedding indeed approximates the geometry of the full corpus - wise tf and tf - idf space .",
        "knowledge graph embedding represents the entities and relations as numerical vectors , and then knowledge analysis could be promoted as a numerical method .",
        "our model could interact both two information sources by characterizing the correlations , by which means , the textual descriptions could make effects to discover semantic relevance and offer precise semantic embedding .",
        "the approach is primarily based on a combination of word embeddings and parserbased features , and employs unidirectional incremental computation of compositional embeddings for multiword expressions .",
        "we address these issues and evaluate bi - lstms with word , character , and unicode byte embeddings for pos tagging .",
        "several resources and techniques to improve our relation extraction systems are also discussed , including word embeddings and training data expansion .",
        "finally , we use additional unlabeled data through distant supervision techniques and word embeddings to further improve stance classification .",
        "in this paper , we enhance the attention - based neural machine translation by adding an explicit coverage embedding model to alleviate issues of repeating and dropping translations in nmt .",
        "for each source word , our model starts with a full coverage embedding vector , and then keeps updating it with a gated recurrent unit as the translation goes .",
        "all the initialized coverage embeddings and updating matrix are learned in the training procedure .",
        "~ we propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases .",
        "do word embeddings converge to learn similar things over different initializations ?",
        "how repeatable are experiments with word embeddings ?",
        "are all word embedding techniques equally reliable ?",
        "our preliminary results illustrate that our metric not only measures a intrinsic property of word embedding methods but also correlates well with other evaluation metrics on downstream tasks .",
        "we believe our methods are is useful in characterizing robustness - - an important property to consider when developing new word embedding methods .",
        "recent work in learning vector - space embeddings for multi - relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora .",
        "in this article , we propose candies ( combined approach for novelty detection in intelligent embedded systems ) , a new approach to novelty detection in technical systems .",
        "moreover , we publish first largest word2vec word embeddings trained on 52 million crisis - related tweets .",
        "to enable embedded devices such as smartphones , google glasses and monitoring cameras with the astonishing power of deep learning , dedicated hardware accelerators can be used to decrease both execution time and power consumption .",
        "based on the theory of hilbert space embedding of distributions , a novel joint distribution discrepancy is proposed to directly compare joint distributions across domains , eliminating the need of marginal - conditional factorization .",
        "for example , when the items are embedded into $ k $ tight clusters , the sample complexity of our algorithm reduces to $ o ( nk ) $ .",
        "our model treats such instances as sub - sequences of lexicalized dependency paths and learns suitable embedding representations .",
        "we experimentally demonstrate that such embeddings can improve results over previous state - of - the - art semantic role labelers , and showcase qualitative improvements obtained by our method .",
        "we characterize a large class of loss functions that allows to naturally embed structured outputs in a linear space .",
        "the novel embedding outperforms state - of - the - art models on predicting word similarities in simlex - 999 , and on distinguishing antonyms from synonyms .",
        "in this paper , we propose a new method for query translation based on dimension projection of embedded vectors from the pseudo - relevant documents in the source language to their equivalents in the target language .",
        "we employ recursive autoencoders to generate tree structures of phrase with embeddings at different levels of granularity ( e .",
        "over these embeddings on the source and target side , we introduce a bidimensional attention network to learn their interactions encoded in a bidimensional attention matrix , from which we extract two soft attention weight distributions simultaneously .",
        "continuous space word embeddings have received a great deal of attention in the natural language processing and machine learning communities for their ability to model term similarity and other relationships .",
        "we demonstrate that word embeddings such as word2vec and glove , when trained globally , underperform corpus and query specific embeddings for retrieval tasks .",
        "these results suggest that other tasks benefiting from global embeddings may also benefit from local embeddings .",
        "most recent approaches to zero - shot learning are based on finding and exploiting relationships between labels using semantic embeddings .",
        "we show in this paper that semantic embeddings , despite being very good at capturing relationships between labels , are not very good at capturing the relationships among labels in a data - dependent manner .",
        "in the first step , we learn what we call a \\ emph { property embedding",
        "we propose a scheme for recycling gaussian random vectors into structured matrices to approximate various kernel functions in sublinear time via random embeddings .",
        "word embeddings show promise as a diachronic tool , but have not been carefully evaluated .",
        "we develop a robust methodology for quantifying semantic change by evaluating word embeddings ( ppmi , svd , word2vec ) against known historical changes .",
        "in this paper , the problem of multi - view embedding from different visual cues and modalities is considered .",
        "we propose a unified solution for subspace learning methods using the rayleigh quotient , which is extensible for multiple views , supervised learning , and non - linear embeddings .",
        "we demonstrate the effectiveness of the proposed multi - view embedding methods on visual object recognition and cross - modal image retrieval , and obtain superior results in both applications compared to related methods .",
        "in this paper , we propose a novel approach to multi - label zsl via concept embedding learned from collections of public users ' annotations of multimedia .",
        "thanks to concept embedding , multi - label zsl can be done by efficiently mapping an instance input features onto the concept embedding space in a similar manner used in single - label zsl .",
        "moreover , our semantic learning model is capable of embedding an out - of - vocabulary label by inferring its meaning from its co - occurring labels .",
        "thus , our approach allows both seen and unseen labels during the concept embedding learning to be used in the aforementioned instance mapping , which makes multi - label zsl more flexible and suitable for real applications .",
        "we introduce a new attention mechanism which uses multiplicative interactions between the query embedding and intermediate states of a recurrent neural network reader .",
        "powered by deep recurrent neural networks and neural embeddings , our proposed cfo achieves an accuracy of 75 .",
        "we then use word embeddings to repre - sent these concepts in a low dimensional vector space , allowing us to expand the meaning around concepts , and thus enabling insight about commonalities and differences among different languages .",
        "instead of aiming to select a single optimal architecture , we propose a $ \" $ fabric $ \" $ that embeds an exponentially large number of cnn architectures .",
        "while individual cnn architectures can be recovered as paths in the trellis , the trellis can in addition ensemble all embedded architectures together , sharing their weights where their paths overlap .",
        "the regularization ability of the dppn allows it to rediscover ( approximate ) convolutional network architectures embedded within a fully connected architecture .",
        "this paper presents a joint model for performing unsupervised morphological analysis on words , and learning a character - level composition function from morphemes to word embeddings .",
        "our morphological analysis is comparable to dedicated morphological analyzers at the task of morpheme boundary recovery , and also performs better than word - based embedding models at the task of syntactic analogy answering .",
        "finally , we show that incorporating morphology explicitly into character - level models help them produce embeddings for unseen words which correlate better with human judgments .",
        "we combine domain - specific word embeddings with a label propagation framework to induce accurate domain - specific sentiment lexicons using small sets of seed words .",
        "we generalize the embedding layer of the encoder in the attentional encoder - - decoder architecture to support the inclusion of arbitrary features , in addition to the baseline word feature .",
        "various systems using word overlap , neural embeddings and neural compositional models are evaluated on two datasets of learner writing .",
        "we propose a new method for sentence - level similarity calculation , which learns to adjust the weights of pre - trained word embeddings for a specific task , achieving substantially higher accuracy compared to other relevant baselines .",
        "text embeddings have played a key role in obtaining state - of - the - art results in natural language processing .",
        "however , extracting universal embeddings of longer word - sequences remains a challenging task .",
        "we employ the convolutional dictionary model for unsupervised learning of embeddings for variable length word - sequences .",
        "the estimated activations are then used as embeddings for downstream tasks such as sentiment analysis , paraphrase detection , and semantic textual similarity estimation .",
        "our word - sequence embeddings achieve state - of - the - art performance in sentiment classification , semantic textual similarity estimation , and paraphrase detection over eight datasets from",
        "psdvec is a python / perl toolbox that learns word embeddings , i .",
        "psdvec implements a word embedding learning method based on a weighted low - rank positive semidefinite approximation .",
        "to scale up the learning process , we implement a blockwise online learning algorithm to learn the embeddings incrementally .",
        "this strategy greatly reduces the learning time of word embeddings on a large vocabulary , and can learn the embeddings of new words without re - learning the whole vocabulary .",
        "on 9 word similarity / analogy benchmark sets and 2 natural language processing ( nlp ) tasks , psdvec produces embeddings that has the best average performance among popular word embedding tools .",
        "since wordnet embeds natural language in the form of a complex network , a transformation mechanism wordnet2vec is proposed in the paper .",
        "this paper reviews machine learning applications and approaches to detection , classification and control of intelligent materials and structures with embedded distributed computation elements .",
        "we trained embeddings of words and phrases with the word2vec skip - gram method , then used those features to learn sentence representations via a hashtag prediction auxiliary task .",
        "neural models capitalize on word embeddings as features , tuning these to the task at hand .",
        "we argue that al strategies for neural text classification should focus on selecting instances that most affect the embedding space ( i .",
        "we propose a simple approach that selects instances containing words whose embeddings are likely to be updated with the greatest magnitude , thereby rapidly learning discriminative , task - specific embeddings .",
        "maximum mean discrepancy ( mmd ) has been successfully applied to learn deep generative models for characterizing a joint distribution of variables via kernel mean embedding .",
        "we propose a tagging model using wsabie , a discriminative embedding - based model with rank - based learning .",
        "we present the siamese continuous bag of words ( siamese cbow ) model , a neural network for efficient estimation of high - quality sentence embeddings .",
        "averaging the embeddings of words in a sentence has proven to be a surprisingly successful and efficient way of obtaining sentence embeddings .",
        "however , word embeddings trained with the methods currently available are not optimized for the task of sentence representation , and , thus , likely to be suboptimal .",
        "siamese cbow handles this problem by training word embeddings directly for the purpose of being averaged .",
        "the underlying neural network learns word embeddings by predicting , from a sentence representation , its surrounding sentences .",
        "word embeddings play a significant role in many modern nlp systems .",
        "however , most used word embedding learning methods learn one representation per word which is problematic for polysemous words and homonymous words .",
        "to address this problem , we propose a multi - phase word sense embedding retrofitting method which utilizes a lexical ontology to learn one embedding per word sense .",
        "experimental results on word similarity task show that our approach remarkablely improves the quality of embeddings .",
        "one - shot learning is usually tackled by using generative models or discriminative embeddings .",
        "the model can be conditioned on any vector , including descriptive labels or tags , or latent embeddings created by other networks .",
        "when conditioned on an embedding produced by a convolutional network given a single image of an unseen face , it generates a variety of new portraits of the same person with different facial expressions , poses and lighting conditions .",
        "in this work , we propose to learn sense embeddings for the wsi task .",
        "in the training stage , our method induces several sense centroids ( embedding ) for each polysemous word .",
        "in the testing stage , our method represents each instance as a contextual vector , and induces its sense by finding the nearest sense centroid in the embedding space .",
        "for each model , we investigate four implementations : a \" standard \" n - gram language model and three discriminatively trained \" neural \" language models that generate embeddings for semantic frames .",
        "universal schema predicts the types of entities and relations in a knowledge base ( kb ) by jointly embedding the union of all available schema types - - - not only types from multiple structured databases ( such as freebase or wikipedia infoboxes ) , but also types expressed as textual patterns from raw text .",
        "factorizing this sparsely observed matrix yields a learned vector embedding for each row and each column .",
        "in this paper we explore the problem of making predictions for entities or entity - pairs unseen at training time ( and hence without a pre - learned row embedding ) .",
        "it has been recently proposed that the cnl approach could be scaled up , building on the concept of embedded cnl and , thus , allowing for cnl - based information extraction from e .",
        "word embedding , specially with its recent developments , promises a quantification of the similarity between terms .",
        "we first observe and quantify the uncertainty factor of the word embedding models regarding to the similarity value .",
        "however , here we make use of complex valued embeddings .",
        "the composition of complex embeddings can handle a large variety of binary relations , among them symmetric and antisymmetric relations .",
        "compared to state - of - the - art models such as neural tensor network and holographic embeddings , our approach based on complex embeddings is arguably simpler , as it only uses the hermitian dot product , the complex counterpart of the standard dot product between real vectors .",
        "in this paper , we define a novel entity representation as a mixture of its neighborhood in the knowledge base and apply this technique on transe - a well - known embedding model for knowledge base completion .",
        "experimental results show that the neighborhood information significantly helps to improve the results of the transe , leading to better performance than obtained by other state - of - the - art embedding models on three benchmark datasets for triple classification , entity prediction and relation prediction tasks .",
        "we also examined the structure of the representation of tactile stimuli in the recorded tactile sensor data using t - sne embeddings .",
        "we investigate the integration of word embeddings as classification features in the setting of large scale text classification .",
        "in this work , we examine efficient composition functions to obtain document - level from word - level embeddings and we subsequently investigate their combination with the traditional one - hot - encoding representations .",
        "the new structure can be easily embedded into many popular rnn models , including lstms and grus .",
        "blstm ) or the augmentation with pre - trained word embeddings can be important and clearly impact the accuracy .",
        "recently , the rapid development of word embedding and neural networks has brought new inspiration to various nlp and ir tasks .",
        "the system uses a bayesian modelling framework with segmental word representations : each word segment is represented as a fixed - dimensional acoustic embedding obtained by mapping the sequence of feature frames to a single embedding vector .",
        "this paper presents preliminary works on using word embedding ( word2vec ) for query expansion in the context of personalized information retrieval .",
        "traditionally , word embeddings are learned on a general corpus , like wikipedia .",
        "in this work we try to personalize the word embeddings learning , by achieving the learning on the user ' s profile .",
        "the word embeddings are then in the same context than the user interests .",
        "the results obtained show that some efforts should be made in the way to apply word embedding in the context of personalized information retrieval .",
        "word embeddings and convolutional neural networks ( cnn ) have attracted extensive attention in various classification tasks for twitter , e .",
        "however , the effect of the configuration used to train and generate the word embeddings on the classification performance has not been studied in the existing literature .",
        "in this paper , using a twitter election classification task that aims to detect election - related tweets , we investigate the impact of the background dataset used to train the embedding models , the context window size and the dimensionality of word embeddings on the classification performance .",
        "by comparing the classification results of two word embedding models , which are trained using different background corpora ( e .",
        "moreover , by evaluating the results of word embeddings models trained using various context window sizes and dimensionalities , we found that large context window and dimension sizes are preferable to improve the performance .",
        "our experimental results also show that using word embeddings and cnn leads to statistically significant improvements over various baselines such as random , sv",
        "the goal of ordinal embedding is to represent items as points in a low - dimensional euclidean space given a set of constraints in the form of distance comparisons like \" item $ i $ is closer to item $ j $ than item $ k $ \" .",
        "first , we derive prediction error bounds for ordinal embedding with noise by exploiting the fact that the rank of a distance matrix of points in $ \\ mathbb { r } ^ d $ is at most $ d + 2 $ .",
        "these bounds characterize how well a learned embedding predicts new comparative judgments .",
        "third , knowledge of the noise model enables us to relate prediction errors to embedding accuracy .",
        "with this in mind , we argue that embedding kbs within deep neural architectures supporting documentquery matching would give rise to fine - grained latent representations of both words and their semantic relations .",
        "word embedding has been shown to be remarkably effective in a lot of natural language processing tasks .",
        "also it can be used as an evaluation measure of the quality of word embedding .",
        "we propose minimizing a joint objective which can learn from diverse data sources and leverage distributional semantic embeddings , enabling the model to generalize and describe novel objects outside of image - caption datasets .",
        "since its introduction , word2vec and its variants are widely used to learn semantics - preserving representations of words or entities in an embedding space , which can be used to produce state - of - art results for various natural language processing tasks .",
        "figment is embedding - based and combines ( i ) a global model that scores based on aggregated contextual information of an entity and ( ii ) a context model that first scores the individual occurrences of an entity and then aggregates the scores .",
        "an acoustic scene instance is then embedded into a low - dimensional feature representation which consists of the likelihoods that it belongs to the meta - classes .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "we also empirically study the use of generalised distillation , and a novel alternative model that directly predicts item embeddings .",
        "this paper combines insights from several previous link prediction models into a new embedding model stranse that represents each entity as a low - dimensional vector , and each relation by two matrices and a translation vector .",
        "stranse is a simple combination of the se and transe models , but it obtains better link prediction performance on two benchmark datasets than previous embedding models .",
        "in taja - seq2seq , information from input posts and information from topics related to the posts are simultaneously embedded into vector spaces by a content encoder and a topic encoder respectively .",
        "we map entity - tuple embeddings into an approximately boolean space and encourage a partial ordering over relation embeddings based on implication rules mined from wordnet .",
        "surprisingly , we find that the strong restriction of the entity - tuple embedding space does not hurt the expressiveness of the model and even acts as a regularizer that improves generalization .",
        "in these cases , one may want to embed additional prior knowledge into the optimization problem associated with the training of the learning machine , modeled , respectively , by the symmetry of its optimal solution with respect to an exchange of order between the two objects , and by its antisymmetry .",
        ", 2012 ) ( where the only symmetric case was considered ) , we show , focusing on support vector binary classification , how such embedding is possible through the choice of a suitable pairwise kernel , which takes as inputs the individual feature vectors and also the group feature vectors associated with the two objects .",
        "in this work , a novel binary embedding method , termed adaptive training quantization ( atq ) , is proposed to learn the ideal transform of random encoder , where the limitation of cosine random mapping is tackled .",
        "we also utilize convolution neural network ( cnn ) in cascade of rnn to get character - based embedded features and employ it with word - embedded features in our model .",
        "crosslingual word embeddings represent lexical items from different languages in the same vector space , enabling transfer of nlp tools .",
        "word embeddings have recently seen a strong increase in interest as a result of strong performance gains on a variety of tasks .",
        "in this paper we demonstrate the performance of multiple types of embeddings , created with both count and prediction - based architectures on a variety of corpora , in two language - specific tasks : relation evaluation , and dialect identification .",
        "with this research , we provide the embeddings themselves , the relation evaluation task benchmark for use in further research , and demonstrate how the benchmarked embeddings prove a useful unsupervised linguistic resource , effectively used in a downstream task .",
        "we constructed a method based on semantic word embeddings and frequency information to arrive at low - dimensional representations for short texts designed to capture semantic similarity .",
        "we find that our method outperforms the baseline approaches in the experiments , and that it generalizes well on different word embeddings without retraining .",
        "that is , the continuous vector representation , or a word embedding vector , of a symbol encodes multiple dimensions of similarity , equivalent to encoding more than one meaning of the word .",
        "based on this observation , in this paper we propose to contextualize the word embedding vectors using a nonlinear bag - of - words representation of the source sentence .",
        "we present charagram embeddings , a simple approach for learning character - based compositional models to embed textual sequences .",
        "a word or sentence is represented using a character n - gram count vector , followed by a single nonlinear transformation to yield a low - dimensional embedding .",
        "we demonstrate that charagram embeddings outperform more complex architectures based on character - level recurrent and convolutional neural networks , achieving new state - of - the - art performance on several similarity tasks .",
        "such a danger is facing us with word embedding , a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks .",
        "we show that even word embeddings trained on google news articles exhibit female / male gender stereotypes to a disturbing extent .",
        "geometrically , gender bias is first shown to be captured by a direction in the word embedding .",
        "second , gender neutral words are shown to be linearly separable from gender definition words in the word embedding .",
        "using these properties , we provide a methodology for modifying an embedding to remove gender stereotypes , such as the association between between the words receptionist and female , while maintaining desired associations such as between the words queen and female .",
        "we define metrics to quantify both direct and indirect gender biases in embeddings , and develop algorithms to \" debias \" the embedding .",
        "word embeddings are a powerful approach for capturing semantic similarity among terms in a vocabulary .",
        "in this paper , we develop exponential family embeddings , a class of methods that extends the idea of word embeddings to other types of high - dimensional data .",
        "each type of embedding model defines the context , the exponential family of conditional distributions , and how the latent embedding vectors are shared across data .",
        "we infer the embeddings with a scalable algorithm based on stochastic gradient descent .",
        "on all three applications - neural activity of zebrafish , users ' shopping behavior , and movie ratings - we found exponential family embedding models to be more effective than other types of dimension",
        "word embeddings allow natural language processing systems to share statistical information across related words .",
        "these embeddings are typically based on distributional statistics , making it difficult for them to generalize to rare or unseen words .",
        "we propose to improve word embeddings by incorporating morphological information , capturing shared sub - word features .",
        "unlike previous work that constructs word embeddings directly from morphemes , we combine morphological and distributional information in a unified probabilistic framework , in which the word embedding is a latent variable .",
        "the morphological information provides a prior distribution on the latent word embeddings , which in turn condition a likelihood function over an observed corpus .",
        "the parsing procedure for each direction is formulated as sequentially querying the memory component that stores continuous headword embeddings .",
        "the proposed parser makes use of soft headword embeddings , allowing the model to implicitly capture high - order parsing history without dramatically increasing the computational complexity .",
        "the analysis sheds light on the relative strengths of different sentence embedding methods with respect to these low level prediction tasks , and on the effect of the encoded vector ' s dimensionality on the resulting representations .",
        "by applying our method on well known chaotic systems , we provide evidence that the lower dimensional embedding retains the dynamical properties of the underlying system better than the full - dimensional internal states of the network .",
        "while cross - lingual word embeddings have been studied extensively in recent years , the qualitative differences between the different algorithms remains vague .",
        "this feature set is also used by traditional alignment algorithms , such as ibm model - 1 , which demonstrate similar performance to state - of - the - art embedding algorithms on a variety of benchmarks .",
        "this paper draws both empirical and theoretical parallels between the embedding and alignment literature , and suggests that adding additional sources of information , which go beyond the traditional signal of bilingual sentence - aligned corpora , is an appealing approach for substantially improving crosslingual word embeddings .",
        "recent work has demonstrated that state - of - the - art word embedding models require different context types to produce high - quality representations for different word classes such as adjectives ( a ) , verbs ( v ) , and nouns ( n ) .",
        "we replicate these using a widely used , purely statistical machine - learning model - - - namely , the glove word embedding - - - trained on a corpus of text from the web .",
        "in this short paper , we propose the split - diffuse ( sd ) algorithm that takes the output of an existing word embedding algorithm , and distributes the data points uniformly across the visualization space .",
        "knowledge representation is a critical topic in ai , and currently embedding as a key branch of knowledge representation takes the numerical form of entities and relations to joint the statistical models .",
        "however , most embedding methods merely concentrate on the triple fitting and ignore the explicit semantic expression , leading to an uninterpretable representation form .",
        "thus , traditional embedding methods do not only degrade the performance , but also restrict many potential applications .",
        "we evaluated this metric in a similarity estimation task on several popular test sets , and our results show that apsyn is in fact highly competitive , even with respect to the results reported in the literature for word embeddings .",
        "in this paper we propose the application of feature hashing to create word embeddings for natural language processing .",
        "in this work we show that feature hashing can be applied to obtain word embeddings in linear time with the size of the data .",
        "as far as we know this is the first application of feature hashing to the word embeddings problem and the results indicate this is a scalable technique with practical results for nlp applications .",
        "in this paper we extend these methods by embedding a measure of semantic similarity based on a human curated taxonomy into a second - - order vector representation .",
        "our results show that embedding semantic semantic similarity into a second order co - - occurrence matrix improves correlation with human judgments for both similarity and relatedness .",
        "though , they also carry along with some attendant problems , such as corpus selection for embedding learning , dictionary transformation for different learning tasks , etc .",
        "in this paper , we propose to straightforwardly model sentences by means of character sequences , and then utilize convolutional neural networks to integrate character embedding learning together with point - wise answer selection training .",
        "compared with deep models pre - trained on word embedding ( we ) strategy , our character - sequential representation ( csr ) based method shows a much simpler procedure and more stable performance across different benchmarks .",
        "we thus provide a unified formulation for two main language processing tasks , namely word embedding and language modeling , based on the neg objective function .",
        "recently , stochastic neighbor embedding ( sne ) methods have widely been applied in data visualization .",
        "furthermore , we show empirically and theoretically that the doubly stochasticity constraint often leads to approximately spherical embeddings .",
        "this suggests replacing a flat space with spheres as the embedding space .",
        "the spherical embedding eliminates the discrepancy between the center and the periphery in visualization and thus resolves the \" crowding problem \" .",
        "within evolutionary processes , the implicit utility function is always reducible to persistence , and the control of superhuman intelligences embedded in evolutionary processes is not possible .",
        "we achieve competitive results for two - point scale sentiment classification and quantification , ranking fifth and a close fourth ( third and second by alternative metrics ) respectively despite using only pre - trained embeddings that contain no sentiment information .",
        "to determine the sentiment towards an aspect , we concatenate an aspect vector with every word embedding and apply a convolution over it .",
        "to accurately capture the fine grained nonlinear coevolution of these features , we propose a recurrent coevolutionary feature embedding process model , which combines recurrent neural network ( rnn ) with a multidimensional point process model .",
        "we compare policy differences across institutions by embedding representations of the entire legal corpus of each institution and the vocabulary shared across all corpora into a continuous vector space .",
        "note our general inference framework can readily be applied to other topic models with embedded pdp nodes .",
        "the proposed network , redundant convolutional encoder decoder ( r - ced ) , demonstrates that a convolutional network can be 12 times smaller than a recurrent network and yet achieves better performance , which shows its applicability for an embedded system : the hearing aids .",
        "the derivative delay embedding ( dde ) is developed to incrementally transform time series to the embedding space , where the intrinsic characteristics of data is preserved as recursive patterns regardless of the stream length and misalignment .",
        "given a sequence of characters , our model embeds each character in vector space , runs the sequence through multiple convolutions with different filter widths , and pools the convolutional representations to obtain a hidden vector representation of the text that is used for predicting the language or dialect .",
        "as such , the word - lattice based encoders not only alleviate the negative impact of tokenization errors but also are more expressive and flexible to embed input sentences .",
        "thanks to its high degree of structure , our architecture has a very small memory footprint and thus fits onto low - power embedded and mobile platforms .",
        "non - linear models recently receive a lot of attention as people are starting to discover the power of statistical and embedding features .",
        "a common model for question answering ( qa ) is that a good answer is one that is closely related to the question , where relatedness is often determined using general - purpose lexical models such as word embeddings .",
        "we argue that a better approach is to look for answers that are related to the question in a relevant way , according to the information need of the question , which may be determined through task - specific embeddings .",
        "first , we generate causal embeddings cost - effectively by bootstrapping cause - effect pairs extracted from free text using a small set of seed patterns .",
        "second , we train dedicated embeddings over this data , by using task - specific contexts , i .",
        "finally , we extend a state - of - the - art reranking approach for qa to incorporate these causal embeddings .",
        "we evaluate the causal embedding models both directly with a casual implication task , and indirectly , in a downstream causal qa task using data from yahoo !",
        "omvfs embeds unsupervised feature selection into a",
        "many current natural language processing applications for social media rely on representation learning and utilize pre - trained word embeddings .",
        "there currently exist several publicly - available , pre - trained sets of word embeddings , but they contain few or no emoji representations even as emoji usage in social media has increased .",
        "in this paper we release emoji2vec , pre - trained embeddings for all unicode emoji which are learned from their description in the unicode emoji standard .",
        "the resulting emoji embeddings can be readily used in downstream social natural language processing applications alongside word2vec .",
        "we demonstrate , for the downstream task of sentiment analysis , that emoji embeddings learned from short descriptions outperforms a skip - gram model trained on a large collection of tweets , while avoiding the need for contexts in which emoji need to appear frequently in order to estimate a representation .",
        "based on recent results in word embeddings that learn se - mantically representations for words from a large corpus , we introduce a novel method , embedding - based topic model ( etm ) , to learn latent topics from short texts .",
        "in this paper we experiment with context and embedding - based selection methods and extend previous work by examining speed and accuracy trade - offs in more detail .",
        "the purpose of this paper is demonstrating that their vector representation based on word embedding provides insights onto many linguistic phenomena , and in particular about verbs undergoing the causative - inchoative alternation .",
        "in this paper , we develop a chinese event extraction system that uses word embedding vectors to represent language , and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering .",
        "our experiments show that our proposed method performs better compared to the system using rich language features , and using unlabeled data benefits the word embeddings .",
        "this study suggests the potential of dnn and word embedding for the event extraction task .",
        "we explore if prior work can be enhanced using semantic similarity / discordance between word embeddings .",
        "we augment word embedding - based features to four feature sets reported in the past .",
        "we also experiment with four types of word embeddings .",
        "we observe an improvement in sarcasm detection , irrespective of the word embedding used or the original feature set to which our features are augmented .",
        "for example , this augmentation results in an improvement in f - score of around 4 \\ % for three out of these four feature sets , and a minor degradation in case of the fourth , when word2vec embeddings are used .",
        "finally , a comparison of the four embeddings shows that word2vec and dependency weight - based features outperform lsa and glove , in terms of their benefit to sarcasm detection .",
        "word embeddings have been extensively studied in large text datasets .",
        "moreover , we show how to inject pre - trained word embeddings into our model in order to improve generalization across examples with similar pivot features .",
        "word embeddings have been demonstrated to benefit nlp tasks impressively .",
        "yet , there is room for improvement in the vector representations , because current word embeddings typically contain unnecessary information , i .",
        "we propose two novel models to improve word embeddings by unsupervised learning , in order to yield word denoising embeddings .",
        "the word denoising embeddings are obtained by strengthening salient information and weakening noise in the original word embeddings , based on a deep feed - forward neural network filter .",
        "results from benchmark tasks show that the filtered word denoising embeddings outperform the original word embeddings .",
        "we propose three data representation techniques based on the characteristics of word distribution and word similarities as a result of word embedding training .",
        "for this , we present several network visualizations based on activation clusters , first derivative saliency , and embedding space transformations , helping us automatically identify several subtle linguistics markers of politeness theories .",
        "these are merged with the word embedding or with a sentence embedding of the question to predict the answer .",
        "applying dropout on the dynamic filters can be seen as drop on words directly , which is superior to the regular dropout on word embeddings .",
        "this paper investigates the problem of network embedding , which aims at learning low - dimensional vector representation of nodes in networks .",
        "most existing network embedding methods rely solely on the network structure , i .",
        "in this paper , we propose content - enhanced network embedding ( cene ) , which is capable of jointly leveraging the network structure and the content information .",
        "experiments on several real world net - works with application to node classification show that our models outperform all existing network embedding methods , demonstrating the merits of content information and joint learning .",
        "evaluation results demonstrate that our model outperforms sequence to sequence , attention - based and bi - directional lstm models on bleu , meteor , ter and an embedding - based sentence similarity metric .",
        "in this work we implement a training of a language model ( lm ) , using recurrent neural network ( rnn ) and glove word embeddings , introduced by pennigton et al .",
        "such approaches are time - and memory - intensive because of the large numbers of parameters for word embeddings and the output layer .",
        "we propose an embedding - enhanced texttiling approach , inspired by the observation that conversation utterances are highly noisy , and that word embeddings provide a robust way of capturing semantics .",
        "the proposed method can also be implemented on any other embedded microcontroller system .",
        "the dependence measure is the difference between analytic embeddings of the joint distribution and the product of the marginals , evaluated at a finite set of locations ( features ) .",
        "in this work we introduce vrpbench , a tool to create instances and visualize solutions to the vehicle routing problem ( vrp ) in a planar graph embedded in the euclidean 2d space .",
        "our models include bag - of - words features ( bow ) , syntactic tree kernels ( tks ) , rank features , embeddings , and machine translation evaluation features .",
        ", recommender systems , topic modeling and word embedding .",
        "for this reason , this paper employs bidirectional lstm with crf decoding initialized with general purpose off - the - shelf word embeddings for ce .",
        "with the advent of word embeddings , lexicons are no longer fully utilized for sentiment analysis although they still provide important features in the traditional setting .",
        "this paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into convolutional neural networks .",
        "our approach performs separate convolutions for word and lexicon embeddings and provides a global view of the document using attention .",
        "our analysis shows that lexicon embeddings allow to build high - performing models with much smaller word embeddings , and the attention mechanism effectively dims out noisy words for sentiment analysis .",
        "secondly , by qualitatively studying attention plots from the decoder we find that the model learns to compress common words into a single embedding whereas rare words , such as names and places , are represented character by character .",
        "we demonstrate that such a network generalizes across a diversity of artistic styles by reducing a painting to a point in an embedding space .",
        "in the first part we discuss word embeddings .",
        "we also compare them to image embeddings and see how word embedding and image embedding can be combined to perform different tasks .",
        "the network is used for several sentence - level classification tasks , and achieves state - of - art ( or comparable ) results , demonstrating the great power of pre - trainted word embeddings over random ones .",
        "in this paper , we employ knowledge - based approaches that also exploit recent advances in neural word / concept embeddings to improve over the state - of - the - art in biomedical wsd using the msh wsd dataset as the test set .",
        "this paper investigates the use of word embeddings to help identify gang members on twitter .",
        "building on our previous work , we generate word embeddings that translate what twitter users post in their profile descriptions , tweets , profile images , and linked youtube content to a real vector format amenable for machine learning classification .",
        "our experimental results show that pre - trained word embeddings can boost the accuracy of supervised learning algorithms trained over gang members social media posts .",
        "existing deep embedding methods in vision tasks are capable of learning a compact euclidean space from images , where euclidean distances correspond to a similarity metric .",
        "the metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner .",
        "our local similarity - aware feature embedding not only demonstrates faster convergence and boosted performance on two complex image retrieval datasets , its large margin nature also leads to superior generalization results under the large and open set scenarios of transfer learning and zero - shot learning on imagenet 2010 and",
        "we first explore the embedding space and show that our vectors capture meaningful construction - specific concepts .",
        "without any parameter tuning , our embeddings give competitive results , and outperform the google news vectors in many cases .",
        "although similarity search in hins has been studied previously , most existing approaches neither explore rich semantic information embedded in the network structures nor take user ' s preference as a guidance .",
        "the key idea is to use 2 - component ( 2c ) shared embedding for word representations .",
        "based on the 2 - component shared embedding ,",
        "most of the existing graph embedding methods focus on nodes , which aim to output a vector representation for each node in the graph such that two nodes being \" close \" on the graph are close too in the low - dimensional space .",
        "despite the success of embedding individual nodes for graph analytics , we notice that an important concept of embedding communities ( i .",
        "embedding communities is useful , not only for supporting various community - level applications , but also to help preserve community structure in graph embedding .",
        "in fact , we see community embedding as providing a higher - order proximity to define the node closeness , whereas most of the popular graph embedding methods focus on first - order and / or second - order proximities .",
        "to learn the community embedding , we hinge upon the insight that community embedding and node embedding reinforce with each other .",
        "as a result , we propose comembed , the first community embedding method , which jointly optimizes the community embedding and node embedding together .",
        "we evaluate comembed on real - world data sets .",
        "to address this problem , we propose to learn sentiment - specific word embedding by exploiting both lexicon resource and distant supervised information .",
        "we develop a multi - level sentiment - enriched word embedding learning method , which uses parallel asymmetric neural network to model n - gram , word level sentiment and tweet level sentiment in learning process .",
        "in practice , the current deep embedding methods use the euclidean distance for the training and test .",
        "intra - class ) training samples within a local range is critical for training the cnn embedding , especially when the data has large intra - class variations .",
        "in this paper , we propose a product - based neural networks ( pnn ) with an embedding layer to learn a distributed representation of the categorical data , a product layer to capture interactive patterns between inter - field categories , and further fully connected layers to explore high - order feature interactions .",
        "we introduce a multiple input deep regression model to predict the cf latent embedding vectors of items based on their textual description and metadata .",
        "then we propose an efficient method to use the fuzzy paraphrases to learn word embeddings .",
        "we approximately estimate the local membership of paraphrases , and train word embeddings using a lexicon jointly by replacing the words in the contexts with their paraphrases randomly subject to the membership of each paraphrase .",
        "this criterion is based on a deep metric embedding over distance relations within the set of labeled samples , together with constraints over the embeddings of the unlabeled set .",
        "we propose a language - agnostic way of automatically generating sets of semantically similar clusters of entities along with sets of \" outlier \" elements , which may then be used to perform an intrinsic evaluation of word embeddings in the outlier detection task .",
        "we used our methodology to create a gold - standard dataset , which we call wikisem500 , and evaluated multiple state - of - the - art embeddings .",
        "ltls embeds large classification problems into simple structured prediction problems and relies on efficient dynamic programming algorithms for inference .",
        "however , dnn - based methods are both computational - intensive and resource - consuming , which hinders the application of these methods on embedded systems like smart phones .",
        "with machine learning penetrating low - power mobile and embedded areas , the need to optimize not only for performance ( accuracy ) , but also for implementation complexity , becomes paramount .",
        "dscnn hierarchically builds textual representations by processing pretrained word embeddings via long short - term memory networks and subsequently extracting features with convolution operators .",
        "acoustic word embeddings - - - fixed - dimensional vector representations of variable - length spoken word segments - - - have begun to be considered for tasks such as speech recognition and query - by - example search .",
        "such embeddings can be learned discriminatively so that they are similar for speech segments corresponding to the same word , while being dissimilar for segments corresponding to different words .",
        "recent work has found that acoustic word embeddings can outperform dynamic time warping on query - by - example search and related word discrimination tasks .",
        "however , the space of embedding models and training approaches is still relatively unexplored .",
        "in this paper we present new discriminative embedding models based on recurrent neural networks ( rnns ) .",
        "we find that both classifier - based and siamese rnn embeddings improve over previously reported results on a word discrimination task , with siamese rnns outperforming classification models .",
        "embedding and visualizing large - scale high - dimensional data in a two - dimensional space is an important problem since such visualization can reveal deep insights out of complex data .",
        "most of the existing embedding approaches , however , run on an excessively high precision , ignoring the fact that at the end , embedding outputs are converted into coarse - grained discrete pixel coordinates in a screen space .",
        "motivated by such an observation and directly considering pixel coordinates in an embedding optimization process , we accelerate barnes - hut tree - based t - distributed stochastic neighbor embedding ( bh - sne ) , known as a state - of - the - art 2d embedding method , and propose a novel method called pixelsne , a highly - efficient , screen resolution - driven 2d embedding method with a linear computational complexity in terms of the number of data items .",
        "our experimental results show the significantly fast running time of pixelsne by a large margin against bh - sne , while maintaining the minimal degradation in the embedding quality .",
        "the empirical evaluation was done using fully implemented translation systems embedded into the mapreduce programming model .",
        "word embeddings are now ubiquitous forms of word representation in natural language processing .",
        "there have been applications of word embeddings for monolingual word sense disambiguation ( wsd ) in english , but few comparisons have been done .",
        "this paper attempts to bridge that gap by examining popular embeddings for the task of monolingual english wsd .",
        "thus we have also applied word embeddings to the novel task of cross - lingual wsd for chinese and provide a public dataset for further benchmarking .",
        "we have also experimented with using word embeddings for lstm networks and found surprisingly that a basic lstm network does not work well .",
        "this position paper advocates a communications - inspired approach to the design of machine learning systems on energy - constrained embedded ` always - on ' platforms .",
        "many recent works have demonstrated the benefits of knowledge graph embeddings in completing monolingual knowledge graphs .",
        "thus , we propose mtranse , a translation - based model for multilingual knowledge graph embeddings , to provide a simple and automated solution .",
        "by encoding entities and relations of each language in a separated embedding space , mtranse provides transitions for each embedding vector to its cross - lingual counterparts in other spaces , while preserving the functionalities of monolingual embeddings .",
        "in this work , we propose a novel framework to embed words , entities and relations into the same continuous vector space .",
        "in this model , both entity and relation embeddings are learned by taking knowledge graph and plain text into consideration .",
        "the constraints guide us to learn knowledge enhanced embeddings ( kee ) from large text corpus .",
        "sequence labeling architectures use word embeddings for capturing similarity , but suffer when handling previously unseen or rare words .",
        "we first present an embedding - based question - to - expert distance metric for expertise matching and propose a ranking factor graph ( rankfg ) model to predict expert response .",
        "recent work has begun exploring neural acoustic word embeddings - - fixed - dimensional vector representations of arbitrary - length speech segments corresponding to words .",
        "such embeddings are applicable to speech retrieval and recognition tasks , where reasoning about whole words may make it possible to avoid ambiguous sub - word representations .",
        "in this work we take a multi - view approach to learning acoustic word embeddings , in which we jointly learn to embed acoustic sequences and their corresponding character sequences .",
        "we use deep bidirectional lstm embedding models and multi - view contrastive losses .",
        "our acoustic word embeddings improve over previous approaches for the task of word discrimination .",
        ", no parallel corpora ) using multimodal embedded representation over texts and images .",
        "recent studies on knowledge base completion , the task of recovering missing relationships based on recorded relations , demonstrate the importance of learning embeddings from multi - step relations .",
        "for similarity computation at a finer granularity , we tune the alignment algorithm by integrating it with a word embedding matrix based topic - to - topic similarity measure .",
        "we consider an erdos - renyi graph with $ n $ nodes and edge probability $ q $ that is embedded with a random subgraph of size $ k $ with edge probabilities $ p $ such that $ p & gt ; q $ .",
        "our work presented here constitutes the first step in opening the black - box of vector embedding for social media posts , with emphasis on tweets in particular .",
        "experiments show that the performance of cdcl solvers can be significantly boosted by embedding domain - specific heuristics , especially on large real - world problems .",
        "to address this challenge , a number of knowledge graph completion methods have been developed using low - dimensional graph embeddings .",
        "in this work , we present a shared variable neural network model called proje that fills - in missing information in a knowledge graph by learning joint embeddings of the knowledge graph ' s entities and edges , and through subtle , but important , changes to the standard loss function .",
        "we propose and evaluate several strategies for achieving zero - shot vqa , including methods based on pretrained word embeddings , object classifiers with semantic embeddings , and test - time retrieval of example images .",
        "neural network based models are a very powerful tool for creating word embeddings , the objective of these models is to group similar words together .",
        "these embeddings have been used as features to improve results in various applications such as document classification , named entity recognition , etc .",
        "each text will alter the embeddings of the words to represent the meaning of the word inside that text .",
        "more specifically , we learn a semantic embedding ( v ) corresponding to each frame ( k ) in the video , thereby creating ( k , v ) memory slots .",
        "exploiting this flexibility of the framework , we additionally capture spatial dependencies while mapping from the visual to semantic embedding .",
        "concerning inference on embedded systems we evaluate these bitwise networks using a hardware efficient stochastic rounding procedure .",
        "our work contributes to efficient embedded bitwise neural networks .",
        "however , paragraph ( or sentence and document ) embedding learning is more suitable / reasonable for some tasks , such as sentiment classification and document summarization .",
        "nevertheless , as far as we are aware , there is relatively less work focusing on the development of unsupervised paragraph embedding methods .",
        "classic paragraph embedding methods infer the representation of a given paragraph by considering all of the words occurring in the paragraph .",
        "consequently , those stop or function words that occur frequently may mislead the embedding learning process to produce a misty paragraph representation .",
        "first , we propose a novel unsupervised paragraph embedding method , named the essence vector ( ev ) model , which aims at not only distilling the most representative information from a paragraph but also excluding the general background information to produce a more informative low - dimensional vector representation for the paragraph .",
        "in this paper , we study the problem of how to better embed entities and relations into different low dimensional spaces .",
        "a compositional learning model of relation paths embedding ( rpe ) is proposed to take full advantage of additional semantic information expressed by relation paths .",
        "more specifically , using corresponding projection matrices , rpe can simultaneously embed entities into corresponding relation and path spaces .",
        "to this end , we instantiate two policy gradient based algorithms , one that creates an explicit embedding space of options and one that represents options implicitly .",
        "to alleviate these challenges , we propose a novel framework named hnil which encodes not only the question contents but also the askers social interactions to enhance the question embedding performance .",
        "in this paper , we focus on training and evaluating effective word embeddings with both text and visual information .",
        "in addition , we construct an evaluation dataset to directly assess the effectiveness of word embeddings in terms of finding semantically similar or related words and phrases .",
        "experiments show that our model benefits from incorporating the visual information into the word embeddings , and a weight sharing strategy is crucial for learning such multimodal embeddings .",
        "random embedding has been applied with empirical success to large - scale black - box optimization problems with low effective dimensions .",
        "this paper proposes the embeddedhunter algorithm , which incorporates the technique in a hierarchical stochastic bandit setting , following the optimism in the face of uncertainty principle and breaking away from the multiple - run framework in which random embedding has been conventionally applied similar to stochastic black - box optimization solvers .",
        "in essence , the embeddedhunter algorithm expands optimistically a partitioning tree over a low - dimensional - - - equal to the effective dimension of the problem - - - search space based on a bounded number of random embeddings of sampled points from the low - dimensional space .",
        "in contrast to the probabilistic theoretical guarantees of multiple - run random - embedding algorithms , the finite - time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm ' s number of iterations .",
        "we propose a novel deep learning framework for single channel speech separation by creating attractor points in high dimensional embedding space of the acoustic signals which pull together the time - frequency bins corresponding to each source .",
        "attractor points in this study are created by finding the centroids of the sources in the embedding space , which are subsequently used to determine the similarity of each bin in the mixture to each source .",
        "the network is then trained to minimize the reconstruction error of each source by optimizing the embeddings .",
        "the model is trained on a visual search task requiring the classification of an object embedded in a visual scene amidst background distractors using the smallest number of fixations .",
        "the key insight is to connect compositionality to a curious geometric property of word embeddings , which is of independent interest .",
        "with this reinforced random walk as a general process embedded in classical topic models , we obtain \\ textit { diverse topic models } that are able to extract the most prominent and diverse topics from data .",
        "we demonstrate an improved method for building conditional models , the co - embedding deep variational auto encoder .",
        "in this paper , we study whether it is possible to utilize distributed representations to generate dictionary definitions of words , as a more direct and transparent representation of the embeddings ' semantics .",
        "we introduce definition modeling , the task of generating a definition for a given word and its embedding .",
        "our results show that a model that controls dependencies between the word being defined and the definition words performs significantly better , and that a character - level convolution layer designed to leverage morphology can complement word - level embeddings .",
        "finally , an error analysis suggests that the errors made by a definition model may provide insight into the shortcomings of word embeddings .",
        "proposing a convolutional document embedding approach , our empirical investigation using the mimic - iii intensive care database shows significant performance gains compared to previously employed methods such as latent topic distributions or generic doc2vec embeddings .",
        "in addition the learned features outperform standard embedding approaches in a classification task .",
        "our approach first leverages on word2vec framework to embed icd codes into vector - valued representation .",
        "we present here a new version of the linked open data resource conceptnet that is particularly well suited to be used with modern nlp techniques such as word embeddings .",
        "on a zc706 embedded fpga platform drawing less than 25 w total system power , we demonstrate up to 12 .",
        "previous researches have shown that learning multiple representations for polysemous words can improve the performance of word embeddings on many tasks .",
        "with the consideration of the detected pseudo multi - sense cases , we try to refine the existing word embeddings to eliminate the influence of pseudo multi - sense .",
        "moreover , we apply our algorithm on previous released multi - sense word embeddings and tested it on artificial word similarity tasks and the analogy task .",
        "in this paper , we implicitly incorporate morpheme information into word embedding .",
        "rather , the externally stored embedding vectors are used at each time - step , but no messages are passed from previous time - steps .",
        "however , these paths are extremely numerous ( one per embedding vector in memory ) and reused for a very long time ( until it leaves the memory ) .",
        "this paper examines bypassing such an explicit representation by depending on a latent neural embedding of state and learning selective attention to dialogue history together with copying to incorporate relevant prior context .",
        "the second sub - system is a character - level rnn language model using embeddings learned from a convolutional neural network .",
        "since the acoustic and text query embeddings occupy different representation spaces , they are input to a third feed - forward neural network that predicts whether the query occurs in the acoustic utterance or not .",
        "a network embedding is a representation of a large graph in a low - dimensional space , where vertices are modeled as vectors .",
        "the objective of a good embedding is to preserve the proximity between vertices in the original graph .",
        "this way , typical search and mining methods can be applied in the embedded space with the help of off - the - shelf multidimensional indexing approaches .",
        "existing network embedding techniques focus on homogeneous networks , where all vertices are considered to belong to a single class .",
        "we address a problem of optimization on product of embedded submanifolds of convolution kernels ( pems ) in convolutional neural networks ( cnns ) .",
        "we present a detailed case study with a complex input format , namely pdf , and a large complex security - critical parser for this format , namely , the pdf parser embedded in microsoft ' s new edge browser .",
        "all three models utilize word and position embedding as latent features and thus do not rely on feature engineering .",
        ", the fiedler vector has the smallest non - zero eigenvalue and is key for laplacian embedding and graph clustering .",
        "we also establish a link with classical laplacian embedding and graph clustering , for which the graph slepian design can serve as a generalization .",
        "we use some of the largest order statistics of the random projections of a reference signal to construct a binary embedding that is adapted to signals correlated with such signal .",
        "the embedding is characterized from the analytical standpoint and shown to provide improved performance on tasks such as classification in a reduced - dimensionality space .",
        "it is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re - use for new tasks .",
        "several novel and recent approaches have also embedded control policy with efficient perceptual representation using deep learning .",
        "in previous work we showed for the first time that it is possible to map this application to power constrained embedded systems , highlighting that decision choices made at the algorithmic design - level have the most impact .",
        "attention networks have proven to be an effective approach for embedding categorical inference within a deep neural network .",
        "we propose a novel discriminative model that learns embeddings from multilingual and multi - modal data , meaning that our model can take advantage of images and descriptions in multiple languages to improve embedding quality .",
        "we evaluate our embeddings on an image - sentence ranking ( isr ) , a semantic textual similarity ( sts ) , and a neural machine translation ( nmt ) task .",
        "we introduce syntactic information in the form of ccg supertags either in the source as an extra feature in the embedding , or in the target , by interleaving the target supertags with the word sequence .",
        "surprisingly , this fact is not well reflected in the way embeddings are evaluated .",
        "in addition , recent practice in word embeddings points towards importance of learning specialized representations .",
        "in the aspect of methodological novelty , the proposed method uses a representation learning strategy to embed each document in a low dimensional vector space where name disambiguation",
        "this paper proposes to use distributed representation of words ( word embeddings ) in cross - language textual similarity detection .",
        "the idea is to embed textual structures into a semantic space of concepts which captures the main topics of these structures .",
        "in this paper we propose two neural embedding models in order to learn continuous concept vectors .",
        "empirical results on a benchmark dataset for measuring entity semantic relatedness show superior performance over other concept embedding models .",
        "using deep learning for different machine learning tasks such as image classification and word embedding has recently gained many attentions .",
        "word embedding is the task of mapping words or phrases to a low dimensional numerical vector .",
        "in this paper , we use deep learning to embed wikipedia concepts and entities .",
        "contrary to word embedding , wikipedia concepts embedding is not ambiguous , so there are different vectors for concepts with similar surface form but different mentions .",
        "showed they can also be found \" offline \" , whereby two pre - trained embeddings are aligned with a linear transformation , using dictionaries compiled from expert knowledge .",
        "in this paper , we present a novel reordering approach utilizing a neural network and dependency - based embeddings to predict whether the translations of two source words linked by a dependency relation should remain in the same order or should be swapped in the translated sentence .",
        "while kleinberg ' s axioms have been discussed heavily in the past , we concentrate here on the case predominantly relevant for $ k $ - means algorithm , that is behavior embedded in euclidean space .",
        "to do so , we leverage an emulator platform we developed , that embeds the tensorflow code into linux containers .",
        "we also proved that the necessary and sufficient dimensionality of the word vector embedding space is exactly the number of document classes .",
        "we show the equivalence of two state - of - the - art link prediction / knowledge graph completion methods : nickel et al ' s holographic embedding and trouillon et ~ al . '",
        "s complex embedding .",
        "we first consider a spectral version of the holographic embedding , exploiting the frequency domain in the fourier transform for efficient computation .",
        "the analysis of the resulting method reveals that it can be viewed as an instance of the complex embedding with certain constraints cast on the initial vectors upon training .",
        "conversely , any complex embedding can be converted to an equivalent holographic embedding .",
        "this type of word - to - vector embedding is able to keep , in the learned vector space , some of the syntactic and semantic relationships present in the original word corpus .",
        "neural networks have been successfully applied to this problem , and in this paper , we propose an attention - based deep neural network which better incorporates different embeddings of the queries and search results with an attention - based mechanism .",
        "the embeddings are trained with convolutional neural networks or the word2vec model .",
        "second , paraphrases of logical forms and questions are embedded in a jointly learned vector space using word and character convolutional neural networks .",
        "we present an unsupervised explainable word embedding technique , called eve , which is built upon the structure of wikipedia .",
        "to test the effectiveness of the proposed word embedding model , we consider its usefulness in three fundamental tasks : 1 ) intruder detection - to evaluate its ability to identify a non - coherent vector from a list of coherent vectors , 2 ) ability to cluster - to evaluate its tendency to group related vectors together while keeping unrelated vectors in separate clusters , and 3 ) sorting relevant items first - to evaluate its ability to rank vectors ( items ) relevant to the query in the top order of the result .",
        "these demonstrate the overall effectiveness of the explainable embeddings generated by eve .",
        "finally , we compare eve with the word2vec , fasttext , and glove embedding techniques across the three tasks , and report improvements over the state - of",
        "vector representations , word embeddings and topic embeddings , map words and topics into a low - dimensional and dense real - value vector space , which have obtained high performance in nlp tasks .",
        "hence vmfmix is used to derive topic embeddings , i .",
        ", representative vectors , from multiple sets of embedding vectors .",
        "recently , there was a paradigm shift towards using word embeddings and deep neural networks , where the use of surface features is very limited .",
        "representation learning of knowledge graphs encodes entities and relation types into a continuous low - dimensional vector space , learns embeddings of entities and relation types .",
        "all entries of the embeddings of relation types are constrained to be non - negative .",
        "it indicates that our model is capable of capturing the transitivity and antisymmetry information , which is significant when learning embeddings of knowledge graphs .",
        "the model represents words and contexts by latent trajectories in an embedding space .",
        "at each moment in time , the embedding vectors are inferred from a probabilistic version of word2vec [ mikolov , 2013 ] .",
        "these embedding vectors are connected in time through a latent diffusion process .",
        "experimental results on three different corpora demonstrate that our dynamic model infers word embedding trajectories that are more interpretable and lead to higher predictive likelihoods than competing methods that are based on static models trained separately on time slices .",
        "our ipms are based on matching statistics of distributions embedded in a finite dimensional feature space .",
        "in this paper we propose the expose neural network , which uses a deep learning approach we have developed to take generic , raw short character strings as input ( a common case for security inputs , which include artifacts like potentially malicious urls , file paths , named pipes , named mutexes , and registry keys ) , and learns to simultaneously extract features and classify using character - level embeddings and convolutional neural network .",
        "scattertext also lends itself to a query - based visualization of how the use of terms with similar embeddings differs between document categories , as well as a visualization for comparing the importance scores of bag - of - words features to univariate metrics .",
        "this paper develops a model that addresses syntactic embedding for machine comprehension , a key task of natural language understanding .",
        "our proposed model , structural embedding of syntactic trees ( sest ) , takes each word in a sentence , constructs a sequence of syntactic nodes extracted from syntactic parse trees , and encodes the sequence into a vector representation .",
        ", for a known algorithm and approximate embedding bit rate ) .",
        "we also present a completeset of experiments using 1 ) eight different image databases , 2 ) image features based on richmodels , and 3 ) three different embedding algorithms : least significant bit ( lsb ) matching , highly undetectable steganography ( hugo ) and wavelet obtained weights ( wow ) .",
        "at the same time , the proposed approach bypasses theproblem of cover source mismatch - when the embedding algorithm and bit rate are known - , since it removes the need of a training database when we have a large enough testing set .",
        "in addition to the main dataset , we open up several derived datasets including mention entity co - occurrence counts and entity embeddings , as well as mappings between freebase ids and wikidata item ids .",
        "here we show that seemingly minor choices made on ( 1 ) the use of pre - trained word embeddings , and ( 2 ) the representation of out - of - vocabulary tokens at test time , can turn out to have a larger impact than architectural choices on the final performance .",
        "while existing works have explored incorporating visual cues into language embeddings , the task of learning word representations that respect auditory grounding remains under - explored .",
        "in this work , we propose a new embedding scheme , sound - word2vec that learns language embeddings by grounding them in sound - - for example , two seemingly unrelated concepts , leaves and paper are closer in our embedding space as they produce similar rustling sounds .",
        "we demonstrate that the proposed embeddings perform better than language - only word representations , on two purely textual tasks that require reasoning about aural cues - - sound retrieval and foley - sound discovery .",
        "finally , we analyze nearest neighbors to highlight the unique dependencies captured by sound - w2v as compared to language - only embeddings .",
        "we demonstrate the significant practical superiority of our approach over traditional als ( with both random initialization and svd - based initialization ) for a variety of tasks on synthetic data - including tensor factorization on exact , noisy and over - complete tensors , as well as tensor completion - and for computing word embeddings from a third - order word tri - occurrence tensor .",
        "the recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings ( i .",
        "our method outperforms the state - of - the - art unsupervised models on most benchmark tasks , and on many tasks even beats supervised models , highlighting the robustness of the produced sentence embeddings .",
        "we then make sequential predictions using a deep rl framework , incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector .",
        "deep convolutional neural network ( cnn ) inference requires significant amount of memory and computation , which limits its deployment on embedded devices .",
        "this paper proposes a new model for extracting an interpretable sentence embedding by introducing self - attention .",
        "instead of using a vector , we use a 2 - d matrix to represent the embedding , with each row of the matrix attending on a different part of the sentence .",
        "as a side effect , the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding .",
        "results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks .",
        "in this paper we \" borrow \" the idea of vector representation of words to capture the information of short texts and embed it into a matrix factorization framework .",
        "concurrently , a different line of research has tackled a very similar problem : in digital watermarking information are embedded in a signal in the presence of an adversary .",
        "knowledge graph embedding aims at translating the knowledge graph into numerical representations by transforming the entities and relations into con - tinuous low - dimensional vectors .",
        "we name our framework as paragraphe , which provides a library for parallel knowledge graph embedding .",
        "many of the existing methods for learning joint embedding of images and text use only supervised information from paired images and its textual attributes .",
        ", maximum mean discrepancy loss ) to learn joint embeddings for semantic and visual features .",
        "a novel technique of unsupervised - data adaptation inference is introduced to construct more comprehensive embeddings for both labeled and unlabeled data .",
        "we use autoencoders to create low - dimensional embeddings of underlying patient phenotypes that we hypothesize are a governing factor in determining how different patients will react to different interventions .",
        "we propose a supervised algorithm for generating type embeddings in the same semantic vector space as a given set of entity embeddings .",
        "the algorithm is agnostic to the derivation of the underlying entity embeddings .",
        "we demonstrate the utility of the embeddings on a type recommendation task , outperforming a non - parametric feature - agnostic baseline while achieving 15x speedup and near - constant memory usage on a full partition of dbpedia .",
        "using state - of - the - art visualization , we illustrate the agreement of our extensionally derived dbpedia type embeddings with the manually curated domain ontology .",
        "finally , we use the embeddings to probabilistically cluster about 4 million dbpedia instances into 415 types in the dbpedia ontology .",
        "the discrete nature of the generation process enables de - duplication of repeated features , further compacting the representation and increasing the diversity of the embeddings .",
        "this article presents an overview of embedding models of entities and relationships for knowledge base completion , with up - to - date experimental results on two standard evaluation tasks of link prediction ( i .",
        "like its bayesian counterpart , this embedded segmental k - means model ( es - kmeans ) represents arbitrary - length word segments as fixed - dimensional acoustic word embeddings .",
        "fgf involves multi - jaccard similarity to compute a robust graph and utilize word embedding method to enhance the recognition results .",
        "our proposed approach to this problem is a joint image pixel and word concept embeddings framework , where word concepts are connected by semantic relations .",
        "we further explore the trained joint embedding space to show its interpretability .",
        "sea is built using a bootstrapping approach that combines word embedding model trained on issue - tracking data and manual scoring of items in the lexicon .",
        "the model uses distributed sub - word embeddings learned from a large corpus .",
        "answer templates are extracted from embeddings derived from past agent answers , without turn - by - turn annotations .",
        "classical higher - order logic , when utilized as a meta - logic in which various other ( classical and non - classical ) logics can be shallowly embedded , is well suited for realising a universal logic reasoning approach .",
        "the proposed approach builds sentence representations using learned embeddings based on neural network .",
        "the learned word embeddings formed a feature space , to which the examined sentence is mapped to .",
        "we also show that the embedded speaker model reproduces many of these pragmatic behaviors .",
        "knowledge graph embedding aims to embed entities and relations of knowledge graphs into low - dimensional vector spaces .",
        "translating embedding methods regard relations as the translation from head entities to tail entities , which achieve the state - of - the - art results among knowledge graph embedding methods .",
        "in this paper , we propose an efficient parallel framework for translating embedding methods , called partrans - x , which enables the methods to be paralleled without locks by utilizing the distinguished structures of knowledge graphs .",
        "experiments on two datasets with three typical translating embedding methods , i .",
        "traditional manifold learning algorithms often bear an assumption that the local neighborhood of any point on embedded manifold is roughly equal to the tangent space at that point without considering the curvature .",
        "the proposed method constructed sentence vectors ( sent2vec ) by averaging the word embeddings , which were learned from anthology collections ( acl - embeddings ) .",
        "i also investigated polarity - specific word embeddings ( ps - embeddings ) for classifying positive and negative citations .",
        "the results showed that word embeddings are effective on classifying positive and negative citations .",
        "we propose to use word embeddings to perform word alignment for segment - level mt evaluation .",
        "we performed experiments with three types of alignment methods using word embeddings .",
        "experimental results show that our proposed methods outperform previous word embeddings - based methods .",
        "our work presented here constitutes the first step in opening the black - box of vector embeddings for tweets .",
        "more specifically , our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company .",
        "ecm addresses the factor in three ways : modeling high - level abstraction of emotion expression by embedding emotion categories , changing of implicit internal emotion states , and using explicit emotion expressions with an external emotion vocabulary .",
        "finally , we show that the model learns a manifold of embeddings that allows for morphing between instruments , meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive .",
        "visual classification or board games ) are becoming obsolete as state - of - the - art learning algorithms approach or even surpass human performance in most of them , having recently encouraged the development of first - person 3d game platforms embedding realistic physics .",
        "this paper explores linear methods for combining several word embedding models into an ensemble .",
        "we explore the ability of word embeddings to capture both semantic and morphological similarity , as affected by the different types of linguistic properties ( surface form , lemma , morphological tag ) used to compose the representation of each word .",
        "these research results convince that the embedded in the ahp and commonly applied , both genuine pp and cm for pcm may significantly deteriorate the quality of",
        "we know that a set of k nodes embedding all k - bandlimited signals always exists , thereby enabling their perfect reconstruction after sampling .",
        "the second and third spaces are two different strategies of combining word embeddings to represent sentences and use a linear svm and a logistic regressor as base classifiers .",
        "the first is a time - series model that relates embedding vectors from one time period to embedding vectors of previous time periods .",
        "firstly , today ' s embedding vectors ( = meaning ) of words can be derived as linear combinations of embedding vectors of their neighbors in previous time periods .",
        "then , we employ a rich set of features , such as link - probability , context - matching , word embeddings , and relatedness among candidate entities as well as their related entities , to rank the candidates under a regression based framework .",
        "by concatenating word and character embeddings , we achieve up to 2 .",
        "in this work we propose a technique based on distributed representation of words ( or word embeddings ) .",
        "based on these features , we present a totally unsupervised , expandable and language and domain independent method for learning normalization lexicons from word embeddings .",
        "the network has two branches , where the first branch extracts appearance feature embedding for each sample and the other branch predicts quality score for each sample .",
        "features and quality scores of all samples in a set are then aggregated to generate the final feature embedding .",
        "our submission to semeval was an update of previous work that builds high - quality , multilingual word embeddings from a combination of conceptnet and distributional semantics .",
        "in this paper , we propose a practical deep embedding method for extreme multi - label classifi - cation .",
        "our method harvests the ideas of non - linear embedding and modeling label space with graph priors at the same time .",
        "when you need to enable deep learning on low - cost embedded socs , is it better to port an existing deep learning framework or should you build one from scratch ?",
        "in this paper , we share our practical experiences of building an embedded inference engine using arm compute library ( acl ) .",
        "our conclusion is that , on embedded devices , we most likely will use very simple deep learning models for inference , and with well - developed building blocks such as acl , it may be better in both performance and development time to build the engine from scratch .",
        "we train both networks using an actor - critic reinforcement learning model , with a novel reward defined by visual - semantic embedding .",
        "existing methods of neural word embeddings , including sngs , are multi - pass algorithms and thus cannot perform incremental model update .",
        "we propose a simple yet effective text - based user geolocation model based on a neural network with one hidden layer , which achieves state of the art performance over three twitter benchmark geolocation datasets , in addition to producing word and phrase embeddings in the hidden layer that we show to be useful for detecting dialectal terms .",
        "we provide experimental evidence that sentences that are close in embedding space are indeed semantically highly related , but often have quite different structure and syntax .",
        "prior work about learning multi - sense embeddings suffered from either ambiguity of different - level embeddings or inefficient sense selection .",
        "in this paper , we model this effect by creating embeddings for characters based on their visual characteristics , creating an image for the character and running it through a convolutional neural network to produce a visual character embedding .",
        "additionally , qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry semantic content , resulting in embeddings that are coherent in visual space .",
        "key components are entity embeddings , a neural attention mechanism over local context windows , and a differentiable joint inference stage for disambiguation .",
        "we modeled the task as a regression analysis problem and combined traditional techniques such as pre - processing short texts , bag - of - words representations and lexical - based features with enhanced financial specific bag - of - embeddings .",
        "we used an external collection of tweets and news headlines mentioning companies / stocks from s \\ & amp ; p 500 to create financial word embeddings which are able to capture domain - specific syntactic and semantic similarities .",
        "the number of parameters in recent state - of - the - art networks makes them hard to deploy , especially on mobile phones and embedded devices .",
        "we experiment with a set of baselines based on cross - lingual embeddings and machine translation .",
        "furthermore , internal representations learned by the network serve as a new semantic representation of words - or sentences - which , unlike standard word embeddings , are learned in an essentially bilingual or even multilingual context .",
        "our model integrates word embedding features with gaussian processes regression .",
        "the agent uses a multimodal embedding between environment observations and natural language to self - monitor progress through a list of english instructions , granting itself reward for completing instructions in addition to increasing the game score .",
        "word embeddings have made enormous inroads in recent years in a wide variety of text mining applications .",
        "in this paper , we explore a word embedding - based architecture for predicting the relevance of a role between two financial entities within the context of natural language sentences .",
        "in this extended abstract , we propose a pooled approach that uses a collection of sentences to train word embeddings using the skip - gram word2vec architecture .",
        "we use the word embeddings to obtain context vectors that are assigned one or more labels based on manual annotations .",
        "although the choice of context ( which often takes the form of a sliding window ) has a direct influence on the resulting embeddings , the exact role of this model component is still not fully understood .",
        "we propose a novel embedding model , \\ emph { itransf } , to perform knowledge base completion .",
        "recent studies have shown that embedding textual relations using deep neural networks greatly helps relation extraction .",
        "in this work , we generalize textual relation embedding to the distant supervision setting , where much larger - scale but noisy training data is available .",
        ", the co - occurrence statistics of textual and knowledge base relations collected from the entire corpus , to embed textual relations .",
        "on a popular relation extraction dataset , we show that the learned textual relation embeddings can be used to augment existing relation extraction models and significantly improve their performance .",
        "we discover two problems , small micro variance and large macro variance , of pre - trained word embeddings that hurdle their direct use in neural networks , and propose standardization techniques as a remedy .",
        "on the popular overnight dataset , which contains eight domains , we show that both cross - domain training and standardized pre - trained word embeddings can bring significant improvement .",
        "in this paper , we propose a new clustering model , called deep embedded regularized clustering ( depict ) , which efficiently maps data into a discriminative embedding subspace and precisely predicts cluster assignments .",
        "furthermore , we employ the reconstruction loss functions in our autoencoder , as a data - dependent regularization term , to prevent the deep embedding function from overfitting .",
        "we show that the most widely - used approach to adaptation ( concatenating the context with the word embedding at the input to the recurrent layer ) is outperformed by a model that has some low - cost improvements : adaptation of both the hidden and output layers .",
        "the output of the regression is a point embedded in a pseudo - euclidean space , which can be analyzed using subsequent dissimilarity - or kernel - based processing methods .",
        "furthermore , we present a qualitative analysis of the obtained phone embeddings , and show that cross - modal visual input can improve the discriminability of phonological features which are visually discernable ( rounding , open /",
        "this paper presents a greedy neural word segmenter with balanced word and character embedding inputs to alleviate the existing drawbacks .",
        "the model architecture uses stack - based embedding features , predicting graphs jointly with unlexicalized predicates and their token alignments .",
        "to model both structured knowledge and unstructured language , we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses .",
        "this paper presents a new graph - based approach that induces synsets using synonymy dictionaries and word embeddings .",
        "we use neural word embeddings to discover words that are morphologically derived from each other and thereby that are semantically similar .",
        "we use letter successor variety counts obtained from tries that are built by neural word embeddings .",
        "our results show that using different information sources such as neural word embeddings and letter successor variety as prior information improves morphological segmentation in a bayesian model .",
        "we develop a streaming ( one - pass , bounded - memory ) word embedding algorithm based on the canonical skip - gram with negative sampling algorithm implemented in word2vec .",
        "because ideas are naturally embedded in texts , we propose the first framework to systematically characterize the relations between ideas based on their occurrence in a corpus of documents , independent of how these ideas are represented .",
        "skip - gram negative sampling ( sgns ) word embedding model , well known by its implementation in \" word2vec \" software , is usually optimized by stochastic gradient descent .",
        "in this paper , we modeled transcripts into complex networks and enriched them with word embedding ( cne ) to better represent short texts produced in neuropsychological assessments .",
        "{ \\ it universal schema } can support reasoning on the union of both structured kbs and unstructured text by aligning them in a common embedded space .",
        "word embeddings provide point representations of words containing useful semantic information .",
        "we show that the resulting approach captures uniquely expressive semantic information , and outperforms alternatives , such as word2vec skip - grams , and gaussian embeddings , on benchmark datasets such as word similarity and entailment .",
        "neural word segmentation research has benefited from large - scale raw texts by leveraging them for pretraining character and word embeddings .",
        "pre - trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for nlp tasks .",
        "in this paper , we demonstrate a general semi - supervised approach for adding pre - trained context embeddings from bidirectional language models to nlp systems and apply it to sequence labeling tasks .",
        "we consider the problem of learning general - purpose , paraphrastic sentence embeddings , revisiting the setting of wieting et al .",
        "we address these drawbacks in our framework which takes advantage of cross - lingual word embeddings trained solely on a high coverage bilingual dictionary .",
        "we propose a novel neural network model for joint training from both sources of data based on cross - lingual word embeddings , and show substantial empirical improvements over baseline techniques .",
        "we report a number of different evaluations using a finance specific word embedding model and reflect on the effects of using different evaluation metrics .",
        "we quantify relevance by measuring the distance between frames and queries in a common textual - visual semantic embedding space induced by a neural network .",
        "we compare our method against previous state of the art on textual - visual embeddings for thumbnail selection and show that our model outperforms them on relevance prediction .",
        "feed - forward neural networks using n - gram embedding features encode messages into vectors which are optimized to give message - response pairs a high dot - product value .",
        "we embed such generalized missing data into a vector space by mapping pointed affine subspace ( generalized missing data point ) to a vector containing imputed values joined with a corresponding projection matrix .",
        "such an operation preserves the scalar product of the embedding defined for flag vectors and allows to input transformed incomplete data to typical classification methods .",
        "an supervised dimensionality reduction algorithm called linear discriminant analysis ( lda ) seeks for an embedding transformation , which can work well with gaussian distribution data or single - modal data , but for non - gaussian distribution data or multimodal data , it gives undesired results .",
        "in order to quantify the quality of approximation , it is natural to consider the candidates and voters as embedded within a common metric space , and to ask how much further the chosen candidate is from the population as compared to the socially optimal one .",
        "ten instances of this network are initialized with the same word embeddings as inputs but with different initializations for the network weights .",
        "we present deep speaker , a neural speaker embedding system that maps utterances to a hypersphere where speaker similarity is measured by cosine similarity .",
        "the embeddings generated by deep speaker can be used for many tasks , including speaker identification , verification , and clustering .",
        "we experiment with rescnn and gru architectures to extract the acoustic features , then mean pool to produce utterance - level speaker embeddings , and train using triplet loss based on cosine similarity .",
        "many modern nlp systems rely on word embeddings , previously trained in an unsupervised manner on large corpora , as base features .",
        "efforts to obtain embeddings for larger chunks of text , such as sentences , have however not been so successful .",
        "large - scale multi - relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs .",
        "this paper proposes a novel framework for optimizing the latent representations with respect to the \\ textit { analogical } properties of the embedded entities and relations .",
        "furthermore , the model offers an elegant unification of several well - known methods in multi - relational embedding , which can be proven to be special instantiations of our framework .",
        "type - level word embeddings use the same set of parameters to represent all instances of a word regardless of its context , ignoring the inherent lexical ambiguity in language .",
        "instead , we embed semantic concepts ( or synsets ) as defined in wordnet and represent a word token in a particular context by estimating a distribution over relevant semantic concepts .",
        "we use the new , context - sensitive embeddings in a model for predicting prepositional phrase ( pp ) attachments and jointly learn the concept embeddings and model parameters .",
        "we show that using context - sensitive embeddings improves the accuracy of the pp attachment model by 5 .",
        "new unsupervised learning methods represent words and phrases in a high - dimensional vector space , and these monolingual embeddings have been shown to encode syntactic and semantic relationships between language elements .",
        "the information captured by these embeddings can be exploited for bilingual translation by learning a transformation matrix that allows to match relative positions across two monolingual vector spaces .",
        "it shows how to process the source data , train a neural network to learn the high - dimensional embeddings for individual languages and expands the framework for testing their quality beyond the english language .",
        "this allows us to foreground and confront the norms embedded in data - driven creativity and productivity assistance tools .",
        "as such tools effectively function as extensions of our cognition into technology , it is important to identify the norms they embed within themselves and , by extension , us .",
        "deeptingle is realized as a web application based on lstm networks and the glove word embedding , implemented in javascript with keras - js .",
        "our best model is the combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which achieves an f1 score of 88 .",
        "we propose a new fast word embedding technique using hash functions .",
        "our experiments show that the proposed method can achieve competitive results , comparable to neural embedding learning techniques , however , with only a fraction of the computational complexity of these methods .",
        "while the proposed derandomization enhances the computational and space complexity of our method , the possibility of applying weighting methods such as positive pointwise mutual information ( ppmi ) to our models after their construction ( and at a reduced dimensionality ) imparts a high discriminatory power to the resulting embeddings .",
        "recent machine learning methods for deriving vector - space embeddings of words ( e .",
        "we evaluate the parallelogram model of analogy as applied to modern word embeddings , providing a detailed analysis of the extent to which this approach captures human relational similarity judgments in a large benchmark dataset .",
        "word - embedding or obtaining vector representation of words from a large corpora of free texts using neural network methods have been shown to give significant performance for several natural language processing tasks .",
        "clblast has four main advantages over other blas libraries : 1 ) it is optimized for and tested on a large variety of opencl devices including less commonly used devices such as embedded and low - power gpus , 2 ) it can be explicitly tuned for specific problem - sizes on specific hardware platforms , 3 ) it can perform operations in half - precision floating - point fp16 saving precious bandwidth , time and energy , 4 ) and it can combine multiple operations in a single batched routine , accelerating smaller problems significantly .",
        "we have used exponential family embeddings as the tool to construct two basic vectors - product embeddings and context vectors .",
        "using the basic vectors , we build combined embeddings , trip embeddings and customer embeddings .",
        "combined embeddings mix linguistic properties of product names with their shopping patterns .",
        "the customer embeddings establish an understand - ing of the buying pattern of customers in a group and help in building customer profile .",
        "similarly , trip embeddings are used to build trip profiles .",
        "people happen to buy similar set of products in a trip and hence their trip embeddings can be used to predict the next product they would like to buy .",
        "this is a novel technique and the first of its kind to make recommendation using product , trip and customer embed",
        "this study presents a method to infer psycholinguistic properties for brazilian portuguese ( bp ) using regressors built with a light set of features usually available for less resourced languages : word length , frequency lists , lexical databases composed of school dictionaries and word embedding models .",
        "regularizing the adjacency of the output nodes , inferred from the predictions of the network , creates an easier optimization problem and ultimately provides that the predictions of the network turn into the optimal embedding .",
        "word embeddings improve the performance of nlp systems by revealing the hidden structural relationships between words .",
        "despite their success , word embeddings have seen very little use in computational social science nlp tasks , presumably due to their reliance on big data , and to a lack of interpretability .",
        "i propose a probabilistic model - based word embedding method which can recover interpretable embeddings , without big data .",
        "leveraging connections to topic models , i show how to train these models in high dimensions using a combination of state - of - the - art techniques for word embeddings and topic modeling .",
        "the models are interpretable , as embeddings of topics are used to encode embeddings for words ( and hence ,",
        "for this , we argue to use word embeddings instead of traditional high - dimensional vector representations in order to leverage their semantic density and to reduce computational cost .",
        "we rigorously test our approach on several domains including tagging data as well as publicly available embeddings based on wikipedia texts and navigation .",
        "for tagging data , we are the first to generate and study embeddings .",
        "how to develop slim and accurate deep neural networks has become crucial for real - world applications , especially for those employed in embedded systems .",
        "in this paper , we address the problem of learning compact similarity - preserving embeddings for massive high - dimensional streams of data in order to perform efficient similarity search .",
        "while previous contributions to feature extraction propose embeddings based on a single layer of the network , in this paper we propose a full - network embedding which successfully integrates convolutional and fully connected features , coming from all layers of a deep convolutional neural network .",
        "to do so , the embedding normalizes features in the context of the problem , and discretizes their values to reduce noise and regularize the embedding space .",
        "the proposed method is shown to outperform single layer embeddings on several image classification tasks , while also being more robust to the choice of the pre - trained model used for obtaining the initial features .",
        "the performance gap in classification accuracy between thoroughly tuned solutions and the full - network embedding is also reduced , which makes of the proposed approach a competitive solution for a large set of applications .",
        "semantic relatedness is computed using transe ~ \\ cite { bordes2013translating } , a method for low dimensional embedding of a triple in a knowledge graph .",
        "generic text embeddings are successfully used in a variety of tasks .",
        "we introduce second - order vector representations of words , induced from nearest neighborhood topological features in pre - trained contextual word embeddings .",
        "we then analyze the effects of using second - order embeddings as input features in two deep natural language processing models , for named entity recognition and recognizing textual entailment , as well as a linear model for paraphrase recognition .",
        "surprisingly , we find that nearest neighbor information alone is sufficient to capture most of the performance benefits derived from using pre - trained word embeddings .",
        "furthermore , second - order embeddings are able to handle highly heterogeneous data better than first - order representations , though at the cost of some specificity .",
        "additionally , augmenting contextual embeddings with second - order information further improves model performance in some cases .",
        "due to variance in the random initializations of word embeddings , utilizing nearest neighbor features from multiple first - order embedding samples can also contribute to downstream performance gains .",
        "finally , we identify intriguing characteristics of second - order embedding spaces for further research , including much higher density and different semantic interpretations of cosine similarity .",
        "we introduce a technique for augmenting neural text - to - speech ( tts ) with lowdimensional trainable speaker embeddings to generate different voices from a single model .",
        "besides the base model , in order to enhance its performance , we also proposed three techniques : the integration of multiple word - embedding library , bi - way integration , and ensemble based on model averaging .",
        "specifically , we embed a differentiable non - projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases .",
        "recurrent neural networks have achieved remarkable success at generating sequences with complex structures , thanks to advances that include richer embeddings of input and cures for vanishing gradients .",
        "an approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated asr confidence measures .",
        "thus hidden state representation of rnn along with word and entity type embedding as features avoid relying on the complex hand - crafted features generated using various nlp toolkits .",
        "by incorporating automatic syntactic features with word embeddings as input for bidirectional long short - term memory ( bi - lstm ) , our system , although simpler than some deep learning architectures , achieves a much better result for vietnamese ner .",
        "adversarial learning has been successfully embedded into deep networks to learn transferable features for domain adaptation , which reduce distribution discrepancy between the source and target domains and improve generalization performance .",
        "we extend the existing laplacian svm and present s3vm - r , by adding a regularization term to exploit exogenous information embedded in our feature space in favor of the task at hand .",
        "these improvements are even better than using pre - trained word embeddings from extra data .",
        "these methods enable the development of mathematically - principled isometric - invariant mappings from a set of vectors to a document embedding , which is stable with respect to the geometry of the document in the selected metric space .",
        "we find that the embeddings do not benefit text analysis .",
        "we perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity .",
        "representations of rare words trained directly on end - tasks are usually poor , requiring us to pre - train embeddings on external data , or treat all rare words as out - of - vocabulary words with a unique representation .",
        "we provide a method for predicting embeddings of rare words on the fly from small amounts of auxiliary data with a network trained against the end task .",
        "we show that this improves results against baselines where embeddings are trained on the end task in a reading comprehension task , a recognizing textual entailment task , and in language modelling .",
        "we show that a concatenation of this representation with the word and character embeddings improves the performance .",
        "recent advances in deep learning motivate the use of deep neutral networks in sensing applications , but their excessive resource needs on constrained embedded devices remain an important impediment .",
        "in this work we propose a solution far simpler but very effective : an evolution of the simple jordan rnn , where labels are re - injected as input into the network , and converted into embeddings , in the same way as words .",
        "thanks to label embeddings and their combination at the hidden layer , the proposed variant , which uses more parameters than elman and jordan rnns , but far fewer than lstm and gru , is more effective than other rnns , but also outperforms sophisticated crf models .",
        "we consider the problem of learning general - purpose , paraphrastic sentence embeddings in the setting of wieting et al .",
        "we evaluate the paraphrase pairs by their ability to serve as training data for learning paraphrastic sentence embeddings .",
        "therefore in this study we introduce a domain specific semantic similarity measure that was created by the synergistic union of word2vec , a word embedding method that is used for semantic similarity calculation and lexicon based ( lexical ) semantic similarity methods .",
        "we prove that this proposed methodology out performs word embedding methods trained on generic corpus and methods trained on domain specific corpus but do not use lexical semantic similarity methods to augment the results .",
        "further , we prove that text lemmatization can improve the performance of word embedding methods .",
        "analogy completion has been a popular task in recent years for evaluating the semantic properties of word embeddings , but the standard methodology makes a number of assumptions about analogies that do not always hold , either in recent benchmark datasets or when expanding into other domains .",
        "we further present bmass , a novel dataset for evaluating linguistic regularities in biomedical embeddings , and demonstrate that the relationships described in the dataset pose significant semantic challenges to current word embedding methods .",
        "a central property of abstract anaphora is that it establishes a relation between the anaphor embedded in the anaphoric sentence and its ( typically non - nominal ) antecedent .",
        "we propose three novel differentiable kernels as graph convolution operators and show that the embedding based kernel achieves the best performance .",
        "we present a new preprocessing algorithm for embedding the nodes of a given edge - weighted undirected graph into a euclidean space .",
        "hence , fastmap is orders of magnitude faster than competing approaches that produce a euclidean embedding using semidefinite programming .",
        "we present models for embedding words in the context of surrounding words .",
        "such models , which we refer to as token embeddings , represent the characteristics of a word that are specific to a given context , such as word sense , syntactic category , and semantic role .",
        "we explore simple , efficient token embedding models based on standard neural network architectures .",
        "we learn token embeddings on a large amount of unannotated text and evaluate them as features for part - of - speech taggers and dependency parsers trained on much smaller amounts of annotated data .",
        "we find that predictors endowed with token embeddings consistently outperform baseline predictors across a range of context window and training set sizes .",
        "ontology classes are sets of homogeneous instance objects that can be converted to a vector space by word vector embeddings .",
        "third , we found that a good word embedding initialization is also essential for learning better sentence representations .",
        "we propose three approaches for contextualizing citations which are based on query reformulation , word embeddings , and supervised learning .",
        "our network architecture is based on a state - of - the - art qa system , extended with biomedical word embeddings and a novel mechanism to answer list questions .",
        "we further find out that the attention mechanism following the top recurrent layer significantly attenuates encoding of phonology and makes the utterance embeddings much more invariant to synonymy .",
        "recent work has shown that comparing speech segments by representing them as fixed - dimensional vectors - - - acoustic word embeddings - - - and measuring their vector distance ( e .",
        "we consider an approach to query - by - example search that embeds both the query and database segments according to a neural model , followed by nearest - neighbor search to find the matching segments .",
        "earlier work on embedding - based query - by - example , using template - based acoustic word embeddings , achieved competitive performance .",
        "we find that our embeddings , based on recurrent neural networks trained to optimize word discrimination , achieve substantial improvements in performance and run - time efficiency over the previous approaches .",
        "while going deeper has been witnessed to improve the performance of convolutional neural networks ( cnn ) , going smaller for cnn has received increasing attention recently due to its attractiveness for mobile / embedded applications .",
        "to address these difficulties , we propose bloom embeddings , a compression technique that can be applied to the input and output of neural network models dealing with sparse high - dimensional binary - coded instances .",
        "bloom embeddings are computationally efficient , and do not seriously compromise the accuracy of the model up to 1 / 5 compression ratios .",
        "we evaluate bloom embeddings on 7 data sets and compare it against 4 alternative methods , obtaining favorable results .",
        "we also discuss a number of further advantages of bloom embeddings , such as ' on - the - fly ' constant - time operation , zero or marginal space requirements , training time speedups , or the fact that they do not require any change to",
        "in this work we describe and evaluate methods to learn musical embeddings .",
        "each embedding is a vector that represents four contiguous beats of music and is derived from a symbolic representation .",
        "we consider autoencoding - based methods including denoising autoencoders , and context reconstruction , and evaluate the resulting embeddings on a forward prediction and a classification task .",
        "cross - lingual embedding models allow us to project words from different languages into a shared embedding space .",
        "in the following , we will survey models that seek to learn cross - lingual embeddings .",
        "finally , we will present challenges and summarize how to evaluate cross - lingual embedding models .",
        "word embeddings are now a standard technique for inducing meaning representations for words .",
        "in this paper , we propose a mixture model for learning multi - sense word embeddings .",
        "we propose a novel embedding model that represents relationships among several elements in bibliographic information with high representation ability and flexibility .",
        "this is done end - to - end in a single stage with the use of associative embeddings .",
        "identifying context information as the backbone of both relation extraction and true label discovery , we adopt embedding techniques to learn the distributed representations of context , which bridges all components with mutual enhancement in an iterative fashion .",
        "aiming at better relating feature and label domain data for improved classification , we uniquely perform joint feature and label embedding by deriving a deep latent space , followed by the introduction of label - correlation sensitive loss function for recovering the predicted label outputs .",
        "doc2vecc represents each document as a simple average of word embeddings .",
        "a corruption model is included , which introduces a data - dependent regularization that favors informative or rare words while forcing the embeddings of common and non - discriminative ones to be close to zero .",
        "doc2vecc produces significantly better word embeddings than word2vec .",
        "the second approach is to project distributed representations of words ( word embeddings ) from a target language to a source language , so that the source - language ner system can be applied to the target language without re - training .",
        "the base of our model is a new type of variational autoencoder on demonstration trajectories that learns semantic policy embeddings .",
        "we show that these embeddings can be learned on a 9 dof jaco robot arm in reaching tasks , and then smoothly interpolated with a resulting smooth interpolation of reaching behavior .",
        "we also compare our networks processing time on nvidia gpu and embedded system device with existing state - of - the - art architectures for different image resolutions .",
        "a compelling aspect of our approach is that our models are trained with the same simple negative sampling objective function that is commonly used in word2vec to learn word embeddings .",
        "we propose a dependency - based embedding model of selectional preferences which allows fine - grained compatibility judgments with high coverage .",
        "more specifically , we describe a novel reinforcement learning framework for learning multi - hop relational paths : we use a policy - based agent with continuous states based on knowledge graph embeddings , which reasons in a kg vector space by sampling the most promising relation to extend its path .",
        "experimentally , we show that our proposed method outperforms a path - ranking based algorithm and knowledge graph embedding methods on freebase and never - ending language learning datasets .",
        "to the best of our knowledge , this is the first study which demonstrates how the architectures for learning word embeddings can be applied to this challenging syntactic - semantic task .",
        "word embeddings improve generalization over lexical features by placing each word in a lower - dimensional space , using distributional information obtained from unlabeled data .",
        "however , the effectiveness of word embeddings for downstream nlp tasks is limited by out - of - vocabulary ( oov ) words , for which embeddings do not exist .",
        "in this paper , we present mimick , an approach to generating oov word embeddings compositionally , by learning a function from spellings to distributional embeddings .",
        "unlike prior work , mimick does not require re - training on the original word embedding corpus ; instead , learning is performed at the type level .",
        "the model computes span embeddings that combine context - dependent boundary representations with a head - finding attention mechanism .",
        "we present a novel neural model hypervec to learn hierarchical embeddings for hypernymy detection and directionality .",
        "while previous embeddings have shown limitations on prototypical hypernyms , hypervec represents an unsupervised measure where embeddings are learned in a specific order and capture the hypernym $ - $ hyponym distributional hierarchy .",
        "results on benchmark datasets show that hypervec outperforms both state $ - $ of $ - $ the $ - $ art unsupervised measures and embedding models on hypernymy detection and directionality , and on predicting graded lexical entailment .",
        "this paper deals with using word embedding models to trace the temporal dynamics of semantic relations between pairs of words .",
        "a word embedding is a low - dimensional , dense and real - valued vector representation of a word .",
        "word embeddings have been used in many nlp tasks .",
        "the embedding of a word cap - tures both its syntactic and semantic aspects .",
        "therefore , it is necessary to have word embeddings learned specifically from tweets .",
        "in this paper , we present ten word embedding data sets .",
        "in addition to the data sets learned from just tweet data , we also built embedding sets from the general data and the combination of tweets with the general data .",
        "these ten embedding models were learned from about 400 million tweets and 7 billion words from the general text .",
        "we propose a method for embedding two - dimensional locations in a continuous vector space using a neural network - based model incorporating mixtures of gaussian distributions , presenting two model variants for text - based geolocation and lexical dialectology .",
        "the method then learns an also n - dimensional embedding of possibly reactive body - affordances that spread as far as possible throughout the target sensor space .",
        "our aim in this paper is to verify which embedding induction method works best for the sentence boundary detection task , specifically whether it be those which were proposed to capture semantic , syntactic or morphological similarities .",
        "the character glyph features are directly learned from the bitmaps of characters by convolutional auto - encoder ( convae ) , and the glyph features improve chinese word representations which are already enhanced by character embeddings .",
        "for each semantic space , modality - specific characteristics within one modality are fully exploited by recurrent attention network , while the data of another modality is projected into this space with attention based joint embedding to utilize the learned attention weights for guiding the",
        "t - distributed stochastic neighbor embedding ( tsne ) is a popular and prize - winning approach for dimensionality reduction and visualizing high - dimensional data .",
        "while recent embedding - based techniques encode entities and relationships in kbs and do not need machine translation for cross - lingual entity alignment , a significant number of attributes remain largely unexplored .",
        "in this paper , we propose a joint attribute - preserving embedding model for cross - lingual entity alignment .",
        "it jointly embeds the structures of two kbs into a unified vector space and further refines it by leveraging attribute correlations in the kbs .",
        "our experimental results on real - world datasets show that this approach significantly outperforms the state - of - the - art embedding approaches for cross - lingual entity alignment and could be complemented with methods based on machine translation .",
        "finally , we visualised the feature space obtained with our proposed method using t - distributed stochastic neighbour embedding ( t - sne ) and could observe distinct clusters of emotions .",
        "we propose a method to diminish the problem of out - of - vocabulary words by introducing an embedding derived from syllables and morphemes which leverages the agglutinative property .",
        "our model outperforms character - level embedding in perplexity by 16 .",
        "experimental results on abcd dataset show that by fusing lexical and word embedding features , our model achieves the state of the art performance of 0 .",
        "the system combines lexical , syntactic and pre - trained word embedding features , trains them on general regressors and finally combines the best performing models to create an ensemble .",
        "word embeddings have been found to capture a surprisingly rich amount of syntactic and semantic knowledge .",
        "however , it is not yet sufficiently well - understood how the relational knowledge that is implicitly encoded in word embeddings can be extracted in a reliable way .",
        "compared to existing approaches , our models lead to more accurate predictions , and they are more explicit about what can and cannot be extracted from the word embedding .",
        "we then proceed to describe methods , inspired by the word sense disambiguation literature , that model the context of the input word with context - aware word embeddings that help to differentiate the word sense be - fore feeding it into the encoder .",
        "we call this technique the continuous hint factory because it embeds student data in a continuous space , in which the most likely edit can be inferred in a probabilistic sense , similar to the hint factory .",
        "this has inspired methods for the joint embedding of entities and relations in continuous low - dimensional vector spaces , that can be used to induce new edges in the graph , i .",
        "in this paper we present an empirical study on the impact of negative sampling on the learned embeddings , assessed through the task of link prediction .",
        "we use state - of - the - art knowledge graph embeddings - - \\ rescal , transe , distmult and complex - - and evaluate on benchmark datasets - - fb15k and wn18 .",
        "we compare well known methods for negative sampling and additionally propose embedding based sampling methods .",
        "most of the previous methods rely on learning a common embedding space allowing to compare visual features of unknown categories with semantic descriptions .",
        "our toolkit is a combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which outperforms previously published toolkits on these three tasks .",
        "first , they take low - dimensional , real - valued embedding vectors as inputs , which can be trained over large raw data , thereby addressing the issue of feature sparsity in discrete models .",
        "to model changing customer and store environments , our recommendation method employs a pair of neural networks : to overcome the cold start problem , a feedforward network generates article embeddings in \" fashion space , \" which serve as input to a recurrent neural network that predicts a style vector in this space for each client , based on their past purchase sequence .",
        "those pairs will be mapped from the original space of symbolic words into some embedded style space .",
        "in particular , we demonstrate empirically the surprising efficiency of word embeddings in both of the two tasks , with both of the two models .",
        "then , we train a model on the first language pair and transfer its parameters , including its source word embeddings , to another model and continue training on the second language pair .",
        "in this work , we propose to explicitly incorporate the visual appearance of a character ' s glyph in its representation , resulting in a novel glyph - aware embedding of chinese characters .",
        "in the context of two basic chinese nlp tasks of language modeling and word segmentation , the model learns to represent each character ' s task - relevant semantic and syntactic information in the character - level embedding .",
        "this can be considered a relevant problem , as linear classifiers have been increasingly used in embedded systems and mobile devices for their low processing time and memory requirements .",
        "also , a recurrent neural network in which a word is represented as a sum of embeddings of its patterns is on",
        "we explore three language - independent alternatives to morphological segmentation using : i ) data - driven sub - word units , ii ) characters as a unit of learning , and iii ) word embeddings learned using a character cnn ( convolution neural network ) .",
        "we introduce the cross - match test - an exact , distribution free , high - dimensional hypothesis test as an intrinsic evaluation metric for word embeddings .",
        "we show that cross - match is an effective means of measuring distributional similarity between different vector representations and of evaluating the statistical significance of different vector embedding models .",
        "we demonstrate that the results of the hypothesis test align with our expectations and note that the framework of two sample hypothesis testing is not limited to word embeddings and can be extended to all vector representations .",
        "we combine a generative model parameterized by deep neural networks with non - linear embedding technique .",
        "our study suggests that the non - linear embedding based on a deep generative model can efficiently regularize a complex model with deep architectures while achieving high prediction accuracy that is far less sensitive to the availability of health status information .",
        "this paper describes a preliminary study for producing and distributing a large - scale database of embeddings from the portuguese twitter stream .",
        "using a single gpu , we were able to scale up vocabulary size from 2048 words embedded and 500k training examples to 32768 words over 10m training examples while keeping a stable validation loss and approximately linear trend on training time per epoch .",
        "we propose embed - rul : a novel approach for rul estimation from sensor data that does not rely on any degradation - trend assumptions , is robust to noise , and handles missing values .",
        "embed - rul utilizes a sequence - to - sequence model based on recurrent neural networks ( rnns ) to generate embeddings for multivariate time series subsequences .",
        "the embeddings for normal and degraded machines tend to be different , and are therefore found to be useful for rul estimation .",
        "we show that the embeddings capture the overall pattern in the time series while filtering out the noise , so that the embeddings of two machines with similar operational behavior are close to each other , even when their sensor readings have significant and varying levels of noise content .",
        "specifically , we learn word salience scores such that , using pre - trained word embeddings as the input , can accurately predict the words that appear in a sentence , given the words that appear in the sentences preceding or succeeding that sentence .",
        "despite the embedded genre in the article , not everyone can recognize the satirical cues and therefore believe the news as true news .",
        "this study addresses the problem of identifying the meaning of unknown words or entities in a discourse with respect to the word embedding approaches used in neural language models .",
        "we proposed a method for on - the - fly construction and exploitation of word embeddings in both the input and output layers of a neural model by tracking contexts .",
        "we study embedded binarized neural networks ( ebnns ) with the aim of allowing current binarized neural networks ( bnns ) in the literature to perform feedforward inference efficiently on small embedded devices .",
        "we present a novel method to embed discourse features in a convolutional neural network text classifier , which achieves a state - of - the - art result by a substantial margin .",
        "we empirically investigate several featurization methods to understand the conditions under which discourse features contribute non - trivial performance gains , and analyze discourse embeddings .",
        "we approach the query answering problems by combining ideas from the areas of kg embedding learning and deep learning for computer vision .",
        "we propose a neural embedding algorithm called network vector , which learns distributed representations of nodes and the entire networks simultaneously .",
        "by embedding networks in a low - dimensional space , the algorithm allows us to compare networks in terms of structural similarity and to solve outstanding predictive problems .",
        "after initial pre - processing phase on data , packets are fed to deep packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic .",
        "with the use of word embeddings in the field of natural language processing , it became a popular topic due to its ability to cope up with semantic sensitivity .",
        "hence , in this study , we propose a novel way of semi - supervised ontology population through word embeddings as the basis .",
        "we built several models including traditional benchmark models and new types of models which are based on word embeddings .",
        "although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices , they overlooked the reliability of mobile computing models .",
        "in this work , we propose rdeepsense , the first deep learning model that provides well - calibrated uncertainty estimations for resource - constrained mobile and embedded devices .",
        "it exploits a suite of both lexicon - and keyword - based features , as well as semantic features based on word embedding .",
        "to encourage replications , we release a lab package including the classifier , the word embedding space , and the gold standard with annotation guidelines .",
        "we also experiment with combining the representations learned from visual data with embeddings learned from textual data .",
        "although yolov2 can achieve real - time performance on a powerful gpu , it still remains very challenging for leveraging this approach for real - time object detection in video on embedded computing devices with limited computational power and limited memory .",
        "in this paper , we propose a new framework called fast yolo , a fast you only look once framework which accelerates yolov2 to be able to perform object detection in video on embedded devices in a real - time manner .",
        "we present a novel and scalable label embedding framework for large - scale multi - label learning a .",
        "our approach draws inspiration from ideas rooted in distributional semantics , specifically the skip gram negative sampling ( sgns ) approach , widely used to learn word embeddings for natural language processing tasks .",
        "learning such embeddings can be reduced to a certain matrix factorization .",
        "our approach is novel in that it highlights interesting connections between label embedding methods used for multi - label learning and paragraph / document embedding methods commonly used for learning representations of text data .",
        "we assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph ; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework , in polynomial time in the number of selected kernels .",
        "we implement a unified framework while delegating complex but well - understood subproblems ( planar embedding , maximum - weight perfect matching ) to established algorithms for which efficient implementations are freely available .",
        "a main drawback of manifold learning methods is , however , that there is no explicit mappings from the input data manifold to the output embedding .",
        "previously , in order to provide explicit mappings for manifold learning methods , many methods have been proposed to get an approximate explicit representation mapping with the assumption that there exists a linear projection between the high - dimensional data samples and their low - dimensional embedding .",
        "in particular , we apply this to the method of locally linear embedding ( lle ) and derive an explicit nonlinear manifold learning algorithm , named neighborhood preserving polynomial embedding ( nppe ) .",
        "ontological knowledge , which is necessary for text understanding , is not in general embedded into documents .",
        "to effectively visualize such data it is important to reduce its dimensionality and visualize the low dimensional embedding as a 2 - d or 3 - d scatter plot .",
        "in this paper we explore dimensionality reduction methods that draw upon domain knowledge in order to achieve a better low dimensional embedding and visualization of documents .",
        "whereas a lot of effort has been put in developing fast optimization methods when the groups are disjoint or embedded in a specific hierarchical structure , we address here the case of general overlapping groups .",
        "inspired by the hierarchical hidden markov models ( hhmm ) , we present the hierarchical semi - markov conditional random field ( hscrf ) , a generalisation of embedded undirectedmarkov chains tomodel complex hierarchical , nestedmarkov processes .",
        "despite its great success , the elastic net does not explicitly use correlation information embedded in data to select correlated variables .",
        "we examine the class of languages that can be defined entirely in terms of provability in an extension of the sorted type theory ( ty _ n ) by embedding the logic of phonologies , without introduction of special types for syntactic entities .",
        "mccain ' s embedding of definite propositional causal theories into logic programming paved the way to the use of answer set solvers for answering queries about actions described in such languages .",
        "in this paper we extend this embedding to nondefinite theories and to first - order causal logic .",
        "the output is an embedding of the objects into euclidean space ( like mds ) ; we refer to this as the \" crowd kernel . \"",
        "we describe our implementation of word level visually - grounded semantics and their embedding in a compositional parsing framework .",
        "the beliefs experienced by the controller often lie near a structured , low - dimensional subspace embedded in the high - dimensional belief space .",
        "specifically , we assume that the objects can be embedded into a $ d $ - dimensional euclidean space and that the rankings reflect their relative distances from a common reference point in $ r ^ d $ .",
        "while nowadays most ai researchers avoid discussing intelligence , the award - winning phd thesis ( legg , 2008 ) provided the philosophical embedding and investigated the uai - based universal measure of rational intelligence , which is formal , objective and non - anthropocentric .",
        "by representing these probability distributions as mean embeddings in the reproducing kernel hilbert space ( rkhs ) , we are able to apply many standard kernel - based learning techniques in straightforward fashion .",
        "a semantic embedding of ( constant domain ) quantified conditional logic in classical higher - order logic is presented .",
        "using a linear complexity algorithm to compute vectors for trees , we embed feature spaces of tree fragments in low - dimensional spaces where the kernel computation is directly done with dot product .",
        "we further show that embedded with",
        "this approach makes use of a recently developed representation of conditional distributions as \\ emph { embeddings } in a reproducing kernel hilbert space ( rkhs ) .",
        "this avoids the need to calculate intractable integrals , since expectations are represented as rkhs inner products whose computation has linear complexity in the number of points used to represent the embedding .",
        "we consider the scenario in which a watermark signal is repeatedly embedded in specific , possibly chosen based on a secret message bitstream , segments ( signals ) of the host data .",
        "we propose a probabilistic model that infers the embedded message bitstream and watermark signal , directly from the watermarked data , without access to the decoder .",
        "we illustrate the theoretical contributions through a series of experiments in feature selection and low - dimensional embedding of distributions .",
        "this paper proposes a framework dedicated to the construction of what we call discrete elastic inner product allowing one to embed sets of non - uniformly sampled multivariate time series or sequences of varying lengths into inner product space structures .",
        "this framework is based on a recursive definition that covers the case of multiple embedded time elastic dimensions .",
        "classification experimentations on time series and symbolic sequences datasets demonstrate the benefits that we can expect by embedding time series or sequences into elastic inner spaces rather than into classical euclidean spaces .",
        "in this paper , we address the problem of embedded feature selection for ranking on top of the list problems .",
        "intuitively , user preferences can be reasonably embedded in a coarse low - dimensional feature space that can be explored efficiently , requiring exploration in the high - dimensional space only as necessary .",
        "local linear embedding ( lle ) is a popular dimension reduction method .",
        "in this paper , we first show lle with nonnegative constraint is equivalent to the widely used laplacian embedding .",
        "specifically , we explicitly incorporate correlation measures as constraints and then propose an efficient embedded feature selection method using recently developed cutting plane strategy .",
        "given all of the ratings , our task is to embed all of the users and items as points in the same euclidean space .",
        "we pose this problem as a real - valued non - linear bayesian network and employ markov chain monte carlo and expectation maximization to find an embedding .",
        "we present a metric by which to judge the quality of a visualization and compare our results to local linear embedding and eigentaste on three real - world datasets .",
        "we study the problem of estimating , in the sense of optimal transport metrics , a measure which is assumed supported on a manifold embedded in a hilbert space .",
        "by embedding an original signal into a family of gradually coarsen signals parameterized with a continuous scale parameter , it provides a formal framework to capture the structure of a signal at different scales in a consistent way .",
        "in this paper , we present a new neural network architecture designed to embed multi - relational graphs into a flexible continuous vector space in which the original data is kept and enhanced .",
        "supervised ( linear ) embedding models like wsabie and psi have proven successful at ranking , recommendation and annotation tasks .",
        "we propose a new class of models which aim to provide improved performance while retaining many of the benefits of the existing class of embedding models .",
        "our new approach works by iteratively learning a linear embedding model where the next iteration ' s features and labels are reweighted as a function of the previous iteration .",
        "however , when a domain contains recursively embedded pi submodels , it may escape the detection of such an algorithm .",
        "in this paper , we propose an improved algorithm that ensures the learning of all embedded pi submodels whose sizes are upper bounded by a predetermined parameter .",
        "the mmse estimate is embedded within the optimization objective to form a novel regularized nmf cost function .",
        "issc adopts the assumption that high - dimensional data actually lie on the low - dimensional manifold such that out - of - sample data could be grouped in the embedding space learned from in - sample data .",
        "deliberation plays an important role in the design of rational agents embedded in the real - world .",
        "in this paper , we present a supervised model to learn the intrinsic structure of the tensors embedded in a high dimensional euclidean space .",
        "with the fixed point continuation procedures , our model automatically and jointly discovers the optimal dimensionality and the representations of the low dimensional embeddings .",
        "furthermore , the generalization of our model based on similarity between the learned low dimensional embeddings can be viewed as counterpart of recognition of human brain .",
        "distributed word representations ( word embeddings ) have recently contributed to competitive performance in language modeling and several nlp tasks .",
        "in this work , we train word embeddings for more than 100 languages using their corresponding wikipedias .",
        "we quantitatively demonstrate the utility of our word embeddings by using them as the sole features for training a part of speech tagger for a subset of these languages .",
        "moreover , we investigate the semantic features captured by these embeddings through the proximity of word groupings .",
        "we will release these embeddings publicly to help researchers in the development and enhancement of multilingual applications .",
        "also , the usage of aiml embedded tags for the handling of sequence dialogue limitations between humans and machines is shown .",
        "the algorithm embeds the trajectory of the markov chain into a reproducing kernel hilbert space ( rkhs ) , such that the feature space covariance of the samples informs the choice of proposal .",
        "in this paper we investigate the problem of estimating the cluster tree for a density $ f $ supported on or near a smooth $ d $ - dimensional manifold $ m $ isometrically embedded in $ \\ mathbb { r } ^ d $ .",
        "it allows for embedding externally defined calculations ( e .",
        "our model is based on two scoring functions that operate by learning low - dimensional embeddings of words and of entities and relationships from a knowledge base .",
        "the key idea of the method is to embed the joint distribution of a multi - view latent variable into a reproducing kernel hilbert space , and then the latent parameters are recovered using a robust tensor power method .",
        "rdfa was proposed as an extension to html for embedding non - intrusive rdf statements in human - readable documents .",
        "deep learning embeddings have been successfully used for many natural language processing ( nlp ) problems .",
        "embeddings are mostly computed for word forms although a number of recent papers have extended this to other linguistic units like morphemes and phrases .",
        "in this paper , we argue that learning embeddings for discontinuous linguistic units should also be considered .",
        "in an experimental evaluation on coreference resolution , we show that such embeddings perform better than word form embeddings .",
        "word embeddings resulting from neural language models have been shown to be successful for a large variety of nlp tasks .",
        "instead , we propose to drastically simplify the word embeddings computation through a hellinger pca of the word co - occurence matrix .",
        "we compare those new word embeddings with some well - known embeddings on ner and movie review tasks and show that we can reach similar or even better performance .",
        "although deep learning is not really necessary for generating good word embeddings , we show that it can provide an easy way to adapt embeddings to specific tasks .",
        "there are two main approaches to the distributed representation of words : low - dimensional deep learning embeddings and high - dimensional distributional models , in which each dimension corresponds to a context word .",
        "in this paper , we combine these two approaches by learning embeddings based on distributional - model vectors - as opposed to one - hot vectors as is standardly done in deep learning .",
        "several recent publications have proposed methods for mapping images into continuous semantic embedding spaces .",
        "in some cases the semantic embedding space is trained jointly with the image transformation , while in other cases the semantic embedding space is established independently by a separate task , such as a natural language processing task on a text corpus , and then the image transformation into that space is learned in a second stage .",
        "proponents of these image embedding systems have stressed their advantages over the traditional n - way classification framing of image understanding , particularly in terms of the promise of zero - shot learning - - the ability to correctly annotate images of previously unseen object categories .",
        "here we propose a simple method for constructing an image embedding system from any existing n - way image classification mechanism and any existing semantic embedding space which contains the n class labels in its vocabulary .",
        "our method maps images into the semantic embedding space via convex combination of the class label embedding vectors , and requires no additional learning .",
        "we show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes , and indeed outperforms state of the art methods on the imagenet zero - shot learning task .",
        "the sparse - to - dense module is a composition of a local spatial pooling step and a low - dimensional embedding process , which takes advantage of the spatial smoothness information in the image .",
        "our model learns to assign similar embeddings to aligned sentences and dissimilar ones to sentence which are not aligned while not requiring word alignments .",
        "the accuracy of the learned distribution depends both on the quantity of information embedded in $ h _ s $ and on the distance between $ h _ s $ and its mean $ h _ r $ .",
        "the selected instances can also be used for data preprocessing tasks such as learning a low - dimensional embedding of the data points or computing a low - rank approximation of the corresponding matrix .",
        "both approaches rely on learning deep semantic embeddings from a large amount of query click log data obtained from a search engine .",
        "finally , we use the dissimilarity metric to define a coordinate system on the embedded riemannian manifold , which gives us a low - dimensional encoding of our original data .",
        "our approach is based on embedding dl - lite logics in suitable fragments of the one - variable first - order logic , which provides useful insights into their properties and , in particular , computational behavior .",
        "we investigate embeddings of rdf in logic and show how standard logic programming and description logic technology can be used for reasoning with rdf .",
        "we use the embeddings and properties of the logics to establish novel upper bounds for the complexity of deciding entailment .",
        "to our knowledge , this work represents the first successful industrial application of embedded domain - independent temporal planning .",
        "it is typically embedded within a search procedure ( \" branch and prune \" ) and used at every node of the search tree to narrow down the search space , so it is critical that it be fast .",
        "the recently developed bayesian gaussian process latent variable model ( gplvm ) is a powerful generative model for discovering low dimensional embeddings in linear time complexity .",
        "in our paper , we introduce an algorithm that gives us the ability to handle huge state spaces and to use a heuristic concept which is easier to embed into search algorithms .",
        "we present a novel technique for learning semantic representations , which extends the distributional hypothesis to multilingual data and joint - space embeddings .",
        "our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences , while maintaining sufficient distance between those of dissimilar sentences .",
        "many of the previous works first embed the manifold to euclidean space and then learn the distance function .",
        "in this paper , we propose to learn the distance function directly on the manifold without embedding .",
        "to date , it has been used to embed in it default logic ( propositional case ) , autoepistemic logic , turner ' s logic of universal causation , and general logic programming under stable model semantics .",
        "besides showing the generality of gk as a logic for nonmonotonic reasoning , these embeddings shed light on the relationships among these other logics .",
        "in this paper , for the first time , we show how the logic of gk can be embedded into disjunctive logic programming in a polynomial but non - modular translation with new variables .",
        "these coding methods attempt to preserve either euclidean distance or angular ( cosine ) distance in the binary embedding space .",
        "binary embedding of high - dimensional data requires long codes to preserve the discriminative power of the input space .",
        "to address this problem , we propose circulant binary embedding ( cbe ) which generates binary codes by projecting the data with a circulant matrix .",
        "we study the convex relaxation of clustering and hamming embedding , focusing on the asymmetric case ( co - clustering and asymmetric hamming embedding ) , understanding their relationship to lsh as studied by ( charikar 2002 ) and to the max - norm ball , and the differences between their symmetric and asymmetric versions .",
        "spectral methods such as locally linear embedding ( lle ) can be useful in this context , as they preserve \" protrusions \" , i .",
        "digital elevation models ( dem ) are images having terrain information embedded into them .",
        "this embedding result has several important consequences : it not only provides a simple new proof theory for the calculus , thereby clarifying the proof - theoretic foundations of hybrid type - logical grammars , but , since the translation is simple and direct , it also provides several new parsing strategies for hybrid type - logical grammars .",
        "the main embedding result also sheds new light on problems with lambda grammars / abstract categorial grammars and shows lambda grammars / abstract categorial grammars suffer from problems of over - generation and from problems at the syntax - semantics interface unlike any other categorial grammar .",
        "accordingly , this work contributes with a regularized variant of moe that incorporates an embedded process for local feature selection using $ l1 $ regularization , with a simultaneous expert selection .",
        "examples are nonnegative matrix / tensor factorization , stochastic neighbor embedding , topic models , and bayesian network optimization .",
        "in this paper we propose a general framework for learning distributed representations of attributes : characteristics of text whose representations can be jointly learned with word embeddings .",
        "our model learns low - dimensional embeddings of words and knowledge base constituents ; these representations are used to score natural language questions against candidate answers .",
        "we introduce a model for bidirectional retrieval of images and sentences through a multi - modal embedding of visual and natural language data .",
        "unlike previous models that directly map images or sentences into a common embedding space , our model works on a finer level and embeds fragments of images ( objects ) and fragments of sentences ( typed dependency tree relations ) into a common space .",
        "some of these techniques we develop , such as a general transformation from a constant success probability subspace embedding to a high success probability subspace embedding with a dimension and sparsity independent of the success probability , may be of independent interest .",
        "in the more constrained tasks , co - occurrence vectors are competitive , although choice of compositional method is important ; on the larger - scale tasks , they are outperformed by neural word embeddings , which show robust , stable performance across the tasks .",
        "the minimum quartet tree cost problem is to construct an optimal weight tree from the $ 3 { n \\ choose 4 } $ weighted quartet topologies on $ n $ objects , where optimality means that the summed weight of the embedded quartet topologies is optimal ( so it can be the case that the optimal tree embeds all quartets as nonoptimal topologies ) .",
        "however , in addition to these semantic information , there are rich information embedded in source codes themselves .",
        "here we investigate the embeddings learned by neural machine translation models .",
        "we show that translation - based embeddings outperform those learned by cutting - edge monolingual models at single - language tasks requiring knowledge of conceptual similarity and / or syntactic role .",
        "we address this question using two neural network - based models for learning embeddings : plain neural networks and neural tensor networks .",
        "inspired by recent advances in multimodal learning and machine translation , we introduce an encoder - decoder pipeline that learns ( a ) : a multimodal joint embedding space with images and text and ( b ) : a novel language model for decoding distributed representations from our space .",
        "our pipeline effectively unifies joint image - text embedding models with multimodal neural language models .",
        "furthermore we show that with linear encoders , the learned embedding space captures multimodal regularities in terms of vector space arithmetic e .",
        "this paper describes an algorithm that is able to embed the preprocessing stage into the learningstage in order to get controllers directly starting from sensorial raw data with no expert knowledgeinvolved .",
        "an extension to the general pronoun resolution method performs inference as an embedded commonsense reasoning method .",
        "the general method and the embedded method utilize features of the ross representational scheme ; in particular the methods use ross ontology classes and the ross situation model .",
        "unlike previous approaches that map both sentences and images to a common embedding , we enable the generation of novel sentences given an image .",
        "we propose a novel parameter free , distance consistent locally linear embedding .",
        "furthermore , we propose a novel improved spectral clustering via embedded label propagation .",
        "a crucial problem for many results and tools about bigraphs and bigraphical reactive systems is bigraph embedding .",
        "an embedding is more informative than a bigraph matching , since it keeps track of the correspondence between the various components of the redex ( guest ) within the agent ( host ) .",
        "in this paper , we present an algorithm for computing embeddings based on a reduction to a constraint satisfaction problem .",
        "we also show how the affinity matrix can be learned from observed data with a simple convex optimization framework that is inspired by locally linear embedding .",
        "our approach learns the analogy - preserving embeddings between the abstract representations learned from each network , allowing for semantics - level transfer or reconstruction of the data among different modalities .",
        "the proposed model can be viewed as incorporating a more powerful compositional function for embedding acquisition in recursive neural networks .",
        "in this paper , we train recurrent neural networks with only raw features , and use word embedding to automatically learn meaningful representations .",
        "we show that a novel but simple feature embedding approach provides better performance , by exploiting the feature template structure common in nlp problems .",
        "this result assumes a planted sparse model , in which the target sparse vector is embedded in an otherwise random subspace .",
        "distributed word representations ( aka word embeddings ) are trained to optimally predict the contexts in which the corresponding words tend to appear .",
        "this prohibits the usage of deep cnns on resource limited hardware , especially cell phones or other embedded devices .",
        "all n - grams are thus embedded in a same semantic space .",
        "neural language models learn word representations , or embeddings , that capture rich linguistic and conceptual information .",
        "here we investigate the embeddings learned by neural machine translation models , a recently - developed class of neural language model .",
        "we show that embeddings from translation models outperform those learned by monolingual models at tasks that require knowledge of both conceptual similarity and lexical - syntactic role .",
        "we further show that these effects hold when translating from both english to french and english to german , and argue that the desirable properties of translation embeddings should emerge largely independently of the source and target languages .",
        "finally , we apply a new method for training neural translation models with very large vocabularies , and show that this vocabulary expansion algorithm results in minimal degradation of embedding quality .",
        "our embedding spaces can be queried in an online demo and downloaded from our web page .",
        "overall , our analyses indicate that translation - based embeddings should be used in applications that require concepts to be organised according to similarity and / or lexical function , while monolingual embeddings are better suited to modelling ( nonspecific ) inter - word relatedness .",
        "for these problems , label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency .",
        "in this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers fast label embedding algorithms and provides us with a unifying view of label embeddings in the multiclass and multilabel settings .",
        "leveraging techniques from randomized linear algebra , the running time of our label embedding algorithm is exponentially faster than naive algorithms .",
        "we consider learning representations of entities and relations in kbs using the neural - embedding approach .",
        "under this framework , we compare a variety of embedding models on the link prediction task .",
        "furthermore , we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules from the kb .",
        "we demonstrate that embeddings trained from the bilinear objective can effectively capture relation composition via matrix multiplication .",
        "we also show that our embedding - based approach can extract rules that involve relation transitivity more effectively than a state - of - the - art rule mining approach that is tailored for large - scale kbs .",
        "this paper advocates for density - based distributed embeddings and presents a method for learning representations in the space of gaussian distributions .",
        "we compare performance on various word embedding benchmarks , investigate the ability of these embeddings to model entailment and other asymmetric relationships , and explore novel properties of the representation .",
        "we investigate the problem of inducing word embeddings that are tailored for a particular bilexical relation .",
        "our learning algorithm takes an existing lexical vector space and compresses it such that the resulting word embeddings are good predictors for a target bilexical relation .",
        "in experiments we show that task - specific embeddings can benefit both the quality and efficiency in lexical prediction tasks .",
        "we propose diverse embedding neural network ( denn ) - a novel architecture for neural network language models ( lms ) .",
        "we also present an empirical analysis of the diverse word embeddings learned by denn - lm .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "further more , we also introduce a random embedding algorithm to scale our approach to sparse high dimensional feature sets .",
        "our model learns to embed image representations ( generated from a previously trained convolutional neural network ) into a multimodal space that is common to the images and the phrases that are used to described them .",
        "introduced the skip - gram model into the study of social network for the first time , and designed an algorithm named deepwalk for learning node embedding on a graph .",
        "we then propose two constraint programming formulation : the first formulation introduces a new global constraint called exists embedding that hides the complexity of the inclusion relation .",
        "we demonstrate the superior performance of our approach over pca , local linear embedding , kernel pca and isomap .",
        "the median variant relaxes the restriction of a metric space embedding for the objects but constrains the prototypes to be in the original data set .",
        "we build upon simon ' s notion of structural equations in order to extract the ( so - called ) causal ordering embedded in a hypothesis structure ( set of mathematical equations ) .",
        "the proposed strategy has been embedded in a local search based metaheuristic from the literature and tested in",
        "the key challenge of this problem is how to learn a metric , such that the instances sharing the same label are more likely close to each other on the embedded space .",
        "supervised manifold learning methods for data classification map data samples residing in a high - dimensional ambient space to a lower - dimensional domain in a structure - preserving way , while enhancing the separation between different classes in the learned embedding .",
        "most nonlinear supervised manifold learning methods compute the embedding of the manifolds only at the initially available training points , while the generalization of the embedding to novel points , known as the out - of - sample extension problem in manifold learning , becomes especially important in classification applications .",
        "the proposed algorithm computes a radial basis function ( rbf ) interpolator that minimizes an objective function consisting of the total embedding error of unlabeled test samples , defined as their distance to the embeddings of the manifolds of their own class , as well as a regularization term that controls the smoothness of the interpolation function in a direction - dependent way .",
        "these different approaches to decomposable cost functions are then embedded in a solver for extensive experiments that confirm the feasibility and efficiency",
        "in dan , hidden representations of all task - specific layers are embedded to a reproducing kernel hilbert space where the mean embeddings of different domain distributions can be explicitly matched .",
        "the domain discrepancy is further reduced using an optimal multi - kernel selection method for mean embedding matching .",
        "dan can learn invariant features with enhanced transferability , and can scale linearly by unbiased estimate of kernel embedding .",
        "specifically , we represent each topic as a cluster of multi - dimensional vectors and embed the corpus into a collection of vectors generated by the gaussian mixture model .",
        "each word is affected not only by its topic , but also by the embedding vector of its surrounding words and the context .",
        "in our experiments , we employ our inferred word embeddings as features in standard tagging tasks , obtaining significant accuracy improvements .",
        "here , we propose a novel model called temporal embedding - enhanced convolutional neural network ( tenet ) to learn repeatedly - occurring - yet - hidden structural elements in periodical time - series , called abstract snippets , for predicting future changes .",
        "our model uses convolutional neural networks and embeds a time - series with its potential neighbors in the temporal domain for aligning it to the dominant patterns in the dataset .",
        "this paper develops a model that addresses sentence embedding using recurrent neural networks ( rnn ) with long short term memory ( lstm ) cells .",
        "the proposed lstm - rnn model sequentially takes each word in a sentence , extracts its information , and embeds it into a semantic vector .",
        "visualization and analysis are performed to understand how the embedding process works .",
        "as a semantic representation of the sentence , the embedding vector can be used in many different applications .",
        "we present a novel learning method for word embeddings designed for relation classification .",
        "our word embeddings are trained by predicting words between noun pairs using lexical relation - specific features on a large unlabeled corpus .",
        "this allows us to explicitly incorporate relation - specific information into the word embeddings .",
        "the learned word embeddings are then used to construct feature vectors for a relation classification model .",
        "on a well - established semantic relation classification task , our method significantly outperforms a baseline based on a previously introduced word embedding method , and compares favorably to previous state - of - the - art models without syntactic information or manually constructed external resources .",
        "this is first carried out for target sets that are convex cones , and then generalized to any convex set by embedding it in a higher - dimensional convex cone .",
        "the model is embedded with a latent layer that is able to capture a richer class of contextual information in both state - state and observation - state pairs .",
        "factorial models can embed non - stationary noise models using markov chains as one of its source chain .",
        "a common strategy to overcome this problem is to perform dimensionality reduction on selected landmarks and to successively embed the entire dataset with the nystr \\ \" om method .",
        "the resulting neighborhood selection based on the bhattacharyya distance improves the embedding of sparsely sampled manifolds .",
        "due to its training speed and very few tunable parameters , the method has strong potential for embedded hardware applications requiring frequent retraining or online training .",
        "we explore the use of semantic word embeddings in text segmentation algorithms , including the c99 segmentation algorithm and new algorithms inspired by the distributed word vector representation .",
        "unsupervised word embeddings have been shown to be valuable as features in supervised learning problems ; however , their role in unsupervised problems has been less thoroughly explored .",
        "in this paper , we show that embeddings can likewise add value to the problem of unsupervised pos induction .",
        "in two representative models of pos induction , we replace multinomial distributions over the vocabulary with multivariate gaussian distributions over word embeddings and observe consistent improvements in eight languages .",
        "we also analyze the effect of various choices while inducing word embeddings on \" downstream \" pos induction results .",
        "it has gained its importance in e - government applications , mobile - based applications , embedded systems , and even business process development .",
        "this paper considers the problem of knowledge inference on large - scale imperfect repositories with incomplete coverage by means of embedding entities and relations at the first attempt .",
        "we propose iike ( imperfect and incomplete knowledge embedding ) , a probabilistic model which measures the probability of each belief , i .",
        "for these problems , label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency .",
        "in this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers a fast label embedding algorithm which works in both the multiclass and multilabel settings .",
        "this paper presents a theoretical analysis of multi - view embedding - - feature embedding that can be learned from unlabeled data through the task of predicting one view from another .",
        "the result explains the effectiveness of some existing methods such as word embedding .",
        "based on this theory , we propose a new semi - supervised learning framework that learns a multi - view embedding of small text regions with convolutional neural networks .",
        "additionally , our experimental results also evidence that : ( 1 ) our approach is more effective than cnn followed by a softmax classifier ; ( 2 ) omitting the representation of the artificial class other improves both precision and recall ; and ( 3 ) using only word embeddings as input features is enough to achieve state - of - the - art results if we consider only the text between the two target nominals .",
        "there is rising interest in vector - space word embeddings and their use in nlp , especially given recent methods for their fast estimation at very large scale .",
        "we present an extension to the skip - gram model that efficiently learns multiple embeddings per word type .",
        "it differs from recent related work by jointly performing word sense discrimination and embedding learning , by non - parametrically estimating the number of senses per word type , and by its efficiency and scalability .",
        "this paper presents an approach that reasons about conjunctions of multi - hop relations non - atomically , composing the implications of a path using a recursive neural network ( rnn ) that takes as inputs vector embeddings of the binary relation in the path .",
        "we assemble a new dataset of over 52m relational triples , and show that our method improves over a traditional classifier by 11 % , and a method leveraging pre - trained embeddings by 7 % .",
        "in our work , we propose to use recurrent neural networks and visual semantic embeddings without intermediate stages such as object detection and image segmentation .",
        "metric learning aims to embed one metric space into another to benefit tasks like classification and clustering .",
        "compositional embedding models build a representation ( or embedding ) for a linguistic structure based on its component word embeddings .",
        "we propose a feature - rich compositional embedding model ( \\ fct { } ) for relation extraction that is expressive , generalizes to new domains , and is easy - to - implement .",
        "the key idea is to combine both ( unlexicalized ) hand - crafted features with learned word embeddings .",
        "the model is able to directly tackle the difficulties met by traditional compositional embeddings models , such as handling arbitrary types of sentence annotations and utilizing global information for composition .",
        "this paper contributes a novel embedding model which measures the probability of each belief $ \\ langle h , r , t , m \\ rangle $ in a large - scale knowledge repository via simultaneously learning distributed representations for entities ( $ h $ and $ t $ ) , relations ( $ r $ ) , and the words in relation mentions ( $ m $ ) .",
        "given an imperfect belief , we can not only infer the missing entities , predict the unknown relations , but also tell the plausibility of the belief , just leveraging the learnt embeddings of remaining evidences .",
        "word embedding , which refers to low - dimensional dense vector representations of natural words , has demonstrated its power in many natural language processing tasks .",
        "to tackle this challenge , there have been quite a few works that leverage knowledge graphs as an additional information source to improve the quality of word embedding .",
        "our approach is based on the charwnn deep neural network , which uses word - level and character - level representations ( embeddings ) to perform sequential classification .",
        "our experimental results shade light on the contribution of neural character embeddings for ner .",
        "knowledge graph embedding refers to projecting entities and relations in knowledge graph into continuous vector spaces .",
        "state - of - the - art methods , such as transe , transh , and transr build embeddings by treating relation as translation from head entity to tail entity .",
        "we introduce a neural network method to encode programs as a linear mapping from an embedded precondition space to an embedded postcondition space and propose an algorithm for feedback at scale using these linear maps as features .",
        "in this paper we investigate the problem of localizing a mobile device based on readings from its embedded sensors utilizing machine learning methodologies .",
        ", word embedding ) could not achieve a good performance , mainly due to the multiple senses of words and the complex relations among words .",
        "second , we obtain distributed representations of words and relations by leveraging a novel word embedding method that considers the multi - sense nature of words and the relational knowledge among words ( or their senses ) contained in dictionaries .",
        "experiments results on 6 embeddings and 4 tasks with 10 datasets show that the proposed fine tuning framework may significantly improve the quality of the vector representation of words .",
        "like the conventional stack data structures used in transition - based parsing , elements can be pushed to or popped from the top of the stack in constant time , but , in addition , an lstm maintains a continuous space embedding of the stack contents .",
        "experiments using joint - embedding and deep learning methods show promising results on these tasks .",
        "representation learning of knowledge bases ( kbs ) aims to embed both entities and relations into a low - dimensional space .",
        "( 2 ) we represent relation paths via semantic composition of relation embeddings .",
        "we introduce an lstm model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words , then decodes this embedding to reconstruct the original paragraph .",
        "in this paper we introduce a pipelined architecture for incorporating multi - sense embeddings into language understanding , and test the performance of a state - of - the - art multi - sense embedding model ( based on chinese restaurant processes ) .",
        "recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces .",
        "to maximize the total data separability while preserving minimized within - class scatter simultaneously , we propose to embed kmeans into the framework generating pseudo class label information in a scenario of unsupervised feature selection .",
        "the resulting word - level distributed representations often ignore morphological information , though character - level embeddings have proven valuable to nlp tasks .",
        "we propose a new neural language model incorporating both word order and character order in its embedding .",
        "neural networks are both computationally intensive and memory intensive , making them difficult to deploy on embedded systems .",
        "embedding words in a vector space has gained a lot of research attention in recent years .",
        "while state - of - the - art methods provide efficient computation of word similarities via a low - dimensional matrix embedding , their motivation is often left unclear .",
        "in this paper , we argue that word embedding can be naturally viewed as a ranking problem .",
        "the performance of wordrank is measured in word similarity and word analogy benchmarks , and the results are compared to the state - of - the - art word embedding techniques .",
        "they allow for learning phrase embeddings as well as improved word embeddings .",
        "we introduce language - driven image generation , the task of generating an image visualizing the semantic contents of a word embedding , e .",
        ", given the word embedding of grasshopper , we generate a natural image of a grasshopper .",
        "the first takes as input a word embedding ( as produced , e .",
        "several user studies suggest that the current system produces images that capture general visual properties of the concepts encoded in the word embedding , such as color or typical environment , and are sufficient to discriminate between general categories of objects .",
        "the model consists of two gated recurrent unit networks with shared word embeddings , and uses a multi - task objective by receiving a textual description of a scene and trying to concurrently predict its visual representation and the next word in the sentence .",
        "on the other hand , word embedding has emerged as a newly favorite research subject because of its excellent performance in many natural language processing ( nlp ) - related tasks .",
        "a common thread of leveraging word embeddings in the summarization process is to represent the document ( or sentence ) by averaging the word embeddings of the words occurring in the document ( or sentence ) .",
        "beyond the continued efforts made to improve the representation of words , this paper focuses on building novel and efficient ranking models based on the general word embedding methods for extractive speech summarization .",
        "this paper addresses the problem of distilling embeddings for nlp tasks .",
        "we propose an encoding approach to distill task - specific knowledge from high - dimensional embeddings , which can retain high performance and reduce model complexity to a large extent .",
        "experimental results show our method is better than directly training neural networks with small embeddings .",
        "by means of pattern aggregation and probabilistic topic models , our siamese architecture captures contextualized semantics from the co - occurring descriptive terms via unsupervised learning , which leads to a concept embedding space of the terms in context .",
        "furthermore , the co - occurring oov concepts can be easily represented in the learnt concept embedding space .",
        "the main properties of the concept embedding space are demonstrated via visualization .",
        "to embed sequences of words ( i .",
        "in this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market .",
        "we introduce embed to control ( e2c ) , a method for model learning and control of non - linear dynamical systems from raw pixel images .",
        "recently , embedding methods have been proposed to represent words and documents by learning essential concepts and representations , such as word2vec and doc2vec .",
        "the embedded representations have shown more effectiveness than lda - style representations in many tasks .",
        "taking advantage of our characterization result , we embed the glp revision operators into structures of boolean lattices , that allow us to bring to light some",
        "we present \\ textit { autoextend } , a system to learn embeddings for synsets and lexemes .",
        "it is flexible in that it can take any word embeddings as input and does not need an additional training corpus .",
        "the synset / lexeme embeddings obtained live in the same vector space as the word embeddings .",
        "we show that its performance can be improved considerably by bootstrapping the learning from a larger question - answer pair corpus and from pretrained word embeddings .",
        "we detail a compositional distributional framework based on a rich form of word embeddings that aims at facilitating the interactions between words in the context of a sentence .",
        "embeddings and composition layers are jointly learned against a generic objective that enhances the vectors with syntactic information from the surrounding context .",
        "this paper aims to compare different regularization strategies to address a common phenomenon , severe overfitting , in embedding - based neural networks for nlp .",
        "we tried several frequently applied or newly proposed regularization strategies , including penalizing weights ( embeddings excluded ) , penalizing embeddings , re - embedding words , and dropout .",
        "most existing word embedding methods can be categorized into neural embedding models and matrix factorization ( mf ) - based methods .",
        "in addition , it is desirable to incorporate global latent factors , such as topics , sentiments or writing styles , into the word embedding model .",
        "since generative models provide a principled way to incorporate latent factors , we propose a generative word embedding model , which is easy to interpret , and can serve as a basis of more sophisticated latent factor models .",
        "we study the effectiveness of word embeddings to overcome this disadvantage of rouge .",
        "specifically , instead of measuring lexical overlaps , word embeddings are used to compute the semantic similarity of the words used in summaries instead .",
        "in this work , we innovatively develop two component - enhanced chinese character embedding models and their bigram extensions .",
        "distinguished from english word embeddings , our models explore the compositions of chinese characters , which often serve as semantic indictors inherently .",
        "it has been previously used to derive word embeddings , where one view indicates a word , and the other view indicates its context .",
        "we describe a way to incorporate prior knowledge into cca , give a theoretical justification for it , and test it by deriving word embeddings and evaluating them on a myriad of datasets .",
        "recent work on word embeddings has shown that simple vector subtraction over pre - trained embeddings is surprisingly effective at capturing different lexical relations , despite lacking explicit supervision .",
        "we find that word embeddings capture a surprising amount of information , and that , under suitable supervised training , vector subtraction generalises well to a broad range of relations , including over unseen lexical items .",
        "in this paper , we investigate whether distributional semantics in the form of word embeddings can enable a deeper , i .",
        "recently , knowledge graph embedding , which projects symbolic entities and relations into continuous vector space , has become a new , hot topic in artificial intelligence .",
        "this paper addresses a new issue of \\ textbf { multiple relation semantics } that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples , and proposes a novel gaussian mixture model for embedding , \\ textbf { transg } .",
        "the new model can discover latent semantics for a relation and leverage a mixture of relation component vectors for embedding a fact triple .",
        "to the best of our knowledge , this is the first generative model for knowledge graph embedding , which is able to deal with multiple relation semantics .",
        "to address this issue , we propose \\ textbf { transa } , an adaptive metric approach for embedding , utilizing the metric learning ideas to provide a more flexible embedding method .",
        "following the recent advances in word representation learning , our model learns dense real - valued word vectors , that is , bilingual word embeddings ( bwes ) .",
        "spectral embedding based on the singular value decomposition ( svd ) is a widely used \" preprocessing \" step in many learning tasks , typically leading to dimensionality reduction by projecting onto a number of dominant singular vectors and rescaling the coordinate axes ( by a predefined function of the singular value ) .",
        "in this paper , we propose a low - complexity it compressive spectral embedding algorithm , which employs random projections and finite order polynomial expansions to compute approximations to svd - based embedding .",
        "for an m times n matrix with t non - zeros , its time complexity is o ( ( t + m + n ) log ( m + n ) ) , and the embedding dimension is o ( log ( m + n ) ) , both of which are independent of the number of singular vectors whose effect we wish to capture .",
        "to the best of our knowledge , this is the first work to circumvent this dependence on the number of singular vectors for general svd - based embeddings .",
        "this prohibits their usage on resource limited hardware , including cell phones or other embedded devices .",
        "neural language models are a powerful tool to meaningfully embed words into semantic vector spaces .",
        "such whole - word segmental systems rely on a function that maps a variable - length speech segment to a vector in a fixed - dimensional space ; the resulting acoustic word embeddings need to allow for accurate discrimination between different word types , directly in the embedding space .",
        "our best approach uses side information in the form of known word pairs to train a siamese convolutional neural network ( cnn ) : a pair of tied networks that take two speech segments as input and produce their embeddings , trained with a hinge loss that separates same - word pairs and different - word pairs by some margin .",
        "to bypass this bottleneck in vocoded speech , this paper proposes a phase - embedded waveform representation framework and establishes a magnitude - phase joint modeling platform for high - quality spss .",
        "to investigate what the classifiers learn , we introduce ' intensional ' and ' denotational ' word vectors , and show that they capture meaning similarity in a way that is different from and complementary to word2vec word embeddings .",
        ", unsupervised embeddings ) , and that the supervised learning procedure updates them to task - specific representations for words contained in the training data .",
        "an experimental approach to studying the properties of word embeddings is proposed .",
        "recently , new upper bounds based on asymmetric locality - sensitive hashing ( alsh ) and asymmetric embeddings have emerged , but little has been known on the lower bound side .",
        "second makes use of the modern nonlinear t - distributed stochastic neighbor embedding method ( t - sne ) .",
        "learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs .",
        "in this work , we propose holographic embeddings ( hole ) to learn compositional vector space representations of entire knowledge graphs .",
        "in extensive experiments we show that holographic embeddings are able to outperform state - of - the - art methods for link prediction in knowledge graphs and relational learning benchmark datasets .",
        "the popular i - vector model represents speakers as lowdimensional continuous vectors ( i - vectors ) , and hence is a way of continuous speaker embedding .",
        "in this paper , we investigate binary speaker embedding , which transforms ivectors to binary vectors ( codes ) by a hash function .",
        "our experiments show that binary speaker embedding can deliver competitive or even better results on both speaker verification and identification tasks , while the memory usage and the computation cost are significant reduced .",
        "while word embedding has been demoed as a powerful representation for characterizing the statistical properties of natural language .",
        "in this study , we propose to use blstm - rnn with word embedding for part - of - speech ( pos ) tagging task .",
        "the embedding features learned from raw text further enhance the performance .",
        "web technology enables cloud - based solutions , embedding in tutorial web pages , atractive rendering of results , web - scale cooperative development , etc .",
        "we connected swish to the cliopatria semantic web toolkit , where it allows for collaborative development of programs and queries related to a dataset as well as performing maintenance tasks on the running server and we embedded swish in the learn prolog now !",
        "in this article , how word embeddings can be used as features in chinese sentiment classification is presented .",
        "then the word embeddings which represent each comment are used as input in different machine learning methods for sentiment classification , including svm , logistic regression , convolutional neural network ( cnn ) and ensemble methods .",
        "this study explores literary works as signals in word embedding space and tries to compare writing styles of popular classic novels using dynamic time warping .",
        "in a recent paper , levy and goldberg pointed out an interesting connection between prediction - based word embedding models and count models based on pointwise mutual information .",
        "we find that the most relevant differences from an optimization perspective are ( i ) predict models work in a low dimensional space where embedding vectors can interact heavily ; ( ii ) since predict models have fewer parameters , they are less prone to overfitting .",
        "we employ a pair of convolutional neural networks to model visual objects and speech signals at the word level , and tie the networks together with an embedding and alignment model which learns a joint semantic space over both modalities .",
        "to that end , we introduce a simplified training objective for learning multimodal embeddings using the skip - gram architecture by introducing convolutional ' pseudowords : ' embeddings composed of the additive combination of distributed word representations and image features from convolutional neural networks projected into the multimodal space .",
        "we present some preliminary results of the representational properties of these embeddings on various word similarity benchmarks .",
        "the basic framework is to build the embeddings of questions and answers based on bidirectional long short - term memory ( bilstm ) models , and measure their closeness by cosine similarity .",
        "to address this challenge , the drrn extracts high - level embedding vectors from the texts that describe states and actions , respectively , and computes the inner products between the state and action embedding vectors to approximate the q - function .",
        "a word embedding based correlation ( wec ) model is proposed by integrating advantages of both the translation model and word embedding , given a random pair of words , wec can score their co - occurrence probability in q \\ & amp ; a pairs and it can also leverage the continuity and smoothness of continuous space word representation to deal with new pairs of words that are rare in the training parallel text .",
        "in addition , to reduce the computational complexity , an over - relaxed monotone fast iterative shrinkage - thresholding technique is adapted and embedded in the iterative reweighted process .",
        "we consider the hashing mechanism for constructing binary data embeddings , that involves pseudo - random projections followed by nonlinear ( sign function ) mappings .",
        "it is a non - parametric and distribution free kernel method based on the hilbert space embedding of probability measures .",
        "with the d - cbow2 model we propose a new approach in which the input embedding layer is augmented with a context anchor layer .",
        "with experiments on french broadcast news videos we show that these two models outperform the baseline methods based on raw embeddings from lda , skip - gram",
        "we present a probabilistic language model that uses word embeddings to associate lingual verbs with their corresponding kinematic structures .",
        ", contiguous subsequences of the input ) are computed by encoding their constituent tokens using bidirectional recurrent neural nets , and these \" segment embeddings \" are used to define compatibility scores with output labels .",
        "we detect communities via standard graph clustering algorithms , and then exploit these communities by learning community - specific projections of word embeddings .",
        "however , it cannot reflect the rich relations between words by representing words as points in the embedded space .",
        "in this paper , we propose the gaussian mixture skip - gram ( gmsg ) model to learn the gaussian mixture embeddings for words based on skip - gram framework .",
        "each word can be regarded as a gaussian mixture distribution in the embedded space , and each gaussian component represents a word sense .",
        "in this paper , we propose deep embedded clustering ( dec ) , a method that simultaneously learns feature representations and cluster assignments using deep neural networks .",
        "to address this issue , we propose manifold regularized networks ( mrnet ) that utilize a novel training objective function that minimizes the difference between multi - layer embedding results of samples and those adversarial .",
        "furthermore , the training process of recent word - sense models is expensive relative to single - sense embedding processes .",
        "this paper presents a novel approach which addresses these concerns by modeling multiple embeddings for each word based on supervised disambiguation , which provides a fast and accurate way for a consuming nlp model to select a sense - disambiguated embedding .",
        "we demonstrate that these embeddings can disambiguate both contrastive senses such as nominal and verbal senses as well as nuanced senses such as sarcasm .",
        "we further evaluate part - of - speech disambiguated embeddings on neural dependency parsing , yielding a greater than 8 % average error reduction in unlabeled attachment scores across 6 languages .",
        "when building a knowledge base ( kb ) of entities and relations from multiple structured kbs and text , universal schema represents the union of all input schema , by jointly embedding all relation types from input kbs as well as textual patterns expressing relations .",
        "in previous work , textual patterns are parametrized as a single embedding , preventing generalization to unseen textual patterns .",
        "additional improvements are obtained by tying word embeddings across languages .",
        "a simple scheme is outlined that can reduce the memory footprint of a state - of - the - art embedding by a factor of 10 , with only minimal impact on performance .",
        "we embed an attention mechanism within a recurrent neural network ( rnn ) based acoustic model to automatically tune its attention to a more reliable input source .",
        "binary embeddings provide efficient and powerful ways to perform operations on large scale data .",
        "however binary embedding typically requires long codes in order to preserve the discriminative power of the input space .",
        "to address this problem , we propose circulant binary embedding ( cbe ) which generates binary codes by projecting the data with a circulant matrix .",
        "we demonstrate that the linear algebraic structure of word embeddings can be used to reduce data requirements for methods of learning facts .",
        "we propose a model to learn visually grounded word embeddings ( vis - w2v ) to capture visual notions of semantic relatedness .",
        "while word embeddings trained using text have been extremely successful , they cannot uncover notions of semantic relatedness implicit in our visual world .",
        "we find that the embeddings we learn capture fine - grained visually grounded notions of semantic relatedness .",
        "we show improvements over text only word embeddings ( word2vec ) on three tasks : common - sense assertion classification , visual paraphrasing and text - based image retrieval .",
        "we present and examine a result related to uncertainty reasoning , namely that a certain plausibility space of cox ' s type can be uniquely embedded in a minimal ordered field .",
        "embedding learning , a .",
        "in recent publications the embedding models were extended to also consider temporal evolutions , temporal patterns and subsymbolic representations .",
        "in this paper , we attempt to map these embedding models , which were developed purely as solutions to technical problems , to various cognitive memory functions , in particular to semantic and concept memory , episodic memory and sensory memory .",
        "in this paper , we show how to create paraphrastic sentence embeddings using the paraphrase database ( ganitkevitch et al .",
        "we make them available to the research community with the hope that they can serve as the new baseline for further work on universal paraphrastic sentence embeddings .",
        "we also learn high - quality category embeddings that reflect topical meanings .",
        "multitask cnn also contains multiple aspect cnns and a sentiment cnn , but different networks share the same word embeddings .",
        "recently , distributed word representations , or word embeddings , have been shown to successfully allow words to match on the semantic level .",
        "we therefore investigated several text representations as a combination of word embeddings in the context of semantic pair matching .",
        "we propose a new zero - shot event detection method by multi - modal distributional semantic embedding of videos .",
        "our model embeds object and action concepts as well as other available modalities from videos into a distributional semantic space .",
        "to our knowledge , this is the first zero - shot event detection model that is built on top of distributional semantics and extends it in the following directions : ( a ) semantic embedding of multimodal information in videos ( with focus on the visual modalities ) , ( b ) automatically determining relevance of concepts / attributes to a free text query , which could be useful for other applications , and ( c ) retrieving videos by free text event query ( e .",
        "we embed videos into a distributional semantic space and then measure the similarity between videos and the event query in a free text form .",
        "neural enquirer can be trained with gradient descent , with which not only the parameters of the controlling components and semantic parsing component , but also the embeddings of the tables and query words can be learned from scratch .",
        "we present a new perspective on neural knowledge base ( kb ) embeddings , from which we build a framework that can model symbolic knowledge in the kb together with its learning process .",
        "we show that this framework well regularizes previous neural kb embedding model for superior performance in reasoning tasks , while having the capabilities of dealing with unseen entities , that is , to learn their embeddings from natural language descriptions , which is very like human ' s behavior of learning semantic concepts .",
        "embedded in the host language , it blends declarative symbolic expression with imperative tensor computation .",
        "knowledge graph embedding aims to represent entities and relations in a large - scale knowledge graph as elements in a continuous vector space .",
        ", transe and transh , learn embedding representation by defining a global margin - based loss function over the data .",
        "moreover , embeddings over two knowledge graphs with different entities and relations share the same set of candidate loss functions , ignoring the locality of both graphs .",
        "this leads to the limited performance of embedding related applications .",
        "in this paper , we propose a locally adaptive translation method for knowledge graph embedding , called transa , to find the optimal loss function by adaptively determining its margin over different knowledge graphs .",
        "one key method for data analysis is dimensionality reduction , for example , to produce 2d embeddings that can be visualized and analyzed efficiently .",
        "t - distributed stochastic neighbor embedding ( tsne ) is a well - suited technique for the visualization of several high - dimensional data .",
        "this paper introduces driverseat , a technology for embedding crowds around learning systems for autonomous driving .",
        "in this paper , we present the first convolutional network accelerator which is scalable to network sizes that are currently only handled by workstation gpus , but remains within the power envelope of embedded systems .",
        "the aog embeds a context sensitive grammar that can describe the hierarchical composition of news topics by semantic elements about people involved , related places and what happened , and model contextual relationships between elements in the hierarchy .",
        "a generative model of object similarities based on the dirichlet distribution is proposed and embedded in the network for encoding the state of the system .",
        "embedding learning , a .",
        "hypothetical datalog is based on an intuitionistic semantics rather than on a classical logic semantics , and embedded implications are allowed in rule bodies .",
        ", the neck of a horn clause ) stands for inferring facts , an embedded implication plays the role of assuming its premise for deriving its consequence .",
        "for solving the problem , we introduce a multi - view embedding in which a latent factorization identifies which aspects in the two data views ( primary data and user data ) are related and which are specific to only one of them .",
        "instead of deriving sentence embeddings for the premise and the hypothesis to be used for classification , our solution uses a matching - lstm that performs word - by - word matching of the hypothesis with the premise .",
        "moreover , we show that our method learns an embedding in which high - level abstract visual features ( e .",
        "we provide the first extensive evaluation of how using different types of context to learn skip - gram word embeddings affects performance on a wide range of intrinsic and extrinsic nlp tasks .",
        "furthermore , for these extrinsic tasks , we find that once the benefit from increasing the embedding dimensionality is mostly exhausted , simple concatenation of word embeddings , learned with different context types , can yield further performance gains .",
        "as an additional contribution , we propose a new variant of the skip - gram model that learns word embeddings from weighted contexts of substitute words .",
        "in this paper , we propose a novel embedding method specifically designed for ned .",
        "by combining contexts based on the proposed embedding with standard ned features , we achieved state - of - the - art accuracy of 93 .",
        "similarly word embedding methods from natural language processing literature learn low - dimensional vector space representation of input elements .",
        "noticing the similarities among word embedding and matrix factorization techniques and based on the previous works that apply techniques from text processing for recommendation , word2vec ' s skip - gram technique is employed to make recommendations .",
        "we introduce trans - gram , a simple and computationally - efficient method to simultaneously learn and align wordembeddings for a variety of languages , using only monolingual data and a smaller set of sentence - aligned data .",
        "we use our new method to compute aligned wordembeddings for twenty - one languages using english as a pivot language .",
        "the discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model .",
        "we formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point - cloud , natural language , and manipulation trajectory data into a shared embedding space using a deep neural network .",
        "in order to learn semantically meaningful spaces throughout our network , we introduce a method for pre - training its lower layers for multimodal feature embedding and a method for fine - tuning this embedding space using a loss - based margin .",
        "it takes a pair of image and sentence and processes them in different channels , finally embedding it into a common multimodal vector space .",
        "these embeddingsencode abstract semantic information about the two inputs and can be comparedusing traditional information retrieval approaches .",
        "we propose a latent feature embedding based link recommendation model for prediction task and utilize bayesian personalized ranking based optimization technique for learning models for each predicate .",
        "the estimator is formulated as an inner product with a reproducing kernel hilbert space embedding and makes no assumption about the type or shape of the underlying data distribution .",
        "in many embedded systems , such as imaging sys - tems , the system has a single designated purpose , and same threads are executed repeatedly .",
        "we show how this objective can be understood in terms of graph embedding as well as how it corresponds to the information - theoretic measure of excess entropy in special cases .",
        "the parsing model uses multilingual word embeddings alongside learned and specified typological information , enabling generalization based on linguistic universals and based on typological similarities .",
        "we introduce new methods for estimating and evaluating embeddings of words from dozens of languages in a single shared embedding space .",
        "we present submatrix - wise vector embedding learner ( swivel ) , a method for generating low - dimensional feature embeddings from a feature co - occurrence matrix .",
        "this approach results in more accurate embeddings than can be achieved with methods that consider only observed co - occurrences , and can scale to much larger corpora than can be handled with sampling methods .",
        "we view it as a special case of a general framework which jointly trains a linear model with a non - linear feature generator consisting of ` text region embedding + pooling ' .",
        "under this framework , we explore a more sophisticated region embedding method using long short - term memory ( lstm ) .",
        "lstm can embed text regions of variable ( and possibly large ) sizes , whereas the region size needs to be fixed in a cnn .",
        "we seek the best use of lstm for the purpose in the supervised and semi - supervised settings , starting with the idea of one - hot lstm , which eliminates the customarily used word embedding layer .",
        "our results indicate that on this task , embeddings of text regions , which can convey higher concepts than single words in isolation , are more useful than word embeddings .",
        "we introduce the value iteration network : a fully differentiable neural network with a ` planning module ' embedded within .",
        "there is a wealth of information about financial systems that is embedded in document collections .",
        "we embed features of multiple layers into reproducing kernel hilbert spaces ( rkhss ) and match feature distributions for feature adaptation .",
        "a reproducing kernel can define an embedding of a data point into an infinite dimensional reproducing kernel hilbert space ( rkhs ) .",
        "to address this issue , we propose a method which learns a vector - space embedding of entities from wikipedia and constrains this embedding such that entities of the same semantic type are located in some lower - dimensional subspace .",
        "this basic problem lies at the core of a number of questions that are currently being considered by different communities , including community detection in sparse random graphs , learning structured models such as topic models or hidden markov models , and the efforts from the natural language processing community to compute \" word embeddings \" .",
        "in this paper , we present the latent skill embedding ( lse ) , a probabilistic model of students and educational content that can be used to recommend personalized sequences of lessons with the goal of helping students prepare for specific assessments .",
        "we formulate this problem as a regularized maximum - likelihood embedding of students , lessons , and assessments from historical student - content interactions .",
        "embeddings are generic representations that are useful for many nlp tasks .",
        "in this paper , we introduce densifier , a method that learns an orthogonal transformation of the embedding space that focuses the information relevant for a task in an ultradense subspace of a dimensionality that is smaller by a factor of 100 than the original space .",
        "we show that ultradense embeddings generated by densifier reach state of the art on a lexicon creation task in which words are annotated with three types of lexical information - sentiment , concreteness and frequency .",
        "the advantage of rnns over the traditional approaches is their capacity to capture long ranges of context and implicitly adapt the word embeddings , trained on a large corpus , into a task - specific word representation , but still preserve the original semantic generalization to be helpful across domains .",
        "as a case study , we use a multi - task gated recurrent network model consisting of two parallel pathways with shared word embeddings trained on predicting the representations of the visual scene corresponding to an input sentence , and predicting the next word in the same sentence .",
        "to demonstrate its effectiveness , we use the representation as the backbone of a greedy , bottom - up dependency parser , achieving state - of - the - art accuracies for english and chinese , without relying on external word embeddings .",
        "recursive neural networks ( rnn ) and their recently proposed extension recursive long short term memory networks ( rlstm ) are models that compute representations for sentences , by recursively combining word embeddings according to an externally provided parse tree .",
        "in this paper , we propose a neural mt system using character - based embeddings in combination with convolutional and highway layers to replace the standard lookup - based word representations .",
        "the resulting unlimited - vocabulary and affix aware source word embeddings are tested in a state - of - the - art neural mt based on an attention - based bidirectional recurrent neural network .",
        "we introduce a novel , simple convolution neural network ( cnn ) architecture - multi - group norm constraint cnn ( mgnc - cnn ) that capitalizes on multiple sets of word embeddings for sentence classification .",
        "mgnc - cnn extracts features from input embedding sets independently and then joins these at the penultimate layer in the network to form a final feature vector .",
        "we then adopt a group regularization strategy that differentially penalizes weights associated with the subcomponents generated from the respective embedding sets .",
        "furthermore , it is flexible in that it does not require input word embeddings to be of the same dimensionality .",
        "recent advances in convolutional neural networks have considered model complexity and hardware efficiency to enable deployment onto embedded systems and mobile devices .",
        "typically , this process is computationally expensive and the produced embedding is limited to the training data .",
        "in many real life scenarios , the ability to produce embedding of unseen samples is essential .",
        "to exploit the combination of different discourse corpora , we design related discourse classification tasks specific to a corpus , and propose a novel convolutional neural network embedded multi - task learning system to synthesize these tasks by learning both unique and shared representations for each task .",
        "in our approach , a potential word segment ( of arbitrary length ) is embedded in a fixed - dimensional acoustic vector space .",
        "we start from learning general embeddings for each entity mention , compose the embeddings of specific contexts using linguistic structures , link the mention to knowledge bases and learn its related knowledge representations .",
        "our paper presents a new method to find local symmetries in a low - dimensional 2 - d grid structure which is embedded in high - dimensional structure .",
        "starting from word embeddings of discourse arguments , semder employs a shallow encoder to generate a distributed surface representation for a discourse .",
        "recently , several works in the field of natural language processing suggested to learn a latent representation of words using neural embedding algorithms .",
        "in this paper , we show that item - based cf can be cast in the same framework of neural word embedding .",
        "inspired by sgns , we describe a method we name item2vec for item - based cf that produces embedding for items in a latent space .",
        "it ( i ) combines diverse versions of pretrained word embeddings and ( ii ) extracts features of multigranular phrases with variable - size convolution filters .",
        "we propose a new algorithm for topic modeling , vec2topic , that identifies the main topics in a corpus using semantic information captured via high - dimensional distributed word embeddings .",
        "the feature embedding module is a cnn which maps each face frame into a feature representation .",
        "the neural aggregation module is composed of two content based attention blocks which is driven by a memory storing all the features extracted from the face video through the feature embedding module .",
        "we present a novel method for jointly learning compositional and non - compositional phrase embeddings by adaptively weighting both types of embeddings using a compositionality scoring function .",
        "the scoring function is used to quantify the level of compositionality of each phrase , and the parameters of the function are jointly optimized with the objective for learning phrase embeddings .",
        "in experiments , we apply the adaptive joint learning method to the task of learning embeddings of transitive verb phrases , and show that the compositionality scores have strong correlation with human ratings for verb - object compositionality , substantially outperforming the previous state of the art .",
        "moreover , our embeddings improve upon the previous best model on a transitive verb disambiguation task .",
        "a speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style .",
        "recently , several works in the domain of natural language processing presented successful methods for word embedding .",
        "in this paper , we propose a scalable bayesian neural word embedding algorithm that can be beneficial to general item similarity tasks as well .",
        "we apply distributed language embedding methods from natural language processing to assign a vector to each database entity associated token ( for example , a token may be a word occurring in a table row , or the name of a column ) .",
        "the results reveal that neural embedding based document representations work better on this analogy task than conventional methods , and we provide some preliminary explanations over these observations .",
        "this paper proposes a model to learn word embeddings with weighted contexts based on part - of - speech ( pos ) relevance weights .",
        "however , state - of - the - art word embedding models fail to consider it .",
        "we utilize the pos relevance weights to model each word - context pairs during the word embedding training process .",
        "when learning nonlinear embeddings with siamese or triplet networks from similarities , we typically assume they are sourced from a single visual concept .",
        "in this paper , we are concerned with the hypothesis that it can be potentially harmful to ignore the heterogeneity of concepts affiliated with observed similarities when learning these embedding networks .",
        "we propose multi - query networks ( mqns ) that leverage recent advances in representation learning on factorized triplet embeddings in combination with convolutional networks in order to learn embeddings differentiated into semantically distinct subspaces , which are learned with a latent space attention mechanism .",
        "secondly , seven emotion embedding vectors , which are corresponding to each classification emotion type , are added to locate the perception attentions .",
        "this paper introduces the visually informed embedding of word ( view ) , a continuous vector representation for a word extracted from a deep neural model trained using the microsoft coco data set to forecast the spatial arrangements between visual objects , given a textual description .",
        "the model is composed of a deep multilayer perceptron ( mlp ) stacked on the top of a long short term memory ( lstm ) network , the latter being preceded by an embedding layer .",
        "we present a semi - supervised learning framework based on graph embeddings .",
        "given a graph between instances , we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph .",
        "in the transductive variant of our method , the class labels are determined by both the learned embeddings and input feature vectors , while in the inductive variant , the embeddings are defined as a parametric function of the feature vectors , so predictions can be made on instances not seen during training .",
        "perspectives range from the word level to sentence fragments to sequences of sentences ; the networks operate only on word - embedding representations of text .",
        "we present an approach to learning multi - sense word embeddings relying both on monolingual and bilingual information .",
        "we propose an unsupervised algorithm based on lesk which performs visual sense disambiguation using textual , visual , or multimodal embeddings .",
        "we find that textual embeddings perform well when gold - standard textual annotations ( object labels and image descriptions ) are available , while multimodal embeddings perform well on unannotated images .",
        "we also verify our findings by using the textual and multimodal embeddings as features in a supervised setting and analyse the performance of visual sense disambiguation task .",
        "to address this challenge , we propose a new deep neural network architecture that jointly leverage pre - trained word embedding and auxiliary character embedding to learn sentence meanings .",
        "this model enables us to naturally exploit the semantic structures of word embeddings while flexibly discovering the number of topics .",
        "despite interest in using cross - lingual knowledge to learn word embeddings for various tasks , a systematic comparison of the possible approaches is lacking in the literature .",
        "we perform an extensive evaluation of four popular approaches of inducing cross - lingual embeddings , each requiring a different form of supervision , on four typographically different language pairs .",
        "this work , concerning paraphrase identification task , on one hand contributes to expanding deep learning embeddings to include continuous and discontinuous linguistic phrases .",
        "on the other hand , it comes up with a new scheme tf - kld - knn to learn the discriminative weights of words and phrases specific to paraphrase task , so that a weighted sum of embeddings can represent sentences more effectively .",
        "importantly , we achieve these results even though our character - level model has 16x less parameters than an equivalent word - embedding model , uses significantly less training data than previous work which relies on data augmentation , and encounters only 1 .",
        "two novel deep bidirectional variant models , in which we increase the depth of nonlinearity transition in different way , are proposed to learn hierarchical visual - language embeddings .",
        "we employ distributional semantic representations of query entities through two models : 1 ) contextual vectors generated from encyclopedic corpora like wikipedia , and 2 ) high dimensional word embedding vectors generated from millions of job postings using word2vec .",
        "the matches are encoded as embeddings with additional parameters ( dimensions ) , which are tuned by the network .",
        "a currently successful approach to computational semantics is to represent words as embeddings in a machine - learned vector space .",
        "we present an ensemble method that combines embeddings produced by glove ( pennington et al .",
        "the embeddings it produces achieve state - of - the - art performance on many word - similarity evaluations .",
        "our results show that the online embedding indeed approximates the geometry of the full corpus - wise tf and tf - idf space .",
        "knowledge graph embedding represents the entities and relations as numerical vectors , and then knowledge analysis could be promoted as a numerical method .",
        "our model could interact both two information sources by characterizing the correlations , by which means , the textual descriptions could make effects to discover semantic relevance and offer precise semantic embedding .",
        "the approach is primarily based on a combination of word embeddings and parserbased features , and employs unidirectional incremental computation of compositional embeddings for multiword expressions .",
        "we address these issues and evaluate bi - lstms with word , character , and unicode byte embeddings for pos tagging .",
        "several resources and techniques to improve our relation extraction systems are also discussed , including word embeddings and training data expansion .",
        "finally , we use additional unlabeled data through distant supervision techniques and word embeddings to further improve stance classification .",
        "in this paper , we enhance the attention - based neural machine translation by adding an explicit coverage embedding model to alleviate issues of repeating and dropping translations in nmt .",
        "for each source word , our model starts with a full coverage embedding vector , and then keeps updating it with a gated recurrent unit as the translation goes .",
        "all the initialized coverage embeddings and updating matrix are learned in the training procedure .",
        "~ we propose a framework that embeds entities and categories into a semantic space by integrating structured knowledge and taxonomy hierarchy from large knowledge bases .",
        "do word embeddings converge to learn similar things over different initializations ?",
        "how repeatable are experiments with word embeddings ?",
        "are all word embedding techniques equally reliable ?",
        "our preliminary results illustrate that our metric not only measures a intrinsic property of word embedding methods but also correlates well with other evaluation metrics on downstream tasks .",
        "we believe our methods are is useful in characterizing robustness - - an important property to consider when developing new word embedding methods .",
        "recent work in learning vector - space embeddings for multi - relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora .",
        "in this article , we propose candies ( combined approach for novelty detection in intelligent embedded systems ) , a new approach to novelty detection in technical systems .",
        "moreover , we publish first largest word2vec word embeddings trained on 52 million crisis - related tweets .",
        "to enable embedded devices such as smartphones , google glasses and monitoring cameras with the astonishing power of deep learning , dedicated hardware accelerators can be used to decrease both execution time and power consumption .",
        "based on the theory of hilbert space embedding of distributions , a novel joint distribution discrepancy is proposed to directly compare joint distributions across domains , eliminating the need of marginal - conditional factorization .",
        "for example , when the items are embedded into $ k $ tight clusters , the sample complexity of our algorithm reduces to $ o ( nk ) $ .",
        "our model treats such instances as sub - sequences of lexicalized dependency paths and learns suitable embedding representations .",
        "we experimentally demonstrate that such embeddings can improve results over previous state - of - the - art semantic role labelers , and showcase qualitative improvements obtained by our method .",
        "we characterize a large class of loss functions that allows to naturally embed structured outputs in a linear space .",
        "the novel embedding outperforms state - of - the - art models on predicting word similarities in simlex - 999 , and on distinguishing antonyms from synonyms .",
        "in this paper , we propose a new method for query translation based on dimension projection of embedded vectors from the pseudo - relevant documents in the source language to their equivalents in the target language .",
        "we employ recursive autoencoders to generate tree structures of phrase with embeddings at different levels of granularity ( e .",
        "over these embeddings on the source and target side , we introduce a bidimensional attention network to learn their interactions encoded in a bidimensional attention matrix , from which we extract two soft attention weight distributions simultaneously .",
        "continuous space word embeddings have received a great deal of attention in the natural language processing and machine learning communities for their ability to model term similarity and other relationships .",
        "we demonstrate that word embeddings such as word2vec and glove , when trained globally , underperform corpus and query specific embeddings for retrieval tasks .",
        "these results suggest that other tasks benefiting from global embeddings may also benefit from local embeddings .",
        "most recent approaches to zero - shot learning are based on finding and exploiting relationships between labels using semantic embeddings .",
        "we show in this paper that semantic embeddings , despite being very good at capturing relationships between labels , are not very good at capturing the relationships among labels in a data - dependent manner .",
        "in the first step , we learn what we call a \\ emph { property embedding",
        "we propose a scheme for recycling gaussian random vectors into structured matrices to approximate various kernel functions in sublinear time via random embeddings .",
        "word embeddings show promise as a diachronic tool , but have not been carefully evaluated .",
        "we develop a robust methodology for quantifying semantic change by evaluating word embeddings ( ppmi , svd , word2vec ) against known historical changes .",
        "in this paper , the problem of multi - view embedding from different visual cues and modalities is considered .",
        "we propose a unified solution for subspace learning methods using the rayleigh quotient , which is extensible for multiple views , supervised learning , and non - linear embeddings .",
        "we demonstrate the effectiveness of the proposed multi - view embedding methods on visual object recognition and cross - modal image retrieval , and obtain superior results in both applications compared to related methods .",
        "in this paper , we propose a novel approach to multi - label zsl via concept embedding learned from collections of public users ' annotations of multimedia .",
        "thanks to concept embedding , multi - label zsl can be done by efficiently mapping an instance input features onto the concept embedding space in a similar manner used in single - label zsl .",
        "moreover , our semantic learning model is capable of embedding an out - of - vocabulary label by inferring its meaning from its co - occurring labels .",
        "thus , our approach allows both seen and unseen labels during the concept embedding learning to be used in the aforementioned instance mapping , which makes multi - label zsl more flexible and suitable for real applications .",
        "we introduce a new attention mechanism which uses multiplicative interactions between the query embedding and intermediate states of a recurrent neural network reader .",
        "powered by deep recurrent neural networks and neural embeddings , our proposed cfo achieves an accuracy of 75 .",
        "we then use word embeddings to repre - sent these concepts in a low dimensional vector space , allowing us to expand the meaning around concepts , and thus enabling insight about commonalities and differences among different languages .",
        "instead of aiming to select a single optimal architecture , we propose a $ \" $ fabric $ \" $ that embeds an exponentially large number of cnn architectures .",
        "while individual cnn architectures can be recovered as paths in the trellis , the trellis can in addition ensemble all embedded architectures together , sharing their weights where their paths overlap .",
        "the regularization ability of the dppn allows it to rediscover ( approximate ) convolutional network architectures embedded within a fully connected architecture .",
        "this paper presents a joint model for performing unsupervised morphological analysis on words , and learning a character - level composition function from morphemes to word embeddings .",
        "our morphological analysis is comparable to dedicated morphological analyzers at the task of morpheme boundary recovery , and also performs better than word - based embedding models at the task of syntactic analogy answering .",
        "finally , we show that incorporating morphology explicitly into character - level models help them produce embeddings for unseen words which correlate better with human judgments .",
        "we combine domain - specific word embeddings with a label propagation framework to induce accurate domain - specific sentiment lexicons using small sets of seed words .",
        "we generalize the embedding layer of the encoder in the attentional encoder - - decoder architecture to support the inclusion of arbitrary features , in addition to the baseline word feature .",
        "various systems using word overlap , neural embeddings and neural compositional models are evaluated on two datasets of learner writing .",
        "we propose a new method for sentence - level similarity calculation , which learns to adjust the weights of pre - trained word embeddings for a specific task , achieving substantially higher accuracy compared to other relevant baselines .",
        "text embeddings have played a key role in obtaining state - of - the - art results in natural language processing .",
        "however , extracting universal embeddings of longer word - sequences remains a challenging task .",
        "we employ the convolutional dictionary model for unsupervised learning of embeddings for variable length word - sequences .",
        "the estimated activations are then used as embeddings for downstream tasks such as sentiment analysis , paraphrase detection , and semantic textual similarity estimation .",
        "our word - sequence embeddings achieve state - of - the - art performance in sentiment classification , semantic textual similarity estimation , and paraphrase detection over eight datasets from",
        "psdvec is a python / perl toolbox that learns word embeddings , i .",
        "psdvec implements a word embedding learning method based on a weighted low - rank positive semidefinite approximation .",
        "to scale up the learning process , we implement a blockwise online learning algorithm to learn the embeddings incrementally .",
        "this strategy greatly reduces the learning time of word embeddings on a large vocabulary , and can learn the embeddings of new words without re - learning the whole vocabulary .",
        "on 9 word similarity / analogy benchmark sets and 2 natural language processing ( nlp ) tasks , psdvec produces embeddings that has the best average performance among popular word embedding tools .",
        "since wordnet embeds natural language in the form of a complex network , a transformation mechanism wordnet2vec is proposed in the paper .",
        "this paper reviews machine learning applications and approaches to detection , classification and control of intelligent materials and structures with embedded distributed computation elements .",
        "we trained embeddings of words and phrases with the word2vec skip - gram method , then used those features to learn sentence representations via a hashtag prediction auxiliary task .",
        "neural models capitalize on word embeddings as features , tuning these to the task at hand .",
        "we argue that al strategies for neural text classification should focus on selecting instances that most affect the embedding space ( i .",
        "we propose a simple approach that selects instances containing words whose embeddings are likely to be updated with the greatest magnitude , thereby rapidly learning discriminative , task - specific embeddings .",
        "maximum mean discrepancy ( mmd ) has been successfully applied to learn deep generative models for characterizing a joint distribution of variables via kernel mean embedding .",
        "we propose a tagging model using wsabie , a discriminative embedding - based model with rank - based learning .",
        "we present the siamese continuous bag of words ( siamese cbow ) model , a neural network for efficient estimation of high - quality sentence embeddings .",
        "averaging the embeddings of words in a sentence has proven to be a surprisingly successful and efficient way of obtaining sentence embeddings .",
        "however , word embeddings trained with the methods currently available are not optimized for the task of sentence representation , and , thus , likely to be suboptimal .",
        "siamese cbow handles this problem by training word embeddings directly for the purpose of being averaged .",
        "the underlying neural network learns word embeddings by predicting , from a sentence representation , its surrounding sentences .",
        "word embeddings play a significant role in many modern nlp systems .",
        "however , most used word embedding learning methods learn one representation per word which is problematic for polysemous words and homonymous words .",
        "to address this problem , we propose a multi - phase word sense embedding retrofitting method which utilizes a lexical ontology to learn one embedding per word sense .",
        "experimental results on word similarity task show that our approach remarkablely improves the quality of embeddings .",
        "one - shot learning is usually tackled by using generative models or discriminative embeddings .",
        "the model can be conditioned on any vector , including descriptive labels or tags , or latent embeddings created by other networks .",
        "when conditioned on an embedding produced by a convolutional network given a single image of an unseen face , it generates a variety of new portraits of the same person with different facial expressions , poses and lighting conditions .",
        "in this work , we propose to learn sense embeddings for the wsi task .",
        "in the training stage , our method induces several sense centroids ( embedding ) for each polysemous word .",
        "in the testing stage , our method represents each instance as a contextual vector , and induces its sense by finding the nearest sense centroid in the embedding space .",
        "for each model , we investigate four implementations : a \" standard \" n - gram language model and three discriminatively trained \" neural \" language models that generate embeddings for semantic frames .",
        "universal schema predicts the types of entities and relations in a knowledge base ( kb ) by jointly embedding the union of all available schema types - - - not only types from multiple structured databases ( such as freebase or wikipedia infoboxes ) , but also types expressed as textual patterns from raw text .",
        "factorizing this sparsely observed matrix yields a learned vector embedding for each row and each column .",
        "in this paper we explore the problem of making predictions for entities or entity - pairs unseen at training time ( and hence without a pre - learned row embedding ) .",
        "it has been recently proposed that the cnl approach could be scaled up , building on the concept of embedded cnl and , thus , allowing for cnl - based information extraction from e .",
        "word embedding , specially with its recent developments , promises a quantification of the similarity between terms .",
        "we first observe and quantify the uncertainty factor of the word embedding models regarding to the similarity value .",
        "however , here we make use of complex valued embeddings .",
        "the composition of complex embeddings can handle a large variety of binary relations , among them symmetric and antisymmetric relations .",
        "compared to state - of - the - art models such as neural tensor network and holographic embeddings , our approach based on complex embeddings is arguably simpler , as it only uses the hermitian dot product , the complex counterpart of the standard dot product between real vectors .",
        "in this paper , we define a novel entity representation as a mixture of its neighborhood in the knowledge base and apply this technique on transe - a well - known embedding model for knowledge base completion .",
        "experimental results show that the neighborhood information significantly helps to improve the results of the transe , leading to better performance than obtained by other state - of - the - art embedding models on three benchmark datasets for triple classification , entity prediction and relation prediction tasks .",
        "we also examined the structure of the representation of tactile stimuli in the recorded tactile sensor data using t - sne embeddings .",
        "we investigate the integration of word embeddings as classification features in the setting of large scale text classification .",
        "in this work , we examine efficient composition functions to obtain document - level from word - level embeddings and we subsequently investigate their combination with the traditional one - hot - encoding representations .",
        "the new structure can be easily embedded into many popular rnn models , including lstms and grus .",
        "blstm ) or the augmentation with pre - trained word embeddings can be important and clearly impact the accuracy .",
        "recently , the rapid development of word embedding and neural networks has brought new inspiration to various nlp and ir tasks .",
        "the system uses a bayesian modelling framework with segmental word representations : each word segment is represented as a fixed - dimensional acoustic embedding obtained by mapping the sequence of feature frames to a single embedding vector .",
        "this paper presents preliminary works on using word embedding ( word2vec ) for query expansion in the context of personalized information retrieval .",
        "traditionally , word embeddings are learned on a general corpus , like wikipedia .",
        "in this work we try to personalize the word embeddings learning , by achieving the learning on the user ' s profile .",
        "the word embeddings are then in the same context than the user interests .",
        "the results obtained show that some efforts should be made in the way to apply word embedding in the context of personalized information retrieval .",
        "word embeddings and convolutional neural networks ( cnn ) have attracted extensive attention in various classification tasks for twitter , e .",
        "however , the effect of the configuration used to train and generate the word embeddings on the classification performance has not been studied in the existing literature .",
        "in this paper , using a twitter election classification task that aims to detect election - related tweets , we investigate the impact of the background dataset used to train the embedding models , the context window size and the dimensionality of word embeddings on the classification performance .",
        "by comparing the classification results of two word embedding models , which are trained using different background corpora ( e .",
        "moreover , by evaluating the results of word embeddings models trained using various context window sizes and dimensionalities , we found that large context window and dimension sizes are preferable to improve the performance .",
        "our experimental results also show that using word embeddings and cnn leads to statistically significant improvements over various baselines such as random , sv",
        "the goal of ordinal embedding is to represent items as points in a low - dimensional euclidean space given a set of constraints in the form of distance comparisons like \" item $ i $ is closer to item $ j $ than item $ k $ \" .",
        "first , we derive prediction error bounds for ordinal embedding with noise by exploiting the fact that the rank of a distance matrix of points in $ \\ mathbb { r } ^ d $ is at most $ d + 2 $ .",
        "these bounds characterize how well a learned embedding predicts new comparative judgments .",
        "third , knowledge of the noise model enables us to relate prediction errors to embedding accuracy .",
        "with this in mind , we argue that embedding kbs within deep neural architectures supporting documentquery matching would give rise to fine - grained latent representations of both words and their semantic relations .",
        "word embedding has been shown to be remarkably effective in a lot of natural language processing tasks .",
        "also it can be used as an evaluation measure of the quality of word embedding .",
        "we propose minimizing a joint objective which can learn from diverse data sources and leverage distributional semantic embeddings , enabling the model to generalize and describe novel objects outside of image - caption datasets .",
        "since its introduction , word2vec and its variants are widely used to learn semantics - preserving representations of words or entities in an embedding space , which can be used to produce state - of - art results for various natural language processing tasks .",
        "figment is embedding - based and combines ( i ) a global model that scores based on aggregated contextual information of an entity and ( ii ) a context model that first scores the individual occurrences of an entity and then aggregates the scores .",
        "an acoustic scene instance is then embedded into a low - dimensional feature representation which consists of the likelihoods that it belongs to the meta - classes .",
        "neural language models or the learning of word - embeddings , often posed as predicting the probability of next words among a vocabulary of size d ( e .",
        "we also empirically study the use of generalised distillation , and a novel alternative model that directly predicts item embeddings .",
        "this paper combines insights from several previous link prediction models into a new embedding model stranse that represents each entity as a low - dimensional vector , and each relation by two matrices and a translation vector .",
        "stranse is a simple combination of the se and transe models , but it obtains better link prediction performance on two benchmark datasets than previous embedding models .",
        "in taja - seq2seq , information from input posts and information from topics related to the posts are simultaneously embedded into vector spaces by a content encoder and a topic encoder respectively .",
        "we map entity - tuple embeddings into an approximately boolean space and encourage a partial ordering over relation embeddings based on implication rules mined from wordnet .",
        "surprisingly , we find that the strong restriction of the entity - tuple embedding space does not hurt the expressiveness of the model and even acts as a regularizer that improves generalization .",
        "in these cases , one may want to embed additional prior knowledge into the optimization problem associated with the training of the learning machine , modeled , respectively , by the symmetry of its optimal solution with respect to an exchange of order between the two objects , and by its antisymmetry .",
        ", 2012 ) ( where the only symmetric case was considered ) , we show , focusing on support vector binary classification , how such embedding is possible through the choice of a suitable pairwise kernel , which takes as inputs the individual feature vectors and also the group feature vectors associated with the two objects .",
        "in this work , a novel binary embedding method , termed adaptive training quantization ( atq ) , is proposed to learn the ideal transform of random encoder , where the limitation of cosine random mapping is tackled .",
        "we also utilize convolution neural network ( cnn ) in cascade of rnn to get character - based embedded features and employ it with word - embedded features in our model .",
        "crosslingual word embeddings represent lexical items from different languages in the same vector space , enabling transfer of nlp tools .",
        "word embeddings have recently seen a strong increase in interest as a result of strong performance gains on a variety of tasks .",
        "in this paper we demonstrate the performance of multiple types of embeddings , created with both count and prediction - based architectures on a variety of corpora , in two language - specific tasks : relation evaluation , and dialect identification .",
        "with this research , we provide the embeddings themselves , the relation evaluation task benchmark for use in further research , and demonstrate how the benchmarked embeddings prove a useful unsupervised linguistic resource , effectively used in a downstream task .",
        "we constructed a method based on semantic word embeddings and frequency information to arrive at low - dimensional representations for short texts designed to capture semantic similarity .",
        "we find that our method outperforms the baseline approaches in the experiments , and that it generalizes well on different word embeddings without retraining .",
        "that is , the continuous vector representation , or a word embedding vector , of a symbol encodes multiple dimensions of similarity , equivalent to encoding more than one meaning of the word .",
        "based on this observation , in this paper we propose to contextualize the word embedding vectors using a nonlinear bag - of - words representation of the source sentence .",
        "we present charagram embeddings , a simple approach for learning character - based compositional models to embed textual sequences .",
        "a word or sentence is represented using a character n - gram count vector , followed by a single nonlinear transformation to yield a low - dimensional embedding .",
        "we demonstrate that charagram embeddings outperform more complex architectures based on character - level recurrent and convolutional neural networks , achieving new state - of - the - art performance on several similarity tasks .",
        "such a danger is facing us with word embedding , a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks .",
        "we show that even word embeddings trained on google news articles exhibit female / male gender stereotypes to a disturbing extent .",
        "geometrically , gender bias is first shown to be captured by a direction in the word embedding .",
        "second , gender neutral words are shown to be linearly separable from gender definition words in the word embedding .",
        "using these properties , we provide a methodology for modifying an embedding to remove gender stereotypes , such as the association between between the words receptionist and female , while maintaining desired associations such as between the words queen and female .",
        "we define metrics to quantify both direct and indirect gender biases in embeddings , and develop algorithms to \" debias \" the embedding .",
        "word embeddings are a powerful approach for capturing semantic similarity among terms in a vocabulary .",
        "in this paper , we develop exponential family embeddings , a class of methods that extends the idea of word embeddings to other types of high - dimensional data .",
        "each type of embedding model defines the context , the exponential family of conditional distributions , and how the latent embedding vectors are shared across data .",
        "we infer the embeddings with a scalable algorithm based on stochastic gradient descent .",
        "on all three applications - neural activity of zebrafish , users ' shopping behavior , and movie ratings - we found exponential family embedding models to be more effective than other types of dimension",
        "word embeddings allow natural language processing systems to share statistical information across related words .",
        "these embeddings are typically based on distributional statistics , making it difficult for them to generalize to rare or unseen words .",
        "we propose to improve word embeddings by incorporating morphological information , capturing shared sub - word features .",
        "unlike previous work that constructs word embeddings directly from morphemes , we combine morphological and distributional information in a unified probabilistic framework , in which the word embedding is a latent variable .",
        "the morphological information provides a prior distribution on the latent word embeddings , which in turn condition a likelihood function over an observed corpus .",
        "the parsing procedure for each direction is formulated as sequentially querying the memory component that stores continuous headword embeddings .",
        "the proposed parser makes use of soft headword embeddings , allowing the model to implicitly capture high - order parsing history without dramatically increasing the computational complexity .",
        "the analysis sheds light on the relative strengths of different sentence embedding methods with respect to these low level prediction tasks , and on the effect of the encoded vector ' s dimensionality on the resulting representations .",
        "by applying our method on well known chaotic systems , we provide evidence that the lower dimensional embedding retains the dynamical properties of the underlying system better than the full - dimensional internal states of the network .",
        "while cross - lingual word embeddings have been studied extensively in recent years , the qualitative differences between the different algorithms remains vague .",
        "this feature set is also used by traditional alignment algorithms , such as ibm model - 1 , which demonstrate similar performance to state - of - the - art embedding algorithms on a variety of benchmarks .",
        "this paper draws both empirical and theoretical parallels between the embedding and alignment literature , and suggests that adding additional sources of information , which go beyond the traditional signal of bilingual sentence - aligned corpora , is an appealing approach for substantially improving crosslingual word embeddings .",
        "recent work has demonstrated that state - of - the - art word embedding models require different context types to produce high - quality representations for different word classes such as adjectives ( a ) , verbs ( v ) , and nouns ( n ) .",
        "we replicate these using a widely used , purely statistical machine - learning model - - - namely , the glove word embedding - - - trained on a corpus of text from the web .",
        "in this short paper , we propose the split - diffuse ( sd ) algorithm that takes the output of an existing word embedding algorithm , and distributes the data points uniformly across the visualization space .",
        "knowledge representation is a critical topic in ai , and currently embedding as a key branch of knowledge representation takes the numerical form of entities and relations to joint the statistical models .",
        "however , most embedding methods merely concentrate on the triple fitting and ignore the explicit semantic expression , leading to an uninterpretable representation form .",
        "thus , traditional embedding methods do not only degrade the performance , but also restrict many potential applications .",
        "we evaluated this metric in a similarity estimation task on several popular test sets , and our results show that apsyn is in fact highly competitive , even with respect to the results reported in the literature for word embeddings .",
        "in this paper we propose the application of feature hashing to create word embeddings for natural language processing .",
        "in this work we show that feature hashing can be applied to obtain word embeddings in linear time with the size of the data .",
        "as far as we know this is the first application of feature hashing to the word embeddings problem and the results indicate this is a scalable technique with practical results for nlp applications .",
        "in this paper we extend these methods by embedding a measure of semantic similarity based on a human curated taxonomy into a second - - order vector representation .",
        "our results show that embedding semantic semantic similarity into a second order co - - occurrence matrix improves correlation with human judgments for both similarity and relatedness .",
        "though , they also carry along with some attendant problems , such as corpus selection for embedding learning , dictionary transformation for different learning tasks , etc .",
        "in this paper , we propose to straightforwardly model sentences by means of character sequences , and then utilize convolutional neural networks to integrate character embedding learning together with point - wise answer selection training .",
        "compared with deep models pre - trained on word embedding ( we ) strategy , our character - sequential representation ( csr ) based method shows a much simpler procedure and more stable performance across different benchmarks .",
        "we thus provide a unified formulation for two main language processing tasks , namely word embedding and language modeling , based on the neg objective function .",
        "recently , stochastic neighbor embedding ( sne ) methods have widely been applied in data visualization .",
        "furthermore , we show empirically and theoretically that the doubly stochasticity constraint often leads to approximately spherical embeddings .",
        "this suggests replacing a flat space with spheres as the embedding space .",
        "the spherical embedding eliminates the discrepancy between the center and the periphery in visualization and thus resolves the \" crowding problem \" .",
        "within evolutionary processes , the implicit utility function is always reducible to persistence , and the control of superhuman intelligences embedded in evolutionary processes is not possible .",
        "we achieve competitive results for two - point scale sentiment classification and quantification , ranking fifth and a close fourth ( third and second by alternative metrics ) respectively despite using only pre - trained embeddings that contain no sentiment information .",
        "to determine the sentiment towards an aspect , we concatenate an aspect vector with every word embedding and apply a convolution over it .",
        "to accurately capture the fine grained nonlinear coevolution of these features , we propose a recurrent coevolutionary feature embedding process model , which combines recurrent neural network ( rnn ) with a multidimensional point process model .",
        "we compare policy differences across institutions by embedding representations of the entire legal corpus of each institution and the vocabulary shared across all corpora into a continuous vector space .",
        "note our general inference framework can readily be applied to other topic models with embedded pdp nodes .",
        "the proposed network , redundant convolutional encoder decoder ( r - ced ) , demonstrates that a convolutional network can be 12 times smaller than a recurrent network and yet achieves better performance , which shows its applicability for an embedded system : the hearing aids .",
        "the derivative delay embedding ( dde ) is developed to incrementally transform time series to the embedding space , where the intrinsic characteristics of data is preserved as recursive patterns regardless of the stream length and misalignment .",
        "given a sequence of characters , our model embeds each character in vector space , runs the sequence through multiple convolutions with different filter widths , and pools the convolutional representations to obtain a hidden vector representation of the text that is used for predicting the language or dialect .",
        "as such , the word - lattice based encoders not only alleviate the negative impact of tokenization errors but also are more expressive and flexible to embed input sentences .",
        "thanks to its high degree of structure , our architecture has a very small memory footprint and thus fits onto low - power embedded and mobile platforms .",
        "non - linear models recently receive a lot of attention as people are starting to discover the power of statistical and embedding features .",
        "a common model for question answering ( qa ) is that a good answer is one that is closely related to the question , where relatedness is often determined using general - purpose lexical models such as word embeddings .",
        "we argue that a better approach is to look for answers that are related to the question in a relevant way , according to the information need of the question , which may be determined through task - specific embeddings .",
        "first , we generate causal embeddings cost - effectively by bootstrapping cause - effect pairs extracted from free text using a small set of seed patterns .",
        "second , we train dedicated embeddings over this data , by using task - specific contexts , i .",
        "finally , we extend a state - of - the - art reranking approach for qa to incorporate these causal embeddings .",
        "we evaluate the causal embedding models both directly with a casual implication task , and indirectly , in a downstream causal qa task using data from yahoo !",
        "omvfs embeds unsupervised feature selection into a",
        "many current natural language processing applications for social media rely on representation learning and utilize pre - trained word embeddings .",
        "there currently exist several publicly - available , pre - trained sets of word embeddings , but they contain few or no emoji representations even as emoji usage in social media has increased .",
        "in this paper we release emoji2vec , pre - trained embeddings for all unicode emoji which are learned from their description in the unicode emoji standard .",
        "the resulting emoji embeddings can be readily used in downstream social natural language processing applications alongside word2vec .",
        "we demonstrate , for the downstream task of sentiment analysis , that emoji embeddings learned from short descriptions outperforms a skip - gram model trained on a large collection of tweets , while avoiding the need for contexts in which emoji need to appear frequently in order to estimate a representation .",
        "based on recent results in word embeddings that learn se - mantically representations for words from a large corpus , we introduce a novel method , embedding - based topic model ( etm ) , to learn latent topics from short texts .",
        "in this paper we experiment with context and embedding - based selection methods and extend previous work by examining speed and accuracy trade - offs in more detail .",
        "the purpose of this paper is demonstrating that their vector representation based on word embedding provides insights onto many linguistic phenomena , and in particular about verbs undergoing the causative - inchoative alternation .",
        "in this paper , we develop a chinese event extraction system that uses word embedding vectors to represent language , and deep neural networks to learn the abstract feature representation in order to greatly reduce the effort of feature engineering .",
        "our experiments show that our proposed method performs better compared to the system using rich language features , and using unlabeled data benefits the word embeddings .",
        "this study suggests the potential of dnn and word embedding for the event extraction task .",
        "we explore if prior work can be enhanced using semantic similarity / discordance between word embeddings .",
        "we augment word embedding - based features to four feature sets reported in the past .",
        "we also experiment with four types of word embeddings .",
        "we observe an improvement in sarcasm detection , irrespective of the word embedding used or the original feature set to which our features are augmented .",
        "for example , this augmentation results in an improvement in f - score of around 4 \\ % for three out of these four feature sets , and a minor degradation in case of the fourth , when word2vec embeddings are used .",
        "finally , a comparison of the four embeddings shows that word2vec and dependency weight - based features outperform lsa and glove , in terms of their benefit to sarcasm detection .",
        "word embeddings have been extensively studied in large text datasets .",
        "moreover , we show how to inject pre - trained word embeddings into our model in order to improve generalization across examples with similar pivot features .",
        "word embeddings have been demonstrated to benefit nlp tasks impressively .",
        "yet , there is room for improvement in the vector representations , because current word embeddings typically contain unnecessary information , i .",
        "we propose two novel models to improve word embeddings by unsupervised learning , in order to yield word denoising embeddings .",
        "the word denoising embeddings are obtained by strengthening salient information and weakening noise in the original word embeddings , based on a deep feed - forward neural network filter .",
        "results from benchmark tasks show that the filtered word denoising embeddings outperform the original word embeddings .",
        "we propose three data representation techniques based on the characteristics of word distribution and word similarities as a result of word embedding training .",
        "for this , we present several network visualizations based on activation clusters , first derivative saliency , and embedding space transformations , helping us automatically identify several subtle linguistics markers of politeness theories .",
        "these are merged with the word embedding or with a sentence embedding of the question to predict the answer .",
        "applying dropout on the dynamic filters can be seen as drop on words directly , which is superior to the regular dropout on word embeddings .",
        "this paper investigates the problem of network embedding , which aims at learning low - dimensional vector representation of nodes in networks .",
        "most existing network embedding methods rely solely on the network structure , i .",
        "in this paper , we propose content - enhanced network embedding ( cene ) , which is capable of jointly leveraging the network structure and the content information .",
        "experiments on several real world net - works with application to node classification show that our models outperform all existing network embedding methods , demonstrating the merits of content information and joint learning .",
        "evaluation results demonstrate that our model outperforms sequence to sequence , attention - based and bi - directional lstm models on bleu , meteor , ter and an embedding - based sentence similarity metric .",
        "in this work we implement a training of a language model ( lm ) , using recurrent neural network ( rnn ) and glove word embeddings , introduced by pennigton et al .",
        "such approaches are time - and memory - intensive because of the large numbers of parameters for word embeddings and the output layer .",
        "we propose an embedding - enhanced texttiling approach , inspired by the observation that conversation utterances are highly noisy , and that word embeddings provide a robust way of capturing semantics .",
        "the proposed method can also be implemented on any other embedded microcontroller system .",
        "the dependence measure is the difference between analytic embeddings of the joint distribution and the product of the marginals , evaluated at a finite set of locations ( features ) .",
        "in this work we introduce vrpbench , a tool to create instances and visualize solutions to the vehicle routing problem ( vrp ) in a planar graph embedded in the euclidean 2d space .",
        "our models include bag - of - words features ( bow ) , syntactic tree kernels ( tks ) , rank features , embeddings , and machine translation evaluation features .",
        ", recommender systems , topic modeling and word embedding .",
        "for this reason , this paper employs bidirectional lstm with crf decoding initialized with general purpose off - the - shelf word embeddings for ce .",
        "with the advent of word embeddings , lexicons are no longer fully utilized for sentiment analysis although they still provide important features in the traditional setting .",
        "this paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into convolutional neural networks .",
        "our approach performs separate convolutions for word and lexicon embeddings and provides a global view of the document using attention .",
        "our analysis shows that lexicon embeddings allow to build high - performing models with much smaller word embeddings , and the attention mechanism effectively dims out noisy words for sentiment analysis .",
        "secondly , by qualitatively studying attention plots from the decoder we find that the model learns to compress common words into a single embedding whereas rare words , such as names and places , are represented character by character .",
        "we demonstrate that such a network generalizes across a diversity of artistic styles by reducing a painting to a point in an embedding space .",
        "in the first part we discuss word embeddings .",
        "we also compare them to image embeddings and see how word embedding and image embedding can be combined to perform different tasks .",
        "the network is used for several sentence - level classification tasks , and achieves state - of - art ( or comparable ) results , demonstrating the great power of pre - trainted word embeddings over random ones .",
        "in this paper , we employ knowledge - based approaches that also exploit recent advances in neural word / concept embeddings to improve over the state - of - the - art in biomedical wsd using the msh wsd dataset as the test set .",
        "this paper investigates the use of word embeddings to help identify gang members on twitter .",
        "building on our previous work , we generate word embeddings that translate what twitter users post in their profile descriptions , tweets , profile images , and linked youtube content to a real vector format amenable for machine learning classification .",
        "our experimental results show that pre - trained word embeddings can boost the accuracy of supervised learning algorithms trained over gang members social media posts .",
        "existing deep embedding methods in vision tasks are capable of learning a compact euclidean space from images , where euclidean distances correspond to a similarity metric .",
        "the metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner .",
        "our local similarity - aware feature embedding not only demonstrates faster convergence and boosted performance on two complex image retrieval datasets , its large margin nature also leads to superior generalization results under the large and open set scenarios of transfer learning and zero - shot learning on imagenet 2010 and",
        "we first explore the embedding space and show that our vectors capture meaningful construction - specific concepts .",
        "without any parameter tuning , our embeddings give competitive results , and outperform the google news vectors in many cases .",
        "although similarity search in hins has been studied previously , most existing approaches neither explore rich semantic information embedded in the network structures nor take user ' s preference as a guidance .",
        "the key idea is to use 2 - component ( 2c ) shared embedding for word representations .",
        "based on the 2 - component shared embedding ,",
        "most of the existing graph embedding methods focus on nodes , which aim to output a vector representation for each node in the graph such that two nodes being \" close \" on the graph are close too in the low - dimensional space .",
        "despite the success of embedding individual nodes for graph analytics , we notice that an important concept of embedding communities ( i .",
        "embedding communities is useful , not only for supporting various community - level applications , but also to help preserve community structure in graph embedding .",
        "in fact , we see community embedding as providing a higher - order proximity to define the node closeness , whereas most of the popular graph embedding methods focus on first - order and / or second - order proximities .",
        "to learn the community embedding , we hinge upon the insight that community embedding and node embedding reinforce with each other .",
        "as a result , we propose comembed , the first community embedding method , which jointly optimizes the community embedding and node embedding together .",
        "we evaluate comembed on real - world data sets .",
        "to address this problem , we propose to learn sentiment - specific word embedding by exploiting both lexicon resource and distant supervised information .",
        "we develop a multi - level sentiment - enriched word embedding learning method , which uses parallel asymmetric neural network to model n - gram , word level sentiment and tweet level sentiment in learning process .",
        "in practice , the current deep embedding methods use the euclidean distance for the training and test .",
        "intra - class ) training samples within a local range is critical for training the cnn embedding , especially when the data has large intra - class variations .",
        "in this paper , we propose a product - based neural networks ( pnn ) with an embedding layer to learn a distributed representation of the categorical data , a product layer to capture interactive patterns between inter - field categories , and further fully connected layers to explore high - order feature interactions .",
        "we introduce a multiple input deep regression model to predict the cf latent embedding vectors of items based on their textual description and metadata .",
        "then we propose an efficient method to use the fuzzy paraphrases to learn word embeddings .",
        "we approximately estimate the local membership of paraphrases , and train word embeddings using a lexicon jointly by replacing the words in the contexts with their paraphrases randomly subject to the membership of each paraphrase .",
        "this criterion is based on a deep metric embedding over distance relations within the set of labeled samples , together with constraints over the embeddings of the unlabeled set .",
        "we propose a language - agnostic way of automatically generating sets of semantically similar clusters of entities along with sets of \" outlier \" elements , which may then be used to perform an intrinsic evaluation of word embeddings in the outlier detection task .",
        "we used our methodology to create a gold - standard dataset , which we call wikisem500 , and evaluated multiple state - of - the - art embeddings .",
        "ltls embeds large classification problems into simple structured prediction problems and relies on efficient dynamic programming algorithms for inference .",
        "however , dnn - based methods are both computational - intensive and resource - consuming , which hinders the application of these methods on embedded systems like smart phones .",
        "with machine learning penetrating low - power mobile and embedded areas , the need to optimize not only for performance ( accuracy ) , but also for implementation complexity , becomes paramount .",
        "dscnn hierarchically builds textual representations by processing pretrained word embeddings via long short - term memory networks and subsequently extracting features with convolution operators .",
        "acoustic word embeddings - - - fixed - dimensional vector representations of variable - length spoken word segments - - - have begun to be considered for tasks such as speech recognition and query - by - example search .",
        "such embeddings can be learned discriminatively so that they are similar for speech segments corresponding to the same word , while being dissimilar for segments corresponding to different words .",
        "recent work has found that acoustic word embeddings can outperform dynamic time warping on query - by - example search and related word discrimination tasks .",
        "however , the space of embedding models and training approaches is still relatively unexplored .",
        "in this paper we present new discriminative embedding models based on recurrent neural networks ( rnns ) .",
        "we find that both classifier - based and siamese rnn embeddings improve over previously reported results on a word discrimination task , with siamese rnns outperforming classification models .",
        "embedding and visualizing large - scale high - dimensional data in a two - dimensional space is an important problem since such visualization can reveal deep insights out of complex data .",
        "most of the existing embedding approaches , however , run on an excessively high precision , ignoring the fact that at the end , embedding outputs are converted into coarse - grained discrete pixel coordinates in a screen space .",
        "motivated by such an observation and directly considering pixel coordinates in an embedding optimization process , we accelerate barnes - hut tree - based t - distributed stochastic neighbor embedding ( bh - sne ) , known as a state - of - the - art 2d embedding method , and propose a novel method called pixelsne , a highly - efficient , screen resolution - driven 2d embedding method with a linear computational complexity in terms of the number of data items .",
        "our experimental results show the significantly fast running time of pixelsne by a large margin against bh - sne , while maintaining the minimal degradation in the embedding quality .",
        "the empirical evaluation was done using fully implemented translation systems embedded into the mapreduce programming model .",
        "word embeddings are now ubiquitous forms of word representation in natural language processing .",
        "there have been applications of word embeddings for monolingual word sense disambiguation ( wsd ) in english , but few comparisons have been done .",
        "this paper attempts to bridge that gap by examining popular embeddings for the task of monolingual english wsd .",
        "thus we have also applied word embeddings to the novel task of cross - lingual wsd for chinese and provide a public dataset for further benchmarking .",
        "we have also experimented with using word embeddings for lstm networks and found surprisingly that a basic lstm network does not work well .",
        "this position paper advocates a communications - inspired approach to the design of machine learning systems on energy - constrained embedded ` always - on ' platforms .",
        "many recent works have demonstrated the benefits of knowledge graph embeddings in completing monolingual knowledge graphs .",
        "thus , we propose mtranse , a translation - based model for multilingual knowledge graph embeddings , to provide a simple and automated solution .",
        "by encoding entities and relations of each language in a separated embedding space , mtranse provides transitions for each embedding vector to its cross - lingual counterparts in other spaces , while preserving the functionalities of monolingual embeddings .",
        "in this work , we propose a novel framework to embed words , entities and relations into the same continuous vector space .",
        "in this model , both entity and relation embeddings are learned by taking knowledge graph and plain text into consideration .",
        "the constraints guide us to learn knowledge enhanced embeddings ( kee ) from large text corpus .",
        "sequence labeling architectures use word embeddings for capturing similarity , but suffer when handling previously unseen or rare words .",
        "we first present an embedding - based question - to - expert distance metric for expertise matching and propose a ranking factor graph ( rankfg ) model to predict expert response .",
        "recent work has begun exploring neural acoustic word embeddings - - fixed - dimensional vector representations of arbitrary - length speech segments corresponding to words .",
        "such embeddings are applicable to speech retrieval and recognition tasks , where reasoning about whole words may make it possible to avoid ambiguous sub - word representations .",
        "in this work we take a multi - view approach to learning acoustic word embeddings , in which we jointly learn to embed acoustic sequences and their corresponding character sequences .",
        "we use deep bidirectional lstm embedding models and multi - view contrastive losses .",
        "our acoustic word embeddings improve over previous approaches for the task of word discrimination .",
        ", no parallel corpora ) using multimodal embedded representation over texts and images .",
        "recent studies on knowledge base completion , the task of recovering missing relationships based on recorded relations , demonstrate the importance of learning embeddings from multi - step relations .",
        "for similarity computation at a finer granularity , we tune the alignment algorithm by integrating it with a word embedding matrix based topic - to - topic similarity measure .",
        "we consider an erdos - renyi graph with $ n $ nodes and edge probability $ q $ that is embedded with a random subgraph of size $ k $ with edge probabilities $ p $ such that $ p & gt ; q $ .",
        "our work presented here constitutes the first step in opening the black - box of vector embedding for social media posts , with emphasis on tweets in particular .",
        "experiments show that the performance of cdcl solvers can be significantly boosted by embedding domain - specific heuristics , especially on large real - world problems .",
        "to address this challenge , a number of knowledge graph completion methods have been developed using low - dimensional graph embeddings .",
        "in this work , we present a shared variable neural network model called proje that fills - in missing information in a knowledge graph by learning joint embeddings of the knowledge graph ' s entities and edges , and through subtle , but important , changes to the standard loss function .",
        "we propose and evaluate several strategies for achieving zero - shot vqa , including methods based on pretrained word embeddings , object classifiers with semantic embeddings , and test - time retrieval of example images .",
        "neural network based models are a very powerful tool for creating word embeddings , the objective of these models is to group similar words together .",
        "these embeddings have been used as features to improve results in various applications such as document classification , named entity recognition , etc .",
        "each text will alter the embeddings of the words to represent the meaning of the word inside that text .",
        "more specifically , we learn a semantic embedding ( v ) corresponding to each frame ( k ) in the video , thereby creating ( k , v ) memory slots .",
        "exploiting this flexibility of the framework , we additionally capture spatial dependencies while mapping from the visual to semantic embedding .",
        "concerning inference on embedded systems we evaluate these bitwise networks using a hardware efficient stochastic rounding procedure .",
        "our work contributes to efficient embedded bitwise neural networks .",
        "however , paragraph ( or sentence and document ) embedding learning is more suitable / reasonable for some tasks , such as sentiment classification and document summarization .",
        "nevertheless , as far as we are aware , there is relatively less work focusing on the development of unsupervised paragraph embedding methods .",
        "classic paragraph embedding methods infer the representation of a given paragraph by considering all of the words occurring in the paragraph .",
        "consequently , those stop or function words that occur frequently may mislead the embedding learning process to produce a misty paragraph representation .",
        "first , we propose a novel unsupervised paragraph embedding method , named the essence vector ( ev ) model , which aims at not only distilling the most representative information from a paragraph but also excluding the general background information to produce a more informative low - dimensional vector representation for the paragraph .",
        "in this paper , we study the problem of how to better embed entities and relations into different low dimensional spaces .",
        "a compositional learning model of relation paths embedding ( rpe ) is proposed to take full advantage of additional semantic information expressed by relation paths .",
        "more specifically , using corresponding projection matrices , rpe can simultaneously embed entities into corresponding relation and path spaces .",
        "to this end , we instantiate two policy gradient based algorithms , one that creates an explicit embedding space of options and one that represents options implicitly .",
        "to alleviate these challenges , we propose a novel framework named hnil which encodes not only the question contents but also the askers social interactions to enhance the question embedding performance .",
        "in this paper , we focus on training and evaluating effective word embeddings with both text and visual information .",
        "in addition , we construct an evaluation dataset to directly assess the effectiveness of word embeddings in terms of finding semantically similar or related words and phrases .",
        "experiments show that our model benefits from incorporating the visual information into the word embeddings , and a weight sharing strategy is crucial for learning such multimodal embeddings .",
        "random embedding has been applied with empirical success to large - scale black - box optimization problems with low effective dimensions .",
        "this paper proposes the embeddedhunter algorithm , which incorporates the technique in a hierarchical stochastic bandit setting , following the optimism in the face of uncertainty principle and breaking away from the multiple - run framework in which random embedding has been conventionally applied similar to stochastic black - box optimization solvers .",
        "in essence , the embeddedhunter algorithm expands optimistically a partitioning tree over a low - dimensional - - - equal to the effective dimension of the problem - - - search space based on a bounded number of random embeddings of sampled points from the low - dimensional space .",
        "in contrast to the probabilistic theoretical guarantees of multiple - run random - embedding algorithms , the finite - time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm ' s number of iterations .",
        "we propose a novel deep learning framework for single channel speech separation by creating attractor points in high dimensional embedding space of the acoustic signals which pull together the time - frequency bins corresponding to each source .",
        "attractor points in this study are created by finding the centroids of the sources in the embedding space , which are subsequently used to determine the similarity of each bin in the mixture to each source .",
        "the network is then trained to minimize the reconstruction error of each source by optimizing the embeddings .",
        "the model is trained on a visual search task requiring the classification of an object embedded in a visual scene amidst background distractors using the smallest number of fixations .",
        "the key insight is to connect compositionality to a curious geometric property of word embeddings , which is of independent interest .",
        "with this reinforced random walk as a general process embedded in classical topic models , we obtain \\ textit { diverse topic models } that are able to extract the most prominent and diverse topics from data .",
        "we demonstrate an improved method for building conditional models , the co - embedding deep variational auto encoder .",
        "in this paper , we study whether it is possible to utilize distributed representations to generate dictionary definitions of words , as a more direct and transparent representation of the embeddings ' semantics .",
        "we introduce definition modeling , the task of generating a definition for a given word and its embedding .",
        "our results show that a model that controls dependencies between the word being defined and the definition words performs significantly better , and that a character - level convolution layer designed to leverage morphology can complement word - level embeddings .",
        "finally , an error analysis suggests that the errors made by a definition model may provide insight into the shortcomings of word embeddings .",
        "proposing a convolutional document embedding approach , our empirical investigation using the mimic - iii intensive care database shows significant performance gains compared to previously employed methods such as latent topic distributions or generic doc2vec embeddings .",
        "in addition the learned features outperform standard embedding approaches in a classification task .",
        "our approach first leverages on word2vec framework to embed icd codes into vector - valued representation .",
        "we present here a new version of the linked open data resource conceptnet that is particularly well suited to be used with modern nlp techniques such as word embeddings .",
        "on a zc706 embedded fpga platform drawing less than 25 w total system power , we demonstrate up to 12 .",
        "previous researches have shown that learning multiple representations for polysemous words can improve the performance of word embeddings on many tasks .",
        "with the consideration of the detected pseudo multi - sense cases , we try to refine the existing word embeddings to eliminate the influence of pseudo multi - sense .",
        "moreover , we apply our algorithm on previous released multi - sense word embeddings and tested it on artificial word similarity tasks and the analogy task .",
        "in this paper , we implicitly incorporate morpheme information into word embedding .",
        "rather , the externally stored embedding vectors are used at each time - step , but no messages are passed from previous time - steps .",
        "however , these paths are extremely numerous ( one per embedding vector in memory ) and reused for a very long time ( until it leaves the memory ) .",
        "this paper examines bypassing such an explicit representation by depending on a latent neural embedding of state and learning selective attention to dialogue history together with copying to incorporate relevant prior context .",
        "the second sub - system is a character - level rnn language model using embeddings learned from a convolutional neural network .",
        "since the acoustic and text query embeddings occupy different representation spaces , they are input to a third feed - forward neural network that predicts whether the query occurs in the acoustic utterance or not .",
        "a network embedding is a representation of a large graph in a low - dimensional space , where vertices are modeled as vectors .",
        "the objective of a good embedding is to preserve the proximity between vertices in the original graph .",
        "this way , typical search and mining methods can be applied in the embedded space with the help of off - the - shelf multidimensional indexing approaches .",
        "existing network embedding techniques focus on homogeneous networks , where all vertices are considered to belong to a single class .",
        "we address a problem of optimization on product of embedded submanifolds of convolution kernels ( pems ) in convolutional neural networks ( cnns ) .",
        "we present a detailed case study with a complex input format , namely pdf , and a large complex security - critical parser for this format , namely , the pdf parser embedded in microsoft ' s new edge browser .",
        "all three models utilize word and position embedding as latent features and thus do not rely on feature engineering .",
        ", the fiedler vector has the smallest non - zero eigenvalue and is key for laplacian embedding and graph clustering .",
        "we also establish a link with classical laplacian embedding and graph clustering , for which the graph slepian design can serve as a generalization .",
        "we use some of the largest order statistics of the random projections of a reference signal to construct a binary embedding that is adapted to signals correlated with such signal .",
        "the embedding is characterized from the analytical standpoint and shown to provide improved performance on tasks such as classification in a reduced - dimensionality space .",
        "it is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re - use for new tasks .",
        "several novel and recent approaches have also embedded control policy with efficient perceptual representation using deep learning .",
        "in previous work we showed for the first time that it is possible to map this application to power constrained embedded systems , highlighting that decision choices made at the algorithmic design - level have the most impact .",
        "attention networks have proven to be an effective approach for embedding categorical inference within a deep neural network .",
        "we propose a novel discriminative model that learns embeddings from multilingual and multi - modal data , meaning that our model can take advantage of images and descriptions in multiple languages to improve embedding quality .",
        "we evaluate our embeddings on an image - sentence ranking ( isr ) , a semantic textual similarity ( sts ) , and a neural machine translation ( nmt ) task .",
        "we introduce syntactic information in the form of ccg supertags either in the source as an extra feature in the embedding , or in the target , by interleaving the target supertags with the word sequence .",
        "surprisingly , this fact is not well reflected in the way embeddings are evaluated .",
        "in addition , recent practice in word embeddings points towards importance of learning specialized representations .",
        "in the aspect of methodological novelty , the proposed method uses a representation learning strategy to embed each document in a low dimensional vector space where name disambiguation",
        "this paper proposes to use distributed representation of words ( word embeddings ) in cross - language textual similarity detection .",
        "the idea is to embed textual structures into a semantic space of concepts which captures the main topics of these structures .",
        "in this paper we propose two neural embedding models in order to learn continuous concept vectors .",
        "empirical results on a benchmark dataset for measuring entity semantic relatedness show superior performance over other concept embedding models .",
        "using deep learning for different machine learning tasks such as image classification and word embedding has recently gained many attentions .",
        "word embedding is the task of mapping words or phrases to a low dimensional numerical vector .",
        "in this paper , we use deep learning to embed wikipedia concepts and entities .",
        "contrary to word embedding , wikipedia concepts embedding is not ambiguous , so there are different vectors for concepts with similar surface form but different mentions .",
        "showed they can also be found \" offline \" , whereby two pre - trained embeddings are aligned with a linear transformation , using dictionaries compiled from expert knowledge .",
        "in this paper , we present a novel reordering approach utilizing a neural network and dependency - based embeddings to predict whether the translations of two source words linked by a dependency relation should remain in the same order or should be swapped in the translated sentence .",
        "while kleinberg ' s axioms have been discussed heavily in the past , we concentrate here on the case predominantly relevant for $ k $ - means algorithm , that is behavior embedded in euclidean space .",
        "to do so , we leverage an emulator platform we developed , that embeds the tensorflow code into linux containers .",
        "we also proved that the necessary and sufficient dimensionality of the word vector embedding space is exactly the number of document classes .",
        "we show the equivalence of two state - of - the - art link prediction / knowledge graph completion methods : nickel et al ' s holographic embedding and trouillon et ~ al . '",
        "s complex embedding .",
        "we first consider a spectral version of the holographic embedding , exploiting the frequency domain in the fourier transform for efficient computation .",
        "the analysis of the resulting method reveals that it can be viewed as an instance of the complex embedding with certain constraints cast on the initial vectors upon training .",
        "conversely , any complex embedding can be converted to an equivalent holographic embedding .",
        "this type of word - to - vector embedding is able to keep , in the learned vector space , some of the syntactic and semantic relationships present in the original word corpus .",
        "neural networks have been successfully applied to this problem , and in this paper , we propose an attention - based deep neural network which better incorporates different embeddings of the queries and search results with an attention - based mechanism .",
        "the embeddings are trained with convolutional neural networks or the word2vec model .",
        "second , paraphrases of logical forms and questions are embedded in a jointly learned vector space using word and character convolutional neural networks .",
        "we present an unsupervised explainable word embedding technique , called eve , which is built upon the structure of wikipedia .",
        "to test the effectiveness of the proposed word embedding model , we consider its usefulness in three fundamental tasks : 1 ) intruder detection - to evaluate its ability to identify a non - coherent vector from a list of coherent vectors , 2 ) ability to cluster - to evaluate its tendency to group related vectors together while keeping unrelated vectors in separate clusters , and 3 ) sorting relevant items first - to evaluate its ability to rank vectors ( items ) relevant to the query in the top order of the result .",
        "these demonstrate the overall effectiveness of the explainable embeddings generated by eve .",
        "finally , we compare eve with the word2vec , fasttext , and glove embedding techniques across the three tasks , and report improvements over the state - of",
        "vector representations , word embeddings and topic embeddings , map words and topics into a low - dimensional and dense real - value vector space , which have obtained high performance in nlp tasks .",
        "hence vmfmix is used to derive topic embeddings , i .",
        ", representative vectors , from multiple sets of embedding vectors .",
        "recently , there was a paradigm shift towards using word embeddings and deep neural networks , where the use of surface features is very limited .",
        "representation learning of knowledge graphs encodes entities and relation types into a continuous low - dimensional vector space , learns embeddings of entities and relation types .",
        "all entries of the embeddings of relation types are constrained to be non - negative .",
        "it indicates that our model is capable of capturing the transitivity and antisymmetry information , which is significant when learning embeddings of knowledge graphs .",
        "the model represents words and contexts by latent trajectories in an embedding space .",
        "at each moment in time , the embedding vectors are inferred from a probabilistic version of word2vec [ mikolov , 2013 ] .",
        "these embedding vectors are connected in time through a latent diffusion process .",
        "experimental results on three different corpora demonstrate that our dynamic model infers word embedding trajectories that are more interpretable and lead to higher predictive likelihoods than competing methods that are based on static models trained separately on time slices .",
        "our ipms are based on matching statistics of distributions embedded in a finite dimensional feature space .",
        "in this paper we propose the expose neural network , which uses a deep learning approach we have developed to take generic , raw short character strings as input ( a common case for security inputs , which include artifacts like potentially malicious urls , file paths , named pipes , named mutexes , and registry keys ) , and learns to simultaneously extract features and classify using character - level embeddings and convolutional neural network .",
        "scattertext also lends itself to a query - based visualization of how the use of terms with similar embeddings differs between document categories , as well as a visualization for comparing the importance scores of bag - of - words features to univariate metrics .",
        "this paper develops a model that addresses syntactic embedding for machine comprehension , a key task of natural language understanding .",
        "our proposed model , structural embedding of syntactic trees ( sest ) , takes each word in a sentence , constructs a sequence of syntactic nodes extracted from syntactic parse trees , and encodes the sequence into a vector representation .",
        ", for a known algorithm and approximate embedding bit rate ) .",
        "we also present a completeset of experiments using 1 ) eight different image databases , 2 ) image features based on richmodels , and 3 ) three different embedding algorithms : least significant bit ( lsb ) matching , highly undetectable steganography ( hugo ) and wavelet obtained weights ( wow ) .",
        "at the same time , the proposed approach bypasses theproblem of cover source mismatch - when the embedding algorithm and bit rate are known - , since it removes the need of a training database when we have a large enough testing set .",
        "in addition to the main dataset , we open up several derived datasets including mention entity co - occurrence counts and entity embeddings , as well as mappings between freebase ids and wikidata item ids .",
        "here we show that seemingly minor choices made on ( 1 ) the use of pre - trained word embeddings , and ( 2 ) the representation of out - of - vocabulary tokens at test time , can turn out to have a larger impact than architectural choices on the final performance .",
        "while existing works have explored incorporating visual cues into language embeddings , the task of learning word representations that respect auditory grounding remains under - explored .",
        "in this work , we propose a new embedding scheme , sound - word2vec that learns language embeddings by grounding them in sound - - for example , two seemingly unrelated concepts , leaves and paper are closer in our embedding space as they produce similar rustling sounds .",
        "we demonstrate that the proposed embeddings perform better than language - only word representations , on two purely textual tasks that require reasoning about aural cues - - sound retrieval and foley - sound discovery .",
        "finally , we analyze nearest neighbors to highlight the unique dependencies captured by sound - w2v as compared to language - only embeddings .",
        "we demonstrate the significant practical superiority of our approach over traditional als ( with both random initialization and svd - based initialization ) for a variety of tasks on synthetic data - including tensor factorization on exact , noisy and over - complete tensors , as well as tensor completion - and for computing word embeddings from a third - order word tri - occurrence tensor .",
        "the recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings ( i .",
        "our method outperforms the state - of - the - art unsupervised models on most benchmark tasks , and on many tasks even beats supervised models , highlighting the robustness of the produced sentence embeddings .",
        "we then make sequential predictions using a deep rl framework , incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector .",
        "deep convolutional neural network ( cnn ) inference requires significant amount of memory and computation , which limits its deployment on embedded devices .",
        "this paper proposes a new model for extracting an interpretable sentence embedding by introducing self - attention .",
        "instead of using a vector , we use a 2 - d matrix to represent the embedding , with each row of the matrix attending on a different part of the sentence .",
        "as a side effect , the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding .",
        "results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks .",
        "in this paper we \" borrow \" the idea of vector representation of words to capture the information of short texts and embed it into a matrix factorization framework .",
        "concurrently , a different line of research has tackled a very similar problem : in digital watermarking information are embedded in a signal in the presence of an adversary .",
        "knowledge graph embedding aims at translating the knowledge graph into numerical representations by transforming the entities and relations into con - tinuous low - dimensional vectors .",
        "we name our framework as paragraphe , which provides a library for parallel knowledge graph embedding .",
        "many of the existing methods for learning joint embedding of images and text use only supervised information from paired images and its textual attributes .",
        ", maximum mean discrepancy loss ) to learn joint embeddings for semantic and visual features .",
        "a novel technique of unsupervised - data adaptation inference is introduced to construct more comprehensive embeddings for both labeled and unlabeled data .",
        "we use autoencoders to create low - dimensional embeddings of underlying patient phenotypes that we hypothesize are a governing factor in determining how different patients will react to different interventions .",
        "we propose a supervised algorithm for generating type embeddings in the same semantic vector space as a given set of entity embeddings .",
        "the algorithm is agnostic to the derivation of the underlying entity embeddings .",
        "we demonstrate the utility of the embeddings on a type recommendation task , outperforming a non - parametric feature - agnostic baseline while achieving 15x speedup and near - constant memory usage on a full partition of dbpedia .",
        "using state - of - the - art visualization , we illustrate the agreement of our extensionally derived dbpedia type embeddings with the manually curated domain ontology .",
        "finally , we use the embeddings to probabilistically cluster about 4 million dbpedia instances into 415 types in the dbpedia ontology .",
        "the discrete nature of the generation process enables de - duplication of repeated features , further compacting the representation and increasing the diversity of the embeddings .",
        "this article presents an overview of embedding models of entities and relationships for knowledge base completion , with up - to - date experimental results on two standard evaluation tasks of link prediction ( i .",
        "like its bayesian counterpart , this embedded segmental k - means model ( es - kmeans ) represents arbitrary - length word segments as fixed - dimensional acoustic word embeddings .",
        "fgf involves multi - jaccard similarity to compute a robust graph and utilize word embedding method to enhance the recognition results .",
        "our proposed approach to this problem is a joint image pixel and word concept embeddings framework , where word concepts are connected by semantic relations .",
        "we further explore the trained joint embedding space to show its interpretability .",
        "sea is built using a bootstrapping approach that combines word embedding model trained on issue - tracking data and manual scoring of items in the lexicon .",
        "the model uses distributed sub - word embeddings learned from a large corpus .",
        "answer templates are extracted from embeddings derived from past agent answers , without turn - by - turn annotations .",
        "classical higher - order logic , when utilized as a meta - logic in which various other ( classical and non - classical ) logics can be shallowly embedded , is well suited for realising a universal logic reasoning approach .",
        "the proposed approach builds sentence representations using learned embeddings based on neural network .",
        "the learned word embeddings formed a feature space , to which the examined sentence is mapped to .",
        "we also show that the embedded speaker model reproduces many of these pragmatic behaviors .",
        "knowledge graph embedding aims to embed entities and relations of knowledge graphs into low - dimensional vector spaces .",
        "translating embedding methods regard relations as the translation from head entities to tail entities , which achieve the state - of - the - art results among knowledge graph embedding methods .",
        "in this paper , we propose an efficient parallel framework for translating embedding methods , called partrans - x , which enables the methods to be paralleled without locks by utilizing the distinguished structures of knowledge graphs .",
        "experiments on two datasets with three typical translating embedding methods , i .",
        "traditional manifold learning algorithms often bear an assumption that the local neighborhood of any point on embedded manifold is roughly equal to the tangent space at that point without considering the curvature .",
        "the proposed method constructed sentence vectors ( sent2vec ) by averaging the word embeddings , which were learned from anthology collections ( acl - embeddings ) .",
        "i also investigated polarity - specific word embeddings ( ps - embeddings ) for classifying positive and negative citations .",
        "the results showed that word embeddings are effective on classifying positive and negative citations .",
        "we propose to use word embeddings to perform word alignment for segment - level mt evaluation .",
        "we performed experiments with three types of alignment methods using word embeddings .",
        "experimental results show that our proposed methods outperform previous word embeddings - based methods .",
        "our work presented here constitutes the first step in opening the black - box of vector embeddings for tweets .",
        "more specifically , our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company .",
        "ecm addresses the factor in three ways : modeling high - level abstraction of emotion expression by embedding emotion categories , changing of implicit internal emotion states , and using explicit emotion expressions with an external emotion vocabulary .",
        "finally , we show that the model learns a manifold of embeddings that allows for morphing between instruments , meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive .",
        "visual classification or board games ) are becoming obsolete as state - of - the - art learning algorithms approach or even surpass human performance in most of them , having recently encouraged the development of first - person 3d game platforms embedding realistic physics .",
        "this paper explores linear methods for combining several word embedding models into an ensemble .",
        "we explore the ability of word embeddings to capture both semantic and morphological similarity , as affected by the different types of linguistic properties ( surface form , lemma , morphological tag ) used to compose the representation of each word .",
        "these research results convince that the embedded in the ahp and commonly applied , both genuine pp and cm for pcm may significantly deteriorate the quality of",
        "we know that a set of k nodes embedding all k - bandlimited signals always exists , thereby enabling their perfect reconstruction after sampling .",
        "the second and third spaces are two different strategies of combining word embeddings to represent sentences and use a linear svm and a logistic regressor as base classifiers .",
        "the first is a time - series model that relates embedding vectors from one time period to embedding vectors of previous time periods .",
        "firstly , today ' s embedding vectors ( = meaning ) of words can be derived as linear combinations of embedding vectors of their neighbors in previous time periods .",
        "then , we employ a rich set of features , such as link - probability , context - matching , word embeddings , and relatedness among candidate entities as well as their related entities , to rank the candidates under a regression based framework .",
        "by concatenating word and character embeddings , we achieve up to 2 .",
        "in this work we propose a technique based on distributed representation of words ( or word embeddings ) .",
        "based on these features , we present a totally unsupervised , expandable and language and domain independent method for learning normalization lexicons from word embeddings .",
        "the network has two branches , where the first branch extracts appearance feature embedding for each sample and the other branch predicts quality score for each sample .",
        "features and quality scores of all samples in a set are then aggregated to generate the final feature embedding .",
        "our submission to semeval was an update of previous work that builds high - quality , multilingual word embeddings from a combination of conceptnet and distributional semantics .",
        "in this paper , we propose a practical deep embedding method for extreme multi - label classifi - cation .",
        "our method harvests the ideas of non - linear embedding and modeling label space with graph priors at the same time .",
        "when you need to enable deep learning on low - cost embedded socs , is it better to port an existing deep learning framework or should you build one from scratch ?",
        "in this paper , we share our practical experiences of building an embedded inference engine using arm compute library ( acl ) .",
        "our conclusion is that , on embedded devices , we most likely will use very simple deep learning models for inference , and with well - developed building blocks such as acl , it may be better in both performance and development time to build the engine from scratch .",
        "we train both networks using an actor - critic reinforcement learning model , with a novel reward defined by visual - semantic embedding .",
        "existing methods of neural word embeddings , including sngs , are multi - pass algorithms and thus cannot perform incremental model update .",
        "we propose a simple yet effective text - based user geolocation model based on a neural network with one hidden layer , which achieves state of the art performance over three twitter benchmark geolocation datasets , in addition to producing word and phrase embeddings in the hidden layer that we show to be useful for detecting dialectal terms .",
        "we provide experimental evidence that sentences that are close in embedding space are indeed semantically highly related , but often have quite different structure and syntax .",
        "prior work about learning multi - sense embeddings suffered from either ambiguity of different - level embeddings or inefficient sense selection .",
        "in this paper , we model this effect by creating embeddings for characters based on their visual characteristics , creating an image for the character and running it through a convolutional neural network to produce a visual character embedding .",
        "additionally , qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry semantic content , resulting in embeddings that are coherent in visual space .",
        "key components are entity embeddings , a neural attention mechanism over local context windows , and a differentiable joint inference stage for disambiguation .",
        "we modeled the task as a regression analysis problem and combined traditional techniques such as pre - processing short texts , bag - of - words representations and lexical - based features with enhanced financial specific bag - of - embeddings .",
        "we used an external collection of tweets and news headlines mentioning companies / stocks from s \\ & amp ; p 500 to create financial word embeddings which are able to capture domain - specific syntactic and semantic similarities .",
        "the number of parameters in recent state - of - the - art networks makes them hard to deploy , especially on mobile phones and embedded devices .",
        "we experiment with a set of baselines based on cross - lingual embeddings and machine translation .",
        "furthermore , internal representations learned by the network serve as a new semantic representation of words - or sentences - which , unlike standard word embeddings , are learned in an essentially bilingual or even multilingual context .",
        "our model integrates word embedding features with gaussian processes regression .",
        "the agent uses a multimodal embedding between environment observations and natural language to self - monitor progress through a list of english instructions , granting itself reward for completing instructions in addition to increasing the game score .",
        "word embeddings have made enormous inroads in recent years in a wide variety of text mining applications .",
        "in this paper , we explore a word embedding - based architecture for predicting the relevance of a role between two financial entities within the context of natural language sentences .",
        "in this extended abstract , we propose a pooled approach that uses a collection of sentences to train word embeddings using the skip - gram word2vec architecture .",
        "we use the word embeddings to obtain context vectors that are assigned one or more labels based on manual annotations .",
        "although the choice of context ( which often takes the form of a sliding window ) has a direct influence on the resulting embeddings , the exact role of this model component is still not fully understood .",
        "we propose a novel embedding model , \\ emph { itransf } , to perform knowledge base completion .",
        "recent studies have shown that embedding textual relations using deep neural networks greatly helps relation extraction .",
        "in this work , we generalize textual relation embedding to the distant supervision setting , where much larger - scale but noisy training data is available .",
        ", the co - occurrence statistics of textual and knowledge base relations collected from the entire corpus , to embed textual relations .",
        "on a popular relation extraction dataset , we show that the learned textual relation embeddings can be used to augment existing relation extraction models and significantly improve their performance .",
        "we discover two problems , small micro variance and large macro variance , of pre - trained word embeddings that hurdle their direct use in neural networks , and propose standardization techniques as a remedy .",
        "on the popular overnight dataset , which contains eight domains , we show that both cross - domain training and standardized pre - trained word embeddings can bring significant improvement .",
        "in this paper , we propose a new clustering model , called deep embedded regularized clustering ( depict ) , which efficiently maps data into a discriminative embedding subspace and precisely predicts cluster assignments .",
        "furthermore , we employ the reconstruction loss functions in our autoencoder , as a data - dependent regularization term , to prevent the deep embedding function from overfitting .",
        "we show that the most widely - used approach to adaptation ( concatenating the context with the word embedding at the input to the recurrent layer ) is outperformed by a model that has some low - cost improvements : adaptation of both the hidden and output layers .",
        "the output of the regression is a point embedded in a pseudo - euclidean space , which can be analyzed using subsequent dissimilarity - or kernel - based processing methods .",
        "furthermore , we present a qualitative analysis of the obtained phone embeddings , and show that cross - modal visual input can improve the discriminability of phonological features which are visually discernable ( rounding , open /",
        "this paper presents a greedy neural word segmenter with balanced word and character embedding inputs to alleviate the existing drawbacks .",
        "the model architecture uses stack - based embedding features , predicting graphs jointly with unlexicalized predicates and their token alignments .",
        "to model both structured knowledge and unstructured language , we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses .",
        "this paper presents a new graph - based approach that induces synsets using synonymy dictionaries and word embeddings .",
        "we use neural word embeddings to discover words that are morphologically derived from each other and thereby that are semantically similar .",
        "we use letter successor variety counts obtained from tries that are built by neural word embeddings .",
        "our results show that using different information sources such as neural word embeddings and letter successor variety as prior information improves morphological segmentation in a bayesian model .",
        "we develop a streaming ( one - pass , bounded - memory ) word embedding algorithm based on the canonical skip - gram with negative sampling algorithm implemented in word2vec .",
        "because ideas are naturally embedded in texts , we propose the first framework to systematically characterize the relations between ideas based on their occurrence in a corpus of documents , independent of how these ideas are represented .",
        "skip - gram negative sampling ( sgns ) word embedding model , well known by its implementation in \" word2vec \" software , is usually optimized by stochastic gradient descent .",
        "in this paper , we modeled transcripts into complex networks and enriched them with word embedding ( cne ) to better represent short texts produced in neuropsychological assessments .",
        "{ \\ it universal schema } can support reasoning on the union of both structured kbs and unstructured text by aligning them in a common embedded space .",
        "word embeddings provide point representations of words containing useful semantic information .",
        "we show that the resulting approach captures uniquely expressive semantic information , and outperforms alternatives , such as word2vec skip - grams , and gaussian embeddings , on benchmark datasets such as word similarity and entailment .",
        "neural word segmentation research has benefited from large - scale raw texts by leveraging them for pretraining character and word embeddings .",
        "pre - trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for nlp tasks .",
        "in this paper , we demonstrate a general semi - supervised approach for adding pre - trained context embeddings from bidirectional language models to nlp systems and apply it to sequence labeling tasks .",
        "we consider the problem of learning general - purpose , paraphrastic sentence embeddings , revisiting the setting of wieting et al .",
        "we address these drawbacks in our framework which takes advantage of cross - lingual word embeddings trained solely on a high coverage bilingual dictionary .",
        "we propose a novel neural network model for joint training from both sources of data based on cross - lingual word embeddings , and show substantial empirical improvements over baseline techniques .",
        "we report a number of different evaluations using a finance specific word embedding model and reflect on the effects of using different evaluation metrics .",
        "we quantify relevance by measuring the distance between frames and queries in a common textual - visual semantic embedding space induced by a neural network .",
        "we compare our method against previous state of the art on textual - visual embeddings for thumbnail selection and show that our model outperforms them on relevance prediction .",
        "feed - forward neural networks using n - gram embedding features encode messages into vectors which are optimized to give message - response pairs a high dot - product value .",
        "we embed such generalized missing data into a vector space by mapping pointed affine subspace ( generalized missing data point ) to a vector containing imputed values joined with a corresponding projection matrix .",
        "such an operation preserves the scalar product of the embedding defined for flag vectors and allows to input transformed incomplete data to typical classification methods .",
        "an supervised dimensionality reduction algorithm called linear discriminant analysis ( lda ) seeks for an embedding transformation , which can work well with gaussian distribution data or single - modal data , but for non - gaussian distribution data or multimodal data , it gives undesired results .",
        "in order to quantify the quality of approximation , it is natural to consider the candidates and voters as embedded within a common metric space , and to ask how much further the chosen candidate is from the population as compared to the socially optimal one .",
        "ten instances of this network are initialized with the same word embeddings as inputs but with different initializations for the network weights .",
        "we present deep speaker , a neural speaker embedding system that maps utterances to a hypersphere where speaker similarity is measured by cosine similarity .",
        "the embeddings generated by deep speaker can be used for many tasks , including speaker identification , verification , and clustering .",
        "we experiment with rescnn and gru architectures to extract the acoustic features , then mean pool to produce utterance - level speaker embeddings , and train using triplet loss based on cosine similarity .",
        "many modern nlp systems rely on word embeddings , previously trained in an unsupervised manner on large corpora , as base features .",
        "efforts to obtain embeddings for larger chunks of text , such as sentences , have however not been so successful .",
        "large - scale multi - relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs .",
        "this paper proposes a novel framework for optimizing the latent representations with respect to the \\ textit { analogical } properties of the embedded entities and relations .",
        "furthermore , the model offers an elegant unification of several well - known methods in multi - relational embedding , which can be proven to be special instantiations of our framework .",
        "type - level word embeddings use the same set of parameters to represent all instances of a word regardless of its context , ignoring the inherent lexical ambiguity in language .",
        "instead , we embed semantic concepts ( or synsets ) as defined in wordnet and represent a word token in a particular context by estimating a distribution over relevant semantic concepts .",
        "we use the new , context - sensitive embeddings in a model for predicting prepositional phrase ( pp ) attachments and jointly learn the concept embeddings and model parameters .",
        "we show that using context - sensitive embeddings improves the accuracy of the pp attachment model by 5 .",
        "new unsupervised learning methods represent words and phrases in a high - dimensional vector space , and these monolingual embeddings have been shown to encode syntactic and semantic relationships between language elements .",
        "the information captured by these embeddings can be exploited for bilingual translation by learning a transformation matrix that allows to match relative positions across two monolingual vector spaces .",
        "it shows how to process the source data , train a neural network to learn the high - dimensional embeddings for individual languages and expands the framework for testing their quality beyond the english language .",
        "this allows us to foreground and confront the norms embedded in data - driven creativity and productivity assistance tools .",
        "as such tools effectively function as extensions of our cognition into technology , it is important to identify the norms they embed within themselves and , by extension , us .",
        "deeptingle is realized as a web application based on lstm networks and the glove word embedding , implemented in javascript with keras - js .",
        "our best model is the combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which achieves an f1 score of 88 .",
        "we propose a new fast word embedding technique using hash functions .",
        "our experiments show that the proposed method can achieve competitive results , comparable to neural embedding learning techniques , however , with only a fraction of the computational complexity of these methods .",
        "while the proposed derandomization enhances the computational and space complexity of our method , the possibility of applying weighting methods such as positive pointwise mutual information ( ppmi ) to our models after their construction ( and at a reduced dimensionality ) imparts a high discriminatory power to the resulting embeddings .",
        "recent machine learning methods for deriving vector - space embeddings of words ( e .",
        "we evaluate the parallelogram model of analogy as applied to modern word embeddings , providing a detailed analysis of the extent to which this approach captures human relational similarity judgments in a large benchmark dataset .",
        "word - embedding or obtaining vector representation of words from a large corpora of free texts using neural network methods have been shown to give significant performance for several natural language processing tasks .",
        "clblast has four main advantages over other blas libraries : 1 ) it is optimized for and tested on a large variety of opencl devices including less commonly used devices such as embedded and low - power gpus , 2 ) it can be explicitly tuned for specific problem - sizes on specific hardware platforms , 3 ) it can perform operations in half - precision floating - point fp16 saving precious bandwidth , time and energy , 4 ) and it can combine multiple operations in a single batched routine , accelerating smaller problems significantly .",
        "we have used exponential family embeddings as the tool to construct two basic vectors - product embeddings and context vectors .",
        "using the basic vectors , we build combined embeddings , trip embeddings and customer embeddings .",
        "combined embeddings mix linguistic properties of product names with their shopping patterns .",
        "the customer embeddings establish an understand - ing of the buying pattern of customers in a group and help in building customer profile .",
        "similarly , trip embeddings are used to build trip profiles .",
        "people happen to buy similar set of products in a trip and hence their trip embeddings can be used to predict the next product they would like to buy .",
        "this is a novel technique and the first of its kind to make recommendation using product , trip and customer embed",
        "this study presents a method to infer psycholinguistic properties for brazilian portuguese ( bp ) using regressors built with a light set of features usually available for less resourced languages : word length , frequency lists , lexical databases composed of school dictionaries and word embedding models .",
        "regularizing the adjacency of the output nodes , inferred from the predictions of the network , creates an easier optimization problem and ultimately provides that the predictions of the network turn into the optimal embedding .",
        "word embeddings improve the performance of nlp systems by revealing the hidden structural relationships between words .",
        "despite their success , word embeddings have seen very little use in computational social science nlp tasks , presumably due to their reliance on big data , and to a lack of interpretability .",
        "i propose a probabilistic model - based word embedding method which can recover interpretable embeddings , without big data .",
        "leveraging connections to topic models , i show how to train these models in high dimensions using a combination of state - of - the - art techniques for word embeddings and topic modeling .",
        "the models are interpretable , as embeddings of topics are used to encode embeddings for words ( and hence ,",
        "for this , we argue to use word embeddings instead of traditional high - dimensional vector representations in order to leverage their semantic density and to reduce computational cost .",
        "we rigorously test our approach on several domains including tagging data as well as publicly available embeddings based on wikipedia texts and navigation .",
        "for tagging data , we are the first to generate and study embeddings .",
        "how to develop slim and accurate deep neural networks has become crucial for real - world applications , especially for those employed in embedded systems .",
        "in this paper , we address the problem of learning compact similarity - preserving embeddings for massive high - dimensional streams of data in order to perform efficient similarity search .",
        "while previous contributions to feature extraction propose embeddings based on a single layer of the network , in this paper we propose a full - network embedding which successfully integrates convolutional and fully connected features , coming from all layers of a deep convolutional neural network .",
        "to do so , the embedding normalizes features in the context of the problem , and discretizes their values to reduce noise and regularize the embedding space .",
        "the proposed method is shown to outperform single layer embeddings on several image classification tasks , while also being more robust to the choice of the pre - trained model used for obtaining the initial features .",
        "the performance gap in classification accuracy between thoroughly tuned solutions and the full - network embedding is also reduced , which makes of the proposed approach a competitive solution for a large set of applications .",
        "semantic relatedness is computed using transe ~ \\ cite { bordes2013translating } , a method for low dimensional embedding of a triple in a knowledge graph .",
        "generic text embeddings are successfully used in a variety of tasks .",
        "we introduce second - order vector representations of words , induced from nearest neighborhood topological features in pre - trained contextual word embeddings .",
        "we then analyze the effects of using second - order embeddings as input features in two deep natural language processing models , for named entity recognition and recognizing textual entailment , as well as a linear model for paraphrase recognition .",
        "surprisingly , we find that nearest neighbor information alone is sufficient to capture most of the performance benefits derived from using pre - trained word embeddings .",
        "furthermore , second - order embeddings are able to handle highly heterogeneous data better than first - order representations , though at the cost of some specificity .",
        "additionally , augmenting contextual embeddings with second - order information further improves model performance in some cases .",
        "due to variance in the random initializations of word embeddings , utilizing nearest neighbor features from multiple first - order embedding samples can also contribute to downstream performance gains .",
        "finally , we identify intriguing characteristics of second - order embedding spaces for further research , including much higher density and different semantic interpretations of cosine similarity .",
        "we introduce a technique for augmenting neural text - to - speech ( tts ) with lowdimensional trainable speaker embeddings to generate different voices from a single model .",
        "besides the base model , in order to enhance its performance , we also proposed three techniques : the integration of multiple word - embedding library , bi - way integration , and ensemble based on model averaging .",
        "specifically , we embed a differentiable non - projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases .",
        "recurrent neural networks have achieved remarkable success at generating sequences with complex structures , thanks to advances that include richer embeddings of input and cures for vanishing gradients .",
        "an approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated asr confidence measures .",
        "thus hidden state representation of rnn along with word and entity type embedding as features avoid relying on the complex hand - crafted features generated using various nlp toolkits .",
        "by incorporating automatic syntactic features with word embeddings as input for bidirectional long short - term memory ( bi - lstm ) , our system , although simpler than some deep learning architectures , achieves a much better result for vietnamese ner .",
        "adversarial learning has been successfully embedded into deep networks to learn transferable features for domain adaptation , which reduce distribution discrepancy between the source and target domains and improve generalization performance .",
        "we extend the existing laplacian svm and present s3vm - r , by adding a regularization term to exploit exogenous information embedded in our feature space in favor of the task at hand .",
        "these improvements are even better than using pre - trained word embeddings from extra data .",
        "these methods enable the development of mathematically - principled isometric - invariant mappings from a set of vectors to a document embedding , which is stable with respect to the geometry of the document in the selected metric space .",
        "we find that the embeddings do not benefit text analysis .",
        "we perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity .",
        "representations of rare words trained directly on end - tasks are usually poor , requiring us to pre - train embeddings on external data , or treat all rare words as out - of - vocabulary words with a unique representation .",
        "we provide a method for predicting embeddings of rare words on the fly from small amounts of auxiliary data with a network trained against the end task .",
        "we show that this improves results against baselines where embeddings are trained on the end task in a reading comprehension task , a recognizing textual entailment task , and in language modelling .",
        "we show that a concatenation of this representation with the word and character embeddings improves the performance .",
        "recent advances in deep learning motivate the use of deep neutral networks in sensing applications , but their excessive resource needs on constrained embedded devices remain an important impediment .",
        "in this work we propose a solution far simpler but very effective : an evolution of the simple jordan rnn , where labels are re - injected as input into the network , and converted into embeddings , in the same way as words .",
        "thanks to label embeddings and their combination at the hidden layer , the proposed variant , which uses more parameters than elman and jordan rnns , but far fewer than lstm and gru , is more effective than other rnns , but also outperforms sophisticated crf models .",
        "we consider the problem of learning general - purpose , paraphrastic sentence embeddings in the setting of wieting et al .",
        "we evaluate the paraphrase pairs by their ability to serve as training data for learning paraphrastic sentence embeddings .",
        "therefore in this study we introduce a domain specific semantic similarity measure that was created by the synergistic union of word2vec , a word embedding method that is used for semantic similarity calculation and lexicon based ( lexical ) semantic similarity methods .",
        "we prove that this proposed methodology out performs word embedding methods trained on generic corpus and methods trained on domain specific corpus but do not use lexical semantic similarity methods to augment the results .",
        "further , we prove that text lemmatization can improve the performance of word embedding methods .",
        "analogy completion has been a popular task in recent years for evaluating the semantic properties of word embeddings , but the standard methodology makes a number of assumptions about analogies that do not always hold , either in recent benchmark datasets or when expanding into other domains .",
        "we further present bmass , a novel dataset for evaluating linguistic regularities in biomedical embeddings , and demonstrate that the relationships described in the dataset pose significant semantic challenges to current word embedding methods .",
        "a central property of abstract anaphora is that it establishes a relation between the anaphor embedded in the anaphoric sentence and its ( typically non - nominal ) antecedent .",
        "we propose three novel differentiable kernels as graph convolution operators and show that the embedding based kernel achieves the best performance .",
        "we present a new preprocessing algorithm for embedding the nodes of a given edge - weighted undirected graph into a euclidean space .",
        "hence , fastmap is orders of magnitude faster than competing approaches that produce a euclidean embedding using semidefinite programming .",
        "we present models for embedding words in the context of surrounding words .",
        "such models , which we refer to as token embeddings , represent the characteristics of a word that are specific to a given context , such as word sense , syntactic category , and semantic role .",
        "we explore simple , efficient token embedding models based on standard neural network architectures .",
        "we learn token embeddings on a large amount of unannotated text and evaluate them as features for part - of - speech taggers and dependency parsers trained on much smaller amounts of annotated data .",
        "we find that predictors endowed with token embeddings consistently outperform baseline predictors across a range of context window and training set sizes .",
        "ontology classes are sets of homogeneous instance objects that can be converted to a vector space by word vector embeddings .",
        "third , we found that a good word embedding initialization is also essential for learning better sentence representations .",
        "we propose three approaches for contextualizing citations which are based on query reformulation , word embeddings , and supervised learning .",
        "our network architecture is based on a state - of - the - art qa system , extended with biomedical word embeddings and a novel mechanism to answer list questions .",
        "we further find out that the attention mechanism following the top recurrent layer significantly attenuates encoding of phonology and makes the utterance embeddings much more invariant to synonymy .",
        "recent work has shown that comparing speech segments by representing them as fixed - dimensional vectors - - - acoustic word embeddings - - - and measuring their vector distance ( e .",
        "we consider an approach to query - by - example search that embeds both the query and database segments according to a neural model , followed by nearest - neighbor search to find the matching segments .",
        "earlier work on embedding - based query - by - example , using template - based acoustic word embeddings , achieved competitive performance .",
        "we find that our embeddings , based on recurrent neural networks trained to optimize word discrimination , achieve substantial improvements in performance and run - time efficiency over the previous approaches .",
        "while going deeper has been witnessed to improve the performance of convolutional neural networks ( cnn ) , going smaller for cnn has received increasing attention recently due to its attractiveness for mobile / embedded applications .",
        "to address these difficulties , we propose bloom embeddings , a compression technique that can be applied to the input and output of neural network models dealing with sparse high - dimensional binary - coded instances .",
        "bloom embeddings are computationally efficient , and do not seriously compromise the accuracy of the model up to 1 / 5 compression ratios .",
        "we evaluate bloom embeddings on 7 data sets and compare it against 4 alternative methods , obtaining favorable results .",
        "we also discuss a number of further advantages of bloom embeddings , such as ' on - the - fly ' constant - time operation , zero or marginal space requirements , training time speedups , or the fact that they do not require any change to",
        "in this work we describe and evaluate methods to learn musical embeddings .",
        "each embedding is a vector that represents four contiguous beats of music and is derived from a symbolic representation .",
        "we consider autoencoding - based methods including denoising autoencoders , and context reconstruction , and evaluate the resulting embeddings on a forward prediction and a classification task .",
        "cross - lingual embedding models allow us to project words from different languages into a shared embedding space .",
        "in the following , we will survey models that seek to learn cross - lingual embeddings .",
        "finally , we will present challenges and summarize how to evaluate cross - lingual embedding models .",
        "word embeddings are now a standard technique for inducing meaning representations for words .",
        "in this paper , we propose a mixture model for learning multi - sense word embeddings .",
        "we propose a novel embedding model that represents relationships among several elements in bibliographic information with high representation ability and flexibility .",
        "this is done end - to - end in a single stage with the use of associative embeddings .",
        "identifying context information as the backbone of both relation extraction and true label discovery , we adopt embedding techniques to learn the distributed representations of context , which bridges all components with mutual enhancement in an iterative fashion .",
        "aiming at better relating feature and label domain data for improved classification , we uniquely perform joint feature and label embedding by deriving a deep latent space , followed by the introduction of label - correlation sensitive loss function for recovering the predicted label outputs .",
        "doc2vecc represents each document as a simple average of word embeddings .",
        "a corruption model is included , which introduces a data - dependent regularization that favors informative or rare words while forcing the embeddings of common and non - discriminative ones to be close to zero .",
        "doc2vecc produces significantly better word embeddings than word2vec .",
        "the second approach is to project distributed representations of words ( word embeddings ) from a target language to a source language , so that the source - language ner system can be applied to the target language without re - training .",
        "the base of our model is a new type of variational autoencoder on demonstration trajectories that learns semantic policy embeddings .",
        "we show that these embeddings can be learned on a 9 dof jaco robot arm in reaching tasks , and then smoothly interpolated with a resulting smooth interpolation of reaching behavior .",
        "we also compare our networks processing time on nvidia gpu and embedded system device with existing state - of - the - art architectures for different image resolutions .",
        "a compelling aspect of our approach is that our models are trained with the same simple negative sampling objective function that is commonly used in word2vec to learn word embeddings .",
        "we propose a dependency - based embedding model of selectional preferences which allows fine - grained compatibility judgments with high coverage .",
        "more specifically , we describe a novel reinforcement learning framework for learning multi - hop relational paths : we use a policy - based agent with continuous states based on knowledge graph embeddings , which reasons in a kg vector space by sampling the most promising relation to extend its path .",
        "experimentally , we show that our proposed method outperforms a path - ranking based algorithm and knowledge graph embedding methods on freebase and never - ending language learning datasets .",
        "to the best of our knowledge , this is the first study which demonstrates how the architectures for learning word embeddings can be applied to this challenging syntactic - semantic task .",
        "word embeddings improve generalization over lexical features by placing each word in a lower - dimensional space , using distributional information obtained from unlabeled data .",
        "however , the effectiveness of word embeddings for downstream nlp tasks is limited by out - of - vocabulary ( oov ) words , for which embeddings do not exist .",
        "in this paper , we present mimick , an approach to generating oov word embeddings compositionally , by learning a function from spellings to distributional embeddings .",
        "unlike prior work , mimick does not require re - training on the original word embedding corpus ; instead , learning is performed at the type level .",
        "the model computes span embeddings that combine context - dependent boundary representations with a head - finding attention mechanism .",
        "we present a novel neural model hypervec to learn hierarchical embeddings for hypernymy detection and directionality .",
        "while previous embeddings have shown limitations on prototypical hypernyms , hypervec represents an unsupervised measure where embeddings are learned in a specific order and capture the hypernym $ - $ hyponym distributional hierarchy .",
        "results on benchmark datasets show that hypervec outperforms both state $ - $ of $ - $ the $ - $ art unsupervised measures and embedding models on hypernymy detection and directionality , and on predicting graded lexical entailment .",
        "this paper deals with using word embedding models to trace the temporal dynamics of semantic relations between pairs of words .",
        "a word embedding is a low - dimensional , dense and real - valued vector representation of a word .",
        "word embeddings have been used in many nlp tasks .",
        "the embedding of a word cap - tures both its syntactic and semantic aspects .",
        "therefore , it is necessary to have word embeddings learned specifically from tweets .",
        "in this paper , we present ten word embedding data sets .",
        "in addition to the data sets learned from just tweet data , we also built embedding sets from the general data and the combination of tweets with the general data .",
        "these ten embedding models were learned from about 400 million tweets and 7 billion words from the general text .",
        "we propose a method for embedding two - dimensional locations in a continuous vector space using a neural network - based model incorporating mixtures of gaussian distributions , presenting two model variants for text - based geolocation and lexical dialectology .",
        "the method then learns an also n - dimensional embedding of possibly reactive body - affordances that spread as far as possible throughout the target sensor space .",
        "our aim in this paper is to verify which embedding induction method works best for the sentence boundary detection task , specifically whether it be those which were proposed to capture semantic , syntactic or morphological similarities .",
        "the character glyph features are directly learned from the bitmaps of characters by convolutional auto - encoder ( convae ) , and the glyph features improve chinese word representations which are already enhanced by character embeddings .",
        "for each semantic space , modality - specific characteristics within one modality are fully exploited by recurrent attention network , while the data of another modality is projected into this space with attention based joint embedding to utilize the learned attention weights for guiding the",
        "t - distributed stochastic neighbor embedding ( tsne ) is a popular and prize - winning approach for dimensionality reduction and visualizing high - dimensional data .",
        "while recent embedding - based techniques encode entities and relationships in kbs and do not need machine translation for cross - lingual entity alignment , a significant number of attributes remain largely unexplored .",
        "in this paper , we propose a joint attribute - preserving embedding model for cross - lingual entity alignment .",
        "it jointly embeds the structures of two kbs into a unified vector space and further refines it by leveraging attribute correlations in the kbs .",
        "our experimental results on real - world datasets show that this approach significantly outperforms the state - of - the - art embedding approaches for cross - lingual entity alignment and could be complemented with methods based on machine translation .",
        "finally , we visualised the feature space obtained with our proposed method using t - distributed stochastic neighbour embedding ( t - sne ) and could observe distinct clusters of emotions .",
        "we propose a method to diminish the problem of out - of - vocabulary words by introducing an embedding derived from syllables and morphemes which leverages the agglutinative property .",
        "our model outperforms character - level embedding in perplexity by 16 .",
        "experimental results on abcd dataset show that by fusing lexical and word embedding features , our model achieves the state of the art performance of 0 .",
        "the system combines lexical , syntactic and pre - trained word embedding features , trains them on general regressors and finally combines the best performing models to create an ensemble .",
        "word embeddings have been found to capture a surprisingly rich amount of syntactic and semantic knowledge .",
        "however , it is not yet sufficiently well - understood how the relational knowledge that is implicitly encoded in word embeddings can be extracted in a reliable way .",
        "compared to existing approaches , our models lead to more accurate predictions , and they are more explicit about what can and cannot be extracted from the word embedding .",
        "we then proceed to describe methods , inspired by the word sense disambiguation literature , that model the context of the input word with context - aware word embeddings that help to differentiate the word sense be - fore feeding it into the encoder .",
        "we call this technique the continuous hint factory because it embeds student data in a continuous space , in which the most likely edit can be inferred in a probabilistic sense , similar to the hint factory .",
        "this has inspired methods for the joint embedding of entities and relations in continuous low - dimensional vector spaces , that can be used to induce new edges in the graph , i .",
        "in this paper we present an empirical study on the impact of negative sampling on the learned embeddings , assessed through the task of link prediction .",
        "we use state - of - the - art knowledge graph embeddings - - \\ rescal , transe , distmult and complex - - and evaluate on benchmark datasets - - fb15k and wn18 .",
        "we compare well known methods for negative sampling and additionally propose embedding based sampling methods .",
        "most of the previous methods rely on learning a common embedding space allowing to compare visual features of unknown categories with semantic descriptions .",
        "our toolkit is a combination of bidirectional long short - term memory ( bi - lstm ) , convolutional neural network ( cnn ) , conditional random field ( crf ) , using pre - trained word embeddings as input , which outperforms previously published toolkits on these three tasks .",
        "first , they take low - dimensional , real - valued embedding vectors as inputs , which can be trained over large raw data , thereby addressing the issue of feature sparsity in discrete models .",
        "to model changing customer and store environments , our recommendation method employs a pair of neural networks : to overcome the cold start problem , a feedforward network generates article embeddings in \" fashion space , \" which serve as input to a recurrent neural network that predicts a style vector in this space for each client , based on their past purchase sequence .",
        "those pairs will be mapped from the original space of symbolic words into some embedded style space .",
        "in particular , we demonstrate empirically the surprising efficiency of word embeddings in both of the two tasks , with both of the two models .",
        "then , we train a model on the first language pair and transfer its parameters , including its source word embeddings , to another model and continue training on the second language pair .",
        "in this work , we propose to explicitly incorporate the visual appearance of a character ' s glyph in its representation , resulting in a novel glyph - aware embedding of chinese characters .",
        "in the context of two basic chinese nlp tasks of language modeling and word segmentation , the model learns to represent each character ' s task - relevant semantic and syntactic information in the character - level embedding .",
        "this can be considered a relevant problem , as linear classifiers have been increasingly used in embedded systems and mobile devices for their low processing time and memory requirements .",
        "also , a recurrent neural network in which a word is represented as a sum of embeddings of its patterns is on",
        "we explore three language - independent alternatives to morphological segmentation using : i ) data - driven sub - word units , ii ) characters as a unit of learning , and iii ) word embeddings learned using a character cnn ( convolution neural network ) .",
        "we introduce the cross - match test - an exact , distribution free , high - dimensional hypothesis test as an intrinsic evaluation metric for word embeddings .",
        "we show that cross - match is an effective means of measuring distributional similarity between different vector representations and of evaluating the statistical significance of different vector embedding models .",
        "we demonstrate that the results of the hypothesis test align with our expectations and note that the framework of two sample hypothesis testing is not limited to word embeddings and can be extended to all vector representations .",
        "we combine a generative model parameterized by deep neural networks with non - linear embedding technique .",
        "our study suggests that the non - linear embedding based on a deep generative model can efficiently regularize a complex model with deep architectures while achieving high prediction accuracy that is far less sensitive to the availability of health status information .",
        "this paper describes a preliminary study for producing and distributing a large - scale database of embeddings from the portuguese twitter stream .",
        "using a single gpu , we were able to scale up vocabulary size from 2048 words embedded and 500k training examples to 32768 words over 10m training examples while keeping a stable validation loss and approximately linear trend on training time per epoch .",
        "we propose embed - rul : a novel approach for rul estimation from sensor data that does not rely on any degradation - trend assumptions , is robust to noise , and handles missing values .",
        "embed - rul utilizes a sequence - to - sequence model based on recurrent neural networks ( rnns ) to generate embeddings for multivariate time series subsequences .",
        "the embeddings for normal and degraded machines tend to be different , and are therefore found to be useful for rul estimation .",
        "we show that the embeddings capture the overall pattern in the time series while filtering out the noise , so that the embeddings of two machines with similar operational behavior are close to each other , even when their sensor readings have significant and varying levels of noise content .",
        "specifically , we learn word salience scores such that , using pre - trained word embeddings as the input , can accurately predict the words that appear in a sentence , given the words that appear in the sentences preceding or succeeding that sentence .",
        "despite the embedded genre in the article , not everyone can recognize the satirical cues and therefore believe the news as true news .",
        "this study addresses the problem of identifying the meaning of unknown words or entities in a discourse with respect to the word embedding approaches used in neural language models .",
        "we proposed a method for on - the - fly construction and exploitation of word embeddings in both the input and output layers of a neural model by tracking contexts .",
        "we study embedded binarized neural networks ( ebnns ) with the aim of allowing current binarized neural networks ( bnns ) in the literature to perform feedforward inference efficiently on small embedded devices .",
        "we present a novel method to embed discourse features in a convolutional neural network text classifier , which achieves a state - of - the - art result by a substantial margin .",
        "we empirically investigate several featurization methods to understand the conditions under which discourse features contribute non - trivial performance gains , and analyze discourse embeddings .",
        "we approach the query answering problems by combining ideas from the areas of kg embedding learning and deep learning for computer vision .",
        "we propose a neural embedding algorithm called network vector , which learns distributed representations of nodes and the entire networks simultaneously .",
        "by embedding networks in a low - dimensional space , the algorithm allows us to compare networks in terms of structural similarity and to solve outstanding predictive problems .",
        "after initial pre - processing phase on data , packets are fed to deep packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic .",
        "with the use of word embeddings in the field of natural language processing , it became a popular topic due to its ability to cope up with semantic sensitivity .",
        "hence , in this study , we propose a novel way of semi - supervised ontology population through word embeddings as the basis .",
        "we built several models including traditional benchmark models and new types of models which are based on word embeddings .",
        "although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices , they overlooked the reliability of mobile computing models .",
        "in this work , we propose rdeepsense , the first deep learning model that provides well - calibrated uncertainty estimations for resource - constrained mobile and embedded devices .",
        "it exploits a suite of both lexicon - and keyword - based features , as well as semantic features based on word embedding .",
        "to encourage replications , we release a lab package including the classifier , the word embedding space , and the gold standard with annotation guidelines .",
        "we also experiment with combining the representations learned from visual data with embeddings learned from textual data .",
        "although yolov2 can achieve real - time performance on a powerful gpu , it still remains very challenging for leveraging this approach for real - time object detection in video on embedded computing devices with limited computational power and limited memory .",
        "in this paper , we propose a new framework called fast yolo , a fast you only look once framework which accelerates yolov2 to be able to perform object detection in video on embedded devices in a real - time manner .",
        "we present a novel and scalable label embedding framework for large - scale multi - label learning a .",
        "our approach draws inspiration from ideas rooted in distributional semantics , specifically the skip gram negative sampling ( sgns ) approach , widely used to learn word embeddings for natural language processing tasks .",
        "learning such embeddings can be reduced to a certain matrix factorization .",
        "our approach is novel in that it highlights interesting connections between label embedding methods used for multi - label learning and paragraph / document embedding methods commonly used for learning representations of text data ."
    ],
    "adversarial net": [
        "we formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron , as in the recently proposed generative adversarial networks ( goodfellow et al .",
        "training a generative adversarial network , however , requires careful optimization of a difficult minimax program .",
        "our method , named \" adversarial autoencoder \" , uses the recently proposed generative adversarial networks ( gan ) in order to match the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior .",
        "we introduce a class of cnns called deep convolutional generative adversarial networks ( dcgans ) , that have certain architectural constraints , and demonstrate that they are a strong candidate for unsupervised learning .",
        "by combining a variational autoencoder ( vae ) with a generative adversarial network ( gan ) we can use learned feature representations in the gan discriminator as basis for the vae reconstruction objective .",
        "we also propose a way to quantitatively compare adversarial networks by having the generators and discriminators of these networks compete against each other .",
        "we also explore itl - regularized autoencoders as an alternative to variational autoencoding bayes , adversarial autoencoders and generative adversarial networks for randomly generating sample data without explicitly defining a partition function .",
        "to generate realistic target images , we employ the real / fake - discriminator in generative adversarial nets , but also introduce a novel domain - discriminator to make the generated image relevant to the input image .",
        "we show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks , from which we derive a model - free imitation learning algorithm that obtains significant performance gains over existing model - free methods in imitating complex behaviors in large , high - dimensional environments .",
        "we present a variety of new architectural features and training procedures that we apply to the generative adversarial networks ( gans ) framework .",
        "this paper describes infogan , an information - theoretic extension to the generative adversarial network that is able to learn disentangled representations in a completely unsupervised manner .",
        "infogan is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation .",
        "we propose a generative adversarial network for video with a spatio - temporal convolutional architecture that untangles the scene ' s foreground from the background .",
        "as a new way of training generative models , generative adversarial nets ( gan ) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real - valued data .",
        "for this , we develop a novel contextual generative adversarial network based on recurrent neural networks ( context - rnn - gans ) , where both the generator and the discriminator modules are based on contextual history ( modeled as rnns ) and the adversarial discriminator guides the generator to produce realistic images for the particular time step in the image sequence .",
        "we propose a novel framework , namely 3d generative adversarial network ( 3d - gan ) , which generates 3d objects from a probabilistic space by leveraging recent advances in volumetric convolutional networks and generative adversarial nets .",
        "generative adversarial networks ( gans ) are a framework for producing a generative model by way of a two - player minimax game .",
        "in this paper , we propose the \\ emph { generative multi - adversarial network } ( gman ) , a framework that extends gans to multiple discriminators .",
        "vgan is inspired by the generative adversarial networks ( gans ) , where $ p ( \\ mathbf { x } ) $ corresponds to the discriminator and $ q ( \\ mathbf { x } ) $ corresponds to the generator , but with several notable differences .",
        "generative adversarial networks ( gans ) are a recently proposed class of generative models in which a generator is trained to optimize a cost function that is being simultaneously learned by a discriminator .",
        "examples include variational autoencoders , generative adversarial networks , and generative moment matching networks .",
        "generative adversarial networks ( gans ) learn to synthesise new samples from a high - dimensional distribution by passing samples drawn from a latent space through a generative network .",
        "generative adversarial networks ( gans ) have recently demonstrated to successfully approximate complex data distributions .",
        "in this paper we propose a generative model , the temporal generative adversarial network ( tgan ) , which can learn a semantic representation of unlabelled videos , and is capable of generating consistent videos .",
        "we propose a higher - level associative memory for learning adversarial networks .",
        "generative adversarial network ( gan ) framework has a discriminator and a generator network .",
        "the proposed associative adversarial networks ( aans ) are generative models in the higher - levels of the learning , and use adversarial non - stochastic models d and g for learning the mapping between data and higher - level representation spaces .",
        "this paper deals with this very problem where an intelligent system tries to learn the handwriting of an entity using generative adversarial networks ( gans ) .",
        "generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks .",
        "although generative adversarial networks achieve state - of - the - art results on a variety of generative tasks , they are regarded as highly unstable and prone to miss modes .",
        "we define this requirement as the \" image - to - image translation \" problem , and propose a general approach to achieve it , based on deep convolutional and conditional generative adversarial networks ( gans ) , which has gained a phenomenal success to learn mapping images from noise input since 2014 .",
        "we achieve this by introducing an auxiliary discriminative network that allows to rephrase the maximum - likelihood - problem as a two - player game , hence establishing a principled connection between vaes and generative adversarial networks ( gans ) .",
        "in this paper , we propose to equip generative adversarial networks with the ability to produce direct energy estimates for samples .",
        "this paper proposes a generative adversarial network ( gan ) based algorithm named malgan to generate adversarial malware examples , which are able to bypass black - box machine learning based detection models .",
        "specifically , we leverage conditional generative adversarial networks to model the distribution of real - world item colors , in which we develop a fully convolutional generator with multi - layer noise to enhance diversity , with multi - layer condition concatenation to maintain reality , and with stride 1 to keep spatial information .",
        "we propose a general formulation of style transfer as an extension of generative adversarial networks , by using a discriminator to regularize a generator with an otherwise separate loss function .",
        "these models are trained using ideas like variational autoencoders and generative adversarial networks .",
        "despite the successes in capturing continuous distributions , the application of generative adversarial networks ( gans ) to discrete settings , like natural language tasks , is rather restricted .",
        "to address these problems , we propose maximum - likelihood augmented discrete generative adversarial networks .",
        "we introduce new families of integral probability metrics ( ipm ) for training generative adversarial networks ( gan ) .",
        "this paper makes progress on several open theoretical issues related to generative adversarial networks .",
        "to address the issue , we propose the unsupervised image - to - image translation ( unit ) framework , which is based on variational autoencoders and generative adversarial networks .",
        "unlike previous generative adversarial networks ( gans ) , the proposed gan learns to generate image background and foregrounds separately and recursively , and stitch the foregrounds on the background in a contextually relevant manner to produce a complete natural image .",
        "generative adversarial nets ( gans ) are good at generating realistic images and have been extended for semi - supervised classification .",
        "we present triple generative adversarial net ( triple - gan ) , a flexible game - theoretical framework for classification and class - conditional generation in semi - supervised learning .",
        "we demonstrate our results using generative models from published variational autoencoder and generative adversarial networks .",
        "this paper proposes a new route for applying the generative adversarial nets ( gans ) to nlp tasks ( taking the neural machine translation as an instance ) and the widespread perspective that gans can ' t work well in the nlp area turns out to be unreasonable .",
        "in this work , we build a conditional sequence generative adversarial net which comprises of two adversarial sub models , a generative model ( generator ) which translates the source sentence into the target sentence as the traditional nmt models do and a discriminative model ( discriminator ) which discriminates the machine - translated target sentence from the human - translated sentence .",
        "we propose anogan , a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability , accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space .",
        "inspired by generative adversarial networks , we generate a massive amount of synthetic data and train a discriminative classifier to select a realistic subset , which we deem synthetic imposters .",
        "in this paper , we propose a new approach , medical generative adversarial network ( medgan ) , to generate realistic synthetic ehrs .",
        ", binary and count features ) via a combination of an autoencoder and generative adversarial networks .",
        "we ' ve even seen image generation from multi - category datasets such as the microsoft common objects in context ( mscoco ) through the use of generative adversarial networks ( gans ) .",
        "the proposed recurrent topic - transition generative adversarial network ( rtt - gan ) builds an adversarial framework between a structured paragraph generator and multi - level paragraph discriminators .",
        "in this work , we propose the use of generative adversarial networks for speech enhancement .",
        "generative adversarial net has shown its great ability in generating samples .",
        "in this paper , we present midinet , a deep convolutional neural network ( cnn ) based generative adversarial network ( gan ) that is intended to provide a general , highly adaptive network structure for symbolic - domain music generation .",
        "in this paper , we propose a non - parallel vc framework with a wasserstein generative adversarial network ( w - gan ) that explicitly takes a vc - related objective into account .",
        "traditional generative adversarial networks ( gan ) and many of its variants are trained by minimizing the kl or js - divergence loss that measures how close the generated data distribution is from the true data distribution .",
        "softmax gan is a novel variant of generative adversarial network ( gan ) .",
        "generative adversarial networks have emerged as an effective technique for estimating data distributions .",
        "these difficulties come from the fact that optimal weights for adversarial nets correspond to saddle points , and not minimizers , of the loss function .",
        "we propose a simple modification of stochastic gradient descent that stabilizes adversarial networks .",
        "this makes adversarial networks less likely to \" collapse \" , and enables faster training with larger learning rates .",
        "both methods start with training a generative adversarial network ( gan ) on a set of real fingerprint images .",
        "in order to quantitatively measure privacy leakage , we train a generative adversarial network ( gan ) , which combines a discriminative model and a generative model , to detect overfitting by relying on the discriminator capacity to learn statistical differences in distributions .",
        "training generative adversarial networks is unstable in high - dimensions when the true data distribution lies on a lower - dimensional manifold .",
        "we propose an enhanced generative adversarial network ( egan ) to initialize an rl agent in order to achieve faster learning .",
        "generative moment matching network ( gmmn ) is a deep generative model that differs from generative adversarial network ( gan ) by replacing the discriminator in gan with a two - sample test based on kernel maximum mean discrepancy ( mmd ) .",
        "in this paper , we analyze the numerics of common algorithms for training generative adversarial networks ( gans ) .",
        "in this paper , we present randomized multilinear adversarial networks ( rman ) , which exploit multiple feature layers and the classifier layer based on a randomized multilinear adversary to enable both deep and discriminative adversarial adaptation .",
        "generative adversarial networks ( gans ) have great successes on synthesizing data .",
        "in this paper , we propose a novel generative adversarial network , rankgan , for generating high - quality language descriptions .",
        "since its appearance , generative adversarial networks ( gans ) have received a lot of interest in the ai community .",
        "we present an optimized image generation process based on a deep convolutional generative adversarial networks ( dcgans ) , in order to create photorealistic high - resolution images ( up to 1024x1024 pixels ) .",
        "in this paper , we describe the \" pixelgan autoencoder \" , a generative autoencoder in which the generative path is a convolutional autoregressive neural network on pixels ( pixelcnn ) that is conditioned on a latent code , and the recognition path uses a generative adversarial network ( gan ) to impose a prior distribution on the latent code .",
        "generative adversarial networks ( gans ) have shown great promise recently in image generation .",
        "the generative adversarial network ( gan ) has achieved great success in generating realistic ( real - valued ) synthetic data .",
        "generative adversarial networks are an effective approach for learning rich latent representations of continuous data , but have proven difficult to apply directly to discrete structured data , such as text sequences or discretized images .",
        "in this paper , we propose a novel 3d - recgan approach , which reconstructs the complete 3d structure of a given object from a single arbitrary depth view using generative adversarial networks .",
        "the key idea is to combine the generative capabilities of autoencoders and the conditional generative adversarial networks ( gan ) framework , to infer accurate and fine - grained 3d structures of objects in high - dimensional voxel space .",
        "we use conditional adversarial networks to learn the loss function to transfer knowledge from teacher to student .",
        "inspired by the generation power of generative adversarial networks ( gans ) in image domains , we introduce a novel hierarchical architecture for learning characteristic topological features from a single arbitrary input graph via gans .",
        "we formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron , as in the recently proposed generative adversarial networks ( goodfellow et al .",
        "training a generative adversarial network , however , requires careful optimization of a difficult minimax program .",
        "our method , named \" adversarial autoencoder \" , uses the recently proposed generative adversarial networks ( gan ) in order to match the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior .",
        "we introduce a class of cnns called deep convolutional generative adversarial networks ( dcgans ) , that have certain architectural constraints , and demonstrate that they are a strong candidate for unsupervised learning .",
        "by combining a variational autoencoder ( vae ) with a generative adversarial network ( gan ) we can use learned feature representations in the gan discriminator as basis for the vae reconstruction objective .",
        "we also propose a way to quantitatively compare adversarial networks by having the generators and discriminators of these networks compete against each other .",
        "we also explore itl - regularized autoencoders as an alternative to variational autoencoding bayes , adversarial autoencoders and generative adversarial networks for randomly generating sample data without explicitly defining a partition function .",
        "to generate realistic target images , we employ the real / fake - discriminator in generative adversarial nets , but also introduce a novel domain - discriminator to make the generated image relevant to the input image .",
        "we show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks , from which we derive a model - free imitation learning algorithm that obtains significant performance gains over existing model - free methods in imitating complex behaviors in large , high - dimensional environments .",
        "we present a variety of new architectural features and training procedures that we apply to the generative adversarial networks ( gans ) framework .",
        "this paper describes infogan , an information - theoretic extension to the generative adversarial network that is able to learn disentangled representations in a completely unsupervised manner .",
        "infogan is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation .",
        "we propose a generative adversarial network for video with a spatio - temporal convolutional architecture that untangles the scene ' s foreground from the background .",
        "as a new way of training generative models , generative adversarial nets ( gan ) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real - valued data .",
        "for this , we develop a novel contextual generative adversarial network based on recurrent neural networks ( context - rnn - gans ) , where both the generator and the discriminator modules are based on contextual history ( modeled as rnns ) and the adversarial discriminator guides the generator to produce realistic images for the particular time step in the image sequence .",
        "we propose a novel framework , namely 3d generative adversarial network ( 3d - gan ) , which generates 3d objects from a probabilistic space by leveraging recent advances in volumetric convolutional networks and generative adversarial nets .",
        "generative adversarial networks ( gans ) are a framework for producing a generative model by way of a two - player minimax game .",
        "in this paper , we propose the \\ emph { generative multi - adversarial network } ( gman ) , a framework that extends gans to multiple discriminators .",
        "vgan is inspired by the generative adversarial networks ( gans ) , where $ p ( \\ mathbf { x } ) $ corresponds to the discriminator and $ q ( \\ mathbf { x } ) $ corresponds to the generator , but with several notable differences .",
        "generative adversarial networks ( gans ) are a recently proposed class of generative models in which a generator is trained to optimize a cost function that is being simultaneously learned by a discriminator .",
        "examples include variational autoencoders , generative adversarial networks , and generative moment matching networks .",
        "generative adversarial networks ( gans ) learn to synthesise new samples from a high - dimensional distribution by passing samples drawn from a latent space through a generative network .",
        "generative adversarial networks ( gans ) have recently demonstrated to successfully approximate complex data distributions .",
        "in this paper we propose a generative model , the temporal generative adversarial network ( tgan ) , which can learn a semantic representation of unlabelled videos , and is capable of generating consistent videos .",
        "we propose a higher - level associative memory for learning adversarial networks .",
        "generative adversarial network ( gan ) framework has a discriminator and a generator network .",
        "the proposed associative adversarial networks ( aans ) are generative models in the higher - levels of the learning , and use adversarial non - stochastic models d and g for learning the mapping between data and higher - level representation spaces .",
        "this paper deals with this very problem where an intelligent system tries to learn the handwriting of an entity using generative adversarial networks ( gans ) .",
        "generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks .",
        "although generative adversarial networks achieve state - of - the - art results on a variety of generative tasks , they are regarded as highly unstable and prone to miss modes .",
        "we define this requirement as the \" image - to - image translation \" problem , and propose a general approach to achieve it , based on deep convolutional and conditional generative adversarial networks ( gans ) , which has gained a phenomenal success to learn mapping images from noise input since 2014 .",
        "we achieve this by introducing an auxiliary discriminative network that allows to rephrase the maximum - likelihood - problem as a two - player game , hence establishing a principled connection between vaes and generative adversarial networks ( gans ) .",
        "in this paper , we propose to equip generative adversarial networks with the ability to produce direct energy estimates for samples .",
        "this paper proposes a generative adversarial network ( gan ) based algorithm named malgan to generate adversarial malware examples , which are able to bypass black - box machine learning based detection models .",
        "specifically , we leverage conditional generative adversarial networks to model the distribution of real - world item colors , in which we develop a fully convolutional generator with multi - layer noise to enhance diversity , with multi - layer condition concatenation to maintain reality , and with stride 1 to keep spatial information .",
        "we propose a general formulation of style transfer as an extension of generative adversarial networks , by using a discriminator to regularize a generator with an otherwise separate loss function .",
        "these models are trained using ideas like variational autoencoders and generative adversarial networks .",
        "despite the successes in capturing continuous distributions , the application of generative adversarial networks ( gans ) to discrete settings , like natural language tasks , is rather restricted .",
        "to address these problems , we propose maximum - likelihood augmented discrete generative adversarial networks .",
        "we introduce new families of integral probability metrics ( ipm ) for training generative adversarial networks ( gan ) .",
        "this paper makes progress on several open theoretical issues related to generative adversarial networks .",
        "to address the issue , we propose the unsupervised image - to - image translation ( unit ) framework , which is based on variational autoencoders and generative adversarial networks .",
        "unlike previous generative adversarial networks ( gans ) , the proposed gan learns to generate image background and foregrounds separately and recursively , and stitch the foregrounds on the background in a contextually relevant manner to produce a complete natural image .",
        "generative adversarial nets ( gans ) are good at generating realistic images and have been extended for semi - supervised classification .",
        "we present triple generative adversarial net ( triple - gan ) , a flexible game - theoretical framework for classification and class - conditional generation in semi - supervised learning .",
        "we demonstrate our results using generative models from published variational autoencoder and generative adversarial networks .",
        "this paper proposes a new route for applying the generative adversarial nets ( gans ) to nlp tasks ( taking the neural machine translation as an instance ) and the widespread perspective that gans can ' t work well in the nlp area turns out to be unreasonable .",
        "in this work , we build a conditional sequence generative adversarial net which comprises of two adversarial sub models , a generative model ( generator ) which translates the source sentence into the target sentence as the traditional nmt models do and a discriminative model ( discriminator ) which discriminates the machine - translated target sentence from the human - translated sentence .",
        "we propose anogan , a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability , accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space .",
        "inspired by generative adversarial networks , we generate a massive amount of synthetic data and train a discriminative classifier to select a realistic subset , which we deem synthetic imposters .",
        "in this paper , we propose a new approach , medical generative adversarial network ( medgan ) , to generate realistic synthetic ehrs .",
        ", binary and count features ) via a combination of an autoencoder and generative adversarial networks .",
        "we ' ve even seen image generation from multi - category datasets such as the microsoft common objects in context ( mscoco ) through the use of generative adversarial networks ( gans ) .",
        "the proposed recurrent topic - transition generative adversarial network ( rtt - gan ) builds an adversarial framework between a structured paragraph generator and multi - level paragraph discriminators .",
        "in this work , we propose the use of generative adversarial networks for speech enhancement .",
        "generative adversarial net has shown its great ability in generating samples .",
        "in this paper , we present midinet , a deep convolutional neural network ( cnn ) based generative adversarial network ( gan ) that is intended to provide a general , highly adaptive network structure for symbolic - domain music generation .",
        "in this paper , we propose a non - parallel vc framework with a wasserstein generative adversarial network ( w - gan ) that explicitly takes a vc - related objective into account .",
        "traditional generative adversarial networks ( gan ) and many of its variants are trained by minimizing the kl or js - divergence loss that measures how close the generated data distribution is from the true data distribution .",
        "softmax gan is a novel variant of generative adversarial network ( gan ) .",
        "generative adversarial networks have emerged as an effective technique for estimating data distributions .",
        "these difficulties come from the fact that optimal weights for adversarial nets correspond to saddle points , and not minimizers , of the loss function .",
        "we propose a simple modification of stochastic gradient descent that stabilizes adversarial networks .",
        "this makes adversarial networks less likely to \" collapse \" , and enables faster training with larger learning rates .",
        "both methods start with training a generative adversarial network ( gan ) on a set of real fingerprint images .",
        "in order to quantitatively measure privacy leakage , we train a generative adversarial network ( gan ) , which combines a discriminative model and a generative model , to detect overfitting by relying on the discriminator capacity to learn statistical differences in distributions .",
        "training generative adversarial networks is unstable in high - dimensions when the true data distribution lies on a lower - dimensional manifold .",
        "we propose an enhanced generative adversarial network ( egan ) to initialize an rl agent in order to achieve faster learning .",
        "generative moment matching network ( gmmn ) is a deep generative model that differs from generative adversarial network ( gan ) by replacing the discriminator in gan with a two - sample test based on kernel maximum mean discrepancy ( mmd ) .",
        "in this paper , we analyze the numerics of common algorithms for training generative adversarial networks ( gans ) .",
        "in this paper , we present randomized multilinear adversarial networks ( rman ) , which exploit multiple feature layers and the classifier layer based on a randomized multilinear adversary to enable both deep and discriminative adversarial adaptation .",
        "generative adversarial networks ( gans ) have great successes on synthesizing data .",
        "in this paper , we propose a novel generative adversarial network , rankgan , for generating high - quality language descriptions .",
        "since its appearance , generative adversarial networks ( gans ) have received a lot of interest in the ai community .",
        "we present an optimized image generation process based on a deep convolutional generative adversarial networks ( dcgans ) , in order to create photorealistic high - resolution images ( up to 1024x1024 pixels ) .",
        "in this paper , we describe the \" pixelgan autoencoder \" , a generative autoencoder in which the generative path is a convolutional autoregressive neural network on pixels ( pixelcnn ) that is conditioned on a latent code , and the recognition path uses a generative adversarial network ( gan ) to impose a prior distribution on the latent code .",
        "generative adversarial networks ( gans ) have shown great promise recently in image generation .",
        "the generative adversarial network ( gan ) has achieved great success in generating realistic ( real - valued ) synthetic data .",
        "generative adversarial networks are an effective approach for learning rich latent representations of continuous data , but have proven difficult to apply directly to discrete structured data , such as text sequences or discretized images .",
        "in this paper , we propose a novel 3d - recgan approach , which reconstructs the complete 3d structure of a given object from a single arbitrary depth view using generative adversarial networks .",
        "the key idea is to combine the generative capabilities of autoencoders and the conditional generative adversarial networks ( gan ) framework , to infer accurate and fine - grained 3d structures of objects in high - dimensional voxel space .",
        "we use conditional adversarial networks to learn the loss function to transfer knowledge from teacher to student .",
        "inspired by the generation power of generative adversarial networks ( gans ) in image domains , we introduce a novel hierarchical architecture for learning characteristic topological features from a single arbitrary input graph via gans ."
    ]
}